arxiv-1704-04760 | In-Datacenter Performance Analysis of a Tensor Processing Unit | http://arxiv.org/abs/1704.04760 | id:1704.04760 author:Norman P. Jouppi, Cliff Young, Nishant Patil, David Patterson, Gaurav Agrawal, Raminder Bajwa, Sarah Bates, Suresh Bhatia, Nan Boden, Al Borchers, Rick Boyle, Pierre-luc Cantin, Clifford Chao, Chris Clark, Jeremy Coriell, Mike Daley, Matt Dau, Jeffrey Dean, Ben Gelb, Tara Vazir Ghaemmaghami, Rajendra Gottipati, William Gulland, Robert Hagmann, C. Richard Ho, Doug Hogberg, John Hu, Robert Hundt, Dan Hurt, Julian Ibarz, Aaron Jaffey, Alek Jaworski, Alexander Kaplan, Harshit Khaitan, Andy Koch, Naveen Kumar, Steve Lacy, James Laudon, James Law, Diemthu Le, Chris Leary, Zhuyuan Liu, Kyle Lucke, Alan Lundin, Gordon MacKean, Adriana Maggiore, Maire Mahony, Kieran Miller, Rahul Nagarajan, Ravi Narayanaswami, Ray Ni, Kathy Nix, Thomas Norrie, Mark Omernick, Narayana Penukonda, Andy Phelps, Jonathan Ross, Matt Ross, Amir Salek, Emad Samadiani, Chris Severn, Gregory Sizikov, Matthew Snelham, Jed Souter, Dan Steinberg, Andy Swing, Mercedes Tan, Gregory Thorson, Bo Tian, Horia Toma, Erick Tuttle, Vijay Vasudevan, Richard Walter, Walter Wang, Eric Wilcox, Doe Hyun Yoon category:cs.AR cs.LG cs.NE  published:2017-04-16 summary:Many architects believe that major improvements in cost-energy-performance must now come from domain-specific hardware. This paper evaluates a custom ASIC---called a Tensor Processing Unit (TPU)---deployed in datacenters since 2015 that accelerates the inference phase of neural networks (NN). The heart of the TPU is a 65,536 8-bit MAC matrix multiply unit that offers a peak throughput of 92 TeraOps/second (TOPS) and a large (28 MiB) software-managed on-chip memory. The TPU's deterministic execution model is a better match to the 99th-percentile response-time requirement of our NN applications than are the time-varying optimizations of CPUs and GPUs (caches, out-of-order execution, multithreading, multiprocessing, prefetching, ...) that help average throughput more than guaranteed latency. The lack of such features helps explain why, despite having myriad MACs and a big memory, the TPU is relatively small and low power. We compare the TPU to a server-class Intel Haswell CPU and an Nvidia K80 GPU, which are contemporaries deployed in the same datacenters. Our workload, written in the high-level TensorFlow framework, uses production NN applications (MLPs, CNNs, and LSTMs) that represent 95% of our datacenters' NN inference demand. Despite low utilization for some applications, the TPU is on average about 15X - 30X faster than its contemporary GPU or CPU, with TOPS/Watt about 30X - 80X higher. Moreover, using the GPU's GDDR5 memory in the TPU would triple achieved TOPS and raise TOPS/Watt to nearly 70X the GPU and 200X the CPU. version:1
arxiv-1704-04749 | AnchorNet: A Weakly Supervised Network to Learn Geometry-sensitive Features For Semantic Matching | http://arxiv.org/abs/1704.04749 | id:1704.04749 author:David Novotny, Diane Larlus, Andrea Vedaldi category:cs.CV  published:2017-04-16 summary:Despite significant progress of deep learning in recent years, state-of-the-art semantic matching methods still rely on legacy features such as SIFT or HoG. We argue that the strong invariance properties that are key to the success of recent deep architectures on the classification task make them unfit for dense correspondence tasks, unless a large amount of supervision is used. In this work, we propose a deep network, termed AnchorNet, that produces image representations that are well-suited for semantic matching. It relies on a set of filters whose response is geometrically consistent across different object instances, even in the presence of strong intra-class, scale, or viewpoint variations. Trained only with weak image-level labels, the final representation successfully captures information about the object structure and improves results of state-of-the-art semantic matching methods such as the deformable spatial pyramid or the proposal flow methods. We show positive results on the cross-instance matching task where different instances of the same object category are matched as well as on a new cross-category semantic matching task aligning pairs of instances each from a different object class. version:1
arxiv-1704-05051 | Google's Cloud Vision API Is Not Robust To Noise | http://arxiv.org/abs/1704.05051 | id:1704.05051 author:Hossein Hosseini, Baicen Xiao, Radha Poovendran category:cs.CV cs.LG  published:2017-04-16 summary:Google has recently introduced the Cloud Vision API for image analysis. According to the demonstration website, the API "quickly classifies images into thousands of categories, detects individual objects and faces within images, and finds and reads printed words contained within images." It can be also used to "detect different types of inappropriate content from adult to violent content." In this paper, we evaluate the robustness of the Google's Cloud Vision API to input perturbation. In particular, we show that by adding sufficient noise to the image, the API generates completely different outputs for the noisy image, while a human observer would perceive its original content. We show that the attack is consistently successful, by performing extensive experiments on different image types, including natural images, images containing faces and images with texts. Our findings indicate the vulnerability of the API in adversarial environments. For example, an adversary can bypass an image filtering system by adding noise to an image with inappropriate content. version:1
arxiv-1704-04718 | Deep Learning Based Regression and Multi-class Models for Acute Oral Toxicity Prediction | http://arxiv.org/abs/1704.04718 | id:1704.04718 author:Youjun Xu, Jianfeng Pei, Luhua Lai category:stat.ML cs.LG q-bio.QM  published:2017-04-16 summary:Median lethal death, LD50, is a general indicator of compound acute oral toxicity (AOT). Various in silico methods were developed for AOT prediction to reduce costs and time. In this study, a deep learning architecture composed of multi-layer convolution neural network was used to develop three types of high-level predictive models: regression model (deepAOT-R), multi-classification (deepAOT-C) model and multitask model (deepAOT-CR) for AOT evaluation. These models highly outperformed previously reported models. For the two external datasets containing 1673 (test set I) and 375 (test set II) compounds, the R2 and mean absolute error (MAE) of deepAOTR on the test set I were 0.864 and 0.195, and the prediction accuracy of deepAOT-C was 95.5% and 96.3% on the test set I and II, respectively. The two external prediction accuracy of deepAOT-CR is 95.0% and 94.1%, while the R2 and MAE are 0.861 and 0.204 for test set I, respectively. We then performed forward and backward exploration of deepAOT models for deep fingerprints, which could support shallow machine learning methods more efficiently than traditional fingerprints or descriptors. We further performed automatic feature learning, a key essence of deep learning, to map the corresponding activation values into fragment space and derive AOT-related chemical substructures by reverse mining of the features. Our deep learning framework for AOT is generally applicable in predicting and exploring other toxicity or property endpoints of chemical compounds. The two deepAOT models are freely available at http://repharma.pku.edu.cn/DLAOT/DLAOThome.php version:1
arxiv-1704-04706 | Trigger for the SoLid Reactor Antineutrino Experiment | http://arxiv.org/abs/1704.04706 | id:1704.04706 author:Lukas On Arnold, for the SoLid collaboration category:physics.ins-det cs.CV hep-ex  published:2017-04-16 summary:SoLid, located at SCK-CEN in Mol, Belgium, is a reactor antineutrino experiment at a very short baseline of 5.5 -- 10m aiming at the search for sterile neutrinos and for high precision measurement of the neutrino energy spectrum of Uranium-235. It uses a novel approach using Lithium-6 sheets and PVT cubes as scintillators for tagging the Inverse Beta-Decay products (neutron and positron). Being located overground and close to the BR2 research reactor, the experiment faces a large amount of backgrounds. Efficient real-time background and noise rejection is essential in order to increase the signal-background ratio for precise oscillation measurement and decrease data production to a rate which can be handled by the online software. Therefore, a reliable distinction between the neutrons and background signals is crucial. This can be performed online with a dedicated firmware trigger. A peak counting algorithm and an algorithm measuring time over threshold have been identified as performing well both in terms of efficiency and fake rate, and have been implemented onto FPGA. version:1
arxiv-1704-03477 | A Neural Representation of Sketch Drawings | http://arxiv.org/abs/1704.03477 | id:1704.03477 author:David Ha, Douglas Eck category:cs.NE cs.LG stat.ML  published:2017-04-11 summary:We present sketch-rnn, a recurrent neural network (RNN) able to construct stroke-based drawings of common objects. The model is trained on thousands of crude human-drawn images representing hundreds of classes. We outline a framework for conditional and unconditional sketch generation, and describe new robust training methods for generating coherent sketch drawings in a vector format. version:2
arxiv-1704-04689 | Video Fill In the Blank using LR/RL LSTMs with Spatial-Temporal Attentions | http://arxiv.org/abs/1704.04689 | id:1704.04689 author:Amir Mazaheri, Dong Zhang, Mubarak Shah category:cs.CV  published:2017-04-15 summary:Given a video and a description sentence with one missing word (we call it the "source sentence"), Video-Fill-In-the-Blank (VFIB) problem is to find the missing word automatically. The contextual information of the sentence, as well as visual cues from the video, are important to infer the missing word accurately. Since the source sentence is broken into two fragments: the sentence's left fragment (before the blank) and the sentence's right fragment (after the blank), traditional Recurrent Neural Networks cannot encode this structure accurately because of many possible variations of the missing word in terms of the location and type of the word in the source sentence. For example, a missing word can be the first word or be in the middle of the sentence and it can be a verb or an adjective. In this paper, we propose a framework to tackle the textual encoding: Two separate LSTMs (the LR and RL LSTMs) are employed to encode the left and right sentence fragments and a novel structure is introduced to combine each fragment with an "external memory" corresponding the opposite fragments. For the visual encoding, end-to-end spatial and temporal attention models are employed to select discriminative visual representations to find the missing word. In the experiments, we demonstrate the superior performance of the proposed method on challenging VFIB problem. Furthermore, we introduce an extended and more generalized version of VFIB, which is not limited to a single blank. Our experiments indicate the generalization capability of our method in dealing with such more realistic scenarios. version:1
arxiv-1704-04688 | Machine Learning and the Future of Realism | http://arxiv.org/abs/1704.04688 | id:1704.04688 author:Giles Hooker, Cliff Hooker category:stat.ML cs.LG  published:2017-04-15 summary:The preceding three decades have seen the emergence, rise, and proliferation of machine learning (ML). From half-recognised beginnings in perceptrons, neural nets, and decision trees, algorithms that extract correlations (that is, patterns) from a set of data points have broken free from their origin in computational cognition to embrace all forms of problem solving, from voice recognition to medical diagnosis to automated scientific research and driverless cars, and it is now widely opined that the real industrial revolution lies less in mobile phone and similar than in the maturation and universal application of ML. Among the consequences just might be the triumph of anti-realism over realism. version:1
arxiv-1704-04683 | RACE: Large-scale ReAding Comprehension Dataset From Examinations | http://arxiv.org/abs/1704.04683 | id:1704.04683 author:Guokun Lai, Qizhe Xie, Hanxiao Liu, Yiming Yang, Eduard Hovy category:cs.CL cs.AI cs.LG  published:2017-04-15 summary:We present RACE, a new dataset for benchmark evaluation of methods in the reading comprehension task. Collected from the English exams for middle and high school Chinese students in the age range between 12 to 18, RACE consists of 28,000+ passages and near 100,000 questions generated by human experts (English instructors), and covers a variety of topics which are carefully designed for evaluating the students' ability in understanding and reasoning. In particular, the proportion of questions that requires reasoning is much larger in RACE than that in other benchmark datasets for reading comprehension, and there is a significant gap between the performance of the state-of-the-art models (43%) and the ceiling human performance (95%). We hope this new dataset can serve as a valuable resource for research and evaluation in machine comprehension. The dataset is freely available at http://www.cs.cmu.edu/~glai1/data/race/. version:1
arxiv-1704-04671 | Temporal Action Localization by Structured Maximal Sums | http://arxiv.org/abs/1704.04671 | id:1704.04671 author:Zehuan Yuan, Jonathan C. Stroud, Tong Lu, Jia Deng category:cs.CV  published:2017-04-15 summary:We address the problem of temporal action localization in videos. We pose action localization as a structured prediction over arbitrary-length temporal windows, where each window is scored as the sum of frame-wise classification scores. Additionally, our model classifies the start, middle, and end of each action as separate components, allowing our system to explicitly model each action's temporal evolution and take advantage of informative temporal dependencies present in this structure. In this framework, we localize actions by searching for the structured maximal sum, a problem for which we develop a novel, provably-efficient algorithmic solution. The frame-wise classification scores are computed using features from a deep Convolutional Neural Network (CNN), which are trained end-to-end to directly optimize for a novel structured objective. We evaluate our system on the THUMOS 14 action detection benchmark and achieve competitive performance. version:1
arxiv-1704-04664 | Online Spatial Concept and Lexical Acquisition with Simultaneous Localization and Mapping | http://arxiv.org/abs/1704.04664 | id:1704.04664 author:Akira Taniguchi, Yoshinobu Hagiwara, Tadahiro Taniguchi, Tetsunari Inamura category:cs.AI cs.CL cs.RO  published:2017-04-15 summary:In this paper, we propose an online learning algorithm based on a Rao-Blackwellized particle filter for spatial concept acquisition and mapping. We have proposed a nonparametric Bayesian spatial concept acquisition model (SpCoA). We propose a novel method (SpCoSLAM) integrating SpCoA and FastSLAM in the theoretical framework of the Bayesian generative model. The proposed method can simultaneously learn place categories and lexicons while incrementally generating an environmental map. Furthermore, the proposed method has scene image features and a language model added to SpCoA. In the experiments, we tested online learning of spatial concepts and environmental maps in a novel environment of which the robot did not have a map. Then, we evaluated the results of online learning of spatial concepts and lexical acquisition. The experimental results demonstrated that the robot was able to more accurately learn the relationships between words and the place in the environmental map incrementally by using the proposed method. version:1
arxiv-1704-05367 | On Improving the Capacity of Solving Large-scale Wireless Network Design Problems by Genetic Algorithms | http://arxiv.org/abs/1704.05367 | id:1704.05367 author:Fabio D'Andreagiovanni category:math.OC cs.NE  published:2017-04-15 summary:Over the last decade, wireless networks have experienced an impressive growth and now play a main role in many telecommunications systems. As a consequence, scarce radio resources, such as frequencies, became congested and the need for effective and efficient assignment methods arose. In this work, we present a Genetic Algorithm for solving large instances of the Power, Frequency and Modulation Assignment Problem, arising in the design of wireless networks. To our best knowledge, this is the first Genetic Algorithm that is proposed for such problem. Compared to previous works, our approach allows a wider exploration of the set of power solutions, while eliminating sources of numerical problems. The performance of the algorithm is assessed by tests over a set of large realistic instances of a Fixed WiMAX Network. version:1
arxiv-1704-04650 | Big Universe, Big Data: Machine Learning and Image Analysis for Astronomy | http://arxiv.org/abs/1704.04650 | id:1704.04650 author:Jan Kremer, Kristoffer Stensbo-Smidt, Fabian Gieseke, Kim Steenstrup Pedersen, Christian Igel category:astro-ph.IM cs.CV stat.ML  published:2017-04-15 summary:Astrophysics and cosmology are rich with data. The advent of wide-area digital cameras on large aperture telescopes has led to ever more ambitious surveys of the sky. Data volumes of entire surveys a decade ago can now be acquired in a single night and real-time analysis is often desired. Thus, modern astronomy requires big data know-how, in particular it demands highly efficient machine learning and image analysis algorithms. But scalability is not the only challenge: Astronomy applications touch several current machine learning research questions, such as learning from biased data and dealing with label and measurement noise. We argue that this makes astronomy a great domain for computer science research, as it pushes the boundaries of data analysis. In the following, we will present this exciting application area for data scientists. We will focus on exemplary results, discuss main challenges, and highlight some recent methodological advancements in machine learning and image analysis triggered by astronomical applications. version:1
arxiv-1704-04640 | A fast ILP-based Heuristic for the robust design of Body Wireless Sensor Networks | http://arxiv.org/abs/1704.04640 | id:1704.04640 author:Fabio D'Andreagiovanni, Antonella Nardin, Enrico Natalizio category:math.OC cs.NE cs.NI  published:2017-04-15 summary:We consider the problem of optimally designing a body wireless sensor network, while taking into account the uncertainty of data generation of biosensors. Since the related min-max robustness Integer Linear Programming (ILP) problem can be difficult to solve even for state-of-the-art commercial optimization solvers, we propose an original heuristic for its solution. The heuristic combines deterministic and probabilistic variable fixing strategies, guided by the information coming from strengthened linear relaxations of the ILP robust model, and includes a very large neighborhood search for reparation and improvement of generated solutions, formulated as an ILP problem solved exactly. Computational tests on realistic instances show that our heuristic finds solutions of much higher quality than a state-of-the-art solver and than an effective benchmark heuristic. version:1
arxiv-1704-04629 | Metropolis Sampling | http://arxiv.org/abs/1704.04629 | id:1704.04629 author:Luca Martino, Victor Elvira category:stat.ME stat.CO stat.ML  published:2017-04-15 summary:Monte Carlo (MC) sampling methods are widely applied in Bayesian inference, system simulation and optimization problems. The Markov Chain Monte Carlo (MCMC) algorithms are a well-known class of MC methods which generate a Markov chain with the desired invariant distribution. In this document, we focus on the Metropolis-Hastings (MH) sampler, which can be considered as the atom of the MCMC techniques, introducing the basic notions and different properties. We describe in details all the elements involved in the MH algorithm and the most relevant variants. Several improvements and recent extensions proposed in the literature are also briefly discussed, providing a quick but exhaustive overview of the current Metropolis-based sampling's world. version:1
arxiv-1704-04613 | Integrating Scene Text and Visual Appearance for Fine-Grained Image Classification with Convolutional Neural Networks | http://arxiv.org/abs/1704.04613 | id:1704.04613 author:Xiang Bai, Mingkun Yang, Pengyuan Lyu, Yongchao Xu category:cs.CV  published:2017-04-15 summary:Text in natural images contains plenty of semantics that are often highly relevant to objects or scene. In this paper, we are concerned with the problem on fully exploiting scene text for visual understanding. The basic idea is combining word representations and deep visual features into a globally trainable deep convolutional neural network. First, the recognized words are obtained by a scene text reading system. Then, we combine the word embedding of the recognized words and the deep visual features into a single representation, which is optimized by a convolutional neural network for fine-grained image classification. In our framework, the attention mechanism is adopted to reveal the relevance between each recognized word and the given image, which reasonably enhances the recognition performance. We have performed experiments on two datasets: Con-Text dataset and Drink Bottle dataset, that are proposed for fine-grained classification of business places and drink bottles respectively. The experimental results consistently demonstrate that the proposed method combining textual and visual cues significantly outperforms classification with only visual representations. Moreover, we have shown that the learned representation improves the retrieval performance on the drink bottle images by a large margin, which is potentially useful in product search. version:1
arxiv-1704-04610 | A learning-based approach for automatic image and video colorization | http://arxiv.org/abs/1704.04610 | id:1704.04610 author:Raj Kumar Gupta, Alex Yong-Sang Chia, Deepu Rajan, Huang Zhiyong category:cs.GR cs.CV  published:2017-04-15 summary:In this paper, we present a color transfer algorithm to colorize a broad range of gray images without any user intervention. The algorithm uses a machine learning-based approach to automatically colorize grayscale images. The algorithm uses the superpixel representation of the reference color images to learn the relationship between different image features and their corresponding color values. We use this learned information to predict the color value of each grayscale image superpixel. As compared to processing individual image pixels, our use of superpixels helps us to achieve a much higher degree of spatial consistency as well as speeds up the colorization process. The predicted color values of the gray-scale image superpixels are used to provide a 'micro-scribble' at the centroid of the superpixels. These color scribbles are refined by using a voting based approach. To generate the final colorization result, we use an optimization-based approach to smoothly spread the color scribble across all pixels within a superpixel. Experimental results on a broad range of images and the comparison with existing state-of-the-art colorization methods demonstrate the greater effectiveness of the proposed algorithm. version:1
arxiv-1704-04601 | MUSE: Modularizing Unsupervised Sense Embeddings | http://arxiv.org/abs/1704.04601 | id:1704.04601 author:Guang-He Lee, Yun-Nung Chen category:cs.CL  published:2017-04-15 summary:This paper proposes to address the word sense ambiguity issue in an unsupervised manner, where word sense representations are learned along a word sense selection mechanism given contexts. Prior work about learning multi-sense embeddings suffered from either ambiguity of different-level embeddings or inefficient sense selection. The proposed modular framework, MUSE, implements flexible modules to optimize distinct mechanisms, achieving the first purely sense-level representation learning system with linear-time sense selection. We leverage reinforcement learning to enable joint training on the proposed modules, and introduce various exploration techniques on sense selection for better robustness. The experiments on benchmark data show that the proposed approach achieves the state-of-the-art performance on synonym selection as well as on contextual word similarities in terms of MaxSimC. version:1
arxiv-1704-03956 | Incremental Skip-gram Model with Negative Sampling | http://arxiv.org/abs/1704.03956 | id:1704.03956 author:Nobuhiro Kaji, Hayato Kobayashi category:cs.CL  published:2017-04-13 summary:This paper explores an incremental training strategy for the skip-gram model with negative sampling (SGNS) from both empirical and theoretical perspectives. Existing methods of neural word embeddings, including SGNS, are multi-pass algorithms and thus cannot perform incremental model update. To address this problem, we present a simple incremental extension of SGNS and provide a thorough theoretical analysis to demonstrate its validity. Empirical experiments demonstrated the correctness of the theoretical analysis as well as the practical usefulness of the incremental algorithm. version:2
arxiv-1704-04587 | Deep Learning for Photoacoustic Tomography from Sparse Data | http://arxiv.org/abs/1704.04587 | id:1704.04587 author:Stephan Antholzer, Markus Haltmeier, Johannes Schwab category:cs.CV cs.LG  published:2017-04-15 summary:The development of fast and accurate image reconstruction algorithms is a central aspect of computed tomography. In this paper we investigate this issue for the sparse data problem of photoacoustic tomography (PAT). We develop direct and highly efficient reconstruction algorithms based on deep-learning. In this approach image reconstruction is performed with a deep convolutional neural network (CNN), whose weights are adjusted prior to the actual image reconstruction based on a set of training data. Our results demonstrate that the proposed deep learning approach reconstructs images with a quality komparable to state of the art iterative approaches from sparse data. At the same time, the numerically complexity of our approach is much smaller and the image reconstruction is performed in a fraction of the time required by iterative methods. version:1
arxiv-1704-03135 | Improving Pairwise Ranking for Multi-label Image Classification | http://arxiv.org/abs/1704.03135 | id:1704.03135 author:Yuncheng Li, Yale Song, Jiebo Luo category:cs.CV  published:2017-04-11 summary:Learning to rank has recently emerged as an attractive technique to train deep convolutional neural networks for various computer vision tasks. Pairwise ranking, in particular, has been successful in multi-label image classification, achieving state-of-the-art results on various benchmarks. However, most existing approaches use the hinge loss to train their models, which is non-smooth and thus is difficult to optimize especially with deep networks. Furthermore, they employ simple heuristics, such as top-k or thresholding, to determine which labels to include in the output from a ranked list of labels, which limits their use in the real-world setting. In this work, we propose two techniques to improve pairwise ranking based multi-label image classification: (1) we propose a novel loss function for pairwise ranking, which is smooth everywhere and thus is easier to optimize; and (2) we incorporate a label decision module into the model, estimating the optimal confidence thresholds for each visual concept. We provide theoretical analyses of our loss function in the Bayes consistency and risk minimization framework, and show its benefit over existing pairwise ranking formulations. We demonstrate the effectiveness of our approach on three large-scale datasets, VOC2007, NUS-WIDE and MS-COCO, achieving the best reported results in the literature. version:2
arxiv-1704-00774 | Restricted Recurrent Neural Tensor Networks: Exploiting Word Frequency and Compositionality for Increased Model Capacity and Performance With No Computational Overhead | http://arxiv.org/abs/1704.00774 | id:1704.00774 author:Alexandre Salle, Aline Villavicencio category:cs.CL  published:2017-04-03 summary:Increasing the capacity of recurrent neural networks (RNN) usually involves augmenting the size of the hidden layer, resulting in a significant increase of computational cost. An alternative is the recurrent neural tensor network (RNTN), which increases capacity by employing distinct hidden layer weights for each vocabulary word. However, memory usage scales linearly with vocabulary size, which can reach millions for word-level language models. In this paper, we introduce restricted recurrent neural tensor networks (r-RNTN) which reserve distinct hidden layer weights for frequent vocabulary words while sharing a single set of weights for infrequent words. Perplexity evaluations show that r-RNTNs improve language model performance over standard RNNs using only a small fraction of the parameters of unrestricted RNTNs. version:2
arxiv-1704-04567 | Asynchronous Parallel Empirical Variance Guided Algorithms for the Thresholding Bandit Problem | http://arxiv.org/abs/1704.04567 | id:1704.04567 author:Jie Zhong, Yijun Huang, Ji Liu category:stat.ML cs.LG  published:2017-04-15 summary:This paper considers the multi-armed thresholding bandit problem -- identifying all arms above a predefined threshold via as few pulls (or rounds) as possible -- proposed by Locatelli et al. [2016] recently. Although the proposed algorithm in Locatelli et al. [2016] achieves the optimal round complexity a certain sense, there still remain unsolved issues. This paper proposes an asynchronous parallel thresholding algorithm and its parameter-free version to improve the efficiency and the applicability. On one hand, the proposed two algorithms use the empirical variance to guide which arm to pull at each round, and improve the round complexity of the "optimal" algorithm when all arms have bounded high order moments. On the other hand, most bandit algorithms assume that the reward can be observed immediately after the pull or the next decision would not be made before all rewards are observed. Our proposed asynchronous parallel algorithms allow making the choice of the next pull with unobserved rewards from earlier pulls, which avoids such an unrealistic assumption and significantly improves the identification process. Our theoretical analysis justifies the effectiveness and the efficiency of proposed asynchronous parallel algorithms. The empirical study is also provided to validate the proposed algorithms. version:1
arxiv-1704-04565 | Neural Paraphrase Identification of Questions with Noisy Pretraining | http://arxiv.org/abs/1704.04565 | id:1704.04565 author:Gaurav Singh Tomar, Thyago Duque, Oscar Täckström, Jakob Uszkoreit, Dipanjan Das category:cs.CL  published:2017-04-15 summary:We present a solution to the problem of paraphrase identification of questions. We focus on a recent dataset of question pairs annotated with binary paraphrase labels and show that a variant of the decomposable attention model (Parikh et al., 2016) results in accurate performance on this task, while being far simpler than many competing neural architectures. Furthermore, when the model is pretrained on a noisy dataset of automatically collected question paraphrases, it obtains the best reported performance on the dataset. version:1
arxiv-1704-04550 | Distributional model on a diet: One-shot word learning from text only | http://arxiv.org/abs/1704.04550 | id:1704.04550 author:Su Wang, Stephen Roller, Katrin Erk category:cs.CL  published:2017-04-14 summary:We test whether distributional models can do one-shot learning of definitional properties from text only. Using Bayesian models, we find that first learning overarching structure in the known data, regularities in textual contexts and in properties, helps one-shot learning, and that individual context items can be highly informative. version:1
arxiv-1704-04548 | On the Gap Between Strict-Saddles and True Convexity: An Omega(log d) Lower Bound for Eigenvector Approximation | http://arxiv.org/abs/1704.04548 | id:1704.04548 author:Max Simchowitz, Ahmed El Alaoui, Benjamin Recht category:cs.LG cs.DS cs.IT math.CO math.IT stat.ML  published:2017-04-14 summary:We prove a \emph{query complexity} lower bound on rank-one principal component analysis (PCA). We consider an oracle model where, given a symmetric matrix $M \in \mathbb{R}^{d \times d}$, an algorithm is allowed to make $T$ \emph{exact} queries of the form $w^{(i)} = Mv^{(i)}$ for $i \in \{1,\dots,T\}$, where $v^{(i)}$ is drawn from a distribution which depends arbitrarily on the past queries and measurements $\{v^{(j)},w^{(j)}\}_{1 \le j \le i-1}$. We show that for a small constant $\epsilon$, any adaptive, randomized algorithm which can find a unit vector $\widehat{v}$ for which $\widehat{v}^{\top}M\widehat{v} \ge (1-\epsilon)\ M\ $, with even small probability, must make $T = \Omega(\log d)$ queries. In addition to settling a widely-held folk conjecture, this bound demonstrates a fundamental gap between convex optimization and "strict-saddle" non-convex optimization of which PCA is a canonical example: in the former, first-order methods can have dimension-free iteration complexity, whereas in PCA, the iteration complexity of gradient-based methods must necessarily grow with the dimension. Our argument proceeds via a reduction to estimating the rank-one spike in a deformed Wigner model. We establish lower bounds for this model by developing a "truncated" analogue of the $\chi^2$ Bayes-risk lower bound of Chen et al. version:1
arxiv-1704-04539 | Cross-lingual Abstract Meaning Representation Parsing | http://arxiv.org/abs/1704.04539 | id:1704.04539 author:Marco Damonte, Shay B. Cohen category:cs.CL  published:2017-04-14 summary:Abstract Meaning Representation (AMR) annotation efforts have mostly focused on English. In order to train parsers on other languages, we propose a method based on annotation projection, which involves exploiting annotations in a source language and a parallel corpus of the source language and a target language. Using English as the source language, we show promising results for Italian, Spanish, German and Chinese as target languages. Besides evaluating the target parsers on non-gold datasets, we further propose an evaluation method that exploits the English gold annotations and does not require access to gold annotations for the target languages. This is achieved by inverting the projection process: a new English parser is learned from the target language parser and evaluated on the existing English gold standard. version:1
arxiv-1704-04530 | Neural Extractive Summarization with Side Information | http://arxiv.org/abs/1704.04530 | id:1704.04530 author:Shashi Narayan, Nikos Papasarantopoulos, Mirella Lapata, Shay B. Cohen category:cs.CL  published:2017-04-14 summary:Most extractive summarization methods focus on the main body of the document from which sentences need to be extracted. The gist of the document often lies in the side information of the document, such as title and image captions. These types of side information are often available for newswire articles. We propose to explore side information in the context of single-document extractive summarization. We develop a framework for single-document summarization composed of a hierarchical document encoder and an attention-based extractor with attention over side information. We evaluate our models on a large scale news dataset. We show that extractive summarization with side information consistently outperforms its counterpart (that does not use any side information), in terms on both informativeness and fluency. version:1
arxiv-1704-04522 | Hierarchic Kernel Recursive Least-Squares | http://arxiv.org/abs/1704.04522 | id:1704.04522 author:Hossein Mohamadipanah, Girish Chowdhary category:cs.LG  published:2017-04-14 summary:We present a new hierarchic kernel based modeling technique for modeling evenly distributed multidimensional datasets that does not rely on input space sparsification. The presented method reorganizes the typical single-layer kernel based model in a hierarchical structure, such that the weights of a kernel model over each dimension are modeled over the adjacent dimension. We show that the imposition of the hierarchical structure in the kernel based model leads to significant computational speedup and improved modeling accuracy (over an order of magnitude in many cases). For instance the presented method is about five times faster and more accurate than Sparsified Kernel Recursive Least- Squares in modeling of a two-dimensional real-world data set. version:1
arxiv-1704-04521 | Translation of Patent Sentences with a Large Vocabulary of Technical Terms Using Neural Machine Translation | http://arxiv.org/abs/1704.04521 | id:1704.04521 author:Zi Long, Takehito Utsuro, Tomoharu Mitsuhashi, Mikio Yamamoto category:cs.CL  published:2017-04-14 summary:Neural machine translation (NMT), a new approach to machine translation, has achieved promising results comparable to those of traditional approaches such as statistical machine translation (SMT). Despite its recent success, NMT cannot handle a larger vocabulary because training complexity and decoding complexity proportionally increase with the number of target words. This problem becomes even more serious when translating patent documents, which contain many technical terms that are observed infrequently. In NMTs, words that are out of vocabulary are represented by a single unknown token. In this paper, we propose a method that enables NMT to translate patent sentences comprising a large vocabulary of technical terms. We train an NMT system on bilingual data wherein technical terms are replaced with technical term tokens; this allows it to translate most of the source sentences except technical terms. Further, we use it as a decoder to translate source sentences with technical term tokens and replace the tokens with technical term translations using SMT. We also use it to rerank the 1,000-best SMT translations on the basis of the average of the SMT score and that of the NMT rescoring of the translated sentences with technical term tokens. Our experiments on Japanese-Chinese patent sentences show that the proposed NMT system achieves a substantial improvement of up to 3.1 BLEU points and 2.3 RIBES points over traditional SMT systems and an improvement of approximately 0.6 BLEU points and 0.8 RIBES points over an equivalent NMT system without our proposed technique. version:1
arxiv-1704-04520 | Neural Machine Translation Model with a Large Vocabulary Selected by Branching Entropy | http://arxiv.org/abs/1704.04520 | id:1704.04520 author:Zi Long, Takehito Utsuro, Tomoharu Mitsuhashi, Mikio Yamamoto category:cs.CL  published:2017-04-14 summary:Neural machine translation (NMT), a new approach to machine translation, has achieved promising results comparable to those of traditional approaches such as statistical machine translation (SMT). Despite its recent success, NMT cannot handle a larger vocabulary because the training complexity and decoding complexity proportionally increase with the number of target words. This problem becomes even more serious when translating patent documents, which contain many technical terms that are observed infrequently. In this paper, we propose to select phrases that contain out-of-vocabulary words using the statistical approach of branching entropy. This allows the proposed NMT system to be applied to a translation task of any language pair without any language-specific knowledge about technical term identification. The selected phrases are then replaced with tokens during training and post-translated by the phrase translation table of SMT. Evaluation on Japanese-to-Chinese and Chinese-to-Japanese patent sentence translation proved the effectiveness of phrases selected with branching entropy, where the proposed NMT system achieves a substantial improvement over a baseline NMT system without our proposed technique. version:1
arxiv-1704-04517 | ShapeWorld - A new test methodology for multimodal language understanding | http://arxiv.org/abs/1704.04517 | id:1704.04517 author:Alexander Kuhnle, Ann Copestake category:cs.CL cs.AI cs.CV  published:2017-04-14 summary:We introduce a novel framework for evaluating multimodal deep learning models with respect to their language understanding and generalization abilities. In this approach, artificial data is automatically generated according to the experimenter's specifications. The content of the data, both during training and evaluation, can be controlled in detail, which enables tasks to be created that require true generalization abilities, in particular the combination of previously introduced concepts in novel ways. We demonstrate the potential of our methodology by evaluating various visual question answering models on four different tasks, and show how our framework gives us detailed insights into their capabilities and limitations. By open-sourcing our framework, we hope to stimulate progress in the field of multimodal language understanding. version:1
arxiv-1704-04516 | Interpretable 3D Human Action Analysis with Temporal Convolutional Networks | http://arxiv.org/abs/1704.04516 | id:1704.04516 author:Tae Soo Kim, Austin Reiter category:cs.CV I.2.10; I.5.4  published:2017-04-14 summary:The discriminative power of modern deep learning models for 3D human action recognition is growing ever so potent. In conjunction with the recent resurgence of 3D human action representation with 3D skeletons, the quality and the pace of recent progress have been significant. However, the inner workings of state-of-the-art learning based methods in 3D human action recognition still remain mostly black-box. In this work, we propose to use a new class of models known as Temporal Convolutional Neural Networks (TCN) for 3D human action recognition. Compared to popular LSTM-based Recurrent Neural Network models, given interpretable input such as 3D skeletons, TCN provides us a way to explicitly learn readily interpretable spatio-temporal representations for 3D human action recognition. We provide our strategy in re-designing the TCN with interpretability in mind and how such characteristics of the model is leveraged to construct a powerful 3D activity recognition method. Through this work, we wish to take a step towards a spatio-temporal model that is easier to understand, explain and interpret. The resulting model, Res-TCN, achieves state-of-the-art results on the largest 3D human action recognition dataset, NTU-RGBD. version:1
arxiv-1704-03754 | A Proof of Orthogonal Double Machine Learning with $Z$-Estimators | http://arxiv.org/abs/1704.03754 | id:1704.03754 author:Vasilis Syrgkanis category:stat.ML cs.LG math.ST stat.TH  published:2017-04-12 summary:We consider two stage estimation with a non-parametric first stage and a generalized method of moments second stage, in a simpler setting than (Chernozhukov et al. 2016). We give an alternative proof of the theorem given in (Chernozhukov et al. 2016) that orthogonal second stage moments, sample splitting and $n^{1/4}$-consistency of the first stage, imply $\sqrt{n}$-consistency and asymptotic normality of second stage estimates. Our proof is for a variant of their estimator, which is based on the empirical version of the moment condition (Z-estimator), rather than a minimization of a norm of the empirical vector of moments (M-estimator). This note is meant primarily for expository purposes, rather than as a new technical contribution. version:2
arxiv-1704-04511 | Recovery of damped exponentials using structured low rank matrix completion | http://arxiv.org/abs/1704.04511 | id:1704.04511 author:Arvind Balachandrasekaran, Vincent Magnotta, Mathews Jacob category:cs.CV  published:2017-04-14 summary:We introduce a structured low rank matrix completion algorithm to recover a series of images from their under-sampled measurements, where the signal along the parameter dimension at every pixel is described by a linear combination of exponentials. We exploit the exponential behavior of the signal at every pixel, along with the spatial smoothness of the exponential parameters to derive an annihilation relation in the Fourier domain. This relation translates to a low-rank property on a structured matrix constructed from the Fourier samples. We enforce the low rank property of the structured matrix as a regularization prior to recover the images. Since the direct use of current low rank matrix recovery schemes to this problem is associated with high computational complexity and memory demand, we adopt an iterative re-weighted least squares (IRLS) algorithm, which facilitates the exploitation of the convolutional structure of the matrix. Novel approximations involving two dimensional Fast Fourier Transforms (FFT) are introduced to drastically reduce the memory demand and computational complexity, which facilitates the extension of structured low rank methods to large scale three dimensional problems. We demonstrate our algorithm in the MR parameter mapping setting and show improvement over the state-of-the-art methods. version:1
arxiv-1704-04503 | Improving Object Detection With One Line of Code | http://arxiv.org/abs/1704.04503 | id:1704.04503 author:Navaneeth Bodla, Bharat Singh, Rama Chellappa, Larry S. Davis category:cs.CV  published:2017-04-14 summary:Non-maximum suppression is an integral part of the object detection pipeline. First, it sorts all detection boxes on the basis of their scores. The detection box M with the maximum score is selected and all other detection boxes with a significant overlap (using a pre-defined threshold) with M are suppressed. This process is recursively applied on the remaining boxes. As per the design of the algorithm, if an object lies within the predefined overlap threshold, it leads to a miss. To this end, we propose Soft-NMS, an algorithm which decays the detection scores of all other objects as a continuous function of their overlap with M. Hence, no object is eliminated in this process. Soft-NMS obtains consistent improvements for the coco-style mAP metric on standard datasets like PASCAL VOC 2007 (1.7\% for both R-FCN and Faster-RCNN) and MS-COCO (1.3\% for R-FCN and 1.1\% for Faster-RCNN) by just changing the NMS algorithm without any additional hyper-parameters. Further, the computational complexity of Soft-NMS is the same as traditional NMS and hence it can be efficiently implemented. Since Soft-NMS does not require any extra training and is simple to implement, it can be easily integrated into any object detection pipeline. Code for Soft-NMS is publicly available on GitHub \url{http://bit.ly/2nJLNMu}. version:1
arxiv-1704-04497 | TGIF-QA: Toward Spatio-Temporal Reasoning in Visual Question Answering | http://arxiv.org/abs/1704.04497 | id:1704.04497 author:Yunseok Jang, Yale Song, Youngjae Yu, Youngjin Kim, Gunhee Kim category:cs.CV  published:2017-04-14 summary:Vision and language understanding has emerged as a subject undergoing intense study in Artificial Intelligence. Among many tasks in this line of research, visual question answering (VQA) has been one of the most successful ones, where the goal is to learn a model that understands visual content at region-level details and finds their associations with pairs of questions and answers in the natural language form. Despite the rapid progress in the past few years, most existing work in VQA have focused primarily on images. In this paper, we focus on extending VQA to the video domain and contribute to the literature in three important ways. First, we propose three new tasks designed specifically for video VQA, which require spatio-temporal reasoning from videos to answer questions correctly. Next, we introduce a new large-scale dataset for video VQA named TGIF-QA that extends existing VQA work with our new tasks. Finally, we propose a dual-LSTM based approach with both spatial and temporal attention, and show its effectiveness over conventional VQA techniques through empirical evaluations. version:1
arxiv-1704-04481 | Deep Structured Learning for Facial Action Unit Intensity Estimation | http://arxiv.org/abs/1704.04481 | id:1704.04481 author:Robert Walecki, Ognjen, Rudovic, Vladimir Pavlovic, Björn Schuller, Maja Pantic category:cs.CV  published:2017-04-14 summary:We consider the task of automated estimation of facial expression intensity. This involves estimation of multiple output variables (facial action units --- AUs) that are structurally dependent. Their structure arises from statistically induced co-occurrence patterns of AU intensity levels. Modeling this structure is critical for improving the estimation performance; however, this performance is bounded by the quality of the input features extracted from face images. The goal of this paper is to model these structures and estimate complex feature representations simultaneously by combining conditional random field (CRF) encoded AU dependencies with deep learning. To this end, we propose a novel Copula CNN deep learning approach for modeling multivariate ordinal variables. Our model accounts for $ordinal$ structure in output variables and their $non$-$linear$ dependencies via copula functions modeled as cliques of a CRF. These are jointly optimized with deep CNN feature encoding layers using a newly introduced balanced batch iterative training algorithm. We demonstrate the effectiveness of our approach on the task of AU intensity estimation on two benchmark datasets. We show that joint learning of the deep features and the target output structure results in significant performance gains compared to existing deep structured models for analysis of facial expressions. version:1
arxiv-1704-04478 | Graphical Models: An Extension to Random Graphs, Trees, and Other Objects | http://arxiv.org/abs/1704.04478 | id:1704.04478 author:Neil Hallonquist category:stat.ML cs.AI cs.SI  published:2017-04-14 summary:In this work, we consider an extension of graphical models to random graphs, trees, and other objects. To do this, many fundamental concepts for multivariate random variables (e.g., marginal variables, Gibbs distribution, Markov properties) must be extended to other mathematical objects; it turns out that this extension is possible, as we will discuss, if we have a consistent, complete system of projections on a given object. Each projection defines a marginal random variable, allowing one to specify independence assumptions between them. Furthermore, these independencies can be specified in terms of a small subset of these marginal variables (which we call the atomic variables), allowing the compact representation of independencies by a directed graph. Projections also define factors, functions on the projected object space, and hence a projection family defines a set of possible factorizations for a distribution; these can be compactly represented by an undirected graph. The invariances used in graphical models are essential for learning distributions, not just on multivariate random variables, but also on other objects. When they are applied to random graphs and random trees, the result is a general class of models that is applicable to a broad range of problems, including those in which the graphs and trees have complicated edge structures. These models need not be conditioned on a fixed number of vertices, as is often the case in the literature for random graphs, and can be used for problems in which attributes are associated with vertices and edges. For graphs, applications include the modeling of molecules, neural networks, and relational real-world scenes; for trees, applications include the modeling of infectious diseases, cell fusion, the structure of language, and the structure of objects in visual scenes. Many classic models are particular instances of this framework. version:1
arxiv-1704-04470 | Lean From Thy Neighbor: Stochastic & Adversarial Bandits in a Network | http://arxiv.org/abs/1704.04470 | id:1704.04470 author:L. Elisa Celis, Farnood Salehi category:cs.LG cs.SI  published:2017-04-14 summary:An individual's decisions are often guided by those of his or her peers, i.e., neighbors in a social network. Presumably, being privy to the experiences of others aids in learning and decision making, but how much advantage does an individual gain by observing her neighbors? Such problems make appearances in sociology and economics and, in this paper, we present a novel model to capture such decision-making processes and appeal to the classical multi-armed bandit framework to analyze it. Each individual, in addition to her own actions, can observe the actions and rewards obtained by her neighbors, and can use all of this information in order to minimize her own regret. We provide algorithms for this setting, both for stochastic and adversarial bandits, and show that their regret smoothly interpolates between the regret in the classical bandit setting and that of the full-information setting as a function of the neighbors' exploration. In the stochastic setting the additional information must simply be incorporated into the usual estimation of the rewards, while in the adversarial setting this is attained by constructing a new unbiased estimator for the rewards and appropriately bounding the amount of additional information provided by the neighbors. These algorithms are optimal up to log factors; despite the fact that the agents act independently and selfishly, this implies that it is an approximate Nash equilibria for all agents to use our algorithms. Further, we show via empirical simulations that our algorithms, often significantly, outperform existing algorithms that one could apply to this setting. version:1
arxiv-1704-04463 | On Generalized Bellman Equations and Temporal-Difference Learning | http://arxiv.org/abs/1704.04463 | id:1704.04463 author:Huizhen Yu, A. Rupam Mahmood, Richard S. Sutton category:cs.LG math.OC  published:2017-04-14 summary:We consider off-policy temporal-difference (TD) learning in discounted Markov decision processes, where the goal is to evaluate a policy in a model-free way by using observations of a state process generated without executing the policy. To curb the high variance issue in off-policy TD learning, we propose a new scheme of setting the $\lambda$-parameters of TD, based on generalized Bellman equations. Our scheme is to set $\lambda$ according to the eligibility trace iterates calculated in TD, thereby easily keeping these traces in a desired bounded range. Compared to prior works, this scheme is more direct and flexible, and allows much larger $\lambda$ values for off-policy TD learning with bounded traces. Using Markov chain theory, we prove the ergodicity of the joint state-trace process under nonrestrictive conditions, and we show that associated with our scheme is a generalized Bellman equation (for the policy to be evaluated) that depends on both the evolution of $\lambda$ and the unique invariant probability measure of the state-trace process. These results not only lead immediately to a characterization of the convergence behavior of least-squares based implementation of our scheme, but also prepare the ground for further analysis of gradient-based implementations. version:1
arxiv-1704-04456 | Liquid Splash Modeling with Neural Networks | http://arxiv.org/abs/1704.04456 | id:1704.04456 author:Kiwon Um, Xiangyu Hu, Nils Thuerey category:cs.GR cs.LG  published:2017-04-14 summary:This paper proposes a new data-driven approach for modeling detailed splashes for liquid simulations with neural networks. Our model learns to generate small-scale splash detail for fluid-implicit-particle methods using training data acquired from physically accurate, high-resolution simulations. We use neural networks to model the regression of splash formation using a classifier together with a velocity modification term. More specifically, we employ a heteroscedastic model for the velocity updates. Our simulation results demonstrate that our model significantly improves visual fidelity with a large amount of realistic droplet formation and yields splash detail much more efficiently than finer discretizations. We show this for two different spatial scales and simulation setups. version:1
arxiv-1704-04455 | Cardinal Virtues: Extracting Relation Cardinalities from Text | http://arxiv.org/abs/1704.04455 | id:1704.04455 author:Paramita Mirza, Simon Razniewski, Fariz Darari, Gerhard Weikum category:cs.CL  published:2017-04-14 summary:Information extraction (IE) from text has largely focused on relations between individual entities, such as who has won which award. However, some facts are never fully mentioned, and no IE method has perfect recall. Thus, it is beneficial to also tap contents about the cardinalities of these relations, for example, how many awards someone has won. We introduce this novel problem of extracting cardinalities and discusses the specific challenges that set it apart from standard IE. We present a distant supervision method using conditional random fields. A preliminary evaluation results in precision between 3% and 55%, depending on the difficulty of relations. version:1
arxiv-1704-04452 | Bringing Structure into Summaries: Crowdsourcing a Benchmark Corpus of Concept Maps | http://arxiv.org/abs/1704.04452 | id:1704.04452 author:Tobias Falke, Iryna Gurevych category:cs.CL  published:2017-04-14 summary:Concept maps can be used to concisely represent important information and bring structure into large document collections. Therefore, we study a variant of multi-document summarization that produces summaries in the form of concept maps. However, suitable evaluation datasets for this task are currently missing. To close this gap, we present a newly created corpus of concept maps that summarize heterogeneous collections of web documents on educational topics. It was created using a novel crowdsourcing approach that allows us to efficiently determine important elements in large document collections. We release the corpus along with a baseline system and proposed evaluation protocol to enable further research on this variant of summarization. version:1
arxiv-1704-04441 | How Robust Are Character-Based Word Embeddings in Tagging and MT Against Wrod Scramlbing or Randdm Nouse? | http://arxiv.org/abs/1704.04441 | id:1704.04441 author:Georg Heigold, Günter Neumann, Josef van Genabith category:cs.CL  published:2017-04-14 summary:This paper investigates the robustness of NLP against perturbed word forms. While neural approaches can achieve (almost) human-like accuracy for certain tasks and conditions, they often are sensitive to small changes in the input such as non-canonical input (e.g., typos). Yet both stability and robustness are desired properties in applications involving user-generated content, and the more as humans easily cope with such noisy or adversary conditions. In this paper, we study the impact of noisy input. We consider different noise distributions (one type of noise, combination of noise types) and mismatched noise distributions for training and testing. Moreover, we empirically evaluate the robustness of different models (convolutional neural networks, recurrent neural networks, non-neural models), different basic units (characters, byte pair encoding units), and different NLP tasks (morphological tagging, machine translation). version:1
arxiv-1704-02665 | Supervised Infinite Feature Selection | http://arxiv.org/abs/1704.02665 | id:1704.02665 author:Sadegh Eskandari, Emre Akbas category:cs.LG  published:2017-04-09 summary:In this paper, we present a new feature selection method that is suitable for both unsupervised and supervised problems. We build upon the recently proposed Infinite Feature Selection (IFS) method where feature subsets of all sizes (including infinity) are considered. We extend IFS in two ways. First, we propose a supervised version of it. Second, we propose new ways of forming the feature adjacency matrix that perform better for unsupervised problems. We extensively evaluate our methods on many benchmark datasets, including large image-classification datasets (PASCAL VOC), and show that our methods outperform both the IFS and the widely used "minimum-redundancy maximum-relevancy (mRMR)" feature selection algorithm. version:2
arxiv-1704-04394 | DESIRE: Distant Future Prediction in Dynamic Scenes with Interacting Agents | http://arxiv.org/abs/1704.04394 | id:1704.04394 author:Namhoon Lee, Wongun Choi, Paul Vernaza, Christopher B. Choy, Philip H. S. Torr, Manmohan Chandraker category:cs.CV  published:2017-04-14 summary:We introduce a Deep Stochastic IOC RNN Encoderdecoder framework, DESIRE, for the task of future predictions of multiple interacting agents in dynamic scenes. DESIRE effectively predicts future locations of objects in multiple scenes by 1) accounting for the multi-modal nature of the future prediction (i.e., given the same context, future may vary), 2) foreseeing the potential future outcomes and make a strategic prediction based on that, and 3) reasoning not only from the past motion history, but also from the scene context as well as the interactions among the agents. DESIRE achieves these in a single end-to-end trainable neural network model, while being computationally efficient. The model first obtains a diverse set of hypothetical future prediction samples employing a conditional variational autoencoder, which are ranked and refined by the following RNN scoring-regression module. Samples are scored by accounting for accumulated future rewards, which enables better long-term strategic decisions similar to IOC frameworks. An RNN scene context fusion module jointly captures past motion histories, the semantic scene context and interactions among multiple agents. A feedback mechanism iterates over the ranking and refinement to further boost the prediction accuracy. We evaluate our model on two publicly available datasets: KITTI and Stanford Drone Dataset. Our experiments show that the proposed model significantly improves the prediction accuracy compared to other baseline methods. version:1
arxiv-1704-03751 | Enabling Embedded Inference Engine with ARM Compute Library: A Case Study | http://arxiv.org/abs/1704.03751 | id:1704.03751 author:Dawei Sun, Shaoshan Liu, Jean-Luc Gaudiot category:cs.LG  published:2017-04-12 summary:When you need to enable deep learning on low-cost embedded SoCs, is it better to port an existing deep learning framework or should you build one from scratch? In this paper, we share our practical experiences of building an embedded inference engine using ARM Compute Library (ACL). The results show that, contradictory to conventional wisdoms, for simple models, it takes much less development time to build an inference engine from scratch compared to porting existing frameworks. In addition, by utilizing ACL, we managed to build an inference engine that outperforms TensorFlow by 25%. Our conclusion is that, on embedded devices, we most likely will use very simple deep learning models for inference, and with well-developed building blocks such as ACL, it may be better in both performance and development time to build the engine from scratch. version:3
arxiv-1704-04375 | Non-parametric Estimation of Stochastic Differential Equations with Sparse Gaussian Processes | http://arxiv.org/abs/1704.04375 | id:1704.04375 author:Constantino A. García, Abraham Otero, Paulo Félix, Jesús Presedo, David G. Márquez category:stat.ML physics.data-an  published:2017-04-14 summary:The application of Stochastic Differential Equations (SDEs) to the analysis of temporal data has attracted increasing attention, due to their ability to describe complex dynamics with physically interpretable equations. In this paper, we introduce a non-parametric method for estimating the drift and diffusion terms of SDEs from a densely observed discrete time series. The use of Gaussian processes as priors permits working directly in a function-space view and thus the inference takes place directly in this space. To cope with the computational complexity that requires the use of Gaussian processes, a sparse Gaussian process approximation is provided. This approximation permits the efficient computation of predictions for the drift and diffusion terms by using a distribution over a small subset of pseudo-samples. The proposed method has been validated using both simulated data and real data from paleoclimatology. The application of the method to real data demonstrates its ability to capture the behaviour of complex systems. version:1
arxiv-1704-06258 | Solving the Uncapacitated Single Allocation p-Hub Median Problem on GPU | http://arxiv.org/abs/1704.06258 | id:1704.06258 author:Abdelhamid Benaini, Achraf Berrajaa, Jaouad Boukachour, Mustapha Oudani category:cs.DM cs.NE  published:2017-04-14 summary:A parallel genetic algorithm (GA) implemented on GPU clusters is proposed to solve the Uncapacitated Single Allocation p-Hub Median problem. The GA uses binary and integer encoding and genetic operators adapted to this problem. Our GA is improved by generated initial solution with hubs located at middle nodes. The obtained experimental results are compared with the best known solutions on all benchmarks on instances up to 1000 nodes. Furthermore, we solve our own randomly generated instances up to 6000 nodes. Our approach outperforms most well-known heuristics in terms of solution quality and time execution and it allows hitherto unsolved problems to be solved. version:1
arxiv-1704-04368 | Get To The Point: Summarization with Pointer-Generator Networks | http://arxiv.org/abs/1704.04368 | id:1704.04368 author:Abigail See, Peter J. Liu, Christopher D. Manning category:cs.CL  published:2017-04-14 summary:Neural sequence-to-sequence models have provided a viable new approach for abstractive text summarization (meaning they are not restricted to simply selecting and rearranging passages from the original text). However, these models have two shortcomings: they are liable to reproduce factual details inaccurately, and they tend to repeat themselves. In this work we propose a novel architecture that augments the standard sequence-to-sequence attentional model in two orthogonal ways. First, we use a hybrid pointer-generator network that can copy words from the source text via pointing, which aids accurate reproduction of information, while retaining the ability to produce novel words through the generator. Second, we use coverage to keep track of what has been summarized, which discourages repetition. We apply our model to the CNN / Daily Mail summarization task, outperforming the current abstractive state-of-the-art by at least 2 ROUGE points. version:1
arxiv-1704-04366 | Runtime Analysis of the $(1+(λ,λ))$ Genetic Algorithm on Random Satisfiable 3-CNF Formulas | http://arxiv.org/abs/1704.04366 | id:1704.04366 author:Maxim Buzdalov, Benjamin Doerr category:cs.NE  published:2017-04-14 summary:The $(1+(\lambda,\lambda))$ genetic algorithm, first proposed at GECCO 2013, showed a surprisingly good performance on so me optimization problems. The theoretical analysis so far was restricted to the OneMax test function, where this GA profited from the perfect fitness-distance correlation. In this work, we conduct a rigorous runtime analysis of this GA on random 3-SAT instances in the planted solution model having at least logarithmic average degree, which are known to have a weaker fitness distance correlation. We prove that this GA with fixed not too large population size again obtains runtimes better than $\Theta(n \log n)$, which is a lower bound for most evolutionary algorithms on pseudo-Boolean problems with unique optimum. However, the self-adjusting version of the GA risks reaching population sizes at which the intermediate selection of the GA, due to the weaker fitness-distance correlation, is not able to distinguish a profitable offspring from others. We show that this problem can be overcome by equipping the self-adjusting GA with an upper limit for the population size. Apart from sparse instances, this limit can be chosen in a way that the asymptotic performance does not worsen compared to the idealistic OneMax case. Overall, this work shows that the $(1+(\lambda,\lambda))$ GA can provably have a good performance on combinatorial search and optimization problems also in the presence of a weaker fitness-distance correlation. version:1
arxiv-1704-04360 | Camera Calibration by Global Constraints on the Motion of Silhouettes | http://arxiv.org/abs/1704.04360 | id:1704.04360 author:Gil Ben-Artzi category:cs.CV  published:2017-04-14 summary:We address the problem of epipolar geometry using the motion of silhouettes. Such methods match epipolar lines or frontier points across views, which are then used as the set of putative correspondences. We introduce an approach that improves by two orders of magnitude the performance over state-of-the-art methods, by significantly reducing the number of outliers in the putative matching. We model the frontier points' correspondence problem as constrained flow optimization, requiring small differences between their coordinates over consecutive frames. Our approach is formulated as a Linear Integer Program and we show that due to the nature of our problem, it can be solved efficiently in an iterative manner. Our method was validated on four standard datasets providing accurate calibrations across very different viewpoints. version:1
arxiv-1704-03993 | ApproxDBN: Approximate Computing for Discriminative Deep Belief Networks | http://arxiv.org/abs/1704.03993 | id:1704.03993 author:Xiaojing Xu, Srinjoy Das, Ken Kreutz-Delgado category:cs.NE  published:2017-04-13 summary:Probabilistic generative neural networks are useful for many applications, such as image classification, speech recognition and occlusion removal. However, the power budget for hardware implementations of neural networks can be extremely tight. To address this challenge we describe a design methodology for using approximate computing methods to implement Approximate Deep Belief Networks (ApproxDBNs) by systematically exploring the use of (1) limited precision of variables; (2) criticality analysis to identify the nodes in the network which can operate with such limited precision while allowing the network to maintain target accuracy levels; and (3) a greedy search methodology with incremental retraining to determine the optimal reduction in precision to enable maximize power savings under user-specified accuracy constraints. Experimental results show that significant bit-length reduction can be achieved by our ApproxDBN with constrained accuracy loss. version:2
arxiv-1704-04336 | An entity-driven recursive neural network model for chinese discourse coherence modeling | http://arxiv.org/abs/1704.04336 | id:1704.04336 author:Fan Xu, Shujing Du, Maoxi Li, Mingwen Wang category:cs.CL  published:2017-04-14 summary:Chinese discourse coherence modeling remains a challenge taskin Natural Language Processing field.Existing approaches mostlyfocus on the need for feature engineering, whichadoptthe sophisticated features to capture the logic or syntactic or semantic relationships acrosssentences within a text.In this paper, we present an entity-drivenrecursive deep modelfor the Chinese discourse coherence evaluation based on current English discourse coherenceneural network model. Specifically, to overcome the shortage of identifying the entity(nouns) overlap across sentences in the currentmodel, Our combined modelsuccessfully investigatesthe entities information into the recursive neural network freamework.Evaluation results on both sentence ordering and machine translation coherence rating task show the effectiveness of the proposed model, which significantly outperforms the existing strong baseline. version:1
arxiv-1704-04333 | Cross-media Similarity Metric Learning with Unified Deep Networks | http://arxiv.org/abs/1704.04333 | id:1704.04333 author:Jinwei Qi, Xin Huang, Yuxin Peng category:cs.MM cs.LG stat.ML  published:2017-04-14 summary:As a highlighting research topic in the multimedia area, cross-media retrieval aims to capture the complex correlations among multiple media types. Learning better shared representation and distance metric for multimedia data is important to boost the cross-media retrieval. Motivated by the strong ability of deep neural network in feature representation and comparison functions learning, we propose the Unified Network for Cross-media Similarity Metric (UNCSM) to associate cross-media shared representation learning with distance metric in a unified framework. First, we design a two-pathway deep network pretrained with contrastive loss, and employ double triplet similarity loss for fine-tuning to learn the shared representation for each media type by modeling the relative semantic similarity. Second, the metric network is designed for effectively calculating the cross-media similarity of the shared representation, by modeling the pairwise similar and dissimilar constraints. Compared to the existing methods which mostly ignore the dissimilar constraints and only use sample distance metric as Euclidean distance separately, our UNCSM approach unifies the representation learning and distance metric to preserve the relative similarity as well as embrace more complex similarity functions for further improving the cross-media retrieval accuracy. The experimental results show that our UNCSM approach outperforms 8 state-of-the-art methods on 4 widely-used cross-media datasets. version:1
arxiv-1704-04327 | Deep API Programmer: Learning to Program with APIs | http://arxiv.org/abs/1704.04327 | id:1704.04327 author:Surya Bhupatiraju, Rishabh Singh, Abdel-rahman Mohamed, Pushmeet Kohli category:cs.AI cs.LG  published:2017-04-14 summary:We present DAPIP, a Programming-By-Example system that learns to program with APIs to perform data transformation tasks. We design a domain-specific language (DSL) that allows for arbitrary concatenations of API outputs and constant strings. The DSL consists of three family of APIs: regular expression-based APIs, lookup APIs, and transformation APIs. We then present a novel neural synthesis algorithm to search for programs in the DSL that are consistent with a given set of examples. The search algorithm uses recently introduced neural architectures to encode input-output examples and to model the program search in the DSL. We show that synthesis algorithm outperforms baseline methods for synthesizing programs on both synthetic and real-world benchmarks. version:1
arxiv-1704-04326 | Dataset Augmentation for Pose and Lighting Invariant Face Recognition | http://arxiv.org/abs/1704.04326 | id:1704.04326 author:Daniel Crispell, Octavian Biris, Nate Crosswhite, Jeffrey Byrne, Joseph L. Mundy category:cs.CV  published:2017-04-14 summary:The performance of modern face recognition systems is a function of the dataset on which they are trained. Most datasets are largely biased toward "near-frontal" views with benign lighting conditions, negatively effecting recognition performance on images that do not meet these criteria. The proposed approach demonstrates how a baseline training set can be augmented to increase pose and lighting variability using semi-synthetic images with simulated pose and lighting conditions. The semi-synthetic images are generated using a fast and robust 3-d shape estimation and rendering pipeline which includes the full head and background. Various methods of incorporating the semi-synthetic renderings into the training procedure of a state of the art deep neural network-based recognition system without modifying the structure of the network itself are investigated. Quantitative results are presented on the challenging IJB-A identification dataset using a state of the art recognition pipeline as a baseline. version:1
arxiv-1704-04313 | CBinfer: Change-Based Inference for Convolutional Neural Networks on Video Data | http://arxiv.org/abs/1704.04313 | id:1704.04313 author:Lukas Cavigelli, Philippe Degen, Luca Benini category:cs.CV cs.LG  published:2017-04-14 summary:Extracting per-frame features using convolutional neural networks for real-time processing of video data is currently mainly performed on powerful GPU-accelerated workstations and compute clusters. However, there are many applications such as smart surveillance cameras that require or would benefit from on-site processing. To this end, we propose and evaluate a novel algorithm for change-based evaluation of CNNs for video data recorded with a static camera setting, exploiting the spatio-temporal sparsity of pixel changes. We achieve an average speed-up of 8.6x over a cuDNN baseline on a realistic benchmark with a negligible accuracy loss of less than 0.1% and no retraining of the network. The resulting energy efficiency is 10x higher than per-frame evaluation and reaches an equivalent of 328 GOp/s/W on the Tegra X1 platform. version:1
arxiv-1704-04296 | FastVentricle: Cardiac Segmentation with ENet | http://arxiv.org/abs/1704.04296 | id:1704.04296 author:Jesse Lieman-Sifry, Matthieu Le, Felix Lau, Sean Sall, Daniel Golden category:cs.CV  published:2017-04-13 summary:Cardiac Magnetic Resonance (CMR) imaging is commonly used to assess cardiac structure and function. One disadvantage of CMR is that post-processing of exams is tedious. Without automation, precise assessment of cardiac function via CMR typically requires an annotator to spend tens of minutes per case manually contouring ventricular structures. Automatic contouring can lower the required time per patient by generating contour suggestions that can be lightly modified by the annotator. Fully convolutional networks (FCNs), a variant of convolutional neural networks, have been used to rapidly advance the state-of-the-art in automated segmentation, which makes FCNs a natural choice for ventricular segmentation. However, FCNs are limited by their computational cost, which increases the monetary cost and degrades the user experience of production systems. To combat this shortcoming, we have developed the FastVentricle architecture, an FCN architecture for ventricular segmentation based on the recently developed ENet architecture. FastVentricle is 4x faster and runs with 6x less memory than the previous state-of-the-art ventricular segmentation architecture while still maintaining excellent clinical accuracy. version:1
arxiv-1704-04289 | Stochastic Gradient Descent as Approximate Bayesian Inference | http://arxiv.org/abs/1704.04289 | id:1704.04289 author:Stephan Mandt, Matthew D. Hoffman, David M. Blei category:stat.ML cs.LG  published:2017-04-13 summary:Stochastic Gradient Descent with a constant learning rate (constant SGD) simulates a Markov chain with a stationary distribution. With this perspective, we derive several new results. (1) We show that constant SGD can be used as an approximate Bayesian posterior inference algorithm. Specifically, we show how to adjust the tuning parameters of constant SGD to best match the stationary distribution to a posterior, minimizing the Kullback-Leibler divergence between these two distributions. (2) We demonstrate that constant SGD gives rise to a new variational EM algorithm that optimizes hyperparameters in complex probabilistic models. (3) We also propose SGD with momentum for sampling and show how to adjust the damping coefficient accordingly. (4) We analyze MCMC algorithms. For Langevin Dynamics and Stochastic Gradient Fisher Scoring, we quantify the approximation errors due to finite learning rates. Finally (5), we use the stochastic process perspective to give a short proof of why Polyak averaging is optimal. Based on this idea, we propose a scalable approximate MCMC algorithm, the Averaged Stochastic Gradient Sampler. version:1
arxiv-1704-04285 | Projection Free Rank-Drop Steps | http://arxiv.org/abs/1704.04285 | id:1704.04285 author:Edward Cheung, Yuying Li category:stat.ML  published:2017-04-13 summary:The Frank-Wolfe (FW) algorithm has been widely used in solving nuclear norm constrained problems, since it does not require projections. However, FW often yields high rank intermediate iterates, which can be very expensive in time and space costs for large problems. To address this issue, we propose a rank-drop method for nuclear norm constrained problems. The goal is to generate descent steps that lead to rank decreases, maintaining low-rank solu- tions throughout the algorithm. Moreover, the op- timization problems are constrained to ensure that the rank-drop step is also feasible and can be read- ily incorporated into a projection-free minimization method, e.g., Frank-Wolfe. We demonstrate that by incorporating rank-drop steps into the Frank-Wolfe algorithm, the rank of the solution is greatly re- duced compared to the original Frank-Wolfe or its common variants. version:1
arxiv-1704-04281 | Applying High-Resolution Visible Imagery to Satellite Melt Pond Fraction Retrieval: A Neural Network Approach | http://arxiv.org/abs/1704.04281 | id:1704.04281 author:Qi Liu, Yawen Zhang, Qin Lv, Li Shang category:physics.ao-ph cs.CV  published:2017-04-13 summary:During summer, melt ponds have a significant influence on Arctic sea-ice albedo. The melt pond fraction (MPF) also has the ability to forecast the Arctic sea-ice in a certain period. It is important to retrieve accurate melt pond fraction (MPF) from satellite data for Arctic research. This paper proposes a satellite MPF retrieval model based on the multi-layer neural network, named MPF-NN. Our model uses multi-spectral satellite data as model input and MPF information from multi-site and multi-period visible imagery as prior knowledge for modeling. It can effectively model melt ponds evolution of different regions and periods over the Arctic. Evaluation results show that the MPF retrieved from MODIS data using the proposed model has an RMSE of 3.91% and a correlation coefficient of 0.73. The seasonal distribution of MPF is also consistent with previous results. version:1
arxiv-1704-03817 | MAGAN: Margin Adaptation for Generative Adversarial Networks | http://arxiv.org/abs/1704.03817 | id:1704.03817 author:Ruohan Wang, Antoine Cully, Hyung Jin Chang, Yiannis Demiris category:cs.LG stat.ML  published:2017-04-12 summary:We propose a novel training procedure for Generative Adversarial Networks (GANs) to improve stability and performance by using an adaptive hinge loss objective function. We estimate the appropriate hinge loss margin with the expected energy of the target distribution, and derive both a principled criterion for updating the margin and an approximate convergence measure. The resulting training procedure is simple yet robust on a diverse set of datasets. We evaluate the proposed training procedure on the task of unsupervised image generation, noting both qualitative and quantitative performance improvements. version:2
arxiv-1703-09831 | A Deep Compositional Framework for Human-like Language Acquisition in Virtual Environment | http://arxiv.org/abs/1703.09831 | id:1703.09831 author:Haonan Yu, Haichao Zhang, Wei Xu category:cs.CL cs.LG  published:2017-03-28 summary:We tackle a task where an agent learns to navigate in a 2D maze-like environment called XWORLD. In each session, the agent perceives a sequence of raw-pixel frames, a natural language command issued by a teacher, and a set of rewards. The agent learns the teacher's language from scratch in a grounded and compositional manner, such that after training it is able to correctly execute zero-shot commands: 1) the combination of words in the command never appeared before, and/or 2) the command contains new object concepts that are learned from another task but never learned from navigation. Our deep framework for the agent is trained end to end: it learns simultaneously the visual representations of the environment, the syntax and semantics of the language, and the action module that outputs actions. The zero-shot learning capability of our framework results from its compositionality and modularity with parameter tying. We visualize the intermediate outputs of the framework, demonstrating that the agent truly understands how to solve the problem. We believe that our results provide some preliminary insights on how to train an agent with similar abilities in a 3D environment. version:2
arxiv-1704-04259 | Identity and Granularity of Events in Text | http://arxiv.org/abs/1704.04259 | id:1704.04259 author:Piek Vossen, Agata Cybulska category:cs.CL  published:2017-04-13 summary:In this paper we describe a method to detect event descrip- tions in different news articles and to model the semantics of events and their components using RDF representations. We compare these descriptions to solve a cross-document event coreference task. Our com- ponent approach to event semantics defines identity and granularity of events at different levels. It performs close to state-of-the-art approaches on the cross-document event coreference task, while outperforming other works when assuming similar quality of event detection. We demonstrate how granularity and identity are interconnected and we discuss how se- mantic anomaly could be used to define differences between coreference, subevent and topical relations. version:1
arxiv-1704-04251 | Visual Recognition of Paper Analytical Device Images for Detection of Falsified Pharmaceuticals | http://arxiv.org/abs/1704.04251 | id:1704.04251 author:Sandipan Banerjee, James Sweet, Christopher Sweet, Marya Lieberman category:cs.CV  published:2017-04-13 summary:Falsification of medicines is a big problem in many developing countries, where technological infrastructure is inadequate to detect these harmful products. We have developed a set of inexpensive paper cards, called Paper Analytical Devices (PADs), which can efficiently classify drugs based on their chemical composition, as a potential solution to the problem. These cards have different reagents embedded in them which produce a set of distinctive color descriptors upon reacting with the chemical compounds that constitute pharmaceutical dosage forms. If a falsified version of the medicine lacks the active ingredient or includes substitute fillers, the difference in color is perceivable by humans. However, reading the cards with accuracy takes training and practice, which may hamper their scaling and implementation in low resource settings. To deal with this, we have developed an automatic visual recognition system to read the results from the PAD images. At first, the optimal set of reagents was found by running singular value decomposition on the intensity values of the color tones in the card images. A dataset of cards embedded with these reagents is produced to generate the most distinctive results for a set of 26 different active pharmaceutical ingredients (APIs) and excipients. Then, we train two popular convolutional neural network (CNN) models, with the card images. We also extract some "hand-crafted" features from the images and train a nearest neighbor classifier and a non-linear support vector machine with them. On testing, higher-level features performed much better in accurately classifying the PAD images, with the CNN models reaching the highest average accuracy of over 94\%. version:1
arxiv-1704-00057 | Frames: A Corpus for Adding Memory to Goal-Oriented Dialogue Systems | http://arxiv.org/abs/1704.00057 | id:1704.00057 author:Layla El Asri, Hannes Schulz, Shikhar Sharma, Jeremie Zumer, Justin Harris, Emery Fine, Rahul Mehrotra, Kaheer Suleman category:cs.CL  published:2017-03-31 summary:This paper presents the Frames dataset (Frames is available at http://datasets.maluuba.com/Frames), a corpus of 1369 human-human dialogues with an average of 15 turns per dialogue. We developed this dataset to study the role of memory in goal-oriented dialogue systems. Based on Frames, we introduce a task called frame tracking, which extends state tracking to a setting where several states are tracked simultaneously. We propose a baseline model for this task. We show that Frames can also be used to study memory in dialogue management and information presentation through natural language generation. version:2
arxiv-1704-04232 | Hide-and-Seek: Forcing a Network to be Meticulous for Weakly-supervised Object and Action Localization | http://arxiv.org/abs/1704.04232 | id:1704.04232 author:Krishna Kumar Singh, Yong Jae Lee category:cs.CV  published:2017-04-13 summary:We propose `Hide-and-Seek', a weakly-supervised framework that aims to improve object localization in images and action localization in videos. Most existing weakly-supervised methods localize only the most discriminative parts of an object rather than all relevant parts, which leads to suboptimal performance. Our key idea is to hide patches in a training image randomly, forcing the network to seek other relevant parts when the most discriminative part is hidden. Our approach only needs to modify the input image and can work with any network designed for object localization. During testing, we do not need to hide any patches. Our Hide-and-Seek approach obtains superior performance compared to previous methods for weakly-supervised object localization on the ILSVRC dataset. We also demonstrate that our framework can be easily extended to weakly-supervised action localization. version:1
arxiv-1704-04224 | Spatial Memory for Context Reasoning in Object Detection | http://arxiv.org/abs/1704.04224 | id:1704.04224 author:Xinlei Chen, Abhinav Gupta category:cs.CV  published:2017-04-13 summary:Modeling instance-level context and object-object relationships is extremely challenging. It requires reasoning about bounding boxes of different classes, locations \etc. Above all, instance-level spatial reasoning inherently requires modeling conditional distributions on previous detections. Unfortunately, our current object detection systems do not have any {\bf memory} to remember what to condition on! The state-of-the-art object detectors still detect all object in parallel followed by non-maximal suppression (NMS). While memory has been used for tasks such as captioning, they mostly use image-level memory cells without capturing the spatial layout. On the other hand, modeling object-object relationships requires {\bf spatial} reasoning -- not only do we need a memory to store the spatial layout, but also a effective reasoning module to extract spatial patterns. This paper presents a conceptually simple yet powerful solution -- Spatial Memory Network (SMN), to model the instance-level context efficiently and effectively. Our spatial memory essentially assembles object instances back into a pseudo "image" representation that is easy to be fed into another ConvNet for object-object context reasoning. This leads to a new sequential reasoning architecture where image and memory are processed in parallel to obtain detections which update the memory again. We show our SMN direction is promising as it provides 2.2\% improvement over baseline Faster RCNN on the COCO dataset so far. version:1
arxiv-1704-04222 | Learning Latent Representations for Speech Generation and Transformation | http://arxiv.org/abs/1704.04222 | id:1704.04222 author:Wei-Ning Hsu, Yu Zhang, James Glass category:cs.CL cs.LG stat.ML  published:2017-04-13 summary:An ability to model a generative process and learn a latent representation for speech in an unsupervised fashion will be crucial to process vast quantities of unlabelled speech data. Recently, deep probabilistic generative models such as Variational Autoencoders (VAEs) have achieved tremendous success in modeling natural images. In this paper, we apply a convolutional VAE to model the generative process of natural speech. We derive latent space arithmetic operations to disentangle learned latent representations. We demonstrate the capability of our model to modify the phonetic content or the speaker identity for speech segments using the derived operations, without the need for parallel supervisory data. version:1
arxiv-1703-06520 | Detecting Oriented Text in Natural Images by Linking Segments | http://arxiv.org/abs/1703.06520 | id:1703.06520 author:Baoguang Shi, Xiang Bai, Serge Belongie category:cs.CV  published:2017-03-19 summary:Most state-of-the-art text detection methods are specific to horizontal Latin text and are not fast enough for real-time applications. We introduce Segment Linking (SegLink), an oriented text detection method. The main idea is to decompose text into two locally detectable elements, namely segments and links. A segment is an oriented box covering a part of a word or text line; A link connects two adjacent segments, indicating that they belong to the same word or text line. Both elements are detected densely at multiple scales by an end-to-end trained, fully-convolutional neural network. Final detections are produced by combining segments connected by links. Compared with previous methods, SegLink improves along the dimensions of accuracy, speed, and ease of training. It achieves an f-measure of 75.0% on the standard ICDAR 2015 Incidental (Challenge 4) benchmark, outperforming the previous best by a large margin. It runs at over 20 FPS on 512x512 images. Moreover, without modification, SegLink is able to detect long lines of non-Latin text, such as Chinese. version:3
arxiv-1704-04198 | Room for improvement in automatic image description: an error analysis | http://arxiv.org/abs/1704.04198 | id:1704.04198 author:Emiel van Miltenburg, Desmond Elliott category:cs.CL  published:2017-04-13 summary:In recent years we have seen rapid and significant progress in automatic image description but what are the open problems in this area? Most work has been evaluated using text-based similarity metrics, which only indicate that there have been improvements, without explaining what has improved. In this paper, we present a detailed error analysis of the descriptions generated by a state-of-the-art attention-based model. Our analysis operates on two levels: first we check the descriptions for accuracy, and then we categorize the types of errors we observe in the inaccurate descriptions. We find only 20% of the descriptions are free from errors, and surprisingly that 26% are unrelated to the image. Finally, we manually correct the most frequently occurring error types (e.g. gender identification) to estimate the performance reward for addressing these errors, observing gains of 0.2--1 BLEU point per type. version:1
arxiv-1704-04186 | Video Acceleration Magnification | http://arxiv.org/abs/1704.04186 | id:1704.04186 author:Yichao Zhang, Silvia L. Pintea, Jan C. van Gemert category:cs.CV  published:2017-04-13 summary:The ability to amplify or reduce subtle image changes over time is useful in contexts such as video editing, medical video analysis, product quality control and sports. In these contexts there is often large motion present which severely distorts current video amplification methods that magnify change linearly. In this work we propose a method to cope with large motions while still magnifying small changes. We make the following two observations: i) large motions are linear on the temporal scale of the small changes; ii) small changes deviate from this linearity. We ignore linear motion and propose to magnify acceleration. Our method is pure Eulerian and does not require any optical flow, temporal alignment or region annotations. We link temporal second-order derivative filtering to spatial acceleration magnification. We apply our method to moving objects where we show motion magnification and color magnification. We provide quantitative as well as qualitative evidence for our method while comparing to the state-of-the-art. version:1
arxiv-1704-04238 | Reward-based stochastic self-configuration of neural circuits | http://arxiv.org/abs/1704.04238 | id:1704.04238 author:David Kappel, Robert Legenstein, Stefan Habenschuss, Michael Hsieh, Wolfgang Maass category:q-bio.NC cs.LG cs.NE  published:2017-04-13 summary:Experimental data suggest that neural circuits configure their synaptic connectivity for a given computational task. They also point to dopamine-gated stochastic spine dynamics as an important underlying mechanism, and they show that the stochastic component of synaptic plasticity is surprisingly strong. We propose a model that elucidates how task-dependent self-configuration of neural circuits can emerge through these mechanisms. The Fokker-Planck equation allows us to relate local stochastic processes at synapses to the stationary distribution of network configurations, and thereby to computational properties of the network. This framework suggests a new model for reward-gated network plasticity, where one replaces the common policy gradient paradigm by continuously ongoing stochastic policy search (sampling) from a posterior distribution of network configurations. This posterior integrates priors that encode for example previously attained knowledge and structural constraints. This model can explain the experimentally found capability of neural circuits to configure themselves for a given task, and to compensate automatically for changes in the network or task. We also show that experimental data on dopamine-modulated spine dynamics can be modeled within this theoretical framework, and that a strong stochastic component of synaptic plasticity is essential for its performance. version:1
arxiv-1704-04163 | Spectrum Approximation Beyond Fast Matrix Multiplication: Algorithms and Hardness | http://arxiv.org/abs/1704.04163 | id:1704.04163 author:Cameron Musco, Praneeth Netrapalli, Aaron Sidford, Shashanka Ubaru, David P. Woodruff category:cs.DS cs.LG math.NA  published:2017-04-13 summary:Understanding the singular value spectrum of a matrix $A \in \mathbb{R}^{n \times n}$ is a fundamental task in countless applications. In matrix multiplication time, it is possible to perform a full SVD and directly compute the singular values $\sigma_1,...,\sigma_n$ in $n^\omega$ time. However, little is known about algorithms that break this runtime barrier. Using tools from stochastic trace estimation, polynomial approximation, and fast system solvers, we show how to efficiently isolate different ranges of $A$'s spectrum and approximate the number of singular values in these ranges. We thus effectively compute a histogram of the spectrum, which can stand in for the true singular values in many applications. We use this primitive to give the first algorithms for approximating a wide class of symmetric matrix norms in faster than matrix multiplication time. For example, we give a $(1 + \epsilon)$ approximation algorithm for the Schatten $1$-norm (the nuclear norm) running in just $\tilde O((nnz(A)n^{1/3} + n^2)\epsilon^{-3})$ time for $A$ with uniform row sparsity or $\tilde O(n^{2.18} \epsilon^{-3})$ time for dense $A$. The runtime scales smoothly for general Schatten-$p$ norms, notably becoming $\tilde O (p \cdot nnz(A) \epsilon^{-3})$ for any $p \ge 2$. At the same time, we show that the complexity of spectrum approximation is inherently tied to fast matrix multiplication in the small $\epsilon$ regime. We prove that achieving milder $\epsilon$ dependencies in our algorithms would imply faster than matrix multiplication time triangle detection for general graphs. This further implies that highly accurate algorithms running in subcubic time yield subcubic time matrix multiplication. As an application of our bounds, we show that precisely computing all effective resistances in a graph in less than matrix multiplication time is likely difficult, barring a major breakthrough. version:1
arxiv-1704-04154 | Learning Joint Multilingual Sentence Representations with Neural Machine Translation | http://arxiv.org/abs/1704.04154 | id:1704.04154 author:Holger Schwenk, Ke Tran, Orhan Firat, Matthijs Douze category:cs.CL 68T50  published:2017-04-13 summary:In this paper, we use the framework of neural machine translation to learn joint sentence representations across different languages. Our hope is that a representation which is independent of the language a sentence is written in, is likely to capture the underlying semantics. We search and compare more than 1.4M sentence representations in three different languages and study the characteristics of close sentences. We provide experimental evidence that sentences that are close in embedding space are indeed semantically highly related, but often have quite different structure and syntax. These relations also hold when comparing sentences in different languages. version:1
arxiv-1704-04141 | A Procedural Texture Generation Framework Based on Semantic Descriptions | http://arxiv.org/abs/1704.04141 | id:1704.04141 author:Junyu Dong, Lina Wang, Jun Liu, Xin Sun category:cs.CV  published:2017-04-13 summary:Procedural textures are normally generated from mathematical models with parameters carefully selected by experienced users. However, for naive users, the intuitive way to obtain a desired texture is to provide semantic descriptions such as "regular," "lacelike," and "repetitive" and then a procedural model with proper parameters will be automatically suggested to generate the corresponding textures. By contrast, it is less practical for users to learn mathematical models and tune parameters based on multiple examinations of large numbers of generated textures. In this study, we propose a novel framework that generates procedural textures according to user-defined semantic descriptions, and we establish a mapping between procedural models and semantic texture descriptions. First, based on a vocabulary of semantic attributes collected from psychophysical experiments, a multi-label learning method is employed to annotate a large number of textures with semantic attributes to form a semantic procedural texture dataset. Then, we derive a low dimensional semantic space in which the semantic descriptions can be separated from one other. Finally, given a set of semantic descriptions, the diverse properties of the samples in the semantic space can lead the framework to find an appropriate generation model that uses appropriate parameters to produce a desired texture. The experimental results show that the proposed framework is effective and that the generated textures closely correlate with the input semantic descriptions. version:1
arxiv-1704-04137 | Fashion Conversation Data on Instagram | http://arxiv.org/abs/1704.04137 | id:1704.04137 author:Yu-I Ha, Sejeong Kwon, Meeyoung Cha, Jungseock Joo category:stat.ML cs.CY  published:2017-04-13 summary:The fashion industry is establishing its presence on a number of visual-centric social media like Instagram. This creates an interesting clash as fashion brands that have traditionally practiced highly creative and editorialized image marketing now have to engage with people on the platform that epitomizes impromptu, realtime conversation. What kinds of fashion images do brands and individuals share and what are the types of visual features that attract likes and comments? In this research, we take both quantitative and qualitative approaches to answer these questions. We analyze visual features of fashion posts first via manual tagging and then via training on convolutional neural networks. The classified images were examined across four types of fashion brands: mega couture, small couture, designers, and high street. We find that while product-only images make up the majority of fashion conversation in terms of volume, body snaps and face images that portray fashion items more naturally tend to receive a larger number of likes and comments by the audience. Our findings bring insights into building an automated tool for classifying or generating influential fashion information. We make our novel dataset of {24,752} labeled images on fashion conversations, containing visual and textual cues, available for the research community. version:1
arxiv-1704-04133 | Explaining the Unexplained: A CLass-Enhanced Attentive Response (CLEAR) Approach to Understanding Deep Neural Networks | http://arxiv.org/abs/1704.04133 | id:1704.04133 author:Devinder Kumar, Alexander Wong, Graham W. Taylor category:cs.CV cs.AI cs.LG cs.MM  published:2017-04-13 summary:In this work, we propose CLass-Enhanced Attentive Response (CLEAR): an approach to visualize and understand the decisions made by deep neural networks (DNNs) given a specific input. CLEAR facilitates the visualization of attentive regions and levels of interest of DNNs during the decision-making process. It also enables the visualization of the most dominant classes associated with these attentive regions of interest. As such, CLEAR can mitigate some of the shortcomings of heatmap-based methods associated with decision ambiguity, and allows for better insights into the decision-making process of DNNs. Quantitative and qualitative experiments across three different datasets demonstrate the efficacy of CLEAR for gaining a better understanding of the inner workings of DNNs during the decision-making process. version:1
arxiv-1704-04131 | Neural Face Editing with Intrinsic Image Disentangling | http://arxiv.org/abs/1704.04131 | id:1704.04131 author:Zhixin Shu, Ersin Yumer, Sunil Hadap, Kalyan Sunkavalli, Eli Shechtman, Dimitris Samaras category:cs.CV  published:2017-04-13 summary:Traditional face editing methods often require a number of sophisticated and task specific algorithms to be applied one after the other --- a process that is tedious, fragile, and computationally intensive. In this paper, we propose an end-to-end generative adversarial network that infers a face-specific disentangled representation of intrinsic face properties, including shape (i.e. normals), albedo, and lighting, and an alpha matte. We show that this network can be trained on "in-the-wild" images by incorporating an in-network physically-based image formation module and appropriate loss functions. Our disentangling latent representation allows for semantically relevant edits, where one aspect of facial appearance can be manipulated while keeping orthogonal properties fixed, and we demonstrate its use for a number of facial editing applications. version:1
arxiv-1704-04126 | Single Image Super-Resolution based on Wiener Filter in Similarity Domain | http://arxiv.org/abs/1704.04126 | id:1704.04126 author:Cristóvão Cruz, Rakesh Mehta, Vladimir Katkovnik, Karen Egiazarian category:cs.CV  published:2017-04-13 summary:Single image super resolution (SISR) is an ill-posed problem aiming at estimating plausible high resolution (HR) image from a single low resolution (LR) image. Current state-of-the-art SISR methods are patch-based. They use either external data or internal self-similarity to learn a prior for a HR image. External data based methods utilize large number of patches from the training data, while self-similarity based approaches use a highly relevant matching patch from the input image as a prior. In this paper, we aim at combining the ideas from both paradigms, i.e. we learn a prior for a patch using a large number of patches collected from the input image. We show that this results in a strong prior. The performance of the proposed algorithm, which is based on iterative collaborative filtering with back-projection, is evaluated on a number of benchmark super-resolution image datasets. Without using any external data, the proposed approach outperforms the current non-CNN based methods on tested standard datasets for various scaling factors. On certain datasets a gain is over 1 dB compared to the recent method A+. For high sampling rates (x4 and higher) the proposed method performs similar to very recent state-of-the-art deep convolutional network-based approaches. version:1
arxiv-1704-04119 | A Search for Improved Performance in Regular Expressions | http://arxiv.org/abs/1704.04119 | id:1704.04119 author:Brendan Cody-Kenny, Michael Fenton, Adrian Ronayne, Eoghan Considine, Thomas McGuire, Michael O'Neill category:cs.NE  published:2017-04-13 summary:The primary aim of automated performance improvement is to reduce the running time of programs while maintaining (or improving on) functionality. In this paper, Genetic Programming is used to find performance improvements in regular expressions for an array of target programs, representing the first application of automated software improvement for run-time performance in the Regular Expression language. This particular problem is interesting as there may be many possible alternative regular expressions which perform the same task while exhibiting subtle differences in performance. A benchmark suite of candidate regular expressions is proposed for improvement. We show that the application of Genetic Programming techniques can result in performance improvements in all cases. As we start evolution from a known good regular expression, diversity is critical in escaping the local optima of the seed expression. In order to understand diversity during evolution we compare an initial population consisting of only seed programs with a population initialised using a combination of a single seed individual with individuals generated using PI Grow and Ramped-half-and-half initialisation mechanisms. version:1
arxiv-1704-04110 | DeepAR: Probabilistic Forecasting with Autoregressive Recurrent Networks | http://arxiv.org/abs/1704.04110 | id:1704.04110 author:Valentin Flunkert, David Salinas, Jan Gasthaus category:cs.AI cs.LG stat.ML  published:2017-04-13 summary:A key enabler for optimizing business processes is accurately estimating the probability distribution of a time series future given its past. Such probabilistic forecasts are crucial for example for reducing excess inventory in supply chains. In this paper we propose DeepAR, a novel methodology for producing accurate probabilistic forecasts, based on training an auto-regressive recurrent network model on a large number of related time series. We show through extensive empirical evaluation on several real-world forecasting data sets that our methodology is more accurate than state-of-the-art models, while requiring minimal feature engineering. version:1
arxiv-1704-04100 | Cross-lingual and cross-domain discourse segmentation of entire documents | http://arxiv.org/abs/1704.04100 | id:1704.04100 author:Chloé Braud, Ophélie Lacroix, Anders Søgaard category:cs.CL  published:2017-04-13 summary:Discourse segmentation is a crucial step in building end-to-end discourse parsers. However, discourse segmenters only exist for a few languages and domains. Typically they only detect intra-sentential segment boundaries, assuming gold standard sentence and token segmentation, and relying on high-quality syntactic parses and rich heuristics that are not generally available across languages and domains. In this paper, we propose statistical discourse segmenters for five languages and three domains that do not rely on gold pre-annotations. We also consider the problem of learning discourse segmenters when no labeled data is available for a language. Our fully supervised system obtains 89.5% F1 for English newswire, with slight drops in performance on other domains, and we report supervised and unsupervised (cross-lingual) results for five languages in total. version:1
arxiv-1704-04097 | Recognizing Activities of Daily Living from Egocentric Images | http://arxiv.org/abs/1704.04097 | id:1704.04097 author:Alejandro Cartas, Juan Marín, Petia Radeva, Mariella Dimiccoli category:cs.CV  published:2017-04-13 summary:Recognizing Activities of Daily Living (ADLs) has a large number of health applications, such as characterize lifestyle for habit improvement, nursing and rehabilitation services. Wearable cameras can daily gather large amounts of image data that provide rich visual information about ADLs than using other wearable sensors. In this paper, we explore the classification of ADLs from images captured by low temporal resolution wearable camera (2fpm) by using a Convolutional Neural Networks (CNN) approach. We show that the classification accuracy of a CNN largely improves when its output is combined, through a random decision forest, with contextual information from a fully connected layer. The proposed method was tested on a subset of the NTCIR-12 egocentric dataset, consisting of 18,674 images and achieved an overall accuracy of 86% activity recognition on 21 classes. version:1
arxiv-1704-04086 | Beyond Face Rotation: Global and Local Perception GAN for Photorealistic and Identity Preserving Frontal View Synthesis | http://arxiv.org/abs/1704.04086 | id:1704.04086 author:Rui Huang, Shu Zhang, Tianyu Li, Ran He category:cs.CV  published:2017-04-13 summary:Photorealistic frontal view synthesis from a single face image has a wide range of applications in the field of face recognition. Although data-driven deep learning methods have been proposed to address this problem by seeking solutions from ample face data, this problem is still challenging because it is intrinsically ill-posed. This paper proposes a Two-Pathway Generative Adversarial Network (TP-GAN) for photorealistic frontal view synthesis by simultaneously perceiving global structures and local details. Four landmark located patch networks are proposed to attend to local textures in addition to the commonly used global encoder-decoder network. Except for the novel architecture, we make this ill-posed problem well constrained by introducing a combination of adversarial loss, symmetry loss and identity preserving loss. The combined loss function leverages both frontal face distribution and pre-trained discriminative deep face models to guide an identity preserving inference of frontal views from profiles. Different from previous deep learning methods that mainly rely on intermediate features for recognition, our method directly leverages the synthesized identity preserving image for downstream tasks like face recognition and attribution estimation. Experimental results demonstrate that our method not only presents compelling perceptual results but also outperforms state-of-the-art results on large pose face recognition. version:1
arxiv-1704-04081 | Learning to Estimate Pose by Watching Videos | http://arxiv.org/abs/1704.04081 | id:1704.04081 author:Prabuddha Chakraborty, Vinay P. Namboodiri category:cs.CV  published:2017-04-13 summary:In this paper we propose a technique for obtaining coarse pose estimation of humans in an image that does not require any manual supervision. While a general unsupervised technique would fail to estimate human pose, we suggest that sufficient information about coarse pose can be obtained by observing human motion in multiple frames. Specifically, we consider obtaining surrogate supervision through videos as a means for obtaining motion based grouping cues. We supplement the method using a basic object detector that detects persons. With just these components we obtain a rough estimate of the human pose. With these samples for training, we train a fully convolutional neural network (FCNN)[20] to obtain accurate dense blob based pose estimation. We show that the results obtained are close to the ground-truth and to the results obtained using a fully supervised convolutional pose estimation method [31] as evaluated on a challenging dataset [15]. This is further validated by evaluating the obtained poses using a pose based action recognition method [5]. In this setting we outperform the results as obtained using the baseline method that uses a fully supervised pose estimation algorithm and is competitive with a new baseline created using convolutional pose estimation with full supervision. version:1
arxiv-1704-04057 | DCFNet: Discriminant Correlation Filters Network for Visual Tracking | http://arxiv.org/abs/1704.04057 | id:1704.04057 author:Qiang Wang, Jin Gao, Junliang Xing, Mengdan Zhang, Weiming Hu category:cs.CV  published:2017-04-13 summary:Discriminant Correlation Filters (DCF) based methods now become a kind of dominant approach to online object tracking. The features used in these methods, however, are either based on hand-crafted features like HoGs, or convolutional features trained independently from other tasks like image classification. In this work, we present an end-to-end lightweight network architecture, namely DCFNet, to learn the convolutional features and perform the correlation tracking process simultaneously. Specifically, we treat DCF as a special correlation filter layer added in a Siamese network, and carefully derive the backpropagation through it by defining the network output as the probability heatmap of object location. Since the derivation is still carried out in Fourier frequency domain, the efficiency property of DCF is preserved. This enables our tracker to run at more than 60 FPS during test time, while achieving a significant accuracy gain compared with KCF using HoGs. Extensive evaluations on OTB-2013, OTB-2015, and VOT2015 benchmarks demonstrate that the proposed DCFNet tracker is competitive with several state-of-the-art trackers, while being more compact and much faster. version:1
arxiv-1704-04055 | Land Cover Classification via Multi-temporal Spatial Data by Recurrent Neural Networks | http://arxiv.org/abs/1704.04055 | id:1704.04055 author:Dino Ienco, Raffaele Gaetano, Claire Dupaquier, Pierre Maurel category:cs.CV cs.LG  published:2017-04-13 summary:Nowadays, modern earth observation programs produce huge volumes of satellite images time series (SITS) that can be useful to monitor geographical areas through time. How to efficiently analyze such kind of information is still an open question in the remote sensing field. Recently, deep learning methods proved suitable to deal with remote sensing data mainly for scene classification (i.e. Convolutional Neural Networks - CNNs - on single images) while only very few studies exist involving temporal deep learning approaches (i.e Recurrent Neural Networks - RNNs) to deal with remote sensing time series. In this letter we evaluate the ability of Recurrent Neural Networks, in particular the Long-Short Term Memory (LSTM) model, to perform land cover classification considering multi-temporal spatial data derived from a time series of satellite images. We carried out experiments on two different datasets considering both pixel-based and object-based classification. The obtained results show that Recurrent Neural Networks are competitive compared to state-of-the-art classifiers, and may outperform classical approaches in presence of low represented and/or highly mixed classes. We also show that using the alternative feature representation generated by LSTM can improve the performances of standard classifiers. version:1
arxiv-1704-04054 | Saliency-guided Adaptive Seeding for Supervoxel Segmentation | http://arxiv.org/abs/1704.04054 | id:1704.04054 author:Ge Gao, Mikko Lauri, Simone Frintrop category:cs.CV  published:2017-04-13 summary:We propose a new saliency-guided method for generating supervoxels in 3D space. Rather than using an evenly distributed spatial seeding procedure, our method uses visual saliency to guide the process of supervoxel generation. This results in densely distributed, small, and precise supervoxels in salient regions which often contain objects, and larger supervoxels in less salient regions that often correspond to background. Our approach largely improves the quality of the resulting supervoxel segmentation in terms of boundary recall and under-segmentation error on publicly available benchmarks. version:1
arxiv-1704-04050 | Adaptive Neighboring Selection Algorithm Based on Curvature Prediction in Manifold Learning | http://arxiv.org/abs/1704.04050 | id:1704.04050 author:Lin Ma, Caifa Zhou, Xi Liu, Yubin Xu category:stat.ME cs.LG stat.ML  published:2017-04-13 summary:Recently manifold learning algorithm for dimensionality reduction attracts more and more interests, and various linear and nonlinear, global and local algorithms are proposed. The key step of manifold learning algorithm is the neighboring region selection. However, so far for the references we know, few of which propose a generally accepted algorithm to well select the neighboring region. So in this paper, we propose an adaptive neighboring selection algorithm, which successfully applies the LLE and ISOMAP algorithms in the test. It is an algorithm that can find the optimal K nearest neighbors of the data points on the manifold. And the theoretical basis of the algorithm is the approximated curvature of the data point on the manifold. Based on Riemann Geometry, Jacob matrix is a proper mathematical concept to predict the approximated curvature. By verifying the proposed algorithm on embedding Swiss roll from R3 to R2 based on LLE and ISOMAP algorithm, the simulation results show that the proposed adaptive neighboring selection algorithm is feasible and able to find the optimal value of K, making the residual variance relatively small and better visualization of the results. By quantitative analysis, the embedding quality measured by residual variance is increased 45.45% after using the proposed algorithm in LLE. version:1
arxiv-1704-04039 | 3D Deep Learning for Biological Function Prediction from Physical Fields | http://arxiv.org/abs/1704.04039 | id:1704.04039 author:Vladimir Golkov, Marcin J. Skwark, Atanas Mirchev, Georgi Dikov, Alexander R. Geanes, Jeffrey Mendenhall, Jens Meiler, Daniel Cremers category:q-bio.BM cs.LG q-bio.QM stat.ML I.2.6; J.3  published:2017-04-13 summary:Predicting the biological function of molecules, be it proteins or drug-like compounds, from their atomic structure is an important and long-standing problem. Function is dictated by structure, since it is by spatial interactions that molecules interact with each other, both in terms of steric complementarity, as well as intermolecular forces. Thus, the electron density field and electrostatic potential field of a molecule contain the "raw fingerprint" of how this molecule can fit to binding partners. In this paper, we show that deep learning can predict biological function of molecules directly from their raw 3D approximated electron density and electrostatic potential fields. Protein function based on EC numbers is predicted from the approximated electron density field. In another experiment, the activity of small molecules is predicted with quality comparable to state-of-the-art descriptor-based methods. We propose several alternative computational models for the GPU with different memory and runtime requirements for different sizes of molecules and of databases. We also propose application-specific multi-channel data representations. With future improvements of training datasets and neural network settings in combination with complementary information sources (sequence, genomic context, expression level), deep learning can be expected to show its generalization power and revolutionize the field of molecular function prediction. version:1
arxiv-1704-04037 | Zero-order Reverse Filtering | http://arxiv.org/abs/1704.04037 | id:1704.04037 author:Xin Tao, Chao Zhou, Xiaoyong Shen, Jue Wang, Jiaya Jia category:cs.CV  published:2017-04-13 summary:In this paper, we study an unconventional but practically meaningful reversibility problem of commonly used image filters. We broadly define filters as operations to smooth images or to produce layers via global or local algorithms. And we raise the intriguingly problem if they are reservable to the status before filtering. To answer it, we present a novel strategy to understand general filter via contraction mappings on a metric space. A very simple yet effective zero-order algorithm is proposed. It is able to practically reverse most filters with low computational cost. We present quite a few experiments in the paper and supplementary file to thoroughly verify its performance. This method can also be generalized to solve other inverse problems and enables new applications. version:1
arxiv-1704-04031 | Infinite Sparse Structured Factor Analysis | http://arxiv.org/abs/1704.04031 | id:1704.04031 author:Matthew C. Pearce, Simon R. White category:stat.ML  published:2017-04-13 summary:Matrix factorisation methods decompose multivariate observations as linear combinations of latent feature vectors. The Indian Buffet Process (IBP) provides a way to model the number of latent features required for a good approximation in terms of regularised reconstruction error. Previous work has focussed on latent feature vectors with independent entries. We extend the model to include nondiagonal latent covariance structures representing characteristics such as smoothness. This is done by . Using simulations we demonstrate that under appropriate conditions a smoothness prior helps to recover the true latent features, while denoising more accurately. We demonstrate our method on a real neuroimaging dataset, where computational tractability is a sufficient challenge that the efficient strategy presented here is essential. version:1
arxiv-1704-04235 | Close Yet Distinctive Domain Adaptation | http://arxiv.org/abs/1704.04235 | id:1704.04235 author:Lingkun Luo, Xiaofang Wang, Shiqiang Hu, Chao Wang, Yuxing Tang, Liming Chen category:cs.LG cs.CV stat.ML  published:2017-04-13 summary:Domain adaptation is transfer learning which aims to generalize a learning model across training and testing data with different distributions. Most previous research tackle this problem in seeking a shared feature representation between source and target domains while reducing the mismatch of their data distributions. In this paper, we propose a close yet discriminative domain adaptation method, namely CDDA, which generates a latent feature representation with two interesting properties. First, the discrepancy between the source and target domain, measured in terms of both marginal and conditional probability distribution via Maximum Mean Discrepancy is minimized so as to attract two domains close to each other. More importantly, we also design a repulsive force term, which maximizes the distances between each label dependent sub-domain to all others so as to drag different class dependent sub-domains far away from each other and thereby increase the discriminative power of the adapted domain. Moreover, given the fact that the underlying data manifold could have complex geometric structure, we further propose the constraints of label smoothness and geometric structure consistency for label propagation. Extensive experiments are conducted on 36 cross-domain image classification tasks over four public datasets. The comprehensive results show that the proposed method consistently outperforms the state-of-the-art methods with significant margins. version:1
arxiv-1704-04023 | Interspecies Knowledge Transfer for Facial Keypoint Detection | http://arxiv.org/abs/1704.04023 | id:1704.04023 author:Maheen Rashid, Xiuye Gu, Yong Jae Lee category:cs.CV  published:2017-04-13 summary:We present a method for localizing facial keypoints on animals by transferring knowledge gained from human faces. Instead of directly finetuning a network trained to detect keypoints on human faces to animal faces (which is sub-optimal since human and animal faces can look quite different), we propose to first adapt the animal images to the pre-trained human detection network by correcting for the differences in animal and human face shape. We first find the nearest human neighbors for each animal image using an unsupervised shape matching method. We use these matches to train a thin plate spline warping network to warp each animal face to look more human-like. The warping network is then jointly finetuned with a pre-trained human facial keypoint detection network using an animal dataset. We demonstrate state-of-the-art results on both horse and sheep facial keypoint detection, and significant improvement over simple finetuning, especially when training data is scarce. Additionally, we present a new dataset with 3717 images with horse face and facial keypoint annotations. version:1
arxiv-1704-04010 | ZigZag: A new approach to adaptive online learning | http://arxiv.org/abs/1704.04010 | id:1704.04010 author:Dylan J. Foster, Alexander Rakhlin, Karthik Sridharan category:cs.LG math.OC stat.ML  published:2017-04-13 summary:We develop a novel family of algorithms for the online learning setting with regret against any data sequence bounded by the empirical Rademacher complexity of that sequence. To develop a general theory of when this type of adaptive regret bound is achievable we establish a connection to the theory of decoupling inequalities for martingales in Banach spaces. When the hypothesis class is a set of linear functions bounded in some norm, such a regret bound is achievable if and only if the norm satisfies certain decoupling inequalities for martingales. Donald Burkholder's celebrated geometric characterization of decoupling inequalities (1984) states that such an inequality holds if and only if there exists a special function called a Burkholder function satisfying certain restricted concavity properties. Our online learning algorithms are efficient in terms of queries to this function. We realize our general theory by giving novel efficient algorithms for classes including lp norms, Schatten p-norms, group norms, and reproducing kernel Hilbert spaces. The empirical Rademacher complexity regret bound implies --- when used in the i.i.d. setting --- a data-dependent complexity bound for excess risk after online-to-batch conversion. To showcase the power of the empirical Rademacher complexity regret bound, we derive improved rates for a supervised learning generalization of the online learning with low rank experts task and for the online matrix prediction task. In addition to obtaining tight data-dependent regret bounds, our algorithms enjoy improved efficiency over previous techniques based on Rademacher complexity, automatically work in the infinite horizon setting, and are scale-free. To obtain such adaptive methods, we introduce novel machinery, and the resulting algorithms are not based on the standard tools of online convex optimization. version:1
arxiv-1704-03992 | Fully Distributed and Asynchronized Stochastic Gradient Descent for Networked Systems | http://arxiv.org/abs/1704.03992 | id:1704.03992 author:Ying Zhang category:cs.LG cs.AI cs.PF  published:2017-04-13 summary:This paper considers a general data-fitting problem over a networked system, in which many computing nodes are connected by an undirected graph. This kind of problem can find many real-world applications and has been studied extensively in the literature. However, existing solutions either need a central controller for information sharing or requires slot synchronization among different nodes, which increases the difficulty of practical implementations, especially for a very large and heterogeneous system. As a contrast, in this paper, we treat the data-fitting problem over the network as a stochastic programming problem with many constraints. By adapting the results in a recent paper, we design a fully distributed and asynchronized stochastic gradient descent (SGD) algorithm. We show that our algorithm can achieve global optimality and consensus asymptotically by only local computations and communications. Additionally, we provide a sharp lower bound for the convergence speed in the regular graph case. This result fits the intuition and provides guidance to design a `good' network topology to speed up the convergence. Also, the merit of our design is validated by experiments on both synthetic and real-world datasets. version:1
arxiv-1704-03987 | Mobile Keyboard Input Decoding with Finite-State Transducers | http://arxiv.org/abs/1704.03987 | id:1704.03987 author:Tom Ouyang, David Rybach, Françoise Beaufays, Michael Riley category:cs.CL  published:2017-04-13 summary:We propose a finite-state transducer (FST) representation for the models used to decode keyboard inputs on mobile devices. Drawing from learnings from the field of speech recognition, we describe a decoding framework that can satisfy the strict memory and latency constraints of keyboard input. We extend this framework to support functionalities typically not present in speech recognition, such as literal decoding, autocorrections, word completions, and next word predictions. We describe the general framework of what we call for short the keyboard "FST decoder" as well as the implementation details that are new compared to a speech FST decoder. We demonstrate that the FST decoder enables new UX features such as post-corrections. Finally, we sketch how this decoder can support advanced features such as personalization and contextualization. version:1
arxiv-1704-03986 | 2D-3D Pose Consistency-based Conditional Random Fields for 3D Human Pose Estimation | http://arxiv.org/abs/1704.03986 | id:1704.03986 author:Ju Yong Chang, Kyoung Mu Lee category:cs.CV  published:2017-04-13 summary:This study considers the 3D human pose estimation problem in a single RGB image by proposing a conditional random field (CRF) model over 2D poses, in which the 3D pose is obtained as a byproduct of the inference process. The unary term of the proposed CRF model is defined based on a powerful heat-map regression network, which has been proposed for 2D human pose estimation. This study also presents a regression network for lifting the 2D pose to 3D pose and proposes the prior term based on the consistency between the estimated 3D pose and the 2D pose. To obtain the approximate solution of the proposed CRF model, the N-best strategy is adopted. The proposed inference algorithm can be viewed as sequential processes of bottom-up generation of 2D and 3D pose proposals from the input 2D image based on deep networks and top-down verification of such proposals by checking their consistencies. To evaluate the proposed method, we use two large-scale datasets: Human3.6M and HumanEva. Experimental results show that the proposed method achieves the state-of-the-art 3D human pose estimation performance. version:1
arxiv-1704-03976 | Virtual Adversarial Training: a Regularization Method for Supervised and Semi-supervised Learning | http://arxiv.org/abs/1704.03976 | id:1704.03976 author:Takeru Miyato, Shin-ichi Maeda, Masanori Koyama, Shin Ishii category:stat.ML cs.LG  published:2017-04-13 summary:We propose a new regularization method based on virtual adversarial loss: a new measure of local smoothness of the output distribution. Virtual adversarial loss is defined as the robustness of the model's posterior distribution against local perturbation around each input data point. Our method is similar to adversarial training, but differs from adversarial training in that it determines the adversarial direction based only on the output distribution and that it is applicable to a semi-supervised setting. Because the directions in which we smooth the model are virtually adversarial, we call our method virtual adversarial training (VAT). The computational cost of VAT is relatively low. For neural networks, the approximated gradient of virtual adversarial loss can be computed with no more than two pairs of forward and backpropagations. In our experiments, we applied VAT to supervised and semi-supervised learning on multiple benchmark datasets. With additional improvement based on entropy minimization principle, our VAT achieves the state-of-the-art performance on SVHN and CIFAR-10 for semi-supervised learning tasks. version:1
arxiv-1704-03969 | Convergence analysis of the information matrix in Gaussian belief propagation | http://arxiv.org/abs/1704.03969 | id:1704.03969 author:Jian Du, Shaodan Ma, Yik-Chung Wu, Soummya Kar, José M. F. Moura category:cs.LG  published:2017-04-13 summary:Gaussian belief propagation (BP) has been widely used for distributed estimation in large-scale networks such as the smart grid, communication networks, and social networks, where local measurements/observations are scattered over a wide geographical area. However, the convergence of Gaus- sian BP is still an open issue. In this paper, we consider the convergence of Gaussian BP, focusing in particular on the convergence of the information matrix. We show analytically that the exchanged message information matrix converges for arbitrary positive semidefinite initial value, and its dis- tance to the unique positive definite limit matrix decreases exponentially fast. version:1
arxiv-1704-03966 | Collaborative Low-Rank Subspace Clustering | http://arxiv.org/abs/1704.03966 | id:1704.03966 author:Stephen Tierney, Yi Guo, Junbin Gao category:cs.CV  published:2017-04-13 summary:In this paper we present Collaborative Low-Rank Subspace Clustering. Given multiple observations of a phenomenon we learn a unified representation matrix. This unified matrix incorporates the features from all the observations, thus increasing the discriminative power compared with learning the representation matrix on each observation separately. Experimental evaluation shows that our method outperforms subspace clustering on separate observations and the state of the art collaborative learning algorithm. version:1
arxiv-1704-03963 | Tractable Clustering of Data on the Curve Manifold | http://arxiv.org/abs/1704.03963 | id:1704.03963 author:Stephen Tierney, Junbin Gao, Yi Guo, Zheng Zhang category:cs.CV  published:2017-04-13 summary:In machine learning it is common to interpret each data point as a vector in Euclidean space. However the data may actually be functional i.e.\ each data point is a function of some variable such as time and the function is discretely sampled. The naive treatment of functional data as traditional multivariate data can lead to poor performance since the algorithms are ignoring the correlation in the curvature of each function. In this paper we propose a tractable method to cluster functional data or curves by adapting the Euclidean Low-Rank Representation (LRR) to the curve manifold. Experimental evaluation on synthetic and real data reveals that this method massively outperforms prior clustering methods in both speed and accuracy when clustering functional data. version:1
arxiv-1704-03958 | Efficient Sparse Subspace Clustering by Nearest Neighbour Filtering | http://arxiv.org/abs/1704.03958 | id:1704.03958 author:Stephen Tierney, Yi Guo, Junbin Gao category:cs.CV  published:2017-04-13 summary:Sparse Subspace Clustering (SSC) has been used extensively for subspace identification tasks due to its theoretical guarantees and relative ease of implementation. However SSC has quadratic computation and memory requirements with respect to the number of input data points. This burden has prohibited SSCs use for all but the smallest datasets. To overcome this we propose a new method, k-SSC, that screens out a large number of data points to both reduce SSC to linear memory and computational requirements. We provide theoretical analysis for the bounds of success for k-SSC. Our experiments show that k-SSC exceeds theoretical expectations and outperforms existing SSC approximations by maintaining the classification performance of SSC. Furthermore in the spirit of reproducible research we have publicly released the source code for k-SSC version:1
arxiv-1704-03952 | Virtual to Real Reinforcement Learning for Autonomous Driving | http://arxiv.org/abs/1704.03952 | id:1704.03952 author:Yurong You, Xinlei Pan, Ziyan Wang, Cewu Lu category:cs.AI cs.CV  published:2017-04-13 summary:Reinforcement learning is considered as a promising direction for driving policy learning. However, training autonomous driving vehicle with reinforcement learning in real environment involves non-affordable trial-and-error. It is more desirable to first train in a virtual environment and then transfer to the real environment. In this paper, we propose a novel realistic translation network to make model trained in virtual environment be workable in real world. The proposed network can convert non-realistic virtual image input into a realistic one with similar scene structure. Given realistic frames as input, driving policy trained by reinforcement learning can nicely adapt to real world driving. Experiments show that our proposed virtual to real (VR) reinforcement learning (RL) works pretty well. To our knowledge, this is the first successful case of driving policy trained by reinforcement learning that can adapt to real world driving data. version:1
arxiv-1704-01574 | Bag-of-Words Method Applied to Accelerometer Measurements for the Purpose of Classification and Energy Estimation | http://arxiv.org/abs/1704.01574 | id:1704.01574 author:Kevin M. Amaral, Ping Chen, Scott Crouter, Wei Ding category:cs.LG stat.ML  published:2017-04-05 summary:Accelerometer measurements are the prime type of sensor information most think of when seeking to measure physical activity. On the market, there are many fitness measuring devices which aim to track calories burned and steps counted through the use of accelerometers. These measurements, though good enough for the average consumer, are noisy and unreliable in terms of the precision of measurement needed in a scientific setting. The contribution of this paper is an innovative and highly accurate regression method which uses an intermediary two-stage classification step to better direct the regression of energy expenditure values from accelerometer counts. We show that through an additional unsupervised layer of intermediate feature construction, we can leverage latent patterns within accelerometer counts to provide better grounds for activity classification than expert-constructed timeseries features. For this, our approach utilizes a mathematical model originating in natural language processing, the bag-of-words model, that has in the past years been appearing in diverse disciplines outside of the natural language processing field such as image processing. Further emphasizing the natural language connection to stochastics, we use a gaussian mixture model to learn the dictionary upon which the bag-of-words model is built. Moreover, we show that with the addition of these features, we're able to improve regression root mean-squared error of energy expenditure by approximately 1.4 units over existing state-of-the-art methods. version:2
arxiv-1704-03946 | Asymmetric Feature Maps with Application to Sketch Based Retrieval | http://arxiv.org/abs/1704.03946 | id:1704.03946 author:Giorgos Tolias, Ondřej Chum category:cs.CV  published:2017-04-12 summary:We propose a novel concept of asymmetric feature maps (AFM), which allows to evaluate multiple kernels between a query and database entries without increasing the memory requirements. To demonstrate the advantages of the AFM method, we derive a short vector image representation that, due to asymmetric feature maps, supports efficient scale and translation invariant sketch-based image retrieval. Unlike most of the short-code based retrieval systems, the proposed method provides the query localization in the retrieved image. The efficiency of the search is boosted by approximating a 2D translation search via trigonometric polynomial of scores by 1D projections. The projections are a special case of AFM. An order of magnitude speed-up is achieved compared to traditional trigonometric polynomials. The results are boosted by an image-based average query expansion, exceeding significantly the state of the art on standard benchmarks. version:1
arxiv-1704-01700 | Accelerated Stochastic Quasi-Newton Optimization on Riemann Manifolds | http://arxiv.org/abs/1704.01700 | id:1704.01700 author:Anirban Roychowdhury, Srinivasan Parthasarathy category:math.OC cs.LG math.DG stat.ML  published:2017-04-06 summary:We propose L-BFGS and trust-region algorithms on Riemann manifolds that use stochastic variance reduction techniques to speed up convergence. For the stochastic L-BFGS algorithm we analyze and prove linear convergence rates for geodesically convex problems on the manifold, without resorting to linesearch methods designed to satisfy Wolfe conditions on the step size. To the best of our knowledge our trust-region method with stochastic variance reduction techniques is the first of its kind in the literature. We conduct experiments on Karcher mean computation for positive definite matrices and computation of leading eigenvectors for both synthetic and real data matrices, and demonstrate notably better performance than recently-proposed first-order stochastic optimization methods on Riemann manifolds, as well as standard trust-region manifold optimization techniques. version:2
arxiv-1704-03942 | Beyond Uniform Priors in Bayesian Network Structure Learning | http://arxiv.org/abs/1704.03942 | id:1704.03942 author:Marco Scutari category:stat.ML stat.ME  published:2017-04-12 summary:Bayesian network structure learning is often performed in a Bayesian setting, evaluating candidate structures using their posterior probabilities for a given data set. Score-based algorithms then use those posterior probabilities as an objective function and return the maximum a posteriori network as the learned model. For discrete Bayesian networks, the canonical choice for a posterior score is the Bayesian Dirichlet equivalent uniform (BDeu) marginal likelihood with a uniform (U) graph prior, which assumes a uniform prior both on the network structures and on the parameters of the networks. In this paper, we investigate the problems arising from these assumptions, focusing on those caused by small sample sizes and sparse data. We then propose an alternative posterior score: the Bayesian Dirichlet sparse (BDs) marginal likelihood with a marginal uniform (MU) graph prior. Like U+BDeu, MU+BDs does not require any prior information on the probabilistic structure of the data and can be used as a replacement noninformative score. We study its theoretical properties and we evaluate its performance in an extensive simulation study, showing that MU+BDs is both more accurate than U+BDeu in learning the structure of the network and competitive in predicting power, while not being computationally more complex to estimate. version:1
arxiv-1704-03926 | Value Directed Exploration in Multi-Armed Bandits with Structured Priors | http://arxiv.org/abs/1704.03926 | id:1704.03926 author:Bence Cserna, Marek Petrik, Reazul Hasan Russel, Wheeler Ruml category:cs.LG cs.AI stat.ML  published:2017-04-12 summary:Multi-armed bandits are a quintessential machine learning problem requiring the balancing of exploration and exploitation. While there has been progress in developing algorithms with strong theoretical guarantees, there has been less focus on practical near-optimal finite-time performance. In this paper, we propose an algorithm for Bayesian multi-armed bandits that utilizes value-function-driven online planning techniques. Building on previous work on UCB and Gittins index, we introduce linearly-separable value functions that take both the expected return and the benefit of exploration into consideration to perform n-step lookahead. The algorithm enjoys a sub-linear performance guarantee and we present simulation results that confirm its strength in problems with structured priors. The simplicity and generality of our approach makes it a strong candidate for analyzing more complex multi-armed bandit problems. version:1
arxiv-1704-03925 | Provable Self-Representation Based Outlier Detection in a Union of Subspaces | http://arxiv.org/abs/1704.03925 | id:1704.03925 author:Chong You, Daniel P. Robinson, René Vidal category:cs.CV stat.ML  published:2017-04-12 summary:Many computer vision tasks involve processing large amounts of data contaminated by outliers, which need to be detected and rejected. While outlier detection methods based on robust statistics have existed for decades, only recently have methods based on sparse and low-rank representation been developed along with guarantees of correct outlier detection when the inliers lie in one or more low-dimensional subspaces. This paper proposes a new outlier detection method that combines tools from sparse representation with random walks on a graph. By exploiting the property that data points can be expressed as sparse linear combinations of each other, we obtain an asymmetric affinity matrix among data points, which we use to construct a weighted directed graph. By defining a suitable Markov Chain from this graph, we establish a connection between inliers/outliers and essential/inessential states of the Markov chain, which allows us to detect outliers by using random walks. We provide a theoretical analysis that justifies the correctness of our method under geometric and connectivity assumptions. Experimental results on image databases demonstrate its superiority with respect to state-of-the-art sparse and low-rank outlier detection methods. version:1
arxiv-1704-03915 | Deep Laplacian Pyramid Networks for Fast and Accurate Super-Resolution | http://arxiv.org/abs/1704.03915 | id:1704.03915 author:Wei-Sheng Lai, Jia-Bin Huang, Narendra Ahuja, Ming-Hsuan Yang category:cs.CV  published:2017-04-12 summary:Convolutional neural networks have recently demonstrated high-quality reconstruction for single-image super-resolution. In this paper, we propose the Laplacian Pyramid Super-Resolution Network (LapSRN) to progressively reconstruct the sub-band residuals of high-resolution images. At each pyramid level, our model takes coarse-resolution feature maps as input, predicts the high-frequency residuals, and uses transposed convolutions for upsampling to the finer level. Our method does not require the bicubic interpolation as the pre-processing step and thus dramatically reduces the computational complexity. We train the proposed LapSRN with deep supervision using a robust Charbonnier loss function and achieve high-quality reconstruction. Furthermore, our network generates multi-scale predictions in one feed-forward pass through the progressive reconstruction, thereby facilitates resource-aware applications. Extensive quantitative and qualitative evaluations on benchmark datasets show that the proposed algorithm performs favorably against the state-of-the-art methods in terms of speed and accuracy. version:1
arxiv-1704-03913 | Higher-order clustering in networks | http://arxiv.org/abs/1704.03913 | id:1704.03913 author:Hao Yin, Austin R. Benson, Jure Leskovec category:cs.SI cond-mat.stat-mech physics.soc-ph stat.ML  published:2017-04-12 summary:A fundamental property of complex networks is the tendency for edges to cluster. The extent of the clustering is typically quantified by the clustering coefficient, which is the probability that a length-2 path is closed, i.e., induces a triangle in the network. However, higher-order structures beyond triangles are crucial to understanding complex networks, and the clustering behavior with respect to such higher-order patterns is not well understood. Here we introduce higher-order clustering coefficients that measure the closure probability of higher-order network structures and provide a more comprehensive view of how the edges of complex networks cluster. Our higher-order clustering coefficients are a natural generalization of the traditional clustering coefficient. We derive several properties about higher-order clustering coefficients and analyze them under common random graph models. Finally, we use higher-order clustering coefficients to gain new insights into the structure of real-world networks from several domains. version:1
arxiv-1704-03899 | Deep Reinforcement Learning-based Image Captioning with Embedding Reward | http://arxiv.org/abs/1704.03899 | id:1704.03899 author:Zhou Ren, Xiaoyu Wang, Ning Zhang, Xutao Lv, Li-Jia Li category:cs.CV cs.AI  published:2017-04-12 summary:Image captioning is a challenging problem owing to the complexity in understanding the image content and diverse ways of describing it in natural language. Recent advances in deep neural networks have substantially improved the performance of this task. Most state-of-the-art approaches follow an encoder-decoder framework, which generates captions using a sequential recurrent prediction model. However, in this paper, we introduce a novel decision-making framework for image captioning. We utilize a "policy network" and a "value network" to collaboratively generate captions. The policy network serves as a local guidance by providing the confidence of predicting the next word according to the current state. Additionally, the value network serves as a global and lookahead guidance by evaluating all possible extensions of the current state. In essence, it adjusts the goal of predicting the correct words towards the goal of generating captions similar to the ground truth captions. We train both networks using an actor-critic reinforcement learning model, with a novel reward defined by visual-semantic embedding. Extensive experiments and analyses on the Microsoft COCO dataset show that the proposed framework outperforms state-of-the-art approaches across different evaluation metrics. version:1
arxiv-1704-03895 | What's in a Question: Using Visual Questions as a Form of Supervision | http://arxiv.org/abs/1704.03895 | id:1704.03895 author:Siddha Ganju, Olga Russakovsky, Abhinav Gupta category:cs.CV  published:2017-04-12 summary:Collecting fully annotated image datasets is challenging and expensive. Many types of weak supervision have been explored: weak manual annotations, web search results, temporal continuity, ambient sound and others. We focus on one particular unexplored mode: visual questions that are asked about images. The key observation that inspires our work is that the question itself provides useful information about the image (even without the answer being available). For instance, the question "what is the breed of the dog?" informs the AI that the animal in the scene is a dog and that there is only one dog present. We make three contributions: (1) providing an extensive qualitative and quantitative analysis of the information contained in human visual questions, (2) proposing two simple but surprisingly effective modifications to the standard visual question answering models that allow them to make use of weak supervision in the form of unanswered questions associated with images and (3) demonstrating that a simple data augmentation strategy inspired by our insights results in a 7.1% improvement on the standard VQA benchmark. version:1
arxiv-1704-03886 | Optimal Threshold Design for Quanta Image Sensor | http://arxiv.org/abs/1704.03886 | id:1704.03886 author:Omar A. Elgendy, Stanley H. Chan category:cs.CV  published:2017-04-12 summary:Quanta Image Sensor (QIS) is a binary imaging device envisioned as a candidate for the next generation image sensor after CCD and CMOS. Equipped with a massive number of single photon detectors, the sensor has a threshold $q$ above which the number of arriving photons will trigger a binary response "1". Existing methods in the device literature typically assume that $q = 1$ for circuit simplicity. We argue that a spatially varying threshold can significantly improve the signal to noise ratio of the reconstructed image. In this paper, we present an optimal threshold design method. We make two contributions. First, we derive a set of oracle threshold results to inform the maximally achievable performance. We show that the oracle threshold should match exactly with the underlying pixel intensity. Second, we show that around the oracle threshold there exists a set of thresholds that give asymptotically unbiased reconstructions. The asymptotic unbiasedness has a phase transition behavior which allows us to develop a practical threshold update scheme using a bisection method. Experimentally, the new threshold design method achieves better rate of convergence than existing methods. version:1
arxiv-1704-03866 | Robustly Learning a Gaussian: Getting Optimal Error, Efficiently | http://arxiv.org/abs/1704.03866 | id:1704.03866 author:Ilias Diakonikolas, Gautam Kamath, Daniel M. Kane, Jerry Li, Ankur Moitra, Alistair Stewart category:cs.DS cs.IT cs.LG math.IT math.ST stat.ML stat.TH  published:2017-04-12 summary:We study the fundamental problem of learning the parameters of a high-dimensional Gaussian in the presence of noise -- where an $\varepsilon$-fraction of our samples were chosen by an adversary. We give robust estimators that achieve estimation error $O(\varepsilon)$ in the total variation distance, which is optimal up to a universal constant that is independent of the dimension. In the case where just the mean is unknown, our robustness guarantee is optimal up to a factor of $\sqrt{2}$ and the running time is polynomial in $d$ and $1/\epsilon$. When both the mean and covariance are unknown, the running time is polynomial in $d$ and quasipolynomial in $1/\varepsilon$. Moreover all of our algorithms require only a polynomial number of samples. Our work shows that the same sorts of error guarantees that were established over fifty years ago in the one-dimensional setting can also be achieved by efficient algorithms in high-dimensional settings. version:1
arxiv-1704-02370 | A Brief Introduction to the Temporal Group LASSO and its Potential Applications in Healthcare | http://arxiv.org/abs/1704.02370 | id:1704.02370 author:Diego Saldana Miranda category:stat.ML  published:2017-04-07 summary:The Temporal Group LASSO is an example of a multi-task, regularized regression approach for the prediction of response variables that vary over time. The aim of this work is to introduce the reader to the concepts behind the Temporal Group LASSO and its related methods, as well as to the type of potential applications in a healthcare setting that the method has. We argue that the method is attractive because of its ability to reduce overfitting, select predictors, learn smooth effect patterns over time, and finally, its simplicity version:2
arxiv-1704-03847 | Semantic3D.net: A new Large-scale Point Cloud Classification Benchmark | http://arxiv.org/abs/1704.03847 | id:1704.03847 author:Timo Hackel, Nikolay Savinov, Lubor Ladicky, Jan D. Wegner, Konrad Schindler, Marc Pollefeys category:cs.CV cs.LG cs.NE cs.RO  published:2017-04-12 summary:This paper presents a new 3D point cloud classification benchmark data set with over four billion manually labelled points, meant as input for data-hungry (deep) learning methods. We also discuss first submissions to the benchmark that use deep convolutional neural networks (CNNs) as a work horse, which already show remarkable performance improvements over state-of-the-art. CNNs have become the de-facto standard for many tasks in computer vision and machine learning like semantic segmentation or object detection in images, but have no yet led to a true breakthrough for 3D point cloud labelling tasks due to lack of training data. With the massive data set presented in this paper, we aim at closing this data gap to help unleash the full potential of deep learning methods for 3D labelling tasks. Our semantic3D.net data set consists of dense point clouds acquired with static terrestrial laser scanners. It contains 8 semantic classes and covers a wide range of urban outdoor scenes: churches, streets, railroad tracks, squares, villages, soccer fields and castles. We describe our labelling interface and show that our data set provides more dense and complete point clouds with much higher overall number of labelled points compared to those already available to the research community. We further provide baseline method descriptions and comparison between methods submitted to our online system. We hope semantic3D.net will pave the way for deep learning methods in 3D point cloud labelling to learn richer, more general 3D representations, and first submissions after only a few months indicate that this might indeed be the case. version:1
arxiv-1704-03844 | Determining Song Similarity via Machine Learning Techniques and Tagging Information | http://arxiv.org/abs/1704.03844 | id:1704.03844 author:Renato L. F. Cunha, Evandro Caldeira, Luciana Fujii category:cs.LG stat.ML  published:2017-04-12 summary:The task of determining item similarity is a crucial one in a recommender system. This constitutes the base upon which the recommender system will work to determine which items are more likely to be enjoyed by a user, resulting in more user engagement. In this paper we tackle the problem of determining song similarity based solely on song metadata (such as the performer, and song title) and on tags contributed by users. We evaluate our approach under a series of different machine learning algorithms. We conclude that tf-idf achieves better results than Word2Vec to model the dataset to feature vectors. We also conclude that k-NN models have better performance than SVMs and Linear Regression for this problem. version:1
arxiv-1704-03822 | Connecting Look and Feel: Associating the visual and tactile properties of physical materials | http://arxiv.org/abs/1704.03822 | id:1704.03822 author:Wenzhen Yuan, Shaoxiong Wang, Siyuan Dong, Edward Adelson category:cs.CV  published:2017-04-12 summary:For machines to interact with the physical world, they must understand the physical properties of objects and materials they encounter. We use fabrics as an example of a deformable material with a rich set of mechanical properties. A thin flexible fabric, when draped, tends to look different from a heavy stiff fabric. It also feels different when touched. Using a collection of 118 fabric sample, we captured color and depth images of draped fabrics along with tactile data from a high resolution touch sensor. We then sought to associate the information from vision and touch by jointly training CNNs across the three modalities. Through the CNN, each input, regardless of the modality, generates an embedding vector that records the fabric's physical property. By comparing the embeddings, our system is able to look at a fabric image and predict how it will feel, and vice versa. We also show that a system jointly trained on vision and touch data can outperform a similar system trained only on visual data when tested purely with visual inputs. version:1
arxiv-1704-03809 | A Neural Parametric Singing Synthesizer | http://arxiv.org/abs/1704.03809 | id:1704.03809 author:Merlijn Blaauw, Jordi Bonada category:cs.SD cs.CL cs.LG  published:2017-04-12 summary:We present a new model for singing synthesis based on a modified version of the WaveNet architecture. Instead of modeling raw waveform, we model features produced by a parametric vocoder that separates the influence of pitch and timbre. This allows conveniently modifying pitch to match any target melody, facilitates training on more modest dataset sizes, and significantly reduces training and generation times. Our model makes frame-wise predictions using mixture density outputs rather than categorical outputs in order to reduce the required parameter count. As we found overfitting to be an issue with the relatively small datasets used in our experiments, we propose a method to regularize the model and make the autoregressive generation process more robust to prediction errors. Using a simple multi-stream architecture, harmonic, aperiodic and voiced/unvoiced components can all be predicted in a coherent manner. We compare our method to existing parametric statistical and state-of-the-art concatenative methods using quantitative metrics and a listening test. While naive implementations of the autoregressive generation algorithm tend to be inefficient, using a smart algorithm we can greatly speed up the process and obtain a system that's competitive in both speed and quality. version:1
arxiv-1704-02930 | Fast Learning and Prediction for Object Detection using Whitened CNN Features | http://arxiv.org/abs/1704.02930 | id:1704.02930 author:Björn Barz, Erik Rodner, Christoph Käding, Joachim Denzler category:cs.CV  published:2017-04-10 summary:We combine features extracted from pre-trained convolutional neural networks (CNNs) with the fast, linear Exemplar-LDA classifier to get the advantages of both: the high detection performance of CNNs, automatic feature engineering, fast model learning from few training samples and efficient sliding-window detection. The Adaptive Real-Time Object Detection System (ARTOS) has been refactored broadly to be used in combination with Caffe for the experimental studies reported in this work. version:2
arxiv-1704-00570 | Spatiotemporal Networks for Video Emotion Recognition | http://arxiv.org/abs/1704.00570 | id:1704.00570 author:Lijie Fan, Yunjie Ke category:cs.CV  published:2017-04-03 summary:Our experiment adapts several popular deep learning methods as well as some traditional methods on the problem of video emotion recognition. In our experiment, we use the CNN-LSTM architecture for visual information extraction and classification and utilize traditional methods such as for audio feature classification. For multimodal fusion, we use the traditional Support Vector Machine. Our experiment yields a good result on the AFEW 6.0 Dataset. version:3
arxiv-1704-03755 | Unsupervised part learning for visual recognition | http://arxiv.org/abs/1704.03755 | id:1704.03755 author:Ronan Sicre, Yannis Avrithis, Ewa Kijak, Frederic Jurie category:cs.CV cs.IR  published:2017-04-12 summary:Part-based image classification aims at representing categories by small sets of learned discriminative parts, upon which an image representation is built. Considered as a promising avenue a decade ago, this direction has been neglected since the advent of deep neural networks. In this context, this paper brings two contributions: first, it shows that despite the recent success of end-to-end holistic models, explicit part learning can boosts classification performance. Second, this work proceeds one step further than recent part-based models (PBM), focusing on how to learn parts without using any labeled data. Instead of learning a set of parts per class, as generally done in the PBM literature, the proposed approach both constructs a partition of a given set of images into visually similar groups, and subsequently learn a set of discriminative parts per group in a fully unsupervised fashion. This strategy opens the door to the use of PBM in new applications for which the notion of image categories is irrelevant, such as instance-based image retrieval, for example. We experimentally show that our learned parts can help building efficient image representations, for classification as well as for indexing tasks, resulting in performance superior to holistic state-of-the art Deep Convolutional Neural Networks (DCNN) encoding. version:1
arxiv-1704-01748 | MRA - Proof of Concept of a Multilingual Report Annotator Web Application | http://arxiv.org/abs/1704.01748 | id:1704.01748 author:Luís Campos, Francisco Couto category:cs.CL  published:2017-04-06 summary:MRA (Multilingual Report Annotator) is a web application that translates Radiology text and annotates it with RadLex terms. Its goal is to explore the solution of translating non-English Radiology reports as a way to solve the problem of most of the Text Mining tools being developed for English. In this brief paper we explain the language barrier problem and shortly describe the application. MRA can be found at https://github.com/lasigeBioTM/MRA . version:3
arxiv-1704-03743 | Deep-FExt: Deep Feature Extraction for Vessel Segmentation and Centerline Prediction | http://arxiv.org/abs/1704.03743 | id:1704.03743 author:Giles Tetteh, Markus Rempfler, Bjoern H. Menze, Claus Zimmer category:stat.ML cs.CV cs.LG  published:2017-04-12 summary:Feature extraction is a very crucial task in image and pixel (voxel) classification and regression in biomedical image modeling. In this work we present a machine learning based feature extraction scheme based on inception models for pixel classification tasks. We extract features under multi-scale and multi-layer schemes through convolutional operators. Layers of Fully Convolutional Network are later stacked on this feature extraction layers and trained end-to-end for the purpose of classification. We test our model on the DRIVE and STARE public data sets for the purpose of segmentation and centerline detection and it out performs most existing hand crafted or deterministic feature schemes found in literature. We achieve an average maximum Dice of 0.85 on the DRIVE data set which out performs the scores from the second human annotator of this data set. We also achieve an average maximum Dice of 0.85 and kappa of 0.84 on the STARE data set. Though these datasets are mainly 2-D we also propose ways of extending this feature extraction scheme to handle 3-D datasets. version:1
arxiv-1704-03732 | Learning from Demonstrations for Real World Reinforcement Learning | http://arxiv.org/abs/1704.03732 | id:1704.03732 author:Todd Hester, Matej Vecerik, Olivier Pietquin, Marc Lanctot, Tom Schaul, Bilal Piot, Andrew Sendonaris, Gabriel Dulac-Arnold, Ian Osband, John Agapiou, Joel Z. Leibo, Audrunas Gruslys category:cs.AI cs.LG  published:2017-04-12 summary:Deep reinforcement learning (RL) has achieved several high profile successes in difficult control problems. However, these algorithms typically require a huge amount of data before they reach reasonable performance. In fact, their performance during learning can be extremely poor. This may be acceptable for a simulator, but it severely limits the applicability of deep RL to many real-world tasks, where the agent must learn in the real environment. In this paper we study a setting where the agent may access data from previous control of the system. We present an algorithm, Deep Q-learning from Demonstrations (DQfD), that leverages this data to massively accelerate the learning process even from relatively small amounts of demonstration data. DQfD works by combining temporal difference updates with large-margin classification of the demonstrator's actions. We show that DQfD has better initial performance than Deep Q-Networks (DQN) on 40 of 42 Atari games and it receives more average rewards than DQN on 27 of 42 Atari games. We also demonstrate that DQfD learns faster than DQN even when given poor demonstration data. version:1
arxiv-1704-03724 | Unsupervised Construction of Human Body Models Using Principles of Organic Computing | http://arxiv.org/abs/1704.03724 | id:1704.03724 author:Thomas Walther, Rolf P. Würtz category:cs.CV I.2.10; I.5.4  published:2017-04-12 summary:Unsupervised learning of a generalizable model of the visual appearance of humans from video data is of major importance for computing systems interacting naturally with their users and others. We propose a step towards automatic behavior understanding by integrating principles of Organic Computing into the posture estimation cycle, thereby relegating the need for human intervention while simultaneously raising the level of system autonomy. The system extracts coherent motion from moving upper bodies and autonomously decides about limbs and their possible spatial relationships. The models from many videos are integrated into meta-models, which show good generalization to different individuals, backgrounds, and attire. These models allow robust interpretation of single video frames without temporal continuity and posture mimicking by an android robot. version:1
arxiv-1704-03718 | Deep Extreme Multi-label Learning | http://arxiv.org/abs/1704.03718 | id:1704.03718 author:Wenjie Zhang, Liwei Wang, Junchi Yan, Xiangfeng Wang, Hongyuan Zha category:cs.LG  published:2017-04-12 summary:Extreme multi-label learning or classification has been a practical and important problem since the boom of big data. The main challenge lies in the exponential label space which involves 2L possible label sets when the label dimension L is very large e.g. in millions for Wikipedia labels. This paper is motivated to better explore the label space by build- ing and modeling an explicit label graph. In the meanwhile, deep learning has been widely studied and used in various classification problems includ- ing multi-label classification, however it has not been sufficiently studied in this extreme but practi- cal case, where the label space can be as large as in millions. In this paper, we propose a practical deep embedding method for extreme multi-label classifi- cation. Our method harvests the ideas of non-linear embedding and modeling label space with graph priors at the same time. Extensive experiments on public datasets for XML show that our method per- form competitively against state-of-the-art result. version:1
arxiv-1704-03711 | Investigation on the use of Hidden-Markov Models in automatic transcription of music | http://arxiv.org/abs/1704.03711 | id:1704.03711 author:D. Cazau, G. Nuel category:stat.ML cs.LG cs.SD  published:2017-04-12 summary:Hidden Markov Models (HMMs) are a ubiquitous tool to model time series data, and have been widely used in two main tasks of Automatic Music Transcription (AMT): note segmentation, i.e. identifying the played notes after a multi-pitch estimation, and sequential post-processing, i.e. correcting note segmentation using training data. In this paper, we employ the multi-pitch estimation method called Probabilistic Latent Component Analysis (PLCA), and develop AMT systems by integrating different HMM-based modules in this framework. For note segmentation, we use two different twostate on/o? HMMs, including a higher-order one for duration modeling. For sequential post-processing, we focused on a musicological modeling of polyphonic harmonic transitions, using a first- and second-order HMMs whose states are defined through candidate note mixtures. These different PLCA plus HMM systems have been evaluated comparatively on two different instrument repertoires, namely the piano (using the MAPS database) and the marovany zither. Our results show that the use of HMMs could bring noticeable improvements to transcription results, depending on the instrument repertoire. version:1
arxiv-1704-03706 | Object proposal generation applying the distance dependent Chinese restaurant process | http://arxiv.org/abs/1704.03706 | id:1704.03706 author:Mikko Lauri, Simone Frintrop category:cs.CV  published:2017-04-12 summary:In application domains such as robotics, it is useful to represent the uncertainty related to the robot's belief about the state of its environment. Algorithms that only yield a single "best guess" as a result are not sufficient. In this paper, we propose object proposal generation based on non-parametric Bayesian inference that allows quantification of the likelihood of the proposals. We apply Markov chain Monte Carlo to draw samples of image segmentations via the distance dependent Chinese restaurant process. Our method achieves state-of-the-art performance on an indoor object discovery data set, while additionally providing a likelihood term for each proposal. We show that the likelihood term can effectively be used to rank proposals according to their quality. version:1
arxiv-1704-03693 | Trainable Referring Expression Generation using Overspecification Preferences | http://arxiv.org/abs/1704.03693 | id:1704.03693 author:Thiago castro Ferreira, Ivandre Paraboni category:cs.CL  published:2017-04-12 summary:Referring expression generation (REG) models that use speaker-dependent information require a considerable amount of training data produced by every individual speaker, or may otherwise perform poorly. In this work we present a simple REG experiment that allows the use of larger training data sets by grouping speakers according to their overspecification preferences. Intrinsic evaluation shows that this method generally outperforms the personalised method found in previous work. version:1
arxiv-1704-03669 | Dilated Convolutional Neural Networks for Cardiovascular MR Segmentation in Congenital Heart Disease | http://arxiv.org/abs/1704.03669 | id:1704.03669 author:Jelmer M. Wolterink, Tim Leiner, Max A. Viergever, Ivana Išgum category:cs.CV  published:2017-04-12 summary:We propose an automatic method using dilated convolutional neural networks (CNNs) for segmentation of the myocardium and blood pool in cardiovascular MR (CMR) of patients with congenital heart disease (CHD). Ten training and ten test CMR scans cropped to an ROI around the heart were provided in the MICCAI 2016 HVSMR challenge. A dilated CNN with a receptive field of 131x131 voxels was trained for myocardium and blood pool segmentation in axial, sagittal and coronal image slices. Performance was evaluated within the HVSMR challenge. Automatic segmentation of the test scans resulted in Dice indices of 0.80$\pm$0.06 and 0.93$\pm$0.02, average distances to boundaries of 0.96$\pm$0.31 and 0.89$\pm$0.24 mm, and Hausdorff distances of 6.13$\pm$3.76 and 7.07$\pm$3.01 mm for the myocardium and blood pool, respectively. Segmentation took 41.5$\pm$14.7 s per scan. In conclusion, dilated CNNs trained on a small set of CMR images of CHD patients showing large anatomical variability provide accurate myocardium and blood pool segmentations. version:1
arxiv-1704-02581 | Modeling Temporal Dynamics and Spatial Configurations of Actions Using Two-Stream Recurrent Neural Networks | http://arxiv.org/abs/1704.02581 | id:1704.02581 author:Hongsong Wang, Liang Wang category:cs.CV  published:2017-04-09 summary:Recently, skeleton based action recognition gains more popularity due to cost-effective depth sensors coupled with real-time skeleton estimation algorithms. Traditional approaches based on handcrafted features are limited to represent the complexity of motion patterns. Recent methods that use Recurrent Neural Networks (RNN) to handle raw skeletons only focus on the contextual dependency in the temporal domain and neglect the spatial configurations of articulated skeletons. In this paper, we propose a novel two-stream RNN architecture to model both temporal dynamics and spatial configurations for skeleton based action recognition. We explore two different structures for the temporal stream: stacked RNN and hierarchical RNN. Hierarchical RNN is designed according to human body kinematics. We also propose two effective methods to model the spatial structure by converting the spatial graph into a sequence of joints. To improve generalization of our model, we further exploit 3D transformation based data augmentation techniques including rotation and scaling transformation to transform the 3D coordinates of skeletons during training. Experiments on 3D action recognition benchmark datasets show that our method brings a considerable improvement for a variety of actions, i.e., generic actions, interaction activities and gestures. version:2
arxiv-1704-03664 | Approximating Optimization Problems using EAs on Scale-Free Networks | http://arxiv.org/abs/1704.03664 | id:1704.03664 author:Ankit Chauhan, Tobias Friedrich, Francesco Quinzan category:cs.DS cs.NE cs.SI  published:2017-04-12 summary:It has been experimentally observed that real-world networks follow certain topological properties, such as small-world, power-law etc. To study these networks, many random graph models, such as Preferential Attachment, have been proposed. In this paper, we consider the deterministic properties which capture power-law degree distribution and degeneracy. Networks with these properties are known as scale-free networks in the literature. Many interesting problems remain NP-hard on scale-free networks. We study the relationship between scale-free properties and the approximation ratio of some commonly used evolutionary algorithms. For the Vertex Cover, we observe experimentally that the (1+1) EA always gives the better result than a greedy local search, even when it runs for only $O(n \log n)$ steps. We give the construction of a scale-free network in which a multi-objective algorithm and a greedy algorithm obtain optimal solutions, while the (1+1) EA obtains the worst possible solution with constant probability. We prove that for the Dominating Set, Vertex Cover, Connected Dominating Set and Independent Set, the (1+1) EA obtains constant-factor approximation in expected run time $O(n \log n)$ and $O(n^4)$ respectively. Whereas, GSEMO gives even better approximation than (1+1) EA in expected run time $O(n^3)$ for Dominating Set, Vertex Cover and Connected Dominating Set on such networks. version:1
arxiv-1704-03660 | Feature Tracking Cardiac Magnetic Resonance via Deep Learning and Spline Optimization | http://arxiv.org/abs/1704.03660 | id:1704.03660 author:Davis M. Vigneault, Weidi Xie, David A. Bluemke, J. Alison Noble category:cs.CV  published:2017-04-12 summary:Feature tracking Cardiac Magnetic Resonance (CMR) has recently emerged as an area of interest for quantification of regional cardiac function from balanced, steady state free precession (SSFP) cine sequences. However, currently available techniques lack full automation, limiting reproducibility. We propose a fully automated technique whereby a CMR image sequence is first segmented with a deep, fully convolutional neural network (CNN) architecture, and quadratic basis splines are fitted simultaneously across all cardiac frames using least squares optimization. Experiments are performed using data from 42 patients with hypertrophic cardiomyopathy (HCM) and 21 healthy control subjects. In terms of segmentation, we compared state-of-the-art CNN frameworks, U-Net and dilated convolution architectures, with and without temporal context, using cross validation with three folds. Performance relative to expert manual segmentation was similar across all networks: pixel accuracy was ~97%, intersection-over-union (IoU) across all classes was ~87%, and IoU across foreground classes only was ~85%. Endocardial left ventricular circumferential strain calculated from the proposed pipeline was significantly different in control and disease subjects (-25.3% vs -29.1%, p = 0.006), in agreement with the current clinical literature. version:1
arxiv-1704-03114 | Detecting Visual Relationships with Deep Relational Networks | http://arxiv.org/abs/1704.03114 | id:1704.03114 author:Bo Dai, Yuqi Zhang, Dahua Lin category:cs.CV  published:2017-04-11 summary:Relationships among objects play a crucial role in image understanding. Despite the great success of deep learning techniques in recognizing individual objects, reasoning about the relationships among objects remains a challenging task. Previous methods often treat this as a classification problem, considering each type of relationship (e.g. "ride") or each distinct visual phrase (e.g. "person-ride-horse") as a category. Such approaches are faced with significant difficulties caused by the high diversity of visual appearance for each kind of relationships or the large number of distinct visual phrases. We propose an integrated framework to tackle this problem. At the heart of this framework is the Deep Relational Network, a novel formulation designed specifically for exploiting the statistical dependencies between objects and their relationships. On two large datasets, the proposed method achieves substantial improvement over state-of-the-art. version:2
arxiv-1704-03651 | Preferential Bayesian Optimization | http://arxiv.org/abs/1704.03651 | id:1704.03651 author:Javier Gonzalez, Zhenwen Dai, Andreas Damianou, Neil D. Lawrence category:stat.ML  published:2017-04-12 summary:Bayesian optimization (BO) has emerged during the last few years as an effective approach to optimizing black-box functions where direct queries of the objective are expensive. In this paper we consider the case where direct access to the function is not possible, but information about user preferences is. Such scenarios arise in problems where human preferences are modeled, such as A/B tests or recommender systems. We present a new framework for this scenario that we call Preferential Bayesian Optimization (PBO) which allows us to find the optimum of a latent function that can only be queried through pairwise comparisons, the so-called duels. PBO extends the applicability of standard BO ideas and generalizes previous discrete dueling approaches by modeling the probability of the winner of each duel by means of a Gaussian process model with a Bernoulli likelihood. The latent preference function is used to define a family of acquisition functions that extend usual policies used in BO. We illustrate the benefits of PBO in a variety of experiments, showing that PBO needs drastically fewer comparisons for finding the optimum. According to our experiments, the way of modeling correlations in PBO is key in obtaining this advantage. version:1
arxiv-1704-03639 | Joint Semi-supervised RSS Dimensionality Reduction and Fingerprint Based Algorithm for Indoor Localization | http://arxiv.org/abs/1704.03639 | id:1704.03639 author:Caifa Zhou, Lin Ma, Xuezhi Tan category:stat.ML stat.ME  published:2017-04-12 summary:With the recent development in mobile computing devices and as the ubiquitous deployment of access points(APs) of Wireless Local Area Networks(WLANs), WLAN based indoor localization systems(WILSs) are of mounting concentration and are becoming more and more prevalent for they do not require additional infrastructure. As to the localization methods in WILSs, for the approaches used to localization in satellite based global position systems are difficult to achieve in indoor environments, fingerprint based localization algorithms(FLAs) are predominant in the RSS based schemes. However, the performance of FLAs has close relationship with the number of APs and the number of reference points(RPs) in WILSs, especially as the redundant deployment of APs and RPs in the system. There are two fatal problems, curse of dimensionality (CoD) and asymmetric matching(AM), caused by increasing number of APs and breaking down APs during online stage. In this paper, a semi-supervised RSS dimensionality reduction algorithm is proposed to solve these two dilemmas at the same time and there are numerous analyses about the theoretical realization of the proposed method. Another significant innovation of this paper is jointing the fingerprint based algorithm with CM-SDE algorithm to improve the localization accuracy of indoor localization. version:1
arxiv-1704-03636 | Energy Propagation in Deep Convolutional Neural Networks | http://arxiv.org/abs/1704.03636 | id:1704.03636 author:Thomas Wiatowski, Philipp Grohs, Helmut Bölcskei category:cs.IT cs.LG math.FA math.IT stat.ML  published:2017-04-12 summary:Many practical machine learning tasks employ very deep convolutional neural networks. Such large depths pose formidable computational challenges in training and operating the network. It is therefore important to understand how many layers are actually needed to have most of the input signal's features be contained in the feature vector generated by the network. This question can be formalized by asking how quickly the energy contained in the feature maps decays across layers. In addition, it is desirable that none of the input signal's features be "lost" in the feature extraction network or, more formally, we want energy conservation in the sense of the energy contained in the feature vector being proportional to that of the corresponding input signal. This paper establishes conditions for energy conservation for a wide class of deep convolutional neural networks and characterizes corresponding feature map energy decay rates. Specifically, we consider general scattering networks, and find that under mild analyticity and high-pass conditions on the filters (which encompass, inter alia, various constructions of Weyl-Heisenberg filters, wavelets, ridgelets, ($\alpha$)-curvelets, and shearlets) the feature map energy decays at least polynomially fast. For broad families of wavelets and Weyl-Heisenberg filters, the guaranteed decay rate is shown to be exponential. Our results yield handy estimates of the number of layers needed to have at least $((1-\varepsilon)\cdot 100)\%$ of the input signal energy be contained in the feature vector. version:1
arxiv-1704-03162 | Show, Ask, Attend, and Answer: A Strong Baseline For Visual Question Answering | http://arxiv.org/abs/1704.03162 | id:1704.03162 author:Vahid Kazemi, Ali Elqursh category:cs.CV  published:2017-04-11 summary:This paper presents a new baseline for visual question answering task. Given an image and a question in natural language, our model produces accurate answers according to the content of the image. Our model, while being architecturally simple and relatively small in terms of trainable parameters, sets a new state of the art on both unbalanced and balanced VQA benchmark. On VQA 1.0 open ended challenge, our model achieves 64.6% accuracy on the test-standard set without using additional data, an improvement of 0.4% over state of the art, and on newly released VQA 2.0, our model scores 59.7% on validation set outperforming best previously reported results by 0.5%. The results presented in this paper are especially interesting because very similar models have been tried before but significantly lower performance were reported. In light of the new results we hope to see more meaningful research on visual question answering in the future. version:2
arxiv-1704-03627 | Real-time On-Demand Crowd-powered Entity Extraction | http://arxiv.org/abs/1704.03627 | id:1704.03627 author:Ting-Hao, Huang, Yun-Nung Chen, Jeffrey P. Bigham category:cs.HC cs.AI cs.CL  published:2017-04-12 summary:Output-agreement mechanisms such as ESP Game have been widely used in human computation to obtain reliable human-generated labels. In this paper, we argue that a "time-limited" output-agreement mechanism can be used to create a fast and robust crowd-powered component in interactive systems, particularly dialogue systems, to extract key information from user utterances on the fly. Our experiments on Amazon Mechanical Turk using the Airline Travel Information System (ATIS) dataset showed that the proposed approach achieves high-quality results with an average response time shorter than 9 seconds. version:1
arxiv-1704-03626 | Sampling-based speech parameter generation using moment-matching networks | http://arxiv.org/abs/1704.03626 | id:1704.03626 author:Shinnosuke Takamichi, Tomoki Koriyama, Hiroshi Saruwatari category:cs.SD cs.LG stat.ML  published:2017-04-12 summary:This paper presents sampling-based speech parameter generation using moment-matching networks for Deep Neural Network (DNN)-based speech synthesis. Although people never produce exactly the same speech even if we try to express the same linguistic and para-linguistic information, typical statistical speech synthesis produces completely the same speech, i.e., there is no inter-utterance variation in synthetic speech. To give synthetic speech natural inter-utterance variation, this paper builds DNN acoustic models that make it possible to randomly sample speech parameters. The DNNs are trained so that they make the moments of generated speech parameters close to those of natural speech parameters. Since the variation of speech parameters is compressed into a low-dimensional simple prior noise vector, our algorithm has lower computation cost than direct sampling of speech parameters. As the first step towards generating synthetic speech that has natural inter-utterance variation, this paper investigates whether or not the proposed sampling-based generation deteriorates synthetic speech quality. In evaluation, we compare speech quality of conventional maximum likelihood-based generation and proposed sampling-based generation. The result demonstrates the proposed generation causes no degradation in speech quality. version:1
arxiv-1704-03617 | Representation Stability as a Regularizer for Improved Text Analytics Transfer Learning | http://arxiv.org/abs/1704.03617 | id:1704.03617 author:Matthew Riemer, Elham Khabiri, Richard Goodwin category:cs.CL cs.LG  published:2017-04-12 summary:Although neural networks are well suited for sequential transfer learning tasks, the catastrophic forgetting problem hinders proper integration of prior knowledge. In this work, we propose a solution to this problem by using a multi-task objective based on the idea of distillation and a mechanism that directly penalizes forgetting at the shared representation layer during the knowledge integration phase of training. We demonstrate our approach on a Twitter domain sentiment analysis task with sequential knowledge transfer from four related tasks. We show that our technique outperforms networks fine-tuned to the target task. Additionally, we show both through empirical evidence and examples that it does not forget useful knowledge from the source task that is forgotten during standard fine-tuning. Surprisingly, we find that first distilling a human made rule based sentiment engine into a recurrent neural network and then integrating the knowledge with the target task data leads to a substantial gain in generalization performance. Our experiments demonstrate the power of multi-source transfer techniques in practical text analytics problems when paired with distillation. In particular, for the SemEval 2016 Task 4 Subtask A (Nakov et al., 2016) dataset we surpass the state of the art established during the competition with a comparatively simple model architecture that is not even competitive when trained on only the labeled task specific data. version:1
arxiv-1704-03615 | Predictive-Corrective Networks for Action Detection | http://arxiv.org/abs/1704.03615 | id:1704.03615 author:Achal Dave, Olga Russakovsky, Deva Ramanan category:cs.CV  published:2017-04-12 summary:While deep feature learning has revolutionized techniques for static-image understanding, the same does not quite hold for video processing. Architectures and optimization techniques used for video are largely based off those for static images, potentially underutilizing rich video information. In this work, we rethink both the underlying network architecture and the stochastic learning paradigm for temporal data. To do so, we draw inspiration from classic theory on linear dynamic systems for modeling time series. By extending such models to include nonlinear mappings, we derive a series of novel recurrent neural networks that sequentially make top-down predictions about the future and then correct those predictions with bottom-up observations. Predictive-corrective networks have a number of desirable properties: (1) they can adaptively focus computation on "surprising" frames where predictions require large corrections, (2) they simplify learning in that only "residual-like" corrective terms need to be learned over time and (3) they naturally decorrelate an input data stream in a hierarchical fashion, producing a more reliable signal for learning at each layer of a network. We provide an extensive analysis of our lightweight and interpretable framework, and demonstrate that our model is competitive with the two-stream network on three challenging datasets without the need for computationally expensive optical flow. version:1
arxiv-1704-03607 | Automatic Discovery, Association Estimation and Learning of Semantic Attributes for a Thousand Categories | http://arxiv.org/abs/1704.03607 | id:1704.03607 author:Ziad Al-Halah, Rainer Stiefelhagen category:cs.CV  published:2017-04-12 summary:Attribute-based recognition models, due to their impressive performance and their ability to generalize well on novel categories, have been widely adopted for many computer vision applications. However, usually both the attribute vocabulary and the class-attribute associations have to be provided manually by domain experts or large number of annotators. This is very costly and not necessarily optimal regarding recognition performance, and most importantly, it limits the applicability of attribute-based models to large scale data sets. To tackle this problem, we propose an end-to-end unsupervised attribute learning approach. We utilize online text corpora to automatically discover a salient and discriminative vocabulary that correlates well with the human concept of semantic attributes. Moreover, we propose a deep convolutional model to optimize class-attribute associations with a linguistic prior that accounts for noise and missing data in text. In a thorough evaluation on ImageNet, we demonstrate that our model is able to efficiently discover and learn semantic attributes at a large scale. Furthermore, we demonstrate that our model outperforms the state-of-the-art in zero-shot learning on three data sets: ImageNet, Animals with Attributes and aPascal/aYahoo. Finally, we enable attribute-based learning on ImageNet and will share the attributes and associations for future research. version:1
arxiv-1704-03604 | Instance-Level Salient Object Segmentation | http://arxiv.org/abs/1704.03604 | id:1704.03604 author:Guanbin Li, Yuan Xie, Liang Lin, Yizhou Yu category:cs.CV  published:2017-04-12 summary:Image saliency detection has recently witnessed rapid progress due to deep convolutional neural networks. However, none of the existing methods is able to identify object instances in the detected salient regions. In this paper, we present a salient instance segmentation method that produces a saliency mask with distinct object instance labels for an input image. Our method consists of three steps, estimating saliency map, detecting salient object contours and identifying salient object instances. For the first two steps, we propose a multiscale saliency refinement network, which generates high-quality salient region masks and salient object contours. Once integrated with multiscale combinatorial grouping and a MAP-based subset optimization framework, our method can generate very promising salient object instance segmentation results. To promote further research and evaluation of salient instance segmentation, we also construct a new database of 1000 images and their pixelwise salient instance annotations. Experimental results demonstrate that our proposed method is capable of achieving state-of-the-art performance on all public benchmarks for salient region detection as well as on our new dataset for salient instance segmentation. version:1
arxiv-1704-03594 | Deep Contextual Recurrent Residual Networks for Scene Labeling | http://arxiv.org/abs/1704.03594 | id:1704.03594 author:T. Hoang Ngan Le, Chi Nhan Duong, Ligong Han, Khoa Luu, Marios Savvides, Dipan Pal category:cs.CV  published:2017-04-12 summary:Designed as extremely deep architectures, deep residual networks which provide a rich visual representation and offer robust convergence behaviors have recently achieved exceptional performance in numerous computer vision problems. Being directly applied to a scene labeling problem, however, they were limited to capture long-range contextual dependence, which is a critical aspect. To address this issue, we propose a novel approach, Contextual Recurrent Residual Networks (CRRN) which is able to simultaneously handle rich visual representation learning and long-range context modeling within a fully end-to-end deep network. Furthermore, our proposed end-to-end CRRN is completely trained from scratch, without using any pre-trained models in contrast to most existing methods usually fine-tuned from the state-of-the-art pre-trained models, e.g. VGG-16, ResNet, etc. The experiments are conducted on four challenging scene labeling datasets, i.e. SiftFlow, CamVid, Stanford background and SUN datasets, and compared against various state-of-the-art scene labeling methods. version:1
arxiv-1704-03593 | Reformulating Level Sets as Deep Recurrent Neural Network Approach to Semantic Segmentation | http://arxiv.org/abs/1704.03593 | id:1704.03593 author:Ngan Le, Kha Gia Quach, Khoa Luu, Marios Savvides, Chenchen Zhu category:cs.CV  published:2017-04-12 summary:Variational Level Set (LS) has been a widely used method in medical segmentation. However, it is limited when dealing with multi-instance objects in the real world. In addition, its segmentation results are quite sensitive to initial settings and highly depend on the number of iterations. To address these issues and boost the classic variational LS methods to a new level of the learnable deep learning approaches, we propose a novel definition of contour evolution named Recurrent Level Set (RLS)} to employ Gated Recurrent Unit under the energy minimization of a variational LS functional. The curve deformation process in RLS is formed as a hidden state evolution procedure and updated by minimizing an energy functional composed of fitting forces and contour length. By sharing the convolutional features in a fully end-to-end trainable framework, we extend RLS to Contextual RLS (CRLS) to address semantic segmentation in the wild. The experimental results have shown that our proposed RLS improves both computational time and segmentation accuracy against the classic variations LS-based method, whereas the fully end-to-end system CRLS achieves competitive performance compared to the state-of-the-art semantic segmentation approaches. version:1
arxiv-1704-03581 | Pólya Urn Latent Dirichlet Allocation: a sparse massively parallel sampler | http://arxiv.org/abs/1704.03581 | id:1704.03581 author:Alexander Terenin, Måns Magnusson, Leif Jonsson, David Draper category:stat.ML stat.CO  published:2017-04-12 summary:Latent Dirichlet Allocation (LDA) is a topic model widely used in natural language processing and machine learning. Most approaches to training the model rely on iterative algorithms, which makes it difficult to run LDA on big data sets that are best analyzed in parallel and distributed computational environments. Indeed, current approaches to parallel inference either don't converge to the correct posterior or require storage of large dense matrices in memory. We present a novel sampler that overcomes both problems, and we show that this sampler is faster, both empirically and theoretically, than previous Gibbs samplers for LDA. We do so by employing a novel P\'{o}lya-Urn-based approximation in the sparse partially collapsed sampler for LDA. We prove that the approximation error vanishes with data size, making our algorithm asymptotically exact, a property of importance for large-scale topic models. In addition, we show, via an explicit example, that - contrary to popular belief in the topic modeling literature - partially collapsed samplers can be more efficient than fully collapsed samplers. We conclude by comparing the performance of our algorithm with that of other approaches on well-known corpora. version:1
arxiv-1704-02046 | End to End Deep Neural Networks Radio Receiver for Speech Signals | http://arxiv.org/abs/1704.02046 | id:1704.02046 author:Dan Elbaz, Michael Zibulevsky category:cs.LG cs.SD  published:2017-04-06 summary:End-to-end learning based approaches have been shown to be effective and are giving excellent performance for many systems with less training data. In this work we present an end to end learning approach for novel application of software defined radio (SDR) that utilizes the prior knowledge of transmitted speech message to detect and denoise the audio speech signal from the in-phase and quadrature components of its base band version. version:3
arxiv-1704-03568 | Beyond Planar Symmetry: Modeling human perception of reflection and rotation symmetries in the wild | http://arxiv.org/abs/1704.03568 | id:1704.03568 author:Christopher Funk, Yanxi Liu category:cs.CV q-bio.NC stat.ML  published:2017-04-11 summary:Humans take advantage of real world symmetries for various tasks, yet capturing their superb symmetry perception mechanism into a computational model remains elusive. Encouraged by a new discovery (CVPR 2016) demonstrating extremely high inter-person accuracy of human perceived symmetries in the wild, we have created the first deep-learning neural network for reflection and rotation symmetry detection (Sym-NET), trained on photos from MS-COCO (Common Object in COntext) dataset with nearly 11K symmetry-labels from more than 400 human observers. We employ novel methods to convert discrete human labels into symmetry heatmaps, capture symmetry densely in an image and quantitatively evaluate Sym-NET against multiple existing computer vision algorithms. Using the symmetry competition testsets from CVPR 2013 and unseen MS-COCO photos, Sym-NET comes out as the winner with significantly superior performance over all other competitors. Beyond mathematically well-defined symmetries on a plane, Sym-NET demonstrates abilities to identify viewpoint-varied 3D symmetries, partially occluded symmetrical objects and symmetries at a semantic level. version:1
arxiv-1704-03564 | Active classification with comparison queries | http://arxiv.org/abs/1704.03564 | id:1704.03564 author:Daniel M. Kane, Shachar Lovett, Shay Moran, Jiapeng Zhang category:cs.LG cs.CG  published:2017-04-11 summary:We study an extension of active learning in which the learning algorithm may ask the annotator to compare the distances of two examples from the boundary of their label-class. For example, in a recommendation system application (say for restaurants), the annotator may be asked whether she liked or disliked a specific restaurant (a label query); or which one of two restaurants did she like more (a comparison query). We focus on the class of half spaces, and show that under natural assumptions, such as large margin or bounded bit-description of the input examples, it is possible to reveal all the labels of a sample of size $n$ using approximately $O(\log n)$ queries. This implies an exponential improvement over classical active learning, where only label queries are allowed. We complement these results by showing that if any of these assumptions is removed then, in the worst case, $\Omega(n)$ queries are required. Our results follow from a new general framework of active learning with additional queries. We identify a combinatorial dimension, called the \emph{inference dimension}, that captures the query complexity when each additional query is determined by $O(1)$ examples (such as comparison queries, each of which is determined by the two compared examples). Our results for half spaces follow by bounding the inference dimension in the cases discussed above. version:1
arxiv-1704-03560 | ConceptNet at SemEval-2017 Task 2: Extending Word Embeddings with Multilingual Relational Knowledge | http://arxiv.org/abs/1704.03560 | id:1704.03560 author:Robert Speer, Joanna Lowry-Duda category:cs.CL I.2.7  published:2017-04-11 summary:This paper describes Luminoso's participation in SemEval 2017 Task 2, "Multilingual and Cross-lingual Semantic Word Similarity", with a system based on ConceptNet. ConceptNet is an open, multilingual knowledge graph that focuses on general knowledge that relates the meanings of words and phrases. Our submission to SemEval was an update of previous work that builds high-quality, multilingual word embeddings from a combination of ConceptNet and distributional semantics. Our system took first place in both subtasks. It ranked first in 4 out of 5 of the separate languages, and also ranked first in all 10 of the cross-lingual language pairs. version:1
arxiv-1704-03557 | Cutting the Error by Half: Investigation of Very Deep CNN and Advanced Training Strategies for Document Image Classification | http://arxiv.org/abs/1704.03557 | id:1704.03557 author:Muhammad Zeshan Afzal, Andreas Kölsch, Sheraz Ahmed, Marcus Liwicki category:cs.CV  published:2017-04-11 summary:We present an exhaustive investigation of recent Deep Learning architectures, algorithms, and strategies for the task of document image classification to finally reduce the error by more than half. Existing approaches, such as the DeepDocClassifier, apply standard Convolutional Network architectures with transfer learning from the object recognition domain. The contribution of the paper is threefold: First, it investigates recently introduced very deep neural network architectures (GoogLeNet, VGG, ResNet) using transfer learning (from real images). Second, it proposes transfer learning from a huge set of document images, i.e. 400,000 documents. Third, it analyzes the impact of the amount of training data (document images) and other parameters to the classification abilities. We use two datasets, the Tobacco-3482 and the large-scale RVL-CDIP dataset. We achieve an accuracy of 91.13% for the Tobacco-3482 dataset while earlier approaches reach only 77.6%. Thus, a relative error reduction of more than 60% is achieved. For the large dataset RVL-CDIP, an accuracy of 90.97% is achieved, corresponding to a relative error reduction of 11.5%. version:1
arxiv-1704-03549 | Attention-based Extraction of Structured Information from Street View Imagery | http://arxiv.org/abs/1704.03549 | id:1704.03549 author:Zbigniew Wojna, Alex Gorban, Dar-Shyang Lee, Kevin Murphy, Qian Yu, Yeqing Li, Julian Ibarz category:cs.CV  published:2017-04-11 summary:We present a neural network model - based on CNNs, RNNs and a novel attention mechanism - which achieves 84.2% accuracy on the challenging French Street Name Signs (FSNS) dataset, significantly outperforming the previous state of the art (Smith'16), which achieved 72.46%. Furthermore, our new method is much simpler and more general than the previous approach. To demonstrate the generality of our model, we show that it also performs well on an even more challenging dataset derived from Google Street View, in which the goal is to extract business names from store fronts. Finally, we study the speed/accuracy tradeoff that results from using CNN feature extractors of different depths. Surprisingly, we find that deeper is not always better (in terms of accuracy, as well as speed). Our resulting model is simple, accurate and fast, allowing it to be used at scale on a variety of challenging real-world text extraction problems. version:1
arxiv-1704-03543 | Leveraging Term Banks for Answering Complex Questions: A Case for Sparse Vectors | http://arxiv.org/abs/1704.03543 | id:1704.03543 author:Peter D. Turney category:cs.IR cs.CL cs.LG H.3.1; I.2.6; I.2.7  published:2017-04-11 summary:While open-domain question answering (QA) systems have proven effective for answering simple questions, they struggle with more complex questions. Our goal is to answer more complex questions reliably, without incurring a significant cost in knowledge resource construction to support the QA. One readily available knowledge resource is a term bank, enumerating the key concepts in a domain. We have developed an unsupervised learning approach that leverages a term bank to guide a QA system, by representing the terminological knowledge with thousands of specialized vector spaces. In experiments with complex science questions, we show that this approach significantly outperforms several state-of-the-art QA systems, demonstrating that significant leverage can be gained from continuous vector representations of domain terminology. version:1
arxiv-1704-03533 | Learning Detection with Diverse Proposals | http://arxiv.org/abs/1704.03533 | id:1704.03533 author:Samaneh Azadi, Jiashi Feng, Trevor Darrell category:cs.CV  published:2017-04-11 summary:To predict a set of diverse and informative proposals with enriched representations, this paper introduces a differentiable Determinantal Point Process (DPP) layer that is able to augment the object detection architectures. Most modern object detection architectures, such as Faster R-CNN, learn to localize objects by minimizing deviations from the ground-truth but ignore correlation between multiple proposals and object categories. Non-Maximum Suppression (NMS) as a widely used proposal pruning scheme ignores label- and instance-level relations between object candidates resulting in multi-labeled detections. In the multi-class case, NMS selects boxes with the largest prediction scores ignoring the semantic relation between categories of potential election. In contrast, our trainable DPP layer, allowing for Learning Detection with Diverse Proposals (LDDP), considers both label-level contextual information and spatial layout relationships between proposals without increasing the number of parameters of the network, and thus improves location and category specifications of final detected bounding boxes substantially during both training and inference schemes. Furthermore, we show that LDDP keeps it superiority over Faster R-CNN even if the number of proposals generated by LDPP is only ~30% as many as those for Faster R-CNN. version:1
arxiv-1704-03530 | Feature Selection Parallel Technique for Remotely Sensed Imagery Classification | http://arxiv.org/abs/1704.03530 | id:1704.03530 author:Nhien-An Le-Khac, M-Tahar Kechadi, Bo Wu, C. Chen category:cs.DC cs.CV  published:2017-04-11 summary:Remote sensing research focusing on feature selection has long attracted the attention of the remote sensing community because feature selection is a prerequisite for image processing and various applications. Different feature selection methods have been proposed to improve the classification accuracy. They vary from basic search techniques to clonal selections, and various optimal criteria have been investigated. Recently, methods using dependence-based measures have attracted much attention due to their ability to deal with very high dimensional datasets. However, these methods are based on Cramers V test, which has performance issues with large datasets. In this paper, we propose a parallel approach to improve their performance. We evaluate our approach on hyper-spectral and high spatial resolution images and compare it to the proposed methods with a centralized version as preliminary results. The results are very promising. version:1
arxiv-1704-03527 | Toward a new approach for massive LiDAR data processing | http://arxiv.org/abs/1704.03527 | id:1704.03527 author:V-H Cao, K-X Chu, Nhien-An Le-Khac, M-T Kechadi, Debra F. Laefer, Linh Truong-Hong category:cs.DC cs.CV  published:2017-04-11 summary:Laser scanning (also known as Light Detection And Ranging) has been widely applied in various application. As part of that, aerial laser scanning (ALS) has been used to collect topographic data points for a large area, which triggers to million points to be acquired. Furthermore, today, with integrating full wareform (FWF) technology during ALS data acquisition, all return information of laser pulse is stored. Thus, ALS data are to be massive and complexity since the FWF of each laser pulse can be stored up to 256 samples and density of ALS data is also increasing significantly. Processing LiDAR data demands heavy operations and the traditional approaches require significant hardware and running time. On the other hand, researchers have recently proposed parallel approaches for analysing LiDAR data. These approaches are normally based on parallel architecture of target systems such as multi-core processors, GPU, etc. However, there is still missing efficient approaches/tools supporting the analysis of LiDAR data due to the lack of a deep study on both library tools and algorithms used in processing this data. In this paper, we present a comparative study of software libraries and algorithms to optimise the processing of LiDAR data. We also propose new method to improve this process with experiments on large LiDAR data. Finally, we discuss on a parallel solution of our approach where we integrate parallel computing in processing LiDAR data. version:1
arxiv-1704-03522 | Improving Fitness Functions in Genetic Programming for Classification on Unbalanced Credit Card Datasets | http://arxiv.org/abs/1704.03522 | id:1704.03522 author:Van Loi Cao, Nhien-An Le-Khac, Miguel Nicolau, Michael ONeill, James McDermott category:cs.NE  published:2017-04-11 summary:Credit card fraud detection based on machine learning has recently attracted considerable interest from the research community. One of the most important tasks in this area is the ability of classifiers to handle the imbalance in credit card data. In this scenario, classifiers tend to yield poor accuracy on the fraud class (minority class) despite realizing high overall accuracy. This is due to the influence of the majority class on traditional training criteria. In this paper, we aim to apply genetic programming to address this issue by adapting existing fitness functions. We examine two fitness functions from previous studies and develop two new fitness functions to evolve GP classifier with superior accuracy on the minority class and overall. Two UCI credit card datasets are used to evaluate the effectiveness of the proposed fitness functions. The results demonstrate that the proposed fitness functions augment GP classifiers, encouraging fitter solutions on both the minority and the majority classes. version:1
arxiv-1704-03520 | Unsupervised Event Abstraction using Pattern Abstraction and Local Process Models | http://arxiv.org/abs/1704.03520 | id:1704.03520 author:Felix Mannhardt, Niek Tax category:cs.DB cs.AI cs.CL  published:2017-04-11 summary:Process mining analyzes business processes based on events stored in event logs. However, some recorded events may correspond to activities on a very low level of abstraction. When events are recorded on a too low level of granularity, process discovery methods tend to generate overgeneralizing process models. Grouping low-level events to higher level activities, i.e., event abstraction, can be used to discover better process models. Existing event abstraction methods are mainly based on common sub-sequences and clustering techniques. In this paper, we propose to first discover local process models and then use those models to lift the event log to a higher level of abstraction. Our conjecture is that process models discovered on the obtained high-level event log return process models of higher quality: their fitness and precision scores are more balanced. We show this with preliminary results on several real-life event logs. version:1
arxiv-1704-03503 | UC Merced Submission to the ActivityNet Challenge 2016 | http://arxiv.org/abs/1704.03503 | id:1704.03503 author:Yi Zhu, Shawn Newsam, Zaikun Xu category:cs.CV cs.MM  published:2017-04-11 summary:This notebook paper describes our system for the untrimmed classification task in the ActivityNet challenge 2016. We investigate multiple state-of-the-art approaches for action recognition in long, untrimmed videos. We exploit hand-crafted motion boundary histogram features as well feature activations from deep networks such as VGG16, GoogLeNet, and C3D. These features are separately fed to linear, one-versus-rest support vector machine classifiers to produce confidence scores for each action class. These predictions are then fused along with the softmax scores of the recent ultra-deep ResNet-101 using weighted averaging. version:1
arxiv-1704-03493 | Creativity: Generating Diverse Questions using Variational Autoencoders | http://arxiv.org/abs/1704.03493 | id:1704.03493 author:Unnat Jain, Ziyu Zhang, Alexander Schwing category:cs.CV  published:2017-04-11 summary:Generating diverse questions for given images is an important task for computational education, entertainment and AI assistants. Different from many conventional prediction techniques is the need for algorithms to generate a diverse set of plausible questions, which we refer to as "creativity". In this paper we propose a creative algorithm for visual question generation which combines the advantages of variational autoencoders with long short-term memory networks. We demonstrate that our framework is able to generate a large set of varying questions given a single input image. version:1
arxiv-1704-02672 | Quaternion Based Camera Pose Estimation From Matched Feature Points | http://arxiv.org/abs/1704.02672 | id:1704.02672 author:Kaveh Fathian, J. Pablo Ramirez-Paredes, Emily A. Doucette, J. Willard Curtis, Nicholas R. Gans category:cs.CV cs.RO  published:2017-04-09 summary:We present a novel solution to the camera pose estimation problem, where rotation and translation of a camera between two views are estimated from matched feature points in the images. The camera pose estimation problem is traditionally solved via algorithms that are based on the essential matrix or the Euclidean homography. With six or more feature points in general positions in the space, essential matrix based algorithms can recover a unique solution. However, such algorithms fail when points are on critical surfaces (e.g., coplanar points) and homography should be used instead. By formulating the problem in quaternions and decoupling the rotation and translation estimation, our proposed algorithm works for all point configurations. Using both simulated and real world images, we compare the estimation accuracy of our algorithm with some of the most commonly used algorithms. Our method is shown to be more robust to noise and outliers. For the benefit of community, we have made the implementation of our algorithm available online and free. version:2
arxiv-1704-03489 | CNN-SLAM: Real-time dense monocular SLAM with learned depth prediction | http://arxiv.org/abs/1704.03489 | id:1704.03489 author:Keisuke Tateno, Federico Tombari, Iro Laina, Nassir Navab category:cs.CV  published:2017-04-11 summary:Given the recent advances in depth prediction from Convolutional Neural Networks (CNNs), this paper investigates how predicted depth maps from a deep neural network can be deployed for accurate and dense monocular reconstruction. We propose a method where CNN-predicted dense depth maps are naturally fused together with depth measurements obtained from direct monocular SLAM. Our fusion scheme privileges depth prediction in image locations where monocular SLAM approaches tend to fail, e.g. along low-textured regions, and vice-versa. We demonstrate the use of depth prediction for estimating the absolute scale of the reconstruction, hence overcoming one of the major limitations of monocular SLAM. Finally, we propose a framework to efficiently fuse semantic labels, obtained from a single frame, with dense SLAM, yielding semantically coherent scene reconstruction from a single view. Evaluation results on two benchmark datasets show the robustness and accuracy of our approach. version:1
arxiv-1703-07478 | Spatially-Varying Blur Detection Based on Multiscale Fused and Sorted Transform Coefficients of Gradient Magnitudes | http://arxiv.org/abs/1703.07478 | id:1703.07478 author:S. Alireza Golestaneh, Lina J. Karam category:cs.CV  published:2017-03-22 summary:The detection of spatially-varying blur without having any information about the blur type is a challenging task. In this paper, we propose a novel effective approach to address the blur detection problem from a single image without requiring any knowledge about the blur type, level, or camera settings. Our approach computes blur detection maps based on a novel High-frequency multiscale Fusion and Sort Transform (HiFST) of gradient magnitudes. The evaluations of the proposed approach on a diverse set of blurry images with different blur types, levels, and contents demonstrate that the proposed algorithm performs favorably against the state-of-the-art methods qualitatively and quantitatively. version:3
arxiv-1704-03488 | Learning Proximal Operators: Using Denoising Networks for Regularizing Inverse Imaging Problems | http://arxiv.org/abs/1704.03488 | id:1704.03488 author:Tim Meinhardt, Michael Möller, Caner Hazirbas, Daniel Cremers category:cs.CV  published:2017-04-11 summary:While variational methods have been among the most powerful tools for solving linear inverse problems in imaging, deep (convolutional) neural networks have recently taken the lead in many challenging benchmarks. A remaining drawback of deep learning approaches is that they require an expensive retraining whenever the specific problem, the noise level, noise type, or desired measure of fidelity changes. On the contrary, variational methods have a plug-and-play nature as they usually consist of separate data fidelity and regularization terms. In this paper we study the possibility of replacing the proximal operator of the regularization used in many convex energy minimization algorithms by a denoising neural network. The latter therefore serves as an implicit natural image prior, while the data term can still be chosen arbitrarily. Using a fixed denoising neural network in exemplary problems of image deconvolution with different blur kernels and image demosaicking, we obtain state-of-the-art results. Additionally, we discuss novel results on the analysis of possible convex optimization algorithms to incorporate the network into, as well as the choices of algorithm parameters and their relation to the noise level the neural network is trained on. version:1
arxiv-1704-03471 | What do Neural Machine Translation Models Learn about Morphology? | http://arxiv.org/abs/1704.03471 | id:1704.03471 author:Yonatan Belinkov, Nadir Durrani, Fahim Dalvi, Hassan Sajjad, James Glass category:cs.CL I.2.7  published:2017-04-11 summary:Neural machine translation (MT) models obtain state-of-the-art performance while maintaining a simple, end-to-end architecture. However, little is known about what these models learn about source and target languages during the training process. In this work, we analyze the representations learned by neural MT models at various levels of granularity and empirically evaluate the quality of the representations for learning morphology through extrinsic part-of-speech and morphological tagging tasks. We conduct a thorough investigation along several parameters: word-based vs. character-based representations, depth of the encoding layer, the identity of the target language, and encoder vs. decoder representations. Our data-driven, quantitative evaluation sheds light on important aspects in the neural MT system and its ability to capture word structure. version:1
arxiv-1704-03453 | The Space of Transferable Adversarial Examples | http://arxiv.org/abs/1704.03453 | id:1704.03453 author:Florian Tramèr, Nicolas Papernot, Ian Goodfellow, Dan Boneh, Patrick McDaniel category:stat.ML cs.CR cs.LG  published:2017-04-11 summary:Adversarial examples are maliciously perturbed inputs designed to mislead machine learning (ML) models at test-time. Adversarial examples are known to transfer across models: a same perturbed input is often misclassified by different models despite being generated to mislead a specific architecture. This phenomenon enables simple yet powerful black-box attacks against deployed ML systems. In this work, we propose novel methods for estimating the previously unknown dimensionality of the space of adversarial inputs. We find that adversarial examples span a contiguous subspace of large dimensionality and that a significant fraction of this space is shared between different models, thus enabling transferability. The dimensionality of the transferred adversarial subspace implies that the decision boundaries learned by different models are eerily close in the input domain, when moving away from data points in adversarial directions. A first quantitative analysis of the similarity of different models' decision boundaries reveals that these boundaries are actually close in arbitrary directions, whether adversarial or benign. We conclude with a formal study of the limits of transferability. We show (1) sufficient conditions on the data distribution that imply transferability for simple model classes and (2) examples of tasks for which transferability fails to hold. This suggests the existence of defenses making models robust to transferability attacks---even when the model is not robust to its own adversarial examples. version:1
arxiv-1704-03443 | Solving the L1 regularized least square problem via a box-constrained smooth minimization | http://arxiv.org/abs/1704.03443 | id:1704.03443 author:Majid Mohammadi, Wout Hofman, Yaohua Tan, S. Hamid Mousavi category:math.OC cs.CV  published:2017-04-11 summary:In this paper, an equivalent smooth minimization for the L1 regularized least square problem is proposed. The proposed problem is a convex box-constrained smooth minimization which allows applying fast optimization methods to find its solution. Further, it is investigated that the property "the dual of dual is primal" holds for the L1 regularized least square problem. A solver for the smooth problem is proposed, and its affinity to the proximal gradient is shown. Finally, the experiments on L1 and total variation regularized problems are performed, and the corresponding results are reported. version:1
arxiv-1704-02798 | Bayesian Recurrent Neural Networks | http://arxiv.org/abs/1704.02798 | id:1704.02798 author:Meire Fortunato, Charles Blundell, Oriol Vinyals category:cs.LG stat.ML  published:2017-04-10 summary:In this work we explore a straightforward variational Bayes scheme for Recurrent Neural Networks. Firstly, we show that a simple adaptation of truncated backpropagation through time can yield good quality uncertainty estimates and superior regularisation at only a small extra computational cost during training. Secondly, we demonstrate how a novel kind of posterior approximation yields further improvements to the performance of Bayesian RNNs. We incorporate local gradient information into the approximate posterior to sharpen it around the current batch statistics. This technique is not exclusive to recurrent neural networks and can be applied more widely to train Bayesian neural networks. We also empirically demonstrate how Bayesian RNNs are superior to traditional RNNs on a language modelling benchmark and an image captioning task, as well as showing how each of these methods improve our model over a variety of other schemes for training them. We also introduce a new benchmark for studying uncertainty for language models so future methods can be easily compared. version:2
arxiv-1704-03432 | Forecasting Human Dynamics from Static Images | http://arxiv.org/abs/1704.03432 | id:1704.03432 author:Yu-Wei Chao, Jimei Yang, Brian Price, Scott Cohen, Jia Deng category:cs.CV  published:2017-04-11 summary:This paper presents the first study on forecasting human dynamics from static images. The problem is to input a single RGB image and generate a sequence of upcoming human body poses in 3D. To address the problem, we propose the 3D Pose Forecasting Network (3D-PFNet). Our 3D-PFNet integrates recent advances on single-image human pose estimation and sequence prediction, and converts the 2D predictions into 3D space. We train our 3D-PFNet using a three-step training strategy to leverage a diverse source of training data, including image and video based human pose datasets and 3D motion capture (MoCap) data. We demonstrate competitive performance of our 3D-PFNet on 2D pose forecasting and 3D pose recovery through quantitative and qualitative results. version:1
arxiv-1704-03421 | Efficient Large Scale Clustering based on data partitioning | http://arxiv.org/abs/1704.03421 | id:1704.03421 author:Malika Bendechache, Nhien-An Le-Khac, M-Tahar Kechadi category:cs.DB cs.LG  published:2017-04-11 summary:Clustering techniques are very attractive for extracting and identifying patterns in datasets. However, their application to very large spatial datasets presents numerous challenges such as high-dimensionality data, heterogeneity, and high complexity of some algorithms. For instance, some algorithms may have linear complexity but they require the domain knowledge in order to determine their input parameters. Distributed clustering techniques constitute a very good alternative to the big data challenges (e.g.,Volume, Variety, Veracity, and Velocity). Usually these techniques consist of two phases. The first phase generates local models or patterns and the second one tends to aggregate the local results to obtain global models. While the first phase can be executed in parallel on each site and, therefore, efficient, the aggregation phase is complex, time consuming and may produce incorrect and ambiguous global clusters and therefore incorrect models. In this paper we propose a new distributed clustering approach to deal efficiently with both phases; generation of local results and generation of global models by aggregation. For the first phase, our approach is capable of analysing the datasets located in each site using different clustering techniques. The aggregation phase is designed in such a way that the final clusters are compact and accurate while the overall process is efficient in time and memory allocation. For the evaluation, we use two well-known clustering algorithms; K-Means and DBSCAN. One of the key outputs of this distributed clustering technique is that the number of global clusters is dynamic; no need to be fixed in advance. Experimental results show that the approach is scalable and produces high quality results. version:1
arxiv-1704-03414 | A-Fast-RCNN: Hard Positive Generation via Adversary for Object Detection | http://arxiv.org/abs/1704.03414 | id:1704.03414 author:Xiaolong Wang, Abhinav Shrivastava, Abhinav Gupta category:cs.CV  published:2017-04-11 summary:How do we learn an object detector that is invariant to occlusions and deformations? Our current solution is to use a data-driven strategy -- collect large-scale datasets which have object instances under different conditions. The hope is that the final classifier can use these examples to learn invariances. But is it really possible to see all the occlusions in a dataset? We argue that like categories, occlusions and object deformations also follow a long-tail. Some occlusions and deformations are so rare that they hardly happen; yet we want to learn a model invariant to such occurrences. In this paper, we propose an alternative solution. We propose to learn an adversarial network that generates examples with occlusions and deformations. The goal of the adversary is to generate examples that are difficult for the object detector to classify. In our framework both the original detector and adversary are learned in a joint manner. Our experimental results indicate a 2.3% mAP boost on VOC07 and a 2.6% mAP boost on VOC2012 object detection challenge compared to the Fast-RCNN pipeline. We also release the code for this paper. version:1
arxiv-1704-03407 | What we really want to find by Sentiment Analysis: The Relationship between Computational Models and Psychological State | http://arxiv.org/abs/1704.03407 | id:1704.03407 author:Hwiyeol Jo, Soo-Min Kim, Jeong Ryu category:cs.CL cs.IR  published:2017-04-11 summary:As the first step to model emotional state of a person, we build sentiment analysis models with existing deep neural network algorithms and compare the models with psychological measurements to enlighten the relationship. In the experiments, we first examined psychological state of 64 participants and asked them to summarize the story of a book, Chronicle of a Death Foretold (Marquez, 1981). Secondly, we trained models using crawled 365,802 movie review data; then we evaluated participants' summaries using the pretrained model as a concept of transfer learning. With the background that emotion affects on memories, we investigated the relationship between the evaluation score of the summaries from computational models and the examined psychological measurements. The result shows that although CNN performed the best among other deep neural network algorithms (LSTM, GRU), its results are not related to the psychological state. Rather, GRU shows more explainable results depending on the psychological state. The contribution of this paper can be summarized as follows: (1) we enlighten the relationship between computational models and psychological measurements. (2) we suggest this framework as objective methods to evaluate the emotion; the real sentiment analysis of a person. version:1
arxiv-1704-03404 | ENWalk: Learning Network Features for Spam Detection in Twitter | http://arxiv.org/abs/1704.03404 | id:1704.03404 author:K C Santosh, Suman Kalyan Maity, Arjun Mukherjee category:cs.LG cs.SI  published:2017-04-11 summary:Social medias are increasing their influence with the vast public information leading to their active use for marketing by the companies and organizations. Such marketing promotions are difficult to identify unlike the traditional medias like TV and newspaper. So, it is very much important to identify the promoters in the social media. Although, there are active ongoing researches, existing approaches are far from solving the problem. To identify such imposters, it is very much important to understand their strategies of social circle creation and dynamics of content posting. Are there any specific spammer types? How successful are each types? We analyze these questions in the light of social relationships in Twitter. Our analyses discover two types of spammers and their relationships with the dynamics of content posts. Our results discover novel dynamics of spamming which are intuitive and arguable. We propose ENWalk, a framework to detect the spammers by learning the feature representations of the users in the social media. We learn the feature representations using the random walks biased on the spam dynamics. Experimental results on large-scale twitter network and the corresponding tweets show the effectiveness of our approach that outperforms the existing approaches version:1
arxiv-1704-02492 | Metric Learning in Codebook Generation of Bag-of-Words for Person Re-identification | http://arxiv.org/abs/1704.02492 | id:1704.02492 author:Lu Tian, Shengjin Wang category:cs.CV  published:2017-04-08 summary:Person re-identification is generally divided into two part: first how to represent a pedestrian by discriminative visual descriptors and second how to compare them by suitable distance metrics. Conventional methods isolate these two parts, the first part usually unsupervised and the second part supervised. The Bag-of-Words (BoW) model is a widely used image representing descriptor in part one. Its codebook is simply generated by clustering visual features in Euclidian space. In this paper, we propose to use part two metric learning techniques in the codebook generation phase of BoW. In particular, the proposed codebook is clustered under Mahalanobis distance which is learned supervised. Extensive experiments prove that our proposed method is effective. With several low level features extracted on superpixel and fused together, our method outperforms state-of-the-art on person re-identification benchmarks including VIPeR, PRID450S, and Market1501. version:2
arxiv-1704-03458 | Personalized Survival Predictions for Cardiac Transplantation via Trees of Predictors | http://arxiv.org/abs/1704.03458 | id:1704.03458 author:J. Yoon, W. R. Zame, A. Banerjee, M. Cadeiras, A. M. Alaa, M. van der Schaar category:stat.AP cs.LG  published:2017-04-11 summary:Given the limited pool of donor organs, accurate predictions of survival on the wait list and post transplantation are crucial for cardiac transplantation decisions and policy. However, current clinical risk scores do not yield accurate predictions. We develop a new methodology (ToPs, Trees of Predictors) built on the principle that specific predictors should be used for specific clusters within the target population. ToPs discovers these specific clusters of patients and the specific predictor that perform best for each cluster. In comparison with current clinical risk scoring systems, our method provides significant improvements in the prediction of survival time on the wait list and post transplantation. For example, in terms of 3 month survival for patients who were on the US patient wait list in the period 1985 to 2015, our method achieves AUC of 0.847, the best commonly used clinical risk score (MAGGIC) achieves 0.630. In terms of 3 month survival/mortality predictions (in comparison to MAGGIC), holding specificity at 80.0 percents, our algorithm correctly predicts survival for 1,228 (26.0 percents more patients out of 4,723 who actually survived, holding sensitivity at 80.0 percents, our algorithm correctly predicts mortality for 839 (33.0 percents) more patients out of 2,542 who did not survive. Our method achieves similar improvements for other time horizons and for predictions post transplantation. Therefore, we offer a more accurate, personalized approach to survival analysis that can benefit patients, clinicians and policymakers in making clinical decisions and setting clinical policy. Because risk prediction is widely used in diagnostic and prognostic clinical decision making across diseases and clinical specialties, the implications of our methods are far reaching. version:1
arxiv-1704-03379 | Deep Learning for Multi-Task Medical Image Segmentation in Multiple Modalities | http://arxiv.org/abs/1704.03379 | id:1704.03379 author:Pim Moeskops, Jelmer M. Wolterink, Bas H. M. van der Velden, Kenneth G. A. Gilhuijs, Tim Leiner, Max A. Viergever, Ivana Išgum category:cs.CV  published:2017-04-11 summary:Automatic segmentation of medical images is an important task for many clinical applications. In practice, a wide range of anatomical structures are visualised using different imaging modalities. In this paper, we investigate whether a single convolutional neural network (CNN) can be trained to perform different segmentation tasks. A single CNN is trained to segment six tissues in MR brain images, the pectoral muscle in MR breast images, and the coronary arteries in cardiac CTA. The CNN therefore learns to identify the imaging modality, the visualised anatomical structures, and the tissue classes. For each of the three tasks (brain MRI, breast MRI and cardiac CTA), this combined training procedure resulted in a segmentation performance equivalent to that of a CNN trained specifically for that task, demonstrating the high capacity of CNN architectures. Hence, a single system could be used in clinical practice to automatically perform diverse segmentation tasks without task-specific training. version:1
arxiv-1704-03375 | Reconstruction of~3-D Rigid Smooth Curves Moving Free when Two Traceable Points Only are Available | http://arxiv.org/abs/1704.03375 | id:1704.03375 author:Mieczysław A. Kłopotek category:cs.CV cs.GR  published:2017-04-11 summary:This paper extends previous research in that sense that for orthogonal projections of rigid smooth (true-3D) curves moving totally free it reduces the number of required traceable points to two only (the best results known so far to the author are 3 points from free motion and 2 for motion restricted to rotation around a fixed direction and and 2 for motion restricted to influence of a homogeneous force field). The method used is exploitation of information on tangential projections. It discusses also possibility of simplification of reconstruction of flat curves moving free for prospective projections. version:1
arxiv-1704-03373 | Quality Aware Network for Set to Set Recognition | http://arxiv.org/abs/1704.03373 | id:1704.03373 author:Yu Liu, Junjie Yan, Wanli Ouyang category:cs.CV cs.AI  published:2017-04-11 summary:This paper targets on the problem of set to set recognition, which learns the metric between two image sets. Images in each set belong to the same identity. Since images in a set can be complementary, they hopefully lead to higher accuracy in practical applications. However, the quality of each sample cannot be guaranteed, and samples with poor quality will hurt the metric. In this paper, the quality aware network (QAN) is proposed to confront this problem, where the quality of each sample can be automatically learned although such information is not explicitly provided in the training stage. The network has two branches, where the first branch extracts appearance feature embedding for each sample and the other branch predicts quality score for each sample. Features and quality scores of all samples in a set are then aggregated to generate the final feature embedding. We show that the two branches can be trained in an end-to-end manner given only the set-level identity annotation. Analysis on gradient spread of this mechanism indicates that the quality learned by the network is beneficial to set-to-set recognition and simplifies the distribution that the network needs to fit. Experiments on both face verification and person re-identification show advantages of the proposed QAN. The source code and network structure can be downloaded at https://github.com/sciencefans/Quality-Aware-Network. version:1
arxiv-1704-03371 | Sublinear Time Low-Rank Approximation of Positive Semidefinite Matrices | http://arxiv.org/abs/1704.03371 | id:1704.03371 author:Cameron Musco, David P. Woodruff category:cs.DS cs.LG math.NA  published:2017-04-11 summary:We show how to compute a relative-error low-rank approximation to any positive semidefinite (PSD) matrix in sublinear time, i.e., for any $n \times n$ PSD matrix $A$, in $\tilde O(n \cdot poly(k/\epsilon))$ time we output a rank-$k$ matrix $B$, in factored form, for which $\ A-B\ _F^2 \leq (1+\epsilon)\ A-A_k\ _F^2$, where $A_k$ is the best rank-$k$ approximation to $A$. When $k$ and $1/\epsilon$ are not too large compared to the sparsity of $A$, our algorithm does not need to read all entries of the matrix. Hence, we significantly improve upon previous $nnz(A)$ time algorithms based on oblivious subspace embeddings, and bypass an $nnz(A)$ time lower bound for general matrices (where $nnz(A)$ denotes the number of non-zero entries in the matrix). We prove time lower bounds for low-rank approximation of PSD matrices, showing that our algorithm is close to optimal. Finally, we extend our techniques to give sublinear time algorithms for low-rank approximation of $A$ in the (often stronger) spectral norm metric $\ A-B\ _2^2$ and for ridge regression on PSD matrices. version:1
arxiv-1704-03354 | Optimized Data Pre-Processing for Discrimination Prevention | http://arxiv.org/abs/1704.03354 | id:1704.03354 author:Flavio P. Calmon, Dennis Wei, Karthikeyan Natesan Ramamurthy, Kush R. Varshney category:stat.ML cs.CY cs.IT math.IT  published:2017-04-11 summary:Non-discrimination is a recognized objective in algorithmic decision making. In this paper, we introduce a novel probabilistic formulation of data pre-processing for reducing discrimination. We propose a convex optimization for learning a data transformation with three goals: controlling discrimination, limiting distortion in individual data samples, and preserving utility. We characterize the impact of limited sample size in accomplishing this objective, and apply two instances of the proposed optimization to datasets, including one on real-world criminal recidivism. The results demonstrate that all three criteria can be simultaneously achieved and also reveal interesting patterns of bias in American society. version:1
arxiv-1704-03298 | The MATLAB Toolbox SciXMiner: User's Manual and Programmer's Guide | http://arxiv.org/abs/1704.03298 | id:1704.03298 author:Ralf Mikut, Andreas Bartschat, Wolfgang Doneit, Jorge Ángel González Ordiano, Benjamin Schott, Johannes Stegmaier, Simon Waczowicz, Markus Reischl category:cs.LG  published:2017-04-11 summary:The Matlab toolbox SciXMiner is designed for the visualization and analysis of time series and features with a special focus to classification problems. It was developed at the Institute of Applied Computer Science of the Karlsruhe Institute of Technology (KIT), a member of the Helmholtz Association of German Research Centres in Germany. The aim was to provide an open platform for the development and improvement of data mining methods and its applications to various medical and technical problems. SciXMiner bases on Matlab (tested for the version 2017a). Many functions do not require additional standard toolboxes but some parts of Signal, Statistics and Wavelet toolboxes are used for special cases. The decision to a Matlab-based solution was made to use the wide mathematical functionality of this package provided by The Mathworks Inc. SciXMiner is controlled by a graphical user interface (GUI) with menu items and control elements like popup lists, checkboxes and edit elements. This makes it easier to work with SciXMiner for inexperienced users. Furthermore, an automatization and batch standardization of analyzes is possible using macros. The standard Matlab style using the command line is also available. SciXMiner is an open source software. The download page is http://sourceforge.net/projects/SciXMiner. It is licensed under the conditions of the GNU General Public License (GNU-GPL) of The Free Software Foundation. version:1
arxiv-1704-03296 | Interpretable Explanations of Black Boxes by Meaningful Perturbation | http://arxiv.org/abs/1704.03296 | id:1704.03296 author:Ruth Fong, Andrea Vedaldi category:cs.CV cs.AI cs.LG stat.ML  published:2017-04-11 summary:As machine learning algorithms are increasingly applied to high impact yet high risk tasks, e.g. problems in health, it is critical that researchers can explain how such algorithms arrived at their predictions. In recent years, a number of image saliency methods have been developed to summarize where highly complex neural networks "look" in an image for evidence for their predictions. However, these techniques are limited by their heuristic nature and architectural constraints. In this paper, we make two main contributions: First, we propose a general framework for learning different kinds of explanations for any black box algorithm. Second, we introduce a paradigm that learns the minimally salient part of an image by directly editing it and learning from the corresponding changes to its output. Unlike previous works, our method is model-agnostic and testable because it is grounded in replicable image perturbations. version:1
arxiv-1704-03295 | Automatic segmentation of MR brain images with a convolutional neural network | http://arxiv.org/abs/1704.03295 | id:1704.03295 author:Pim Moeskops, Max A. Viergever, Adriënne M. Mendrik, Linda S. de Vries, Manon J. N. L. Benders, Ivana Išgum category:cs.CV  published:2017-04-11 summary:Automatic segmentation in MR brain images is important for quantitative analysis in large-scale studies with images acquired at all ages. This paper presents a method for the automatic segmentation of MR brain images into a number of tissue classes using a convolutional neural network. To ensure that the method obtains accurate segmentation details as well as spatial consistency, the network uses multiple patch sizes and multiple convolution kernel sizes to acquire multi-scale information about each voxel. The method is not dependent on explicit features, but learns to recognise the information that is important for the classification based on training data. The method requires a single anatomical MR image only. The segmentation method is applied to five different data sets: coronal T2-weighted images of preterm infants acquired at 30 weeks postmenstrual age (PMA) and 40 weeks PMA, axial T2- weighted images of preterm infants acquired at 40 weeks PMA, axial T1-weighted images of ageing adults acquired at an average age of 70 years, and T1-weighted images of young adults acquired at an average age of 23 years. The method obtained the following average Dice coefficients over all segmented tissue classes for each data set, respectively: 0.87, 0.82, 0.84, 0.86 and 0.91. The results demonstrate that the method obtains accurate segmentations in all five sets, and hence demonstrates its robustness to differences in age and acquisition protocol. version:1
arxiv-1704-03285 | Online Video Deblurring via Dynamic Temporal Blending Network | http://arxiv.org/abs/1704.03285 | id:1704.03285 author:Tae Hyun Kim, Kyoung Mu Lee, Bernhard Schölkopf, Michael Hirsch category:cs.CV  published:2017-04-11 summary:State-of-the-art video deblurring methods are capable of removing non-uniform blur caused by unwanted camera shake and/or object motion in dynamic scenes. However, most existing methods are based on batch processing and thus need access to all recorded frames, rendering them computationally demanding and time consuming and thus limiting their practical use. In contrast, we propose an online (sequential) video deblurring method based on a spatio-temporal recurrent network that allows for real-time performance. In particular, we introduce a novel architecture which extends the receptive field while keeping the overall size of the network small to enable fast execution. In doing so, our network is able to remove even large blur caused by strong camera shake and/or fast moving objects. Furthermore, we propose a novel network layer that enforces temporal consistency between consecutive frames by dynamic temporal blending which compares and adaptively (at test time) shares features obtained at different time steps. We show the superiority of the proposed method in an extensive experimental evaluation. version:1
arxiv-1704-03801 | Ensemble classifier approach in breast cancer detection and malignancy grading- A review | http://arxiv.org/abs/1704.03801 | id:1704.03801 author:Deepti Ameta category:cs.CV  published:2017-04-11 summary:The diagnosed cases of Breast cancer is increasing annually and unfortunately getting converted into a high mortality rate. Cancer, at the early stages, is hard to detect because the malicious cells show similar properties (density) as shown by the non-malicious cells. The mortality ratio could have been minimized if the breast cancer could have been detected in its early stages. But the current systems have not been able to achieve a fully automatic system which is not just capable of detecting the breast cancer but also can detect the stage of it. Estimation of malignancy grading is important in diagnosing the degree of growth of malicious cells as well as in selecting a proper therapy for the patient. Therefore, a complete and efficient clinical decision support system is proposed which is capable of achieving breast cancer malignancy grading scheme very efficiently. The system is based on Image processing and machine learning domains. Classification Imbalance problem, a machine learning problem, occurs when instances of one class is much higher than the instances of the other class resulting in an inefficient classification of samples and hence a bad decision support system. Therefore EUSBoost, ensemble based classifier is proposed which is efficient and is able to outperform other classifiers as it takes the benefits of both-boosting algorithm with Random Undersampling techniques. Also comparison of EUSBoost with other techniques is shown in the paper. version:1
arxiv-1704-03279 | Unfolding and Shrinking Neural Machine Translation Ensembles | http://arxiv.org/abs/1704.03279 | id:1704.03279 author:Felix Stahlberg, Bill Byrne category:cs.CL  published:2017-04-11 summary:Ensembling is a well-known technique in neural machine translation (NMT). Instead of a single neural net, multiple neural nets with the same topology are trained separately, and the decoder generates predictions by averaging over the individual models. Ensembling often improves the quality of the generated translations drastically. However, it is not suitable for production systems because it is cumbersome and slow. This work aims to reduce the runtime to be on par with a single system without compromising the translation quality. First, we show that the ensemble can be unfolded into a single large neural network which imitates the output of the ensemble system. We show that unfolding can already improve the runtime in practice since more work can be done on the GPU. We proceed by describing a set of techniques to shrink the unfolded network by reducing the dimensionality of layers. On Japanese-English we report that the resulting network has the size and decoding speed of a single NMT network but performs on the level of a 3-ensemble system. version:1
arxiv-1704-03273 | Simultaneous Stereo Video Deblurring and Scene Flow Estimation | http://arxiv.org/abs/1704.03273 | id:1704.03273 author:Liyuan Pan, Yuchao Dai, Miaomiao Liu, Fatih Porikli category:cs.CV  published:2017-04-11 summary:Videos for outdoor scene often show unpleasant blur effects due to the large relative motion between the camera and the dynamic objects and large depth variations. Existing works typically focus monocular video deblurring. In this paper, we propose a novel approach to deblurring from stereo videos. In particular, we exploit the piece-wise planar assumption about the scene and leverage the scene flow information to deblur the image. Unlike the existing approach [31] which used a pre-computed scene flow, we propose a single framework to jointly estimate the scene flow and deblur the image, where the motion cues from scene flow estimation and blur information could reinforce each other, and produce superior results than the conventional scene flow estimation or stereo deblurring methods. We evaluate our method extensively on two available datasets and achieve significant improvement in flow estimation and removing the blur effect over the state-of-the-art methods. version:1
arxiv-1704-02598 | A Sample Complexity Measure with Applications to Learning Optimal Auctions | http://arxiv.org/abs/1704.02598 | id:1704.02598 author:Vasilis Syrgkanis category:cs.GT cs.LG math.ST stat.TH  published:2017-04-09 summary:We introduce a new sample complexity measure, which we refer to as split-sample growth rate. For any hypothesis $H$ and for any sample $S$ of size $m$, the split-sample growth rate $\hat{\tau}_H(m)$ counts how many different hypotheses can empirical risk minimization output on any sub-sample of $S$ of size $m/2$. We show that the expected generalization error is upper bounded by $O\left(\sqrt{\frac{\log(\hat{\tau}_H(2m))}{m}}\right)$. Our result is enabled by a strengthening of the Rademacher complexity analysis of the expected generalization error. We show that this sample complexity measure, greatly simplifies the analysis of the sample complexity of optimal auction design, for many auction classes studied in the literature. Their sample complexity can be derived solely by noticing that in these auction classes, ERM on any sample or sub-sample will pick parameters that are equal to one of the points in the sample. version:2
arxiv-1704-02268 | Deep Unsupervised Similarity Learning using Partially Ordered Sets | http://arxiv.org/abs/1704.02268 | id:1704.02268 author:Miguel A Bautista, Artsiom Sanakoyeu, Björn Ommer category:cs.CV  published:2017-04-07 summary:Unsupervised learning of visual similarities is of paramount importance to computer vision, particularly due to lacking training data for fine-grained similarities. Deep learning of similarities is often based on relationships between pairs or triplets of samples. Many of these relations are unreliable and mutually contradicting, implying inconsistencies when trained without supervision information that relates different tuples or triplets to each other. To overcome this problem, we use local estimates of reliable (dis-)similarities to initially group samples into compact surrogate classes and use local partial orders of samples to classes to link classes to each other. Similarity learning is then formulated as a partial ordering task with soft correspondences of all samples to classes. Adopting a strategy of self-supervision, a CNN is trained to optimally represent samples in a mutually consistent manner while updating the classes. The similarity learning and grouping procedure are integrated in a single model and optimized jointly. The proposed unsupervised approach shows competitive performance on detailed pose estimation and object classification. version:3
arxiv-1704-03264 | Learning Deep CNN Denoiser Prior for Image Restoration | http://arxiv.org/abs/1704.03264 | id:1704.03264 author:Kai Zhang, Wangmeng Zuo, Shuhang Gu, Lei Zhang category:cs.CV  published:2017-04-11 summary:Model-based optimization methods and discriminative learning methods have been the two dominant strategies for solving various inverse problems in low-level vision. Typically, those two kinds of methods have their respective merits and drawbacks, e.g., model-based optimization methods are flexible for handling different inverse problems but are usually time-consuming with sophisticated priors for the purpose of good performance; in the meanwhile, discriminative learning methods have fast testing speed but their application range is greatly restricted by the specialized task. Recent works have revealed that, with the aid of variable splitting techniques, denoiser prior can be plugged in as a modular part of model-based optimization methods to solve other inverse problems (e.g., deblurring). Such an integration induces considerable advantage when the denoiser is obtained via discriminative learning. However, the study of integration with fast discriminative denoiser prior is still lacking. To this end, this paper aims to train a set of fast and effective CNN (convolutional neural network) denoisers and integrate them into model-based optimization method to solve other inverse problems. Experimental results demonstrate that the learned set of denoisers not only achieve promising Gaussian denoising results but also can be used as prior to deliver good performance for various low-level vision applications. version:1
arxiv-1704-03242 | Automatic Keyword Extraction for Text Summarization: A Survey | http://arxiv.org/abs/1704.03242 | id:1704.03242 author:Santosh Kumar Bharti, Korra Sathya Babu category:cs.CL  published:2017-04-11 summary:In recent times, data is growing rapidly in every domain such as news, social media, banking, education, etc. Due to the excessiveness of data, there is a need of automatic summarizer which will be capable to summarize the data especially textual data in original document without losing any critical purposes. Text summarization is emerged as an important research area in recent past. In this regard, review of existing work on text summarization process is useful for carrying out further research. In this paper, recent literature on automatic keyword extraction and text summarization are presented since text summarization process is highly depend on keyword extraction. This literature includes the discussion about different methodology used for keyword extraction and text summarization. It also discusses about different databases used for text summarization in several domains along with evaluation matrices. Finally, it discusses briefly about issues and research challenges faced by researchers along with future direction. version:1
arxiv-1704-03225 | Reconstruction of three-dimensional porous media using generative adversarial neural networks | http://arxiv.org/abs/1704.03225 | id:1704.03225 author:Lukas Mosser, Olivier Dubrule, Martin J. Blunt category:cs.CV cond-mat.mtrl-sci physics.flu-dyn physics.geo-ph  published:2017-04-11 summary:To evaluate the variability of multi-phase flow properties of porous media at the pore scale, it is necessary to acquire a number of representative samples of the void-solid structure. While modern x-ray computer tomography has made it possible to extract three-dimensional images of the pore space, assessment of the variability in the inherent material properties is often experimentally not feasible. We present a novel method to reconstruct the solid-void structure of porous media by applying a generative neural network that allows an implicit description of the probability distribution represented by three-dimensional image datasets. We show, by using an adversarial learning approach for neural networks, that this method of unsupervised learning is able to generate representative samples of porous media that honor their statistics. We successfully compare measures of pore morphology, such as the Euler characteristic, two-point statistics and directional single-phase permeability of synthetic realizations with the calculated properties of a bead pack, Berea sandstone, and Ketton limestone. Results show that GANs can be used to reconstruct high-resolution three-dimensional images of porous media at different scales that are representative of the morphology of the images used to train the neural network. The fully convolutional nature of the trained neural network allows the generation of large samples while maintaining computational efficiency. Compared to classical stochastic methods of image reconstruction, the implicit representation of the learned data distribution can be stored and reused to generate multiple realizations of the pore structure very rapidly. version:1
arxiv-1704-03223 | Persian Wordnet Construction using Supervised Learning | http://arxiv.org/abs/1704.03223 | id:1704.03223 author:Zahra Mousavi, Heshaam Faili category:cs.CL cs.LG stat.ML  published:2017-04-11 summary:This paper presents an automated supervised method for Persian wordnet construction. Using a Persian corpus and a bi-lingual dictionary, the initial links between Persian words and Princeton WordNet synsets have been generated. These links will be discriminated later as correct or incorrect by employing seven features in a trained classification system. The whole method is just a classification system, which has been trained on a train set containing FarsNet as a set of correct instances. State of the art results on the automatically derived Persian wordnet is achieved. The resulted wordnet with a precision of 91.18% includes more than 16,000 words and 22,000 synsets. version:1
arxiv-1704-03217 | Pyramidal Gradient Matching for Optical Flow Estimation | http://arxiv.org/abs/1704.03217 | id:1704.03217 author:Yuanwei Li category:cs.CV  published:2017-04-11 summary:Initializing optical flow field by either sparse descriptor matching or dense patch matches has been proved to be particularly useful for capturing large displacements. In this paper, we present a pyramidal gradient matching approach that can provide dense matches for highly accurate and efficient optical flow estimation. A novel contribution of our method is that image gradient is used to describe image patches and proved to be able to produce robust matching. Therefore, our method is more efficient than methods that adopt special features (like SIFT) or patch distance metric. Moreover, we find that image gradient is scalable for optical flow estimation, which means we can use different levels of gradient feature (for example, full gradients or only direction information of gradients) to obtain different complexity without dramatic changes in accuracy. Another contribution is that we uncover the secrets of limited PatchMatch through a thorough analysis and design a pyramidal matching framework based these secrets. Our pyramidal matching framework is aimed at robust gradient matching and effective to grow inliers and reject outliers. In this framework, we present some special enhancements for outlier filtering in gradient matching. By initializing EpicFlow with our matches, experimental results show that our method is efficient and robust (ranking 1st on both clean pass and final pass of MPI Sintel dataset among published methods). version:1
arxiv-1704-03205 | On Feature Reduction using Deep Learning for Trend Prediction in Finance | http://arxiv.org/abs/1704.03205 | id:1704.03205 author:Luigi Troiano, Elena Mejuto, Pravesh Kriplani category:q-fin.TR cs.LG  published:2017-04-11 summary:One of the major advantages in using Deep Learning for Finance is to embed a large collection of information into investment decisions. A way to do that is by means of compression, that lead us to consider a smaller feature space. Several studies are proving that non-linear feature reduction performed by Deep Learning tools is effective in price trend prediction. The focus has been put mainly on Restricted Boltzmann Machines (RBM) and on output obtained by them. Few attention has been payed to Auto-Encoders (AE) as an alternative means to perform a feature reduction. In this paper we investigate the application of both RBM and AE in more general terms, attempting to outline how architectural and input space characteristics can affect the quality of prediction. version:1
arxiv-1704-03188 | Simplified Stochastic Feedforward Neural Networks | http://arxiv.org/abs/1704.03188 | id:1704.03188 author:Kimin Lee, Jaehyung Kim, Song Chong, Jinwoo Shin category:cs.LG  published:2017-04-11 summary:It has been believed that stochastic feedforward neural networks (SFNNs) have several advantages beyond deterministic deep neural networks (DNNs): they have more expressive power allowing multi-modal mappings and regularize better due to their stochastic nature. However, training large-scale SFNN is notoriously harder. In this paper, we aim at developing efficient training methods for SFNN, in particular using known architectures and pre-trained parameters of DNN. To this end, we propose a new intermediate stochastic model, called Simplified-SFNN, which can be built upon any baseline DNNand approximates certain SFNN by simplifying its upper latent units above stochastic ones. The main novelty of our approach is in establishing the connection between three models, i.e., DNN->Simplified-SFNN->SFNN, which naturally leads to an efficient training procedure of the stochastic models utilizing pre-trained parameters of DNN. Using several popular DNNs, we show how they can be effectively transferred to the corresponding stochastic models for both multi-modal and classification tasks on MNIST, TFD, CASIA, CIFAR-10, CIFAR-100 and SVHN datasets. In particular, we train a stochastic model of 28 layers and 36 million parameters, where training such a large-scale stochastic network is significantly challenging without using Simplified-SFNN version:1
arxiv-1704-03173 | Mining Object Parts from CNNs via Active Question-Answering | http://arxiv.org/abs/1704.03173 | id:1704.03173 author:Quanshi Zhang, Ruiming Cao, Ying Nian Wu, Song-Chun Zhu category:cs.CV  published:2017-04-11 summary:Given a convolutional neural network (CNN) that is pre-trained for object classification, this paper proposes to use active question-answering to semanticize neural patterns in conv-layers of the CNN and mine part concepts. For each part concept, we mine neural patterns in the pre-trained CNN, which are related to the target part, and use these patterns to construct an And-Or graph (AOG) to represent a four-layer semantic hierarchy of the part. As an interpretable model, the AOG associates different CNN units with different explicit object parts. We use an active human-computer communication to incrementally grow such an AOG on the pre-trained CNN as follows. We allow the computer to actively identify objects, whose neural patterns cannot be explained by the current AOG. Then, the computer asks human about the unexplained objects, and uses the answers to automatically discover certain CNN patterns corresponding to the missing knowledge. We incrementally grow the AOG to encode new knowledge discovered during the active-learning process. In experiments, our method exhibits high learning efficiency. Our method uses about 1/6-1/3 of the part annotations for training, but achieves similar or better part-localization performance than fast-RCNN methods. version:1
arxiv-1704-03169 | Later-stage Minimum Bayes-Risk Decoding for Neural Machine Translation | http://arxiv.org/abs/1704.03169 | id:1704.03169 author:Raphael Shu, Hideki Nakayama category:cs.CL  published:2017-04-11 summary:For extended periods of time, sequence generation models rely on beam search algorithm to generate output sequence. However, the correctness of beam search degrades when the a model is over-confident about a suboptimal prediction. In this paper, we propose to perform minimum Bayes-risk (MBR) decoding for some extra steps at a later stage. In order to speed up MBR decoding, we compute the Bayes risks on GPU in batch mode. In our experiments, we found that MBR reranking works with a large beam size. Later-stage MBR decoding is shown to outperform simple MBR reranking in machine translation tasks. version:1
arxiv-1704-03165 | struc2vec: Learning Node Representations from Structural Identity | http://arxiv.org/abs/1704.03165 | id:1704.03165 author:Daniel R. Figueiredo, Leonardo F. R. Ribeiro, Pedro H. P. Saverese category:cs.SI cs.LG stat.ML  published:2017-04-11 summary:Structural identity is a concept of symmetry in which network nodes are identified according to the network structure and their relationship to other nodes. Structural identity has been studied in theory and practice over the past decades, but has only recently been addressed with techniques from representational learning. This work presents struc2vec, a novel and flexible framework for learning latent representations of node's structural identity. struc2vec assesses structural similarity without using node or edge attributes, uses a hierarchy to measure similarity at different scales, and constructs a multilayer graph to encode the structural similarities and generate structural context for nodes. Numerical experiments indicate that state-of-the-art techniques for learning node representations fail in capturing stronger notions of structural identity, while struc2vec exhibits much superior performance in this task, as it overcomes limitations of prior techniques. version:1
arxiv-1704-03155 | EAST: An Efficient and Accurate Scene Text Detector | http://arxiv.org/abs/1704.03155 | id:1704.03155 author:Xinyu Zhou, Cong Yao, He Wen, Yuzhi Wang, Shuchang Zhou, Weiran He, Jiajun Liang category:cs.CV  published:2017-04-11 summary:Previous approaches for scene text detection have already achieved promising performances across various benchmarks. However, they usually fall short when dealing with challenging scenarios, even when equipped with deep neural network models, because the overall performance is determined by the interplay of multiple stages and components in the pipelines. In this work, we propose a simple yet powerful pipeline that yields fast and accurate text detection in natural scenes. The pipeline directly predicts words or text lines of arbitrary orientations and quadrilateral shapes in full images, eliminating unnecessary intermediate steps (e.g., candidate aggregation and word partitioning), with a single neural network. The simplicity of our pipeline allows concentrating efforts on designing loss functions and neural network architecture. Experiments on standard datasets including ICDAR 2015, COCO-Text and MSRA-TD500 demonstrate that the proposed algorithm significantly outperforms state-of-the-art methods in terms of both accuracy and efficiency. On the ICDAR 2015 dataset, the proposed algorithm achieves an F-score of 0.7820 at 13.2fps at 720p resolution. version:1
arxiv-1704-03152 | Deep Multimodal Representation Learning from Temporal Data | http://arxiv.org/abs/1704.03152 | id:1704.03152 author:Xitong Yang, Palghat Ramesh, Radha Chitta, Sriganesh Madhvanath, Edgar A. Bernal, Jiebo Luo category:cs.CV  published:2017-04-11 summary:In recent years, Deep Learning has been successfully applied to multimodal learning problems, with the aim of learning useful joint representations in data fusion applications. When the available modalities consist of time series data such as video, audio and sensor signals, it becomes imperative to consider their temporal structure during the fusion process. In this paper, we propose the Correlational Recurrent Neural Network (CorrRNN), a novel temporal fusion model for fusing multiple input modalities that are inherently temporal in nature. Key features of our proposed model include: (i) simultaneous learning of the joint representation and temporal dependencies between modalities, (ii) use of multiple loss terms in the objective function, including a maximum correlation loss term to enhance learning of cross-modal information, and (iii) the use of an attention model to dynamically adjust the contribution of different input modalities to the joint representation. We validate our model via experimentation on two different tasks: video- and sensor-based activity classification, and audio-visual speech recognition. We empirically analyze the contributions of different components of the proposed CorrRNN model, and demonstrate its robustness, effectiveness and state-of-the-art performance on multiple datasets. version:1
arxiv-1612-01895 | Multimodal Transfer: A Hierarchical Deep Convolutional Neural Network for Fast Artistic Style Transfer | http://arxiv.org/abs/1612.01895 | id:1612.01895 author:Xin Wang, Geoffrey Oxholm, Da Zhang, Yuan-Fang Wang category:cs.CV  published:2016-11-17 summary:Transferring artistic styles onto everyday photographs has become an extremely popular task in both academia and industry. Recently, offline training has replaced on-line iterative optimization, enabling nearly real-time stylization. When those stylization networks are applied directly to high-resolution images, however, the style of localized regions often appears less similar to the desired artistic style. This is because the transfer process fails to capture small, intricate textures and maintain correct texture scales of the artworks. Here we propose a multimodal convolutional neural network that takes into consideration faithful representations of both color and luminance channels, and performs stylization hierarchically with multiple losses of increasing scales. Compared to state-of-the-art networks, our network can also perform style transfer in nearly real-time by conducting much more sophisticated training offline. By properly handling style and texture cues at multiple scales using several modalities, we can transfer not just large-scale, obvious style cues but also subtle, exquisite ones. That is, our scheme can generate results that are visually pleasing and more similar to multiple desired artistic styles with color and texture cues at multiple scales. version:2
arxiv-1704-03144 | Parametric Gaussian Process Regression for Big Data | http://arxiv.org/abs/1704.03144 | id:1704.03144 author:Maziar Raissi category:stat.ML cs.LG  published:2017-04-11 summary:This work introduces the concept of parametric Gaussian processes (PGPs), which is built upon the seemingly self-contradictory idea of making Gaussian processes parametric. Parametric Gaussian processes, by construction, are designed to operate in "big data" regimes where one is interested in quantifying the uncertainty associated with noisy data. The proposed methodology circumvents the well-established need for stochastic variational inference, a scalable algorithm for approximating posterior distributions. The effectiveness of the proposed approach is demonstrated using an illustrative example with simulated data and a benchmark dataset in the airline industry with approximately $6$ million records. version:1
arxiv-1704-03141 | Federated Tensor Factorization for Computational Phenotyping | http://arxiv.org/abs/1704.03141 | id:1704.03141 author:Yejin Kim, Jimeng Sun, Hwanjo Yu, Xiaoqian Jiang category:cs.LG stat.ML  published:2017-04-11 summary:Tensor factorization models offer an effective approach to convert massive electronic health records into meaningful clinical concepts (phenotypes) for data analysis. These models need a large amount of diverse samples to avoid population bias. An open challenge is how to derive phenotypes jointly across multiple hospitals, in which direct patient-level data sharing is not possible (e.g., due to institutional policies). In this paper, we developed a novel solution to enable federated tensor factorization for computational phenotyping without sharing patient-level data. We developed secure data harmonization and federated computation procedures based on alternating direction method of multipliers (ADMM). Using this method, the multiple hospitals iteratively update tensors and transfer secure summarized information to a central server, and the server aggregates the information to generate phenotypes. We demonstrated with real medical datasets that our method resembles the centralized training model (based on combined datasets) in terms of accuracy and phenotypes discovery while respecting privacy. version:1
arxiv-1704-03140 | Restoration of Atmospheric Turbulence-distorted Images via RPCA and Quasiconformal Maps | http://arxiv.org/abs/1704.03140 | id:1704.03140 author:Chun Pong Lau, Yu Hin Lai, Lok Ming Lui category:cs.CV cs.CG cs.GR  published:2017-04-11 summary:We address the problem of restoring a high-quality image from an observed image sequence strongly distorted by atmospheric turbulence. A novel algorithm is proposed in this paper to reduce geometric distortion as well as space-and-time-varying blur due to strong turbulence. By considering a suitable energy functional, our algorithm first obtains a sharp reference image and a subsampled image sequence containing sharp and mildly distorted image frames with respect to the reference image. The subsampled image sequence is then stabilized by applying the Robust Principal Component Analysis (RPCA) on the deformation fields between image frames and warping the image frames by a quasiconformal map associated with the low-rank part of the deformation matrix. After image frames are registered to the reference image, the low-rank part of them are deblurred via a blind deconvolution, and the deblurred frames are then fused with the enhanced sparse part. Experiments have been carried out on both synthetic and real turbulence-distorted video. Results demonstrate that our method is effective in alleviating distortions and blur, restoring image details and enhancing visual quality. version:1
arxiv-1704-01168 | Learning Approximately Objective Priors | http://arxiv.org/abs/1704.01168 | id:1704.01168 author:Eric Nalisnick, Padhraic Smyth category:stat.ML stat.CO  published:2017-04-04 summary:In modern probabilistic learning we often wish to perform automatic inference for Bayesian models. However, informative prior distributions can be costly and difficult to elicit, and, as a consequence, flat priors are often chosen with the hope that they are reasonably uninformative. Objective priors such as the Jeffreys and reference priors are generally preferable over flat priors but are not tractable to derive for many models of interest. We address this issue by proposing techniques for learning reference prior approximations: we select a parametric family and optimize a lower bound on the reference prior objective to find the member of the family that serves as a good approximation. Moreover, optimization can be made derivation-free via differentiable Monte Carlo expectations. We experimentally demonstrate the method's effectiveness by recovering Jeffreys priors and learning the Variational Autoencoder's reference prior. version:2
arxiv-1704-00849 | Voice Conversion from Unaligned Corpora using Variational Autoencoding Wasserstein Generative Adversarial Networks | http://arxiv.org/abs/1704.00849 | id:1704.00849 author:Chin-Cheng Hsu, Hsin-Te Hwang, Yi-Chiao Wu, Yu Tsao, Hsin-Min Wang category:cs.CL  published:2017-04-04 summary:Building a voice conversion (VC) system from non-parallel speech corpora is challenging but highly valuable in real application scenarios. In most situations, the source and the target speakers do not repeat the same texts or they may even speak different languages. In this case, one possible, although indirect, solution is to build a generative model for speech. Generative models focus on explaining the observations with latent variables instead of learning a pairwise transformation function, thereby bypassing the requirement of speech frame alignment. In this paper, we propose a non-parallel VC framework with a Wasserstein generative adversarial network (W-GAN) that explicitly takes a VC-related objective into account. Experimental results corroborate the capability of our framework for building a VC system from unaligned data, and demonstrate improved conversion quality. version:2
arxiv-1704-03116 | DOPE: Distributed Optimization for Pairwise Energies | http://arxiv.org/abs/1704.03116 | id:1704.03116 author:Jose Dolz, Ismail Ben Ayed, Christian Desrosiers category:cs.CV  published:2017-04-11 summary:We formulate an Alternating Direction Method of Mul-tipliers (ADMM) that systematically distributes the computations of any technique for optimizing pairwise functions, including non-submodular potentials. Such discrete functions are very useful in segmentation and a breadth of other vision problems. Our method decomposes the problem into a large set of small sub-problems, each involving a sub-region of the image domain, which can be solved in parallel. We achieve consistency between the sub-problems through a novel constraint that can be used for a large class of pair-wise functions. We give an iterative numerical solution that alternates between solving the sub-problems and updating consistency variables, until convergence. We report comprehensive experiments, which demonstrate the benefit of our general distributed solution in the case of the popular serial algorithm of Boykov and Kolmogorov (BK algorithm) and, also, in the context of non-submodular functions. version:1
arxiv-1704-02654 | Dimensionality Reduction as a Defense against Evasion Attacks on Machine Learning Classifiers | http://arxiv.org/abs/1704.02654 | id:1704.02654 author:Arjun Nitin Bhagoji, Daniel Cullina, Prateek Mittal category:cs.CR cs.LG  published:2017-04-09 summary:We propose the use of dimensionality reduction as a defense against evasion attacks on ML classifiers. We present and investigate a strategy for incorporating dimensionality reduction via Principal Component Analysis to enhance the resilience of machine learning, targeting both the classification and the training phase. We empirically evaluate and demonstrate the feasibility of dimensionality reduction of data as a defense mechanism against evasion attacks using multiple real-world datasets. Our key findings are that the defenses are (i) effective against strategic evasion attacks in the literature, increasing the resources required by an adversary for a successful attack by a factor of about two, (ii) applicable across a range of ML classifiers, including Support Vector Machines and Deep Neural Networks, and (iii) generalizable to multiple application domains, including image classification, and human activity classification. version:2
arxiv-1703-10675 | Applying Ricci Flow to Manifold Learning | http://arxiv.org/abs/1703.10675 | id:1703.10675 author:Yangyang Li, Ruqian Lu category:cs.LG F.2.2  published:2017-03-03 summary:Traditional manifold learning algorithms often bear an assumption that the local neighborhood of any point on embedded manifold is roughly equal to the tangent space at that point without considering the curvature. The curvature indifferent way of manifold processing often makes traditional dimension reduction poorly neighborhood preserving. To overcome this drawback we propose a new algorithm called RF-ML to perform an operation on the manifold with help of Ricci flow before reducing the dimension of manifold. version:3
arxiv-1704-03079 | WRPN: Training and Inference using Wide Reduced-Precision Networks | http://arxiv.org/abs/1704.03079 | id:1704.03079 author:Asit Mishra, Jeffrey J Cook, Eriko Nurvitadhi, Debbie Marr category:cs.LG cs.AI cs.CV cs.NE  published:2017-04-10 summary:For computer vision applications, prior works have shown the efficacy of reducing the numeric precision of model parameters (network weights) in deep neural networks but also that reducing the precision of activations hurts model accuracy much more than reducing the precision of model parameters. We study schemes to train networks from scratch using reduced-precision activations without hurting the model accuracy. We reduce the precision of activation maps (along with model parameters) using a novel quantization scheme and increase the number of filter maps in a layer, and find that this scheme compensates or surpasses the accuracy of the baseline full-precision network. As a result, one can significantly reduce the dynamic memory footprint, memory bandwidth, computational energy and speed up the training and inference process with appropriate hardware support. We call our scheme WRPN - wide reduced-precision networks. We report results using our proposed schemes and show that our results are better than previously reported accuracies on ILSVRC-12 dataset while being computationally less expensive compared to previously reported reduced-precision networks. version:1
arxiv-1704-03073 | Data-efficient Deep Reinforcement Learning for Dexterous Manipulation | http://arxiv.org/abs/1704.03073 | id:1704.03073 author:Ivaylo Popov, Nicolas Heess, Timothy Lillicrap, Roland Hafner, Gabriel Barth-Maron, Matej Vecerik, Thomas Lampe, Yuval Tassa, Tom Erez, Martin Riedmiller category:cs.LG cs.RO  published:2017-04-10 summary:Deep learning and reinforcement learning methods have recently been used to solve a variety of problems in continuous control domains. An obvious application of these techniques is dexterous manipulation tasks in robotics which are difficult to solve using traditional control theory or hand-engineered approaches. One example of such a task is to grasp an object and precisely stack it on another. Solving this difficult and practically relevant problem in the real world is an important long-term goal for the field of robotics. Here we take a step towards this goal by examining the problem in simulation and providing models and techniques aimed at solving it. We introduce two extensions to the Deep Deterministic Policy Gradient algorithm (DDPG), a model-free Q-learning based method, which make it significantly more data-efficient and scalable. Our results show that by making extensive use of off-policy data and replay, it is possible to find control policies that robustly grasp objects and stack them. Further, our results hint that it may soon be feasible to train successful stacking policies by collecting interactions on real robots. version:1
arxiv-1704-03069 | A semidiscrete version of the Petitot model as a plausible model for anthropomorphic image reconstruction and pattern recognition | http://arxiv.org/abs/1704.03069 | id:1704.03069 author:Dario Prandi, Jean-Paul Gauthier category:cs.CV math.AP math.RT  published:2017-04-10 summary:In his beautiful book [54], Jean Petitot proposes a subriemannian model for the primary visual cortex of mammals. This model is neurophysiologically justified. Further developments of this theory lead to efficient algorithms for image reconstruction, based upon the consideration of an associated hypoelliptic diffusion. The subriemannian model of Petitot (or certain of its improvements) is a left-invariant structure over the group $SE(2)$ of rototranslations of the plane. Here, we propose a semi-discrete version of this theory, leading to a left-invariant structure over the group $SE(2,N)$, restricting to a finite number of rotations. This apparently very simple group is in fact quite atypical: it is maximally almost periodic, which leads to much simpler harmonic analysis compared to $SE(2).$ Based upon this semi-discrete model, we improve on the image-reconstruction algorithms and we develop a pattern-recognition theory that leads also to very efficient algorithms in practice. version:1
arxiv-1704-03067 | Action Unit Detection with Region Adaptation, Multi-labeling Learning and Optimal Temporal Fusing | http://arxiv.org/abs/1704.03067 | id:1704.03067 author:Wei Li, Farnaz Abitahi, Zhigang Zhu category:cs.CV  published:2017-04-10 summary:Action Unit (AU) detection becomes essential for facial analysis. Many proposed approaches face challenging problems in dealing with the alignments of different face regions, in the effective fusion of temporal information, and in training a model for multiple AU labels. To better address these problems, we propose a deep learning framework for AU detection with region of interest (ROI) adaptation, integrated multi-label learning, and optimal LSTM-based temporal fusing. First, ROI cropping nets (ROI Nets) are designed to make sure specifically interested regions of faces are learned independently; each sub-region has a local convolutional neural network (CNN) - an ROI Net, whose convolutional filters will only be trained for the corresponding region. Second, multi-label learning is employed to integrate the outputs of those individual ROI cropping nets, which learns the inter-relationships of various AUs and acquires global features across sub-regions for AU detection. Finally, the optimal selection of multiple LSTM layers to form the best LSTM Net is carried out to best fuse temporal features, in order to make the AU prediction the most accurate. The proposed approach is evaluated on two popular AU detection datasets, BP4D and DISFA, outperforming the state of the art significantly, with an average improvement of around 13% on BP4D and 25% on DISFA, respectively. version:1
arxiv-1704-03058 | CERN: Confidence-Energy Recurrent Network for Group Activity Recognition | http://arxiv.org/abs/1704.03058 | id:1704.03058 author:Tianmin Shu, Sinisa Todorovic, Song-Chun Zhu category:cs.CV cs.LG stat.ML  published:2017-04-10 summary:This work is about recognizing human activities occurring in videos at distinct semantic levels, including individual actions, interactions, and group activities. The recognition is realized using a two-level hierarchy of Long Short-Term Memory (LSTM) networks, forming a feed-forward deep architecture, which can be trained end-to-end. In comparison with existing architectures of LSTMs, we make two key contributions giving the name to our approach as Confidence-Energy Recurrent Network -- CERN. First, instead of using the common softmax layer for prediction, we specify a novel energy layer (EL) for estimating the energy of our predictions. Second, rather than finding the common minimum-energy class assignment, which may be numerically unstable under uncertainty, we specify that the EL additionally computes the p-values of the solutions, and in this way estimates the most confident energy minimum. The evaluation on the Collective Activity and Volleyball datasets demonstrates: (i) advantages of our two contributions relative to the common softmax and energy-minimization formulations and (ii) a superior performance relative to the state-of-the-art approaches. version:1
arxiv-1704-03057 | DRAW: Deep networks for Recognizing styles of Artists Who illustrate children's books | http://arxiv.org/abs/1704.03057 | id:1704.03057 author:Samet Hicsonmez, Nermin Samet, Fadime Sener, Pinar Duygulu category:cs.CV  published:2017-04-10 summary:This paper is motivated from a young boy's capability to recognize an illustrator's style in a totally different context. In the book "We are All Born Free" [1], composed of selected rights from the Universal Declaration of Human Rights interpreted by different illustrators, the boy was surprised to see a picture similar to the ones in the "Winnie the Witch" series drawn by Korky Paul (Figure 1). The style was noticeable in other characters of the same illustrator in different books as well. The capability of a child to easily spot the style was shown to be valid for other illustrators such as Axel Scheffler and Debi Gliori. The boy's enthusiasm let us to start the journey to explore the capabilities of machines to recognize the style of illustrators. We collected pages from children's books to construct a new illustrations dataset consisting of about 6500 pages from 24 artists. We exploited deep networks for categorizing illustrators and with around 94% classification performance our method over-performed the traditional methods by more than 10%. Going beyond categorization we explored transferring style. The classification performance on the transferred images has shown the ability of our system to capture the style. Furthermore, we discovered representative illustrations and discriminative stylistic elements. version:1
arxiv-1704-03039 | Semantically Consistent Regularization for Zero-Shot Recognition | http://arxiv.org/abs/1704.03039 | id:1704.03039 author:Pedro Morgado, Nuno Vasconcelos category:cs.CV cs.AI cs.LG  published:2017-04-10 summary:The role of semantics in zero-shot learning is considered. The effectiveness of previous approaches is analyzed according to the form of supervision provided. While some learn semantics independently, others only supervise the semantic subspace explained by training classes. Thus, the former is able to constrain the whole space but lacks the ability to model semantic correlations. The latter addresses this issue but leaves part of the semantic space unsupervised. This complementarity is exploited in a new convolutional neural network (CNN) framework, which proposes the use of semantics as constraints for recognition.Although a CNN trained for classification has no transfer ability, this can be encouraged by learning an hidden semantic layer together with a semantic code for classification. Two forms of semantic constraints are then introduced. The first is a loss-based regularizer that introduces a generalization constraint on each semantic predictor. The second is a codeword regularizer that favors semantic-to-class mappings consistent with prior semantic knowledge while allowing these to be learned from data. Significant improvements over the state-of-the-art are achieved on several datasets. version:1
arxiv-1704-03037 | Learning from Multi-View Structural Data via Structural Factorization Machines | http://arxiv.org/abs/1704.03037 | id:1704.03037 author:Chun-Ta Lu, Lifang He, Hao Ding, Philip S. Yu category:cs.LG  published:2017-04-10 summary:Real-world relations among entities can often be observed and determined by different perspectives/views. For example, the decision made by a user on whether to adopt an item relies on multiple aspects such as the contextual information of the decision, the item's attributes, the user's profile and the reviews given by other users. Different views may exhibit multi-way interactions among entities and provide complementary information. In this paper, we introduce a multi-tensor-based approach that can preserve the underlying structure of multi-view data in a generic predictive model. Specifically, we propose structural factorization machines (SFMs) that learn the common latent spaces shared by multi-view tensors and automatically adjust the importance of each view in the predictive model. Furthermore, the complexity of SFMs is linear in the number of parameters, which make SFMs suitable to large-scale problems. Extensive experiments on real-world datasets demonstrate that the proposed SFMs outperform several state-of-the-art methods in terms of prediction accuracy and computational cost. version:1
arxiv-1704-03033 | A probabilistic data-driven model for planar pushing | http://arxiv.org/abs/1704.03033 | id:1704.03033 author:Maria Bauza, Alberto Rodriguez category:cs.RO cs.LG stat.ML  published:2017-04-10 summary:This paper presents a data-driven approach to model planar pushing interaction to predict both the most likely outcome of a push and its expected variability. The learned models rely on a variation of Gaussian processes with input-dependent noise called Variational Heteroscedastic Gaussian processes (VHGP) that capture the mean and variance of a stochastic function. We show that we can learn accurate models that outperform analytical models after less than 100 samples and saturate in performance with less than 1000 samples. We validate the results against a collected dataset of repeated trajectories, and use the learned models to study questions such as the nature of the variability in pushing, and the validity of the quasi-static assumption. version:1
arxiv-1704-03016 | Automatic semantic role labeling on non-revised syntactic trees of journalistic texts | http://arxiv.org/abs/1704.03016 | id:1704.03016 author:Nathan Siegle Hartmann, Magali Sanches Duran, Sandra Maria Aluísio category:cs.CL  published:2017-04-10 summary:Semantic Role Labeling (SRL) is a Natural Language Processing task that enables the detection of events described in sentences and the participants of these events. For Brazilian Portuguese (BP), there are two studies recently concluded that perform SRL in journalistic texts. [1] obtained F1-measure scores of 79.6, using the PropBank.Br corpus, which has syntactic trees manually revised, [8], without using a treebank for training, obtained F1-measure scores of 68.0 for the same corpus. However, the use of manually revised syntactic trees for this task does not represent a real scenario of application. The goal of this paper is to evaluate the performance of SRL on revised and non-revised syntactic trees using a larger and balanced corpus of BP journalistic texts. First, we have shown that [1]'s system also performs better than [8]'s system on the larger corpus. Second, the SRL system trained on non-revised syntactic trees performs better over non-revised trees than a system trained on gold-standard data. version:1
arxiv-1704-03013 | Automatic Classification of the Complexity of Nonfiction Texts in Portuguese for Early School Years | http://arxiv.org/abs/1704.03013 | id:1704.03013 author:Nathan Siegle Hartmann, Livia Cucatto, Danielle Brants, Sandra Aluísio category:cs.CL  published:2017-04-10 summary:Recent research shows that most Brazilian students have serious problems regarding their reading skills. The full development of this skill is key for the academic and professional future of every citizen. Tools for classifying the complexity of reading materials for children aim to improve the quality of the model of teaching reading and text comprehension. For English, Fengs work [11] is considered the state-of-art in grade level prediction and achieved 74% of accuracy in automatically classifying 4 levels of textual complexity for close school grades. There are no classifiers for nonfiction texts for close grades in Portuguese. In this article, we propose a scheme for manual annotation of texts in 5 grade levels, which will be used for customized reading to avoid the lack of interest by students who are more advanced in reading and the blocking of those that still need to make further progress. We obtained 52% of accuracy in classifying texts into 5 levels and 74% in 3 levels. The results prove to be promising when compared to the state-of-art work.9 version:1
arxiv-1704-03012 | Stochastic Neural Networks for Hierarchical Reinforcement Learning | http://arxiv.org/abs/1704.03012 | id:1704.03012 author:Carlos Florensa, Yan Duan, Pieter Abbeel category:cs.AI cs.LG cs.NE cs.RO  published:2017-04-10 summary:Deep reinforcement learning has achieved many impressive results in recent years. However, tasks with sparse rewards or long horizons continue to pose significant challenges. To tackle these important problems, we propose a general framework that first learns useful skills in a pre-training environment, and then leverages the acquired skills for learning faster in downstream tasks. Our approach brings together some of the strengths of intrinsic motivation and hierarchical methods: the learning of useful skill is guided by a single proxy reward, the design of which requires very minimal domain knowledge about the downstream tasks. Then a high-level policy is trained on top of these skills, providing a significant improvement of the exploration and allowing to tackle sparse rewards in the downstream tasks. To efficiently pre-train a large span of skills, we use Stochastic Neural Networks combined with an information-theoretic regularizer. Our experiments show that this combination is effective in learning a wide span of interpretable skills in a sample-efficient way, and can significantly boost the learning performance uniformly across a wide range of downstream tasks. version:1
arxiv-1704-03003 | Automated Curriculum Learning for Neural Networks | http://arxiv.org/abs/1704.03003 | id:1704.03003 author:Alex Graves, Marc G. Bellemare, Jacob Menick, Remi Munos, Koray Kavukcuoglu category:cs.NE  published:2017-04-10 summary:We introduce a method for automatically selecting the path, or syllabus, that a neural network follows through a curriculum so as to maximise learning efficiency. A measure of the amount that the network learns from each data sample is provided as a reward signal to a nonstationary multi-armed bandit algorithm, which then determines a stochastic syllabus. We consider a range of signals derived from two distinct indicators of learning progress: rate of increase in prediction accuracy, and rate of increase in network complexity. Experimental results for LSTM networks on three curricula demonstrate that our approach can significantly accelerate learning, in some cases halving the time required to attain a satisfactory performance level. version:1
arxiv-1704-02998 | Weakly-Supervised Spatial Context Networks | http://arxiv.org/abs/1704.02998 | id:1704.02998 author:Zuxuan Wu, Larry S. Davis, Leonid Sigal category:cs.CV  published:2017-04-10 summary:We explore the power of spatial context as a self-supervisory signal for learning visual representations. In particular, we propose spatial context networks that learn to predict a representation of one image patch from another image patch, within the same image, conditioned on their real-valued relative spatial offset. Unlike auto-encoders, that aim to encode and reconstruct original image patches, our network aims to encode and reconstruct intermediate representations of the spatially offset patches. As such, the network learns a spatially conditioned contextual representation. By testing performance with various patch selection mechanisms we show that focusing on object-centric patches is important, and that using object proposal as a patch selection mechanism leads to the highest improvement in performance. Further, unlike auto-encoders, context encoders [21], or other forms of unsupervised feature learning, we illustrate that contextual supervision (with pre-trained model initialization) can improve on existing pre-trained model performance. We build our spatial context networks on top of standard VGG_19 and CNN_M architectures and, among other things, show that we can achieve improvements (with no additional explicit supervision) over the original ImageNet pre-trained VGG_19 and CNN_M models in object categorization and detection on VOC2007. version:1
arxiv-1704-02966 | Loss Max-Pooling for Semantic Image Segmentation | http://arxiv.org/abs/1704.02966 | id:1704.02966 author:Samuel Rota Bulò, Gerhard Neuhold, Peter Kontschieder category:cs.CV stat.ML  published:2017-04-10 summary:We introduce a novel loss max-pooling concept for handling imbalanced training data distributions, applicable as alternative loss layer in the context of deep neural networks for semantic image segmentation. Most real-world semantic segmentation datasets exhibit long tail distributions with few object categories comprising the majority of data and consequently biasing the classifiers towards them. Our method adaptively re-weights the contributions of each pixel based on their observed losses, targeting under-performing classification results as often encountered for under-represented object classes. Our approach goes beyond conventional cost-sensitive learning attempts through adaptive considerations that allow us to indirectly address both, inter- and intra-class imbalances. We provide a theoretical justification of our approach, complementary to experimental analyses on benchmark datasets. In our experiments on the Cityscapes and Pascal VOC 2012 segmentation datasets we find consistently improved results, demonstrating the efficacy of our approach. version:1
arxiv-1704-02965 | Using convolutional networks and satellite imagery to identify patterns in urban environments at a large scale | http://arxiv.org/abs/1704.02965 | id:1704.02965 author:Adrian Albert, Jasleen Kaur, Marta Gonzalez category:cs.CV  published:2017-04-10 summary:Urban planning applications (energy audits, investment, etc.) require an understanding of built infrastructure and its environment, i.e., both low-level, physical features (amount of vegetation, building area and geometry etc.), as well as higher-level concepts such as land use classes (which encode expert understanding of socio-economic end uses). This kind of data is expensive and labor-intensive to obtain, which limits its availability (particularly in developing countries). We analyze patterns in land use in urban neighborhoods using large-scale satellite imagery data (which is available worldwide from third-party providers) and state-of-the-art computer vision techniques based on deep convolutional neural networks. For supervision, given the limited availability of standard benchmarks for remote-sensing data, we obtain ground truth land use class labels carefully sampled from open-source surveys, in particular the Urban Atlas land classification dataset of $20$ land use classes across $~300$ European cities. We use this data to train and compare deep architectures which have recently shown good performance on standard computer vision tasks (image classification and segmentation), including on geospatial data. Furthermore, we show that the deep representations extracted from satellite imagery of urban environments can be used to compare neighborhoods across several cities. We make our dataset available for other machine learning researchers to use for remote-sensing applications. version:1
arxiv-1704-02963 | Exploring Word Embeddings for Unsupervised Textual User-Generated Content Normalization | http://arxiv.org/abs/1704.02963 | id:1704.02963 author:Thales Felipe Costa Bertaglia, Maria das Graças Volpe Nunes category:cs.CL cs.AI  published:2017-04-10 summary:Text normalization techniques based on rules, lexicons or supervised training requiring large corpora are not scalable nor domain interchangeable, and this makes them unsuitable for normalizing user-generated content (UGC). Current tools available for Brazilian Portuguese make use of such techniques. In this work we propose a technique based on distributed representation of words (or word embeddings). It generates continuous numeric vectors of high-dimensionality to represent words. The vectors explicitly encode many linguistic regularities and patterns, as well as syntactic and semantic word relationships. Words that share semantic similarity are represented by similar vectors. Based on these features, we present a totally unsupervised, expandable and language and domain independent method for learning normalization lexicons from word embeddings. Our approach obtains high correction rate of orthographic errors and internet slang in product reviews, outperforming the current available tools for Brazilian Portuguese. version:1
arxiv-1704-02958 | On the Fine-Grained Complexity of Empirical Risk Minimization: Kernel Methods and Neural Networks | http://arxiv.org/abs/1704.02958 | id:1704.02958 author:Arturs Backurs, Piotr Indyk, Ludwig Schmidt category:cs.CC cs.DS cs.LG stat.ML  published:2017-04-10 summary:Empirical risk minimization (ERM) is ubiquitous in machine learning and underlies most supervised learning methods. While there has been a large body of work on algorithms for various ERM problems, the exact computational complexity of ERM is still not understood. We address this issue for multiple popular ERM problems including kernel SVMs, kernel ridge regression, and training the final layer of a neural network. In particular, we give conditional hardness results for these problems based on complexity-theoretic assumptions such as the Strong Exponential Time Hypothesis. Under these assumptions, we show that there are no algorithms that solve the aforementioned ERM problems to high accuracy in sub-quadratic time. We also give similar hardness results for computing the gradient of the empirical loss, which is the main computational burden in many non-convex learning tasks. version:1
arxiv-1704-02956 | Surface Normals in the Wild | http://arxiv.org/abs/1704.02956 | id:1704.02956 author:Weifeng Chen, Donglai Xiang, Jia Deng category:cs.CV  published:2017-04-10 summary:We study the problem of single-image depth estimation for images in the wild. We collect human annotated surface normals and use them to train a neural network that directly predicts pixel-wise depth. We propose two novel loss functions for training with surface normal annotations. Experiments on NYU Depth and our own dataset demonstrate that our approach can significantly improve the quality of depth estimation in the wild. version:1
arxiv-1703-05840 | Conditional Accelerated Lazy Stochastic Gradient Descent | http://arxiv.org/abs/1703.05840 | id:1703.05840 author:Guanghui Lan, Sebastian Pokutta, Yi Zhou, Daniel Zink category:cs.LG stat.ML 90C25 G.1.6  published:2017-03-16 summary:In this work we introduce a conditional accelerated lazy stochastic gradient descent algorithm with optimal number of calls to a stochastic first-order oracle and convergence rate $O\left(\frac{1}{\varepsilon^2}\right)$ improving over the projection-free, Online Frank-Wolfe based stochastic gradient descent of Hazan and Kale [2012] with convergence rate $O\left(\frac{1}{\varepsilon^4}\right)$. version:4
arxiv-1704-00406 | Sparse Autoencoder for Unsupervised Nucleus Detection and Representation in Histopathology Images | http://arxiv.org/abs/1704.00406 | id:1704.00406 author:Le Hou, Vu Nguyen, Dimitris Samaras, Tahsin M. Kurc, Yi Gao, Tianhao Zhao, Joel H. Saltz category:cs.CV  published:2017-04-03 summary:Histopathology images are crucial to the study of complex diseases such as cancer. The histologic characteristics of nuclei play a key role in disease diagnosis, prognosis and analysis. In this work, we propose a sparse Convolutional Autoencoder (CAE) for fully unsupervised, simultaneous nucleus detection and feature extraction in histopathology tissue images. Our CAE detects and encodes nuclei in image patches in tissue images into sparse feature maps that encode both the location and appearance of nuclei. Our CAE is the first unsupervised detection network for computer vision applications. The pretrained nucleus detection and feature extraction modules in our CAE can be fine-tuned for supervised learning in an end-to-end fashion. We evaluate our method on four datasets and reduce the errors of state-of-the-art methods up to 42%. We are able to achieve comparable performance with only 5% of the fully-supervised annotation cost. version:2
arxiv-1703-08770 | SCAN: Structure Correcting Adversarial Network for Organ Segmentation in Chest X-rays | http://arxiv.org/abs/1703.08770 | id:1703.08770 author:Wei Dai, Joseph Doyle, Xiaodan Liang, Hao Zhang, Nanqing Dong, Yuan Li, Eric P. Xing category:cs.CV  published:2017-03-26 summary:Chest X-ray (CXR) is one of the most commonly prescribed medical imaging procedures, often with over 2-10x more scans than other imaging modalities such as MRI, CT scan, and PET scans. These voluminous CXR scans place significant workloads on radiologists and medical practitioners. Organ segmentation is a crucial step to obtain effective computer-aided detection on CXR. In this work, we propose Structure Correcting Adversarial Network (SCAN) to segment lung fields and the heart in CXR images. SCAN incorporates a critic network to impose on the convolutional segmentation network the structural regularities emerging from human physiology. During training, the critic network learns to discriminate between the ground truth organ annotations from the masks synthesized by the segmentation network. Through this adversarial process the critic network learns the higher order structures and guides the segmentation model to achieve realistic segmentation outcomes. Extensive experiments show that our method produces highly accurate and natural segmentation. Using only very limited training data available, our model reaches human-level performance without relying on any existing trained model or dataset. Our method also generalizes well to CXR images from a different patient population and disease profiles, surpassing the current state-of-the-art. version:2
arxiv-1704-02923 | Pay Attention to Those Sets! Learning Quantification from Images | http://arxiv.org/abs/1704.02923 | id:1704.02923 author:Ionut Sorodoc, Sandro Pezzelle, Aurélie Herbelot, Mariella Dimiccoli, Raffaella Bernardi category:cs.CL cs.AI cs.CV  published:2017-04-10 summary:Major advances have recently been made in merging language and vision representations. But most tasks considered so far have confined themselves to the processing of objects and lexicalised relations amongst objects (content words). We know, however, that humans (even pre-school children) can abstract over raw data to perform certain types of higher-level reasoning, expressed in natural language by function words. A case in point is given by their ability to learn quantifiers, i.e. expressions like 'few', 'some' and 'all'. From formal semantics and cognitive linguistics, we know that quantifiers are relations over sets which, as a simplification, we can see as proportions. For instance, in 'most fish are red', most encodes the proportion of fish which are red fish. In this paper, we study how well current language and vision strategies model such relations. We show that state-of-the-art attention mechanisms coupled with a traditional linguistic formalisation of quantifiers gives best performance on the task. Additionally, we provide insights on the role of 'gist' representations in quantification. A 'logical' strategy to tackle the task would be to first obtain a numerosity estimation for the two involved sets and then compare their cardinalities. We however argue that precisely identifying the composition of the sets is not only beyond current state-of-the-art models but perhaps even detrimental to a task that is most efficiently performed by refining the approximate numerosity estimator of the system. version:1
arxiv-1704-02916 | Reinterpreting Importance-Weighted Autoencoders | http://arxiv.org/abs/1704.02916 | id:1704.02916 author:Chris Cremer, Quaid Morris, David Duvenaud category:stat.ML  published:2017-04-10 summary:The standard interpretation of importance-weighted autoencoders is that they maximize a tighter lower bound on the marginal likelihood. We give an alternate interpretation of this procedure: that it optimizes the standard variational lower bound, but using a more complex distribution. We formally derive this result, and visualize the implicit importance-weighted approximate posterior. version:1
arxiv-1704-02906 | Multi-Agent Diverse Generative Adversarial Networks | http://arxiv.org/abs/1704.02906 | id:1704.02906 author:Arnab Ghosh, Viveka Kulharia, Vinay Namboodiri, Philip H. S. Torr, Puneet K. Dokania category:cs.CV cs.AI cs.GR cs.LG stat.ML  published:2017-04-10 summary:This paper describes an intuitive generalization to the Generative Adversarial Networks (GANs) to generate samples while capturing diverse modes of the true data distribution. Firstly, we propose a very simple and intuitive multi-agent GAN architecture that incorporates multiple generators capable of generating samples from high probability modes. Secondly, in order to enforce different generators to generate samples from diverse modes, we propose two extensions to the standard GAN objective function. (1) We augment the generator specific GAN objective function with a diversity enforcing term that encourage different generators to generate diverse samples using a user-defined similarity based function. (2) We modify the discriminator objective function where along with finding the real and fake samples, the discriminator has to predict the generator which generated the given fake sample. Intuitively, in order to succeed in this task, the discriminator must learn to push different generators towards different identifiable modes. Our framework is generalizable in the sense that it can be easily combined with other existing variants of GANs to produce diverse samples. Experimentally we show that our framework is able to produce high quality diverse samples for the challenging tasks such as image/face generation and image-to-image translation. We also show that it is capable of learning a better feature representation in an unsupervised setting. version:1
arxiv-1704-02901 | Dynamic Edge-Conditioned Filters in Convolutional Neural Networks on Graphs | http://arxiv.org/abs/1704.02901 | id:1704.02901 author:Martin Simonovsky, Nikos Komodakis category:cs.CV cs.LG cs.NE  published:2017-04-10 summary:A number of problems can be formulated as prediction on graph-structured data. In this work, we generalize the convolution operator from regular grids to arbitrary graphs while avoiding the spectral domain, which allows us to handle graphs of varying size and connectivity. To move beyond a simple diffusion, filter weights are conditioned on the specific edge labels in the neighborhood of a vertex. Together with the proper choice of graph coarsening, we explore constructing deep neural networks for graph classification. In particular, we demonstrate the generality of our formulation in point cloud classification, where we set the new state of the art, and on a graph classification dataset, where we outperform other deep learning approaches. version:1
arxiv-1704-02899 | Continuously heterogeneous hyper-objects in cryo-EM and 3-D movies of many temporal dimensions | http://arxiv.org/abs/1704.02899 | id:1704.02899 author:Roy R. Lederman, Amit Singer category:cs.CV  published:2017-04-10 summary:Single particle cryo-electron microscopy (EM) is an increasingly popular method for determining the 3-D structure of macromolecules from noisy 2-D images of single macromolecules whose orientations and positions are random and unknown. One of the great opportunities in cryo-EM is to recover the structure of macromolecules in heterogeneous samples, where multiple types or multiple conformations are mixed together. Indeed, in recent years, many tools have been introduced for the analysis of multiple discrete classes of molecules mixed together in a cryo-EM experiment. However, many interesting structures have a continuum of conformations which do not fit discrete models nicely; the analysis of such continuously heterogeneous models has remained a more elusive goal. In this manuscript, we propose to represent heterogeneous molecules and similar structures as higher dimensional objects. We generalize the basic operations used in many existing reconstruction algorithms, making our approach generic in the sense that, in principle, existing algorithms can be adapted to reconstruct those higher dimensional objects. As proof of concept, we present a prototype of a new algorithm which we use to solve simulated reconstruction problems. version:1
arxiv-1704-02895 | ActionVLAD: Learning spatio-temporal aggregation for action classification | http://arxiv.org/abs/1704.02895 | id:1704.02895 author:Rohit Girdhar, Deva Ramanan, Abhinav Gupta, Josef Sivic, Bryan Russell category:cs.CV  published:2017-04-10 summary:In this work, we introduce a new video representation for action classification that aggregates local convolutional features across the entire spatio-temporal extent of the video. We do so by integrating state-of-the-art two-stream networks with learnable spatio-temporal feature aggregation. The resulting architecture is end-to-end trainable for whole-video classification. We investigate different strategies for pooling across space and time and combining signals from the different streams. We find that: (i) it is important to pool jointly across space and time, but (ii) appearance and motion streams are best aggregated into their own separate representations. Finally, we show that our representation outperforms the two-stream base architecture by a large margin (13% relative) as well as out-performs other baselines with comparable base architectures on HMDB51, UCF101, and Charades video classification benchmarks. version:1
arxiv-1704-02978 | Field of Groves: An Energy-Efficient Random Forest | http://arxiv.org/abs/1704.02978 | id:1704.02978 author:Zafar Takhirov, Joseph Wang, Marcia S. Louis, Venkatesh Saligrama, Ajay Joshi category:cs.DC stat.ML  published:2017-04-10 summary:Machine Learning (ML) algorithms, like Convolutional Neural Networks (CNN), Support Vector Machines (SVM), etc. have become widespread and can achieve high statistical performance. However their accuracy decreases significantly in energy-constrained mobile and embedded systems space, where all computations need to be completed under a tight energy budget. In this work, we present a field of groves (FoG) implementation of random forests (RF) that achieves an accuracy comparable to CNNs and SVMs under tight energy budgets. Evaluation of the FoG shows that at comparable accuracy it consumes ~1.48x, ~24x, ~2.5x, and ~34.7x lower energy per classification compared to conventional RF, SVM_RBF , MLP, and CNN, respectively. FoG is ~6.5x less energy efficient than SVM_LR, but achieves 18% higher accuracy on average across all considered datasets. version:1
arxiv-1704-02882 | Can AIs learn to avoid human interruption? | http://arxiv.org/abs/1704.02882 | id:1704.02882 author:El Mahdi El Mhamdi, Rachid Guerraoui, Hadrien Hendrikx, Alexandre Maurer category:cs.AI cs.LG cs.MA stat.ML  published:2017-04-10 summary:Recent progress in artificial intelligence enabled the design and implementation of autonomous computing devices, agents, that may interact and learn from each other to achieve certain goals. Sometimes however, a human operator needs to intervene and interrupt an agent in order to prevent certain dangerous situations. Yet, as part of their learning process, agents may link these interruptions that impact their reward to specific states, and deliberately avoid them. The situation is particularly challenging in a distributed context because agents might not only learn from their own past interruptions, but also from those of other agents. This paper defines the notion of safe interruptibility as a distributed computing problem, and studies this notion in the two main learning frameworks: joint action learners and independent learners. We give realistic sufficient conditions on the learning algorithm for safe interruptibility in the case of joint action learners, yet show that these conditions are not sufficient for independent learners. We show however that if agents can detect interruptions, it is possible to prune the observations to ensure safe interruptibility even for independent learners version:1
arxiv-1704-01552 | Deep Learning and Quantum Entanglement: Fundamental Connections with Implications to Network Design | http://arxiv.org/abs/1704.01552 | id:1704.01552 author:Yoav Levine, David Yakira, Nadav Cohen, Amnon Shashua category:cs.LG cs.NE quant-ph  published:2017-04-05 summary:Deep convolutional networks have witnessed unprecedented success in various machine learning applications. Formal understanding on what makes these networks so successful is gradually unfolding, but for the most part there are still significant mysteries to unravel. The inductive bias, which reflects prior knowledge embedded in the network architecture, is one of them. In this work, we establish a fundamental connection between the fields of quantum physics and deep learning. We use this connection for asserting novel theoretical observations regarding the role that the number of channels in each layer of the convolutional network fulfills in the overall inductive bias. Specifically, we show an equivalence between the function realized by a deep convolutional arithmetic circuit (ConvAC) and a quantum many-body wave function, which relies on their common underlying tensorial structure. This facilitates the use of quantum entanglement measures as well-defined quantifiers of a deep network's expressive ability to model intricate correlation structures of its inputs. Most importantly, the construction of a deep ConvAC in terms of a Tensor Network is made available. This description enables us to carry a graph-theoretic analysis of a convolutional network, with which we demonstrate a direct control over the inductive bias of the deep network via its channel numbers, that are related to the min-cut in the underlying graph. This result is relevant to any practitioner designing a network for a specific task. We theoretically analyze ConvACs, and empirically validate our findings on more common ConvNets which involve ReLU activations and max pooling. Beyond the results described above, the description of a deep convolutional network in well-defined graph-theoretic tools and the formal connection to quantum entanglement, are two interdisciplinary bridges that are brought forth by this work. version:2
arxiv-1704-03834 | Deep Neural Network Based Precursor microRNA Prediction on Eleven Species | http://arxiv.org/abs/1704.03834 | id:1704.03834 author:Jaya Thomas, Lee Sael category:q-bio.QM cs.LG  published:2017-04-10 summary:MicroRNA (miRNA) are small non-coding RNAs that regulates the gene expression at the post-transcriptional level. Determining whether a sequence segment is miRNA is experimentally challenging. Also, experimental results are sensitive to the experimental environment. These limitations inspire the development of computational methods for predicting the miRNAs. We propose a deep learning based classification model, called DP-miRNA, for predicting precursor miRNA sequence that contains the miRNA sequence. The feature set based Restricted Boltzmann Machine method, which we call DP-miRNA, uses 58 features that are categorized into four groups: sequence features, folding measures, stem-loop features and statistical feature. We evaluate the performance of the DP-miRNA on eleven twelve data sets of varying species, including the human. The deep neural network based classification outperformed support vector machine, neural network, naive Baye's classifiers, k-nearest neighbors, random forests, and a hybrid system combining support vector machine and genetic algorithm. version:1
arxiv-1704-02848 | Unsupervised prototype learning in an associative-memory network | http://arxiv.org/abs/1704.02848 | id:1704.02848 author:Huiling Zhen, Shang-Nan Wang, Hai-Jun Zhou category:cs.NE cond-mat.dis-nn cs.LG  published:2017-04-10 summary:Unsupervised learning in a generalized Hopfield associative-memory network is investigated in this work. First, we prove that the (generalized) Hopfield model is equivalent to a semi-restricted Boltzmann machine with a layer of visible neurons and another layer of hidden binary neurons, so it could serve as the building block for a multilayered deep-learning system. We then demonstrate that the Hopfield network can learn to form a faithful internal representation of the observed samples, with the learned memory patterns being prototypes of the input data. Furthermore, we propose a spectral method to extract a small set of concepts (idealized prototypes) as the most concise summary or abstraction of the empirical data. version:1
arxiv-1704-02846 | Multi-Kernel LS-SVM Based Bio-Clinical Data Integration: Applications to Ovarian Cancer | http://arxiv.org/abs/1704.02846 | id:1704.02846 author:Jaya Thomas, Lee Sael category:q-bio.GN q-bio.QM stat.ML  published:2017-04-10 summary:The medical research facilitates to acquire a diverse type of data from the same individual for particular cancer. Recent studies show that utilizing such diverse data results in more accurate predictions. The major challenge faced is how to utilize such diverse data sets in an effective way. In this paper, we introduce a multiple kernel based pipeline for integrative analysis of high-throughput molecular data (somatic mutation, copy number alteration, DNA methylation and mRNA) and clinical data. We apply the pipeline on Ovarian cancer data from TCGA. After multiple kernels have been generated from the weighted sum of individual kernels, it is used to stratify patients and predict clinical outcomes. We examine the survival time, vital status, and neoplasm cancer status of each subtype to verify how well they cluster. We have also examined the power of molecular and clinical data in predicting dichotomized overall survival data and to classify the tumor grade for the cancer samples. It was observed that the integration of various data types yields higher log-rank statistics value. We were also able to predict clinical status with higher accuracy as compared to using individual data types. version:1
arxiv-1704-02828 | Integral Transforms from Finite Data: An Application of Gaussian Process Regression to Fourier Analysis | http://arxiv.org/abs/1704.02828 | id:1704.02828 author:Luca Ambrogioni, Eric Maris category:stat.ML  published:2017-04-10 summary:Computing an accurate estimate of the Fourier transform of a continuum-time signal from a discrete set of data points is crucially important in many areas of science and engineering. The conventional approach of performing the discrete Fourier transform of the data has the shortcoming of assuming periodicity and discreteness of the signal. In this paper, we show that it is possible to use Gaussian process regression for estimating any arbitrary integral transform without making these assumptions. This is possible because the posterior expectation of Gaussian process regression maps a finite set of samples to a function defined on the whole real line. In order to accurately extrapolate, we need to learn the covariance function from the data using an appropriately designed hierarchical Bayesian model. Our simulations show that the new method, when applied to the Fourier transform, leads to sharper and more precise estimation of the spectral density of deterministic and stochastic signals. version:1
arxiv-1704-02827 | Learning Human Motion Models for Long-term Predictions | http://arxiv.org/abs/1704.02827 | id:1704.02827 author:Partha Ghosh, Jie Song, Emre Aksan, Otmar Hilliges category:cs.CV  published:2017-04-10 summary:We propose a new architecture for the learning of predictive spatio-temporal motion models from data alone. Our approach, dubbed the Dropout Autoencoder LSTM, is capable of synthesizing natural looking motion sequences over long time horizons without catastrophic drift or motion degradation. The model consists of two components, a 3-layer recurrent neural network to model temporal aspects and a novel auto-encoder that is trained to implicitly recover the spatial structure of the human skeleton via randomly removing information about joints during training time. This Dropout Autoencoder (D-AE) is then used to filter each predicted pose of the LSTM, reducing accumulation of error and hence drift over time. Furthermore, we propose new evaluation protocols to assess the quality of synthetic motion sequences even for which no ground truth data exists. The proposed protocols can be used to assess generated sequences of arbitrary length. Finally, we evaluate our proposed method on two of the largest motion-capture datasets available to date and show that our model outperforms the state-of-the-art on a variety of actions, including cyclic and acyclic motion, and that it can produce natural looking sequences over longer time horizons than previous methods. version:1
arxiv-1704-02813 | Character-Word LSTM Language Models | http://arxiv.org/abs/1704.02813 | id:1704.02813 author:Lyan Verwimp, Joris Pelemans, Hugo Van hamme, Patrick Wambacq category:cs.CL  published:2017-04-10 summary:We present a Character-Word Long Short-Term Memory Language Model which both reduces the perplexity with respect to a baseline word-level language model and reduces the number of parameters of the model. Character information can reveal structural (dis)similarities between words and can even be used when a word is out-of-vocabulary, thus improving the modeling of infrequent and unknown words. By concatenating word and character embeddings, we achieve up to 2.77% relative improvement on English compared to a baseline model with a similar amount of parameters and 4.57% on Dutch. Moreover, we also outperform baseline word-level models with a larger number of parameters. version:1
arxiv-1704-02809 | R-Clustering for Egocentric Video Segmentation | http://arxiv.org/abs/1704.02809 | id:1704.02809 author:Estefania Talavera, Mariella Dimiccoli, Marc Bolaños, Maedeh Aghaei, Petia Radeva category:cs.CV  published:2017-04-10 summary:In this paper, we present a new method for egocentric video temporal segmentation based on integrating a statistical mean change detector and agglomerative clustering(AC) within an energy-minimization framework. Given the tendency of most AC methods to oversegment video sequences when clustering their frames, we combine the clustering with a concept drift detection technique (ADWIN) that has rigorous guarantee of performances. ADWIN serves as a statistical upper bound for the clustering-based video segmentation. We integrate both techniques in an energy-minimization framework that serves to disambiguate the decision of both techniques and to complete the segmentation taking into account the temporal continuity of video frames descriptors. We present experiments over egocentric sets of more than 13.000 images acquired with different wearable cameras, showing that our method outperforms state-of-the-art clustering methods. version:1
arxiv-1704-02801 | Bayesian Inference of Individualized Treatment Effects using Multi-task Gaussian Processes | http://arxiv.org/abs/1704.02801 | id:1704.02801 author:Ahmed M. Alaa, Mihaela van der Schaar category:cs.LG  published:2017-04-10 summary:We consider the problem of obtaining individualized estimates for the effect of a certain treatment given observational data. The problem differs fundamentally from classical supervised learning since for each individual subject, we either observe the response with or without the treatment but never both. Hence, estimating the effect of a treatment entails a causal inference task in which we need to estimate counterfactual outcomes. To address this problem, we propose a novel multi-task learning framework in which the individuals' responses with and without the treatment are modeled as a vector-valued function that belongs to a reproducing kernel Hilbert space. Unlike previous methods for causal inference that use the G-computation formula, our approach does not obtain separate estimates for the treatment and control response surfaces, but rather obtains a joint estimate that ensures data efficiency in scenarios where the selection bias is strong. In order to be able to provide individualized measures of uncertainty in our estimates, we adopt a Bayesian approach for learning this vector-valued function using a multi-task Gaussian process prior; uncertainty is quantified via posterior credible intervals. We develop a novel risk based empirical Bayes approach for calibrating the Gaussian process hyper-parameters in a data-driven fashion based on gradient descent in which the update rule is itself learned from the data using a recurrent neural network. Experiments conducted on semi-synthetic data show that our algorithm significantly outperforms state-of-the-art causal inference methods. version:1
arxiv-1704-02799 | A Comparative Study for Predicting Heart Diseases Using Data Mining Classification Methods | http://arxiv.org/abs/1704.02799 | id:1704.02799 author:Israa Ahmed Zriqat, Ahmad Mousa Altamimi, Mohammad Azzeh category:cs.LG  published:2017-04-10 summary:Improving the precision of heart diseases detection has been investigated by many researchers in the literature. Such improvement induced by the overwhelming health care expenditures and erroneous diagnosis. As a result, various methodologies have been proposed to analyze the disease factors aiming to decrease the physicians practice variation and reduce medical costs and errors. In this paper, our main motivation is to develop an effective intelligent medical decision support system based on data mining techniques. In this context, five data mining classifying algorithms, with large datasets, have been utilized to assess and analyze the risk factors statistically related to heart diseases in order to compare the performance of the implemented classifiers (e.g., Na\"ive Bayes, Decision Tree, Discriminant, Random Forest, and Support Vector Machine). To underscore the practical viability of our approach, the selected classifiers have been implemented using MATLAB tool with two datasets. Results of the conducted experiments showed that all classification algorithms are predictive and can give relatively correct answer. However, the decision tree outperforms other classifiers with an accuracy rate of 99.0% followed by Random forest. That is the case because both of them have relatively same mechanism but the Random forest can build ensemble of decision tree. Although ensemble learning has been proved to produce superior results, but in our case the decision tree has outperformed its ensemble version. version:1
arxiv-1704-02792 | Fine-graind Image Classification via Combining Vision and Language | http://arxiv.org/abs/1704.02792 | id:1704.02792 author:Xiangteng He, Yuxin Peng category:cs.CV  published:2017-04-10 summary:Fine-grained image classification is a challenging task due to the large intra-class variance and small inter-class variance, aiming at recognizing hundreds of sub-categories belonging to the same basic-level category. Most existing fine-grained image classification methods generally learn part detection models to obtain the semantic parts for better classification accuracy. Despite achieving promising results, these methods mainly have two limitations: (1) not all the parts which obtained through the part detection models are beneficial and indispensable for classification, and (2) fine-grained image classification requires more detailed visual descriptions which could not be provided by the part locations or attribute annotations. For addressing the above two limitations, this paper proposes the two-stream model combing vision and language (CVL) for learning latent semantic representations. The vision stream learns deep representations from the original visual information via deep convolutional neural network. The language stream utilizes the natural language descriptions which could point out the discriminative parts or characteristics for each image, and provides a flexible and compact way of encoding the salient visual aspects for distinguishing sub-categories. Since the two streams are complementary, combing the two streams can further achieves better classification accuracy. Comparing with 12 state-of-the-art methods on the widely used CUB-200-2011 dataset for fine-grained image classification, the experimental results demonstrate our CVL approach achieves the best performance. version:1
arxiv-1704-02215 | EELECTION at SemEval-2017 Task 10: Ensemble of nEural Learners for kEyphrase ClassificaTION | http://arxiv.org/abs/1704.02215 | id:1704.02215 author:Steffen Eger, Erik-Lân Do Dinh, Ilia Kuznetsov, Masoud Kiaeeha, Iryna Gurevych category:cs.CL  published:2017-04-07 summary:This paper describes our approach to the SemEval 2017 Task 10: "Extracting Keyphrases and Relations from Scientific Publications", specifically to Subtask (B): "Classification of identified keyphrases". We explored three different deep learning approaches: a character-level convolutional neural network (CNN), a stacked learner with an MLP meta-classifier, and an attention based Bi-LSTM. From these approaches, we created an ensemble of differently hyper-parameterized systems, achieving a micro-F1-score of 0.63 on the test data. Our approach ranks 2nd (score of 1st placed system: 0.64) out of four according to this official score. However, we erroneously trained 2 out of 3 neural nets (the stacker and the CNN) on only roughly 15% of the full data, namely, the original development set. When trained on the full data (training+development), our ensemble has a micro-F1-score of 0.69. Our code is available from https://github.com/UKPLab/semeval2017-scienceie. version:2
arxiv-1704-02789 | Parsimonious Random Vector Functional Link Network for Data Streams | http://arxiv.org/abs/1704.02789 | id:1704.02789 author:Mahardhika Pratama, Plamen P. Angelov, Edwin Lughofer, Meng Joo Er category:cs.NE cs.LG  published:2017-04-10 summary:The theory of random vector functional link network (RVFLN) has provided a breakthrough in the design of neural networks (NNs) since it conveys solid theoretical justification of randomized learning. Existing works in RVFLN are hardly scalable for data stream analytics because they are inherent to the issue of complexity as a result of the absence of structural learning scenarios. A novel class of RVLFN, namely parsimonious random vector functional link network (pRVFLN), is proposed in this paper. pRVFLN features an open structure paradigm where its network structure can be built from scratch and can be automatically generated in accordance with degree of nonlinearity and time-varying property of system being modelled. pRVFLN is equipped with complexity reduction scenarios where inconsequential hidden nodes can be pruned and input features can be dynamically selected. pRVFLN puts into perspective an online active learning mechanism which expedites the training process and relieves operator labelling efforts. In addition, pRVFLN introduces a non-parametric type of hidden node, developed using an interval-valued data cloud. The hidden node completely reflects the real data distribution and is not constrained by a specific shape of the cluster. All learning procedures of pRVFLN follow a strictly single-pass learning mode, which is applicable for an online real-time deployment. The efficacy of pRVFLN was rigorously validated through numerous simulations and comparisons with state-of-the art algorithms where it produced the most encouraging numerical results. Furthermore, the robustness of pRVFLN was investigated and a new conclusion is made to the scope of random parameters where it plays vital role to the success of randomized learning. version:1
arxiv-1704-02787 | Deep Affordance-grounded Sensorimotor Object Recognition | http://arxiv.org/abs/1704.02787 | id:1704.02787 author:Spyridon Thermos, Georgios Th. Papadopoulos, Petros Daras, Gerasimos Potamianos category:cs.CV  published:2017-04-10 summary:It is well-established by cognitive neuroscience that human perception of objects constitutes a complex process, where object appearance information is combined with evidence about the so-called object "affordances", namely the types of actions that humans typically perform when interacting with them. This fact has recently motivated the "sensorimotor" approach to the challenging task of automatic object recognition, where both information sources are fused to improve robustness. In this work, the aforementioned paradigm is adopted, surpassing current limitations of sensorimotor object recognition research. Specifically, the deep learning paradigm is introduced to the problem for the first time, developing a number of novel neuro-biologically and neuro-physiologically inspired architectures that utilize state-of-the-art neural networks for fusing the available information sources in multiple ways. The proposed methods are evaluated using a large RGB-D corpus, which is specifically collected for the task of sensorimotor object recognition and is made publicly available. Experimental results demonstrate the utility of affordance information to object recognition, achieving an up to 29% relative error reduction by its inclusion. version:1
arxiv-1704-02781 | Tracking the Trackers: An Analysis of the State of the Art in Multiple Object Tracking | http://arxiv.org/abs/1704.02781 | id:1704.02781 author:Laura Leal-Taixé, Anton Milan, Konrad Schindler, Daniel Cremers, Ian Reid, Stefan Roth category:cs.CV  published:2017-04-10 summary:Standardized benchmarks are crucial for the majority of computer vision applications. Although leaderboards and ranking tables should not be over-claimed, benchmarks often provide the most objective measure of performance and are therefore important guides for research. We present a benchmark for Multiple Object Tracking launched in the late 2014, with the goal of creating a framework for the standardized evaluation of multiple object tracking methods. This paper collects the two releases of the benchmark made so far, and provides an in-depth analysis of almost 50 state-of-the-art trackers that were tested on over 11000 frames. We show the current trends and weaknesses of multiple people tracking methods, and provide pointers of what researchers should be focusing on to push the field forward. version:1
arxiv-1704-02738 | Detail-revealing Deep Video Super-resolution | http://arxiv.org/abs/1704.02738 | id:1704.02738 author:Xin Tao, Hongyun Gao, Renjie Liao, Jue Wang, Jiaya Jia category:cs.CV  published:2017-04-10 summary:Previous CNN-based video super-resolution approaches need to align multiple frames to the reference. In this paper, we show that proper frame alignment and motion compensation is crucial for achieving high quality results. We accordingly propose a `sub-pixel motion compensation' (SPMC) layer in a CNN framework. Analysis and experiments show the suitability of this layer in video SR. The final end-to-end, scalable CNN framework effectively incorporates the SPMC layer and fuses multiple frames to reveal image details. Our implementation can generate visually and quantitatively high-quality results, superior to current state-of-the-arts, without the need of parameter tuning. version:1
arxiv-1704-02729 | DeepPermNet: Visual Permutation Learning | http://arxiv.org/abs/1704.02729 | id:1704.02729 author:Rodrigo Santa Cruz, Basura Fernando, Anoop Cherian, Stephen Gould category:cs.CV  published:2017-04-10 summary:We present a principled approach to uncover the structure of visual data by solving a novel deep learning task coined visual permutation learning. The goal of this task is to find the permutation that recovers the structure of data from shuffled versions of it. In the case of natural images, this task boils down to recovering the original image from patches shuffled by an unknown permutation matrix. Unfortunately, permutation matrices are discrete, thereby posing difficulties for gradient-based methods. To this end, we resort to a continuous approximation of these matrices using doubly-stochastic matrices which we generate from standard CNN predictions using Sinkhorn iterations. Unrolling these iterations in a Sinkhorn network layer, we propose DeepPermNet, an end-to-end CNN model for this task. The utility of DeepPermNet is demonstrated on two challenging computer vision problems, namely, (i) relative attributes learning and (ii) self-supervised representation learning. Our results show state-of-the-art performance on the Public Figures and OSR benchmarks for (i) and on the classification and segmentation tasks on the PASCAL VOC dataset for (ii). version:1
arxiv-1704-02718 | Distributed Learning for Cooperative Inference | http://arxiv.org/abs/1704.02718 | id:1704.02718 author:Angelia Nedić, Alex Olshevsky, César A. Uribe category:math.OC cs.LG cs.MA math.PR stat.ML  published:2017-04-10 summary:We study the problem of cooperative inference where a group of agents interact over a network and seek to estimate a joint parameter that best explains a set of observations. Agents do not know the network topology or the observations of other agents. We explore a variational interpretation of the Bayesian posterior density, and its relation to the stochastic mirror descent algorithm, to propose a new distributed learning algorithm. We show that, under appropriate assumptions, the beliefs generated by the proposed algorithm concentrate around the true parameter exponentially fast. We provide explicit non-asymptotic bounds for the convergence rate. Moreover, we develop explicit and computationally efficient algorithms for observation models belonging to exponential families. version:1
arxiv-1704-02712 | Adaptive Relaxed ADMM: Convergence Theory and Practical Implementation | http://arxiv.org/abs/1704.02712 | id:1704.02712 author:Zheng Xu, Mario A. T. Figueiredo, Xiaoming Yuan, Christoph Studer, Tom Goldstein category:cs.CV cs.AI cs.LG  published:2017-04-10 summary:Many modern computer vision and machine learning applications rely on solving difficult optimization problems that involve non-differentiable objective functions and constraints. The alternating direction method of multipliers (ADMM) is a widely used approach to solve such problems. Relaxed ADMM is a generalization of ADMM that often achieves better performance, but its efficiency depends strongly on algorithm parameters that must be chosen by an expert user. We propose an adaptive method that automatically tunes the key algorithm parameters to achieve optimal performance without user oversight. Inspired by recent work on adaptivity, the proposed adaptive relaxed ADMM (ARADMM) is derived by assuming a Barzilai-Borwein style linear gradient. A detailed convergence analysis of ARADMM is provided, and numerical results on several applications demonstrate fast practical convergence. version:1
arxiv-1704-02709 | Improving Implicit Semantic Role Labeling by Predicting Semantic Frame Arguments | http://arxiv.org/abs/1704.02709 | id:1704.02709 author:Quynh Ngoc Thi Do, Steven Bethard, Marie-Francine Moens category:cs.CL  published:2017-04-10 summary:We introduce an approach to implicit semantic role labeling (iSRL) based on a recurrent neural semantic frame model that learns probability distributions over sequences of explicit semantic frame arguments. On the NomBank iSRL test set, the approach results in better state-of-the-art performance with much less reliance on manually constructed language resources. version:1
arxiv-1704-02708 | Distribution-free Evolvability of Vector Spaces: All it takes is a Generating Set | http://arxiv.org/abs/1704.02708 | id:1704.02708 author:Richard Nock, Frank Nielsen category:cs.LG I.2.6; G.1.6  published:2017-04-10 summary:In Valiant's model of evolution, a class of representations is evolvable iff a polynomial-time process of random mutations guided by selection converges with high probability to a representation as $\epsilon$-close as desired from the optimal one, for any required $\epsilon>0$. Several previous positive results exist that can be related to evolving a vector space, but each former result imposes restrictions either on (re)initialisations, distributions, performance functions and/or the mutator. In this paper, we show that all it takes to evolve a complete normed vector space is merely a set that generates the space. Furthermore, it takes only $\tilde{O}(1/\epsilon^2)$ steps and it is essentially strictly monotonic, agnostic and handles target drifts that rival some proven in fairly restricted settings. In the context of the model, we bring to the fore new results not documented previously. Evolution appears to occur in a mean-divergence model reminiscent of Markowitz mean-variance model for portfolio selection, and the risk-return efficient frontier of evolution shows an interesting pattern: when far from the optimum, the mutator always has access to mutations close to the efficient frontier. Toy experiments in supervised and unsupervised learning display promising directions for this scheme to be used as a (new) provable gradient-free stochastic optimisation algorithm. version:1
arxiv-1704-02703 | Automatic Liver Lesion Detection using Cascaded Deep Residual Networks | http://arxiv.org/abs/1704.02703 | id:1704.02703 author:Lei Bi, Jinman Kim, Ashnil Kumar, Dagan Feng category:cs.CV  published:2017-04-10 summary:Automatic segmentation of liver lesions is a fundamental requirement towards the creation of computer aided diagnosis (CAD) and decision support systems (CDS). Traditional segmentation approaches depend heavily upon hand-crafted features and a priori knowledge of the user. As such, these methods are difficult to adopt within a clinical environment. Recently, deep learning methods based on fully convolutional networks (FCNs) have been successful in many segmentation problems primarily because they leverage a large labelled dataset to hierarchically learn the features that best correspond to the shallow visual appearance as well as the deep semantics of the areas to be segmented. However, FCNs based on a 16 layer VGGNet architecture have limited capacity to add additional layers. Therefore, it is challenging to learn more discriminative features among different classes for FCNs. In this study, we overcome these limitations using deep residual networks (ResNet) to segment liver lesions. ResNet contain skip connections between convolutional layers, which solved the problem of the training degradation of training accuracy in very deep networks and thereby enables the use of additional layers for learning more discriminative features. In addition, we achieve more precise boundary definitions through a novel cascaded ResNet architecture with multi-scale fusion to gradually learn and infer the boundaries of both the liver and the liver lesions. Our proposed method achieved 4th place in the ISBI 2017 Liver Tumor Segmentation Challenge by the submission deadline. version:1
arxiv-1704-02694 | Fully Convolutional Deep Neural Networks for Persistent Multi-Frame Multi-Object Detection in Wide Area Aerial Videos | http://arxiv.org/abs/1704.02694 | id:1704.02694 author:Rodney LaLonde, Dong Zhang, Mubarak Shah category:cs.CV  published:2017-04-10 summary:Multiple object detection in wide area aerial videos, has drawn the attention of the computer vision research community for a number of years. A novel framework is proposed in this paper using a fully convolutional deep neural network, which is able to detect all objects simultaneously for a given region of interest. The network is designed to accept multiple video frames at a time as the input and yields detection results for all objects in the temporally center frame. This multi-frame approach yield far better results than its single frame counterpart. Additionally, the proposed method can detect vehicles which are slowing, stopped, and/or partially or fully occluded during some frames, which cannot be handled by nearly all state-of-the-art methods. To the best of our knowledge, this is the first use of a multiple-frame, fully convolutional deep model for detecting multiple small objects and the only framework which can detect stopped and temporarily occluded vehicles, for aerial videos. The proposed network exceeds state-of-the-art results significantly on WPAFB 2009 dataset. version:1
arxiv-1704-02686 | Word Embeddings via Tensor Factorization | http://arxiv.org/abs/1704.02686 | id:1704.02686 author:Eric Bailey, Shuchin Aeron category:stat.ML cs.CL cs.LG  published:2017-04-10 summary:Most popular word embedding techniques involve implicit or explicit factorization of a word co-occurrence based matrix into low rank factors. In this paper, we aim to generalize this trend by using numerical methods to factor higher-order word co-occurrence based arrays, or \textit{tensors}. We present four word embeddings using tensor factorization and analyze their advantages and disadvantages. One of our main contributions is a novel joint symmetric tensor factorization technique related to the idea of coupled tensor factorization. We show that embeddings based on tensor factorization can be used to discern the various meanings of polysemous words without being explicitly trained to do so, and motivate the intuition behind why this works in a way that doesn't with existing methods. We also modify an existing word embedding evaluation metric known as Outlier Detection [Camacho-Collados and Navigli, 2016] to evaluate the quality of the order-$N$ relations that a word embedding captures, and show that tensor-based methods outperform existing matrix-based methods at this task. Experimentally, we show that all of our word embeddings either outperform or are competitive with state-of-the-art baselines commonly used today on a variety of recent datasets. Suggested applications of tensor factorization-based word embeddings are given, and all source code and pre-trained vectors are publicly available online. version:1
arxiv-1704-02685 | Learning Important Features Through Propagating Activation Differences | http://arxiv.org/abs/1704.02685 | id:1704.02685 author:Avanti Shrikumar, Peyton Greenside, Anshul Kundaje category:cs.CV cs.LG cs.NE  published:2017-04-10 summary:The purported "black box"' nature of neural networks is a barrier to adoption in applications where interpretability is essential. Here we present DeepLIFT (Deep Learning Important FeaTures), a method for decomposing the output prediction of a neural network on a specific input by backpropagating the contributions of all neurons in the network to every feature of the input. DeepLIFT compares the activation of each neuron to its 'reference activation' and assigns contribution scores according to the difference. By optionally giving separate consideration to positive and negative contributions, DeepLIFT can also reveal dependencies which are missed by other approaches. Scores can be computed efficiently in a single backward pass. We apply DeepLIFT to models trained on MNIST and simulated genomic data, and show significant advantages over gradient-based methods. A detailed video tutorial on the method is at http://goo.gl/qKb7pL and code is at http://goo.gl/RM8jvH. version:1
arxiv-1704-02681 | Pyramid Vector Quantization for Deep Learning | http://arxiv.org/abs/1704.02681 | id:1704.02681 author:Vincenzo Liguori category:cs.LG cs.NE  published:2017-04-10 summary:This paper explores the use of Pyramid Vector Quantization (PVQ) to reduce the computational cost for a variety of neural networks (NNs) while, at the same time, compressing the weights that describe them. This is based on the fact that the dot product between an N dimensional vector of real numbers and an N dimensional PVQ vector can be calculated with only additions and subtractions and one multiplication. This is advantageous since tensor products, commonly used in NNs, can be re-conduced to a dot product or a set of dot products. Finally, it is stressed that any NN architecture that is based on an operation that can be re-conduced to a dot product can benefit from the techniques described here. version:1
arxiv-1704-02621 | Mixed Graphical Models for Causal Analysis of Multi-modal Variables | http://arxiv.org/abs/1704.02621 | id:1704.02621 author:Andrew J Sedgewick, Joseph D. Ramsey, Peter Spirtes, Clark Glymour, Panayiotis V. Benos category:cs.AI stat.ML  published:2017-04-09 summary:Graphical causal models are an important tool for knowledge discovery because they can represent both the causal relations between variables and the multivariate probability distributions over the data. Once learned, causal graphs can be used for classification, feature selection and hypothesis generation, while revealing the underlying causal network structure and thus allowing for arbitrary likelihood queries over the data. However, current algorithms for learning sparse directed graphs are generally designed to handle only one type of data (continuous-only or discrete-only), which limits their applicability to a large class of multi-modal biological datasets that include mixed type variables. To address this issue, we developed new methods that modify and combine existing methods for finding undirected graphs with methods for finding directed graphs. These hybrid methods are not only faster, but also perform better than the directed graph estimation methods alone for a variety of parameter settings and data set sizes. Here, we describe a new conditional independence test for learning directed graphs over mixed data types and we compare performances of different graph learning strategies on synthetic data. version:1
arxiv-1703-09625 | Learning and Refining of Privileged Information-based RNNs for Action Recognition from Depth Sequences | http://arxiv.org/abs/1703.09625 | id:1703.09625 author:Zhiyuan Shi, Tae-Kyun Kim category:cs.CV  published:2017-03-28 summary:Existing RNN-based approaches for action recognition from depth sequences require either skeleton joints or hand-crafted depth features as inputs. An end-to-end manner, mapping from raw depth maps to action classes, is non-trivial to design due to the fact that: 1) single channel map lacks texture thus weakens the discriminative power; 2) relatively small set of depth training data. To address these challenges, we propose to learn an RNN driven by privileged information (PI) in three-steps: An encoder is pre-trained to learn a joint embedding of depth appearance and PI (i.e. skeleton joints). The learned embedding layers are then tuned in the learning step, aiming to optimize the network by exploiting PI in a form of multi-task loss. However, exploiting PI as a secondary task provides little help to improve the performance of a primary task (i.e. classification) due to the gap between them. Finally, a bridging matrix is defined to connect two tasks by discovering latent PI in the refining step. Our PI-based classification loss maintains a consistency between latent PI and predicted distribution. The latent PI and network are iteratively estimated and updated in an expectation-maximization procedure. The proposed learning process provides greater discriminative power to model subtle depth difference, while helping avoid overfitting the scarcer training data. Our experiments show significant performance gains over state-of-the-art methods on three public benchmark datasets and our newly collected Blanket dataset. version:2
arxiv-1704-02612 | BigHand2.2M Benchmark: Hand Pose Dataset and State of the Art Analysis | http://arxiv.org/abs/1704.02612 | id:1704.02612 author:Shanxin Yuan, Qi Ye, Bjorn Stenger, Siddhand Jain, Tae-Kyun Kim category:cs.CV  published:2017-04-09 summary:In this paper we introduce a large-scale hand pose dataset, collected using a novel capture method. Existing datasets are either generated synthetically or captured using depth sensors: synthetic datasets exhibit a certain level of appearance difference from real depth images, and real datasets are limited in quantity and coverage, mainly due to the difficulty to annotate them. We propose a tracking system with six 6D magnetic sensors and inverse kinematics to automatically obtain 21-joints hand pose annotations of depth maps captured with minimal restriction on the range of motion. The capture protocol aims to fully cover the natural hand pose space. As shown in embedding plots, the new dataset exhibits a significantly wider and denser range of hand poses compared to existing benchmarks. Current state-of-the-art methods are evaluated on the dataset, and we demonstrate significant improvements in cross-benchmark performance. We also show significant improvements in egocentric hand pose estimation with a CNN trained on the new dataset. version:1
arxiv-1704-02602 | Automatic Image Filtering on Social Networks Using Deep Learning and Perceptual Hashing During Crises | http://arxiv.org/abs/1704.02602 | id:1704.02602 author:Dat Tien Nguyen, Firoj Alam, Ferda Ofli, Muhammad Imran category:cs.CY cs.CV cs.SI  published:2017-04-09 summary:The extensive use of social media platforms, especially during disasters, creates unique opportunities for humanitarian organizations to gain situational awareness and launch relief operations accordingly. In addition to the textual content, people post overwhelming amounts of imagery data on social networks within minutes of a disaster hit. Studies point to the importance of this online imagery content for emergency response. Despite recent advances in the computer vision field, automatic processing of the crisis-related social media imagery data remains a challenging task. It is because a majority of which consists of redundant and irrelevant content. In this paper, we present an image processing pipeline that comprises de-duplication and relevancy filtering mechanisms to collect and filter social media image content in real-time during a crisis event. Results obtained from extensive experiments on real-world crisis datasets demonstrate the significance of the proposed pipeline for optimal utilization of both human and machine computing resources. version:1
arxiv-1704-02592 | MLC Toolbox: A MATLAB/OCTAVE Library for Multi-Label Classification | http://arxiv.org/abs/1704.02592 | id:1704.02592 author:Keigo Kimura, Lu Sun, Mineichi Kudo category:cs.LG  published:2017-04-09 summary:Multi-Label Classification toolbox is a MATLAB/OCTAVE library for Multi-Label Classification (MLC). There exists a few Java libraries for MLC, but no MATLAB/OCTAVE library that covers various methods. This toolbox offers an environment for evaluation, comparison and visualization of the MLC results. One attraction of this toolbox is that it enables us to try many combinations of feature space dimension reduction, sample clustering, label space dimension reduction and ensemble, etc. version:1
arxiv-1704-02578 | Strictly Proper Kernel Scoring Rules and Divergences with an Application to Kernel Two-Sample Hypothesis Testing | http://arxiv.org/abs/1704.02578 | id:1704.02578 author:Hamed Masnadi-Shirazi category:stat.ML  published:2017-04-09 summary:We study strictly proper scoring rules in the Reproducing Kernel Hilbert Space. We propose a general Kernel Scoring rule and associated Kernel Divergence. We consider conditions under which the Kernel Score is strictly proper. We then demonstrate that the Kernel Score includes the Maximum Mean Discrepancy as a special case. We also consider the connections between the Kernel Score and the minimum risk of a proper loss function. We show that the Kernel Score incorporates more information pertaining to the projected embedded distributions compared to the Maximum Mean Discrepancy. Finally, we show how to integrate the information provided from different Kernel Divergences, such as the proposed Bhattacharyya Kernel Divergence, using a one-class classifier for improved two-sample hypothesis testing results. version:1
arxiv-1704-02568 | An Outlyingness Matrix for Multivariate Functional Data Classification | http://arxiv.org/abs/1704.02568 | id:1704.02568 author:Wenlin Dai, Marc G. Genton category:stat.ME stat.ML  published:2017-04-09 summary:The classification of multivariate functional data is an important task in scientific research. Unlike point-wise data, functional data are usually classified by their shapes rather than by their scales. We define an outlyingness matrix by extending directional outlyingness, an effective measure of the shape variation of curves that combines the direction of outlyingness with conventional depth. We propose two classifiers based on directional outlyingness and the outlyingness matrix, respectively. Our classifiers provide better performance compared with existing depth-based classifiers when applied on both univariate and multivariate functional data from simulation studies. We also test our methods on two data problems: speech recognition and gesture classification, and obtain results that are consistent with the findings from the simulated data. version:1
arxiv-1704-02567 | Motion Saliency Based Automatic Delineation of Glottis Contour in High-speed Digital Images | http://arxiv.org/abs/1704.02567 | id:1704.02567 author:Xin Chen, Emma Marriott, Yuling Yan category:cs.CV  published:2017-04-09 summary:In recent years, high-speed videoendoscopy (HSV) has significantly aided the diagnosis of voice pathologies and furthered the understanding the voice production in recent years. As the first step of these studies, automatic segmentation of glottal images till presents a major challenge for this technique. In this paper, we propose an improved Saliency Network that automatically delineates the contour of the glottis from HSV image sequences. Our proposed additional saliency measure, Motion Saliency (MS), improves upon the original Saliency Network by using the velocities of defined edges. In our results and analysis, we demonstrate the effectiveness of our approach and discuss its potential applications for computer-aided assessment of voice pathologies and understanding voice production. version:1
arxiv-1704-02565 | Prosody: The Rhythms and Melodies of Speech | http://arxiv.org/abs/1704.02565 | id:1704.02565 author:Dafydd Gibbon category:cs.CL  published:2017-04-09 summary:The present contribution is a tutorial on selected aspects of prosody, the rhythms and melodies of speech, based on a course of the same name at the Summer School on Contemporary Phonetics and Phonology at Tongji University, Shanghai, China in July 2016. The tutorial is not intended as an introduction to experimental methodology or as an overview of the literature on the topic, but as an outline of observationally accessible aspects of fundamental frequency and timing patterns with the aid of computational visualisation, situated in a semiotic framework of sign ranks and interpretations. After an informal introduction to the basic concepts of prosody in the introduction and a discussion of the place of prosody in the architecture of language, a selection of acoustic phonetic topics in phonemic tone and accent prosody, word prosody, phrasal prosody and discourse prosody are discussed, and a stylisation method for visualising aspects of prosody is introduced. Examples are taken from a number of typologically different languages: Anyi/Agni (Niger-Congo>Kwa, Ivory Coast), English, Kuki-Thadou (Sino-Tibetan, North-East India and Myanmar), Mandarin Chinese, Tem (Niger-Congo>Gur, Togo) and Farsi. The main focus is on fundamental frequency patterns, but issues of timing and rhythm are also discussed. In the final section, further reading and possible future research directions are outlined. version:1
arxiv-1704-00485 | Stop That Join! Discarding Dimension Tables when Learning High Capacity Classifiers | http://arxiv.org/abs/1704.00485 | id:1704.00485 author:Vraj Shah, Arun Kumar, Xiaojin Zhu category:cs.DB cs.LG  published:2017-04-03 summary:Many datasets have multiple tables connected by key-foreign key dependencies. Data scientists usually join all tables to bring in extra features from the so-called dimension tables. Unlike the statistical relational learning setting, such joins do not cause record duplications, which means regular IID models are typically used. Recent work demonstrated the possibility of using foreign key features as representatives for the dimension tables' features and eliminating the latter a priori, potentially saving runtime and effort of data scientists. However, the prior work was restricted to linear models and it established a dichotomy of when dimension tables are safe to discard due to extra overfitting caused by the use of foreign key features. In this work, we revisit that question for two popular high capacity models: decision tree and SVM with RBF kernel. Our extensive empirical and simulation-based analyses show that these two classifiers are surprisingly and counter-intuitively more robust to discarding dimension tables and face much less extra overfitting than linear models. We provide intuitive explanations for their behavior and identify new open questions for further ML theoretical research. We also identify and resolve two key practical bottlenecks in using foreign key features. version:2
arxiv-1704-02534 | Noisy Tensor Completion for Tensors with a Sparse Canonical Polyadic Factor | http://arxiv.org/abs/1704.02534 | id:1704.02534 author:Swayambhoo Jain, Alexander Gutierrez, Jarvis Haupt category:stat.ML  published:2017-04-08 summary:In this paper we study the problem of noisy tensor completion for tensors that admit a canonical polyadic or CANDECOMP/PARAFAC (CP) decomposition with one of the factors being sparse. We present general theoretical error bounds for an estimate obtained by using a complexity-regularized maximum likelihood principle and then instantiate these bounds for the case of additive white Gaussian noise. We also provide an ADMM-type algorithm for solving the complexity-regularized maximum likelihood problem and validate the theoretical finding via experiments on synthetic data set. version:1
arxiv-1704-02532 | Deep Reinforcement Learning framework for Autonomous Driving | http://arxiv.org/abs/1704.02532 | id:1704.02532 author:Ahmad El Sallab, Mohammed Abdou, Etienne Perot, Senthil Yogamani category:stat.ML cs.LG cs.RO  published:2017-04-08 summary:Reinforcement learning is considered to be a strong AI paradigm which can be used to teach machines through interaction with the environment and learning from their mistakes. Despite its perceived utility, it has not yet been successfully applied in automotive applications. Motivated by the successful demonstrations of learning of Atari games and Go by Google DeepMind, we propose a framework for autonomous driving using deep reinforcement learning. This is of particular relevance as it is difficult to pose autonomous driving as a supervised learning problem due to strong interactions with the environment including other vehicles, pedestrians and roadworks. As it is a relatively new area of research for autonomous driving, we provide a short overview of deep reinforcement learning and then describe our proposed framework. It incorporates Recurrent Neural Networks for information integration, enabling the car to handle partially observable scenarios. It also integrates the recent work on attention models to focus on relevant information, thereby reducing the computational complexity for deployment on embedded hardware. The framework was tested in an open source 3D car racing simulator called TORCS. Our simulation results demonstrate learning of autonomous maneuvering in a scenario of complex road curvatures and simple interaction of other vehicles. version:1
arxiv-1704-02518 | Deep Generative Adversarial Compression Artifact Removal | http://arxiv.org/abs/1704.02518 | id:1704.02518 author:Leonardo Galteri, Lorenzo Seidenari, Marco Bertini, Alberto Del Bimbo category:cs.CV  published:2017-04-08 summary:Compression artifacts arise in images whenever a lossy compression algorithm is applied. These artifacts eliminate details present in the original image, or add noise and small structures; because of these effects they make images less pleasant for the human eye, and may also lead to decreased performance of computer vision algorithms such as object detectors. To eliminate such artifacts, when decompressing an image, it is required to recover the original image from a disturbed version. To this end, we present a feed-forward fully convolutional residual network model that directly optimizes the Structural Similarity (SSIM), which is a better loss with respect to the simpler Mean Squared Error (MSE). We then build on the same architecture to re-formulate the problem in a generative adversarial framework. Our GAN is able to produce images with more photorealistic details than MSE or SSIM based networks. Moreover we show that our approach can be used as a pre-processing step for object detection in case images are degraded by compression to a point that state-of-the art detectors fail. In this task, our GAN method obtains better performance than MSE or SSIM trained networks. version:1
arxiv-1704-02516 | An Empirical Evaluation of Visual Question Answering for Novel Objects | http://arxiv.org/abs/1704.02516 | id:1704.02516 author:Santhosh K. Ramakrishnan, Ambar Pal, Gaurav Sharma, Anurag Mittal category:cs.CV  published:2017-04-08 summary:We study the problem of answering questions about images in the harder setting, where the test questions and corresponding images contain novel objects, which were not queried about in the training data. Such setting is inevitable in real world-owing to the heavy tailed distribution of the visual categories, there would be some objects which would not be annotated in the train set. We show that the performance of two popular existing methods drop significantly (up to 28%) when evaluated on novel objects cf. known objects. We propose methods which use large existing external corpora of (i) unlabeled text, i.e. books, and (ii) images tagged with classes, to achieve novel object based visual question answering. We do systematic empirical studies, for both an oracle case where the novel objects are known textually, as well as a fully automatic case without any explicit knowledge of the novel objects, but with the minimal assumption that the novel objects are semantically related to the existing objects in training. The proposed methods for novel object based visual question answering are modular and can potentially be used with many visual question answering architectures. We show consistent improvements with the two popular architectures and give qualitative analysis of the cases where the model does well and of those where it fails to bring improvements. version:1
arxiv-1703-10756 | Novel Framework for Spectral Clustering using Topological Node Features(TNF) | http://arxiv.org/abs/1703.10756 | id:1703.10756 author:Lalith Srikanth Chintalapati, Raghunatha Sarma Rachakonda category:cs.CV  published:2017-03-31 summary:Spectral clustering has gained importance in recent years due to its ability to cluster complex data as it requires only pairwise similarity among data points with its ease of implementation. The central point in spectral clustering is the process of capturing pair-wise similarity. In the literature, many research techniques have been proposed for effective construction of affinity matrix with suitable pair- wise similarity. In this paper a general framework for capturing pairwise affinity using local features such as density, proximity and structural similarity is been proposed. Topological Node Features are exploited to define the notion of density and local structure. These local features are incorporated into the construction of the affinity matrix. Experimental results, on widely used datasets such as synthetic shape datasets, UCI real datasets and MNIST handwritten datasets show that the proposed framework outperforms standard spectral clustering methods. version:2
arxiv-1704-02510 | DualGAN: Unsupervised Dual Learning for Image-to-Image Translation | http://arxiv.org/abs/1704.02510 | id:1704.02510 author:Zili Yi, Hao Zhang, Ping Tan. Minglun Gong category:cs.CV  published:2017-04-08 summary:Using conditional Generative Adversarial Network (conditional GAN) for cross-domain image-to-image translation has achieved significant improvements in the past year. Depending on the degree of task complexity, thousands or even millions of labeled image pairs are needed to train conditional GANs. However, human labeling is very expensive and sometimes impractical. Inspired by the success of dual learning paradigm in natural language translation, we develop a novel dual-GAN mechanism, which enables image translators to be trained from two sets of unlabeled images each representing a domain. In our architecture, the primal GAN learns to translate images from domain $U$ to those in domain $V$, while the dual GAN learns to convert images from $V$ to $U$. The closed loop made by the primal and dual tasks allows images from either domain to be translated and then reconstructed. Hence a loss function that accounts for the reconstruction error of images can be used to train the translation models. Experiments on multiple image translation tasks with unlabeled data show considerable performance gain of our dual-GAN architecture over a single GAN. For some tasks, our model can even achieve comparable or slightly better results to conditional GAN trained on fully labeled data. version:1
arxiv-1704-02502 | Interactive Graphics for Visually Diagnosing Forest Classifiers in R | http://arxiv.org/abs/1704.02502 | id:1704.02502 author:Natalia da Silva, Dianne Cook, Eun-Kyung Lee category:stat.ML  published:2017-04-08 summary:This paper describes structuring data and constructing plots to explore forest classification models interactively. A forest classifier is an example of an ensemble, produced by bagging multiple trees. The process of bagging and combining results from multiple trees, produces numerous diagnostics which, with interactive graphics, can provide a lot of insight into class structure in high dimensions. Various aspects are explored in this paper, to assess model complexity, individual model contributions, variable importance and dimension reduction, and uncertainty in prediction associated with individual observations. The ideas are applied to the random forest algorithm, and to the projection pursuit forest, but could be more broadly applied to other bagged ensembles. Interactive graphics are built in R, using the ggplot2, plotly, and shiny packages. version:1
arxiv-1704-02497 | On the Linearity of Semantic Change: Investigating Meaning Variation via Dynamic Graph Models | http://arxiv.org/abs/1704.02497 | id:1704.02497 author:Steffen Eger, Alexander Mehler category:cs.CL  published:2017-04-08 summary:We consider two graph models of semantic change. The first is a time-series model that relates embedding vectors from one time period to embedding vectors of previous time periods. In the second, we construct one graph for each word: nodes in this graph correspond to time points and edge weights to the similarity of the word's meaning across two time points. We apply our two models to corpora across three different languages. We find that semantic change is linear in two senses. Firstly, today's embedding vectors (= meaning) of words can be derived as linear combinations of embedding vectors of their neighbors in previous time periods. Secondly, self-similarity of words decays linearly in time. We consider both findings as new laws/hypotheses of semantic change. version:1
arxiv-1704-02470 | DSLR-Quality Photos on Mobile Devices with Deep Convolutional Networks | http://arxiv.org/abs/1704.02470 | id:1704.02470 author:Andrey Ignatov, Nikolay Kobyshev, Kenneth Vanhoey, Radu Timofte, Luc Van Gool category:cs.CV  published:2017-04-08 summary:Despite a rapid rise in the quality of built-in smartphone cameras, their physical limitations - small sensor size, compact lenses and the lack of specific hardware, - impede them to achieve the quality results of DSLR cameras. In this work we present an end-to-end deep learning approach that bridges this gap by translating ordinary photos into DSLR-produced images. We propose learning the translation function using a residual convolutional neural network that improves both color rendition and image sharpness. Since the standard mean squared loss is not well suited for measuring perceptual image quality, we introduce a composite perceptual error function that combines content, color and texture losses. The first two losses are defined analytically, while the texture loss is learned using an adversarial network. We also present a large-scale dataset that consists of real photos captured from three different phones and one high-end reflex camera. Our quantitative and qualitative assessments reveal that the enhanced images demonstrate the quality comparable to DSLR-taken photos, while the method itself can be applied to any type of digital cameras. version:1
arxiv-1704-02463 | First-Person Hand Action Benchmark with RGB-D Videos and 3D Hand Pose Annotations | http://arxiv.org/abs/1704.02463 | id:1704.02463 author:Guillermo Garcia-Hernando, Shanxin Yuan, Seungryul Baek, Tae-Kyun Kim category:cs.CV  published:2017-04-08 summary:In this work we study the use of 3D hand poses to recognize first-person hand actions interacting with 3D objects. Towards this goal, we collected RGB-D video sequences of more than 100K frames of 45 daily hand action categories, involving 25 different objects in several hand grasp configurations. To obtain high quality hand pose annotations from real sequences, we used our own mo-cap system that automatically infers the location of each of the 21 joints of the hand via 6 magnetic sensors on the finger tips and the inverse-kinematics of a hand model. To the best of our knowledge, this is the first benchmark for RGB-D hand action sequences with 3D hand poses. Additionally, we recorded the 6D (i.e. 3D rotations and locations) object poses and provide 3D object models for a subset of hand-object interaction sequences. We present extensive experimental evaluations of RGB-D and pose-based action recognition by 18 baselines/state-of-the-art. The impact of using appearance features, poses and their combinations are measured, and the different training/testing protocols including cross-persons are evaluated. Finally, we assess how ready the current hand pose estimation is when hands are severely occluded by objects in egocentric views and its influence on action recognition. From the results, we see clear benefits of using hand pose as a cue for action recognition compared to other data modalities. Our dataset and experiments can be of interest to communities of 6D object pose, robotics, and 3D hand pose estimation as well as action recognition. version:1
arxiv-1704-02455 | A New Pseudo-color Technique Based on Intensity Information Protection for Passive Sensor Imagery | http://arxiv.org/abs/1704.02455 | id:1704.02455 author:Mohammad Reza Khosravi, Habib Rostami, Gholam Reza Ahmadi, Suleiman Mansouri, Ahmad Keshavarz category:cs.CV  published:2017-04-08 summary:Remote sensing image processing is so important in geo-sciences. Images which are obtained by different types of sensors might initially be unrecognizable. To make an acceptable visual perception in the images, some pre-processing steps (for removing noises and etc) are preformed which they affect the analysis of images. There are different types of processing according to the types of remote sensing images. The method that we are going to introduce in this paper is to use virtual colors to colorize the gray-scale images of satellite sensors. This approach helps us to have a better analysis on a sample single-band image which has been taken by Landsat-8 (OLI) sensor (as a multi-band sensor with natural color bands, its images' natural color can be compared to synthetic color by our approach). A good feature of this method is the original image reversibility in order to keep the suitable resolution of output images. version:1
arxiv-1704-02450 | Coupled Deep Learning for Heterogeneous Face Recognition | http://arxiv.org/abs/1704.02450 | id:1704.02450 author:Xiang Wu, Lingxiao Song, Ran He, Tieniu Tan category:cs.CV  published:2017-04-08 summary:Heterogeneous face matching is a challenge issue in face recognition due to large domain difference as well as insufficient pairwise images in different modalities during training. This paper proposes a coupled deep learning (CDL) approach for the heterogeneous face matching. CDL seeks a shared feature space in which the heterogeneous face matching problem can be approximately treated as a homogeneous face matching problem. The objective function of CDL mainly includes two parts. The first part contains a trace norm as a relevance constraint, which makes unpaired images from multiple modalities be clustered and correlated. An approximate variational formulation is introduced to deal with the difficulties of optimizing low-rank constraint directly. The second part contains a cross modal ranking among triplet domain specific images to maximize the margin for different identities and increase data for a small amount of training samples. Besides, an alternating minimization method is employed to iteratively update the parameters of CDL. Experimental results show that CDL achieves better performance on the challenging CASIA NIR-VIS 2.0 face recognition database, the IIIT-D Sketch database, the CUHK Face Sketch (CUFS), and the CUHK Face Sketch FERET (CUFSF), which significantly outperforms state-of-the-art heterogeneous face recognition methods. version:1
arxiv-1704-02447 | Weakly-supervised Transfer for 3D Human Pose Estimation in the Wild | http://arxiv.org/abs/1704.02447 | id:1704.02447 author:Xingyi Zhou, Qixing Huang, Xiao Sun, Xiangyang Xue, Yichen Wei category:cs.CV  published:2017-04-08 summary:In this paper, we study the task of 3D human pose estimation in the wild. This task is challenging because existing benchmark datasets provide either 2D annotations in the wild or 3D annotations in controlled environments. We propose a weakly-supervised transfer learning method that learns an end-to-end network using training data with mixed 2D and 3D labels. The network augments a state-of-the-art 2D pose estimation network with a 3D depth regression network. Unlike previous approaches that train these two sub-networks in a sequential manner, we introduce a unified training method that fully exploits the correlation between these two sub-tasks and learns common feature representations. In doing so, the 3D pose labels in controlled environments are transferred to images in the wild that only possess 2D annotations. In addition, we introduce a 3D geometric constraint to regularize the prediction 3D poses, which is effective on images that only have 2D annotations. Our method leads to considerable performance gains and achieves competitive results on both 2D and 3D benchmarks. It produces high quality 3D human poses in the wild, without supervision of in-the-wild 3D data. version:1
arxiv-1704-02446 | Seismic facies recognition based on prestack data using deep convolutional autoencoder | http://arxiv.org/abs/1704.02446 | id:1704.02446 author:Feng Qian, Miao Yin, Ming-Jun Su, Yaojun Wang, Guangmin Hu category:cs.CV  published:2017-04-08 summary:Prestack seismic data carries much useful information that can help us find more complex atypical reservoirs. Therefore, we are increasingly inclined to use prestack seismic data for seis- mic facies recognition. However, due to the inclusion of ex- cessive redundancy, effective feature extraction from prestack seismic data becomes critical. In this paper, we consider seis- mic facies recognition based on prestack data as an image clus- tering problem in computer vision (CV) by thinking of each prestack seismic gather as a picture. We propose a convo- lutional autoencoder (CAE) network for deep feature learn- ing from prestack seismic data, which is more effective than principal component analysis (PCA) in redundancy removing and valid information extraction. Then, using conventional classification or clustering techniques (e.g. K-means or self- organizing maps) on the extracted features, we can achieve seismic facies recognition. We applied our method to the prestack data from physical model and LZB region. The re- sult shows that our approach is superior to the conventionals. version:1
arxiv-1704-04429 | 3D seismic data denoising using two-dimensional sparse coding scheme | http://arxiv.org/abs/1704.04429 | id:1704.04429 author:Ming-Jun Su, Jingbo Chang, Feng Qian, Guangmin Hu, Xiao-Yang Liu category:cs.CV cs.CE  published:2017-04-08 summary:Seismic data denoising is vital to geophysical applications and the transform-based function method is one of the most widely used techniques. However, it is challenging to design a suit- able sparse representation to express a transform-based func- tion group due to the complexity of seismic data. In this paper, we apply a seismic data denoising method based on learning- type overcomplete dictionaries which uses two-dimensional sparse coding (2DSC). First, we model the input seismic data and dictionaries as third-order tensors and introduce tensor- linear combinations for data approximation. Second, we ap- ply learning-type overcomplete dictionary, i.e., optimal sparse data representation is achieved through learning and training. Third, we exploit the alternating minimization algorithm to solve the optimization problem of seismic denoising. Finally we evaluate its denoising performance on synthetic seismic data and land data survey. Experiment results show that the two-dimensional sparse coding scheme reduces computational costs and enhances the signal-to-noise ratio. version:1
arxiv-1704-02431 | Learning Cross-Modal Deep Representations for Robust Pedestrian Detection | http://arxiv.org/abs/1704.02431 | id:1704.02431 author:Dan Xu, Wanli Ouyang, Elisa Ricci, Xiaogang Wang, Nicu Sebe category:cs.CV  published:2017-04-08 summary:This paper presents a novel method for detecting pedestrians under adverse illumination conditions. Our approach relies on a novel cross-modality learning framework and it is based on two main phases. First, given a multimodal dataset, a deep convolutional network is employed to learn a non-linear mapping, modeling the relations between RGB and thermal data. Then, the learned feature representations are transferred to a second deep network, which receives as input an RGB image and outputs the detection results. In this way, features which are both discriminative and robust to bad illumination conditions are learned. Importantly, at test time, only the second pipeline is considered and no thermal data are required. Our extensive evaluation demonstrates that the proposed approach outperforms the state-of- the-art on the challenging KAIST multispectral pedestrian dataset and it is competitive with previous methods on the popular Caltech dataset. version:1
arxiv-1704-02422 | A Deep Cascade of Convolutional Neural Networks for Dynamic MR Image Reconstruction | http://arxiv.org/abs/1704.02422 | id:1704.02422 author:Jo Schlemper, Jose Caballero, Joseph V. Hajnal, Anthony Price, Daniel Rueckert category:cs.CV  published:2017-04-08 summary:Inspired by recent advances in deep learning, we propose a framework for reconstructing dynamic sequences of 2D cardiac magnetic resonance (MR) images from undersampled data using a deep cascade of convolutional neural networks (CNNs) to accelerate the data acquisition process. In particular, we address the case where data is acquired using aggressive Cartesian undersampling. Firstly, we show that when each 2D image frame is reconstructed independently, the proposed method outperforms state-of-the-art 2D compressed sensing approaches such as dictionary learning-based MR image reconstruction, in terms of reconstruction error and reconstruction speed. Secondly, when reconstructing the frames of the sequences jointly, we demonstrate that CNNs can learn spatio-temporal correlations efficiently by combining convolution and data sharing approaches. We show that the proposed method consistently outperforms Dictionary Learning with Temporal Gradients (DLTG) and is capable of preserving anatomical structure more faithfully up to 11-fold undersampling. Moreover, reconstruction is very fast: each complete dynamic sequence can be reconstructed in less than 10s and, for the 2D case, each image frame can be reconstructed in 23ms, enabling real-time applications. version:1
