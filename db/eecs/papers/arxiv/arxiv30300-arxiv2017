arxiv-1704-05539 | Beating Atari with Natural Language Guided Reinforcement Learning | http://arxiv.org/abs/1704.05539 | id:1704.05539 author:Russell Kaplan, Christopher Sauer, Alexander Sosa category:cs.AI  published:2017-04-18 summary:We introduce the first deep reinforcement learning agent that learns to beat Atari games with the aid of natural language instructions. The agent uses a multimodal embedding between environment observations and natural language to self-monitor progress through a list of English instructions, granting itself reward for completing instructions in addition to increasing the game score. Our agent significantly outperforms Deep Q-Networks (DQNs), Asynchronous Advantage Actor-Critic (A3C) agents, and the best agents posted to OpenAI Gym on what is often considered the hardest Atari 2600 environment: Montezuma's Revenge. version:1
arxiv-1704-05521 | Building Regular Registers with Rational Malicious Servers and Anonymous Clients -- Extended Version | http://arxiv.org/abs/1704.05521 | id:1704.05521 author:Antonella Del Pozzo, Silvia Bonomi, Riccardo Lazzeretti, Roberto Baldoni category:cs.DC cs.CR 68  published:2017-04-18 summary:The paper addresses the problem of emulating a regular register in a synchronous distributed system where clients invoking ${\sf read}()$ and ${\sf write}()$ operations are anonymous while server processes maintaining the state of the register may be compromised by rational adversaries (i.e., a server might behave as \emph{rational malicious Byzantine} process). We first model our problem as a Bayesian game between a client and a rational malicious server where the equilibrium depends on the decisions of the malicious server (behave correctly and not be detected by clients vs returning a wrong register value to clients with the risk of being detected and then excluded by the computation). We prove such equilibrium exists and finally we design a protocol implementing the regular register that forces the rational malicious server to behave correctly. version:1
arxiv-1704-05519 | Computer Vision for Autonomous Vehicles: Problems, Datasets and State-of-the-Art | http://arxiv.org/abs/1704.05519 | id:1704.05519 author:Joel Janai, Fatma Güney, Aseem Behl, Andreas Geiger category:cs.CV cs.RO  published:2017-04-18 summary:Recent years have witnessed amazing progress in AI related fields such as computer vision, machine learning and autonomous vehicles. As with any rapidly growing field, however, it becomes increasingly difficult to stay up-to-date or enter the field as a beginner. While several topic specific survey papers have been written, to date no general survey on problems, datasets and methods in computer vision for autonomous vehicles exists. This paper attempts to narrow this gap by providing a state-of-the-art survey on this topic. Our survey includes both the historically most relevant literature as well as the current state-of-the-art on several specific topics, including recognition, reconstruction, motion estimation, tracking, scene understanding and end-to-end learning. Towards this goal, we first provide a taxonomy to classify each approach and then analyze the performance of the state-of-the-art on several challenging benchmarking datasets including KITTI, ISPRS, MOT and Cityscapes. Besides, we discuss open problems and current research challenges. To ease accessibility and accommodate missing references, we will also provide an interactive platform which allows to navigate topics and methods, and provides additional information and project links for each paper. version:1
arxiv-1704-05513 | 25 Tweets to Know You: A New Model to Predict Personality with Social Media | http://arxiv.org/abs/1704.05513 | id:1704.05513 author:Pierre-Hadrien Arnoux, Anbang Xu, Neil Boyette, Jalal Mahmud, Rama Akkiraju, Vibha Sinha category:cs.SI cs.AI cs.CL cs.HC  published:2017-04-18 summary:Predicting personality is essential for social applications supporting human-centered activities, yet prior modeling methods with users written text require too much input data to be realistically used in the context of social media. In this work, we aim to drastically reduce the data requirement for personality modeling and develop a model that is applicable to most users on Twitter. Our model integrates Word Embedding features with Gaussian Processes regression. Based on the evaluation of over 1.3K users on Twitter, we find that our model achieves comparable or better accuracy than state of the art techniques with 8 times fewer data. version:1
arxiv-1701-02547 | A Convenient Category for Higher-Order Probability Theory | http://arxiv.org/abs/1701.02547 | id:1701.02547 author:Chris Heunen, Ohad Kammar, Sam Staton, Hongseok Yang category:cs.PL cs.AI cs.LO math.CT math.PR  published:2017-01-10 summary:Higher-order probabilistic programming languages allow programmers to write sophisticated models in machine learning and statistics in a succinct and structured way, but step outside the standard measure-theoretic formalization of probability theory. Programs may use both higher-order functions and continuous distributions, or even define a probability distribution on functions. But standard probability theory does not handle higher-order functions well: the category of measurable spaces is not cartesian closed. Here we introduce quasi-Borel spaces. We show that these spaces: form a new formalization of probability theory replacing measurable spaces; form a cartesian closed category and so support higher-order functions; form a well-pointed category and so support good proof principles for equational reasoning; and support continuous probability distributions. We demonstrate the use of quasi-Borel spaces for higher-order functions and probability by: showing that a well-known construction of probability theory involving random functions gains a cleaner expression; and generalizing de Finetti's theorem, that is a crucial theorem in probability theory, to quasi-Borel spaces. version:3
arxiv-1704-05495 | Investigating Recurrence and Eligibility Traces in Deep Q-Networks | http://arxiv.org/abs/1704.05495 | id:1704.05495 author:Jean Harb, Doina Precup category:cs.AI cs.LG  published:2017-04-18 summary:Eligibility traces in reinforcement learning are used as a bias-variance trade-off and can often speed up training time by propagating knowledge back over time-steps in a single update. We investigate the use of eligibility traces in combination with recurrent networks in the Atari domain. We illustrate the benefits of both recurrent nets and eligibility traces in some Atari games, and highlight also the importance of the optimization used in the training. version:1
arxiv-1704-05477 | Generalized Ideals and Co-Granular Rough Sets | http://arxiv.org/abs/1704.05477 | id:1704.05477 author:A Mani category:math.LO cs.AI cs.IT cs.LO math.IT I.2.4; H.1.1  published:2017-04-18 summary:Lattice-theoretic ideals have been used to define and generate non granular rough approximations over general approximation spaces over the last few years by few authors. The goal of these studies, in relation based rough sets, have been to obtain nice properties comparable to those of classical rough approximations. In this research paper, these ideas are generalized in a severe way by the present author and associated semantic features are investigated by her. Granules are used in the construction of approximations in implicit ways and so a concept of co-granularity is introduced. Knowledge interpretation associable with the approaches is also investigated. This research will be of relevance for a number of logico-algebraic approaches to rough sets that proceed from point-wise definitions of approximations and also for using alternative approximations in spatial mereological contexts involving actual contact relations. The antichain based semantics invented in earlier papers by the present author also applies to the contexts considered. version:1
arxiv-1704-05443 | Approximations from Anywhere and General Rough Sets | http://arxiv.org/abs/1704.05443 | id:1704.05443 author:A. Mani category:math.LO cs.AI cs.DM cs.IT math.IT  published:2017-04-18 summary:Not all approximations arise from information systems. The problem of fitting approximations, subjected to some rules (and related data), to information systems in a rough scheme of things is known as the \emph{inverse problem}. The inverse problem is more general than the duality (or abstract representation) problems and was introduced by the present author in her earlier papers. From the practical perspective, a few (as opposed to one) theoretical frameworks may be suitable for formulating the problem itself. \emph{Granular operator spaces} have been recently introduced and investigated by the present author in her recent work in the context of antichain based and dialectical semantics for general rough sets. The nature of the inverse problem is examined from number-theoretic and combinatorial perspectives in a higher order variant of granular operator spaces and some necessary conditions are proved. The results and the novel approach would be useful in a number of unsupervised and semi supervised learning contexts and algorithms. version:1
arxiv-1704-04977 | Probabilistic programs for inferring the goals of autonomous agents | http://arxiv.org/abs/1704.04977 | id:1704.04977 author:Marco F. Cusumano-Towner, Alexey Radul, David Wingate, Vikash K. Mansinghka category:cs.AI  published:2017-04-17 summary:Intelligent systems sometimes need to infer the probable goals of people, cars, and robots, based on partial observations of their motion. This paper introduces a class of probabilistic programs for formulating and solving these problems. The formulation uses randomized path planning algorithms as the basis for probabilistic models of the process by which autonomous agents plan to achieve their goals. Because these path planning algorithms do not have tractable likelihood functions, new inference algorithms are needed. This paper proposes two Monte Carlo techniques for these "likelihood-free" models, one of which can use likelihood estimates from neural networks to accelerate inference. The paper demonstrates efficacy on three simple examples, each using under 50 lines of probabilistic code. version:2
arxiv-1704-05356 | Understanding Negations in Information Processing: Learning from Replicating Human Behavior | http://arxiv.org/abs/1704.05356 | id:1704.05356 author:Nicolas Pröllochs, Stefan Feuerriegel, Dirk Neumann category:cs.AI stat.AP stat.ML  published:2017-04-18 summary:Information systems experience an ever-growing volume of unstructured data, particularly in the form of textual materials. This represents a rich source of information from which one can create value for people, organizations and businesses. For instance, recommender systems can benefit from automatically understanding preferences based on user reviews or social media. However, it is difficult for computer programs to correctly infer meaning from narrative content. One major challenge is negations that invert the interpretation of words and sentences. As a remedy, this paper proposes a novel learning strategy to detect negations: we apply reinforcement learning to find a policy that replicates the human perception of negations based on an exogenous response, such as a user rating for reviews. Our method yields several benefits, as it eliminates the former need for expensive and subjective manual labeling in an intermediate stage. Moreover, the inferred policy can be used to derive statistical inferences and implications regarding how humans process and act on negations. version:1
arxiv-1704-05325 | Anomaly detection and motif discovery in symbolic representations of time series | http://arxiv.org/abs/1704.05325 | id:1704.05325 author:Fabio Guigou, Pierre Collet, Pierre Parrend category:cs.AI  published:2017-04-18 summary:The advent of the Big Data hype and the consistent recollection of event logs and real-time data from sensors, monitoring software and machine configuration has generated a huge amount of time-varying data in about every sector of the industry. Rule-based processing of such data has ceased to be relevant in many scenarios where anomaly detection and pattern mining have to be entirely accomplished by the machine. Since the early 2000s, the de-facto standard for representing time series has been the Symbolic Aggregate approXimation (SAX).In this document, we present a few algorithms using this representation for anomaly detection and motif discovery, also known as pattern mining, in such data. We propose a benchmark of anomaly detection algorithms using data from Cloud monitoring software. version:1
arxiv-1704-05316 | Benchmarking OpenCL, OpenACC, OpenMP, and CUDA: programming productivity, performance, and energy consumption | http://arxiv.org/abs/1704.05316 | id:1704.05316 author:Suejb Memeti, Lu Li, Sabri Pllana, Joanna Kolodziej, Christoph Kessler category:cs.DC cs.PF cs.PL cs.SE  published:2017-04-18 summary:Many modern parallel computing systems are heterogeneous at their node level. Such nodes may comprise general purpose CPUs and accelerators (such as, GPU, or Intel Xeon Phi) that provide high performance with suitable energy-consumption characteristics. However, exploiting the available performance of heterogeneous architectures may be challenging. There are various parallel programming frameworks (such as, OpenMP, OpenCL, OpenACC, CUDA) and selecting the one that is suitable for a target context is not straightforward. In this paper, we study empirically the characteristics of OpenMP, OpenACC, OpenCL, and CUDA with respect to programming productivity, performance, and energy. To evaluate the programming productivity we use our homegrown tool CodeStat, which enables us to determine the percentage of code lines that was required to parallelize the code using a specific framework. We use our tool x-MeterPU to evaluate the energy consumption and the performance. Experiments are conducted using the industry-standard SPEC benchmark suite and the Rodinia benchmark suite for accelerated computing on heterogeneous systems that combine Intel Xeon E5 Processors with a GPU accelerator or an Intel Xeon Phi co-processor. version:1
arxiv-1604-08066 | The Manne et al. self-stabilizing 2/3-approximation matching algorithm is sub-exponential | http://arxiv.org/abs/1604.08066 | id:1604.08066 author:Johanne Cohen, Jonas Lefèvre, Khaled Maâmra, George Manoussakis, Laurence Pilard category:cs.DC C.2.1; F.2; F.2.1  published:2016-04-27 summary:Manne et al. designed the first algorithm computing a maximal matching that is a 2/3 -approximation of the maximum matching in $O(^2n)$ moves. However, the complexity tightness was not proved. In this paper, we exhibit a sub-exponential execution of this matching algorithm. version:3
arxiv-1704-05295 | Semantic Similarity from Natural Language and Ontology Analysis | http://arxiv.org/abs/1704.05295 | id:1704.05295 author:Sébastien Harispe, Sylvie Ranwez, Stefan Janaqi, Jacky Montmain category:cs.AI cs.CL  published:2017-04-18 summary:Artificial Intelligence federates numerous scientific fields in the aim of developing machines able to assist human operators performing complex treatments -- most of which demand high cognitive skills (e.g. learning or decision processes). Central to this quest is to give machines the ability to estimate the likeness or similarity between things in the way human beings estimate the similarity between stimuli. In this context, this book focuses on semantic measures: approaches designed for comparing semantic entities such as units of language, e.g. words, sentences, or concepts and instances defined into knowledge bases. The aim of these measures is to assess the similarity or relatedness of such semantic entities by taking into account their semantics, i.e. their meaning -- intuitively, the words tea and coffee, which both refer to stimulating beverage, will be estimated to be more semantically similar than the words toffee (confection) and coffee, despite that the last pair has a higher syntactic similarity. The two state-of-the-art approaches for estimating and quantifying semantic similarities/relatedness of semantic entities are presented in detail: the first one relies on corpora analysis and is based on Natural Language Processing techniques and semantic models while the second is based on more or less formal, computer-readable and workable forms of knowledge such as semantic networks, thesaurus or ontologies. (...) Beyond a simple inventory and categorization of existing measures, the aim of this monograph is to convey novices as well as researchers of these domains towards a better understanding of semantic similarity estimation and more generally semantic measures. version:1
arxiv-1704-05272 | Scalable Global Grid catalogue for LHC Run3 and beyond | http://arxiv.org/abs/1704.05272 | id:1704.05272 author:M Martinez Pedreira, C Grigoras for the A category:cs.DC cs.DB  published:2017-04-18 summary:The AliEn (ALICE Environment) file catalogue is a global unique namespace providing mapping between a UNIX-like logical name structure and the corresponding physical files distributed over 80 storage elements worldwide. Powerful search tools and hierarchical metadata information are integral parts of the system and are used by the Grid jobs as well as local users to store and access all files on the Grid storage elements. The catalogue has been in production since 2005 and over the past 11 years has grown to more than 2 billion logical file names. The backend is a set of distributed relational databases, ensuring smooth growth and fast access. Due to the anticipated fast future growth, we are looking for ways to enhance the performance and scalability by simplifying the catalogue schema while keeping the functionality intact. We investigated different backend solutions, such as distributed key value stores, as replacement for the relational database. This contribution covers the architectural changes in the system, together with the technology evaluation, benchmark results and conclusions. version:1
arxiv-1704-02222 | MOMA: Visual Mobile Marker Odometry | http://arxiv.org/abs/1704.02222 | id:1704.02222 author:Raul Acuna, Zaijuan Li, Volker Willert category:cs.RO  published:2017-04-07 summary:In this paper, we present a cooperative odometry scheme based on the detection of mobile markers in line with the idea of cooperative positioning for multiple robots [1]. To this end, we introduce a simple optimization scheme that realizes visual mobile marker odometry via accurate fixed marker-based camera positioning and analyse the characteristics of errors inherent to the method compared to classical fixed marker-based navigation and visual odometry. In addition, we provide a specific UAV-UGV configuration that allows for continuous movements of the UAV without doing stops and a minimal caterpillar-like configuration that works with one UGV alone. Finally, we present a real-world implementation and evaluation for the proposed UAV-UGV configuration. version:2
arxiv-1704-05215 | Multisensory Omni-directional Long-term Place Recognition: Benchmark Dataset and Analysis | http://arxiv.org/abs/1704.05215 | id:1704.05215 author:Ashwin Mathur, Fei Han, Hao Zhang category:cs.RO  published:2017-04-18 summary:Recognizing a previously visited place, also known as place recognition (or loop closure detection) is the key towards fully autonomous mobile robots and self-driving vehicle navigation. Augmented with various Simultaneous Localization and Mapping techniques (SLAM), loop closure detection allows for incremental pose correction and can bolster efficient and accurate map creation. However, repeated and similar scenes (perceptual aliasing) and long term appearance changes (e.g. weather variations) are major challenges for current place recognition algorithms. We introduce a new dataset Multisensory Omnidirectional Long-term Place recognition (MOLP) comprising omnidirectional intensity and disparity images. This dataset presents many of the challenges faced by outdoor mobile robots and current place recognition algorithms. Using MOLP dataset, we formulate the place recognition problem as a regularized sparse convex optimization problem. We conclude that information extracted from intensity image is superior to disparity image in isolating discriminative features for successful long term place recognition. Furthermore, when these discriminative features are extracted from an omnidirectional vision sensor, a robust bidirectional loop closure detection approach is established, allowing mobile robots to close the loop, regardless of the difference in the direction when revisiting a place. version:1
arxiv-1704-04712 | Learn-Memorize-Recall-Reduce A Robotic Cloud Computing Paradigm | http://arxiv.org/abs/1704.04712 | id:1704.04712 author:Shaoshan Liu, Bolin Ding, Jie Tang, Dawei Sun, Zhe Zhang, Grace Tsai, Jean-Luc Gaudiot category:cs.DC cs.AI cs.RO  published:2017-04-16 summary:The rise of robotic applications has led to the generation of a huge volume of unstructured data, whereas the current cloud infrastructure was designed to process limited amounts of structured data. To address this problem, we propose a learn-memorize-recall-reduce paradigm for robotic cloud computing. The learning stage converts incoming unstructured data into structured data; the memorization stage provides effective storage for the massive amount of data; the recall stage provides efficient means to retrieve the raw data; while the reduction stage provides means to make sense of this massive amount of unstructured data with limited computing resources. version:2
arxiv-1704-05138 | Exploiting Data Longevity for Enhancing the Lifetime of Flash-based Storage Class Memory | http://arxiv.org/abs/1704.05138 | id:1704.05138 author:Wonil Choi, Mohammad Arjomand, Myoungsoo Jung, Mahmut Kandemir category:cs.AR  published:2017-04-17 summary:Storage-class memory (SCM) combines the benefits of a solid-state memory, such as high-performance and robustness, with the archival capabilities and low cost of conventional hard-disk magnetic storage. Among candidate solid-state nonvolatile memory technologies that could potentially be used to construct SCM, flash memory is a well-established technology and have been widely used in commercially available SCM incarnations. Flash-based SCM enables much better tradeoffs between performance, space and power than disk-based systems. However, write endurance is a significant challenge for a flash-based SCM (each act of writing a bit may slightly damage a cell, so one flash cell can be written 10^4--10^5 times, depending on the flash technology, before it becomes unusable). This is a well-documented problem and has received a lot of attention by manufactures that are using some combination of write reduction and wear-leveling techniques for achieving longer lifetime. In an effort to improve flash lifetime, first, by quantifying data longevity in an SCM, we show that a majority of the data stored in a solid-state SCM do not require long retention times provided by flash memory (i.e., up to 10 years in modern devices); second, by exploiting retention time relaxation, we propose a novel mechanism, called Dense-SLC (D-SLC), which enables us perform multiple writes into a cell during each erase cycle for lifetime extension; and finally, we discuss the required changes in the flash management software (FTL) in order to use this characteristic for extending the lifetime of the solid-state part of an SCM. Using an extensive simulation-based analysis of a flash-based SCM, we demonstrate that D-SLC is able to significantly improve device lifetime (between 5.1X and 8.6X) with no performance overhead and also very small changes at the FTL software. version:1
arxiv-1704-05132 | A hybrid CPU-GPU parallelization scheme of variable neighborhood search for inventory optimization problems | http://arxiv.org/abs/1704.05132 | id:1704.05132 author:Nikolaos Antoniadis, Angelo Sifaleras category:cs.NE cs.DC cs.DM 68R99 F.2.2; I.2.8; D.1.3  published:2017-04-17 summary:In this paper, we study various parallelization schemes for the Variable Neighborhood Search (VNS) metaheuristic on a CPU-GPU system via OpenMP and OpenACC. A hybrid parallel VNS method is applied to recent benchmark problem instances for the multi-product dynamic lot sizing problem with product returns and recovery, which appears in reverse logistics and is known to be NP-hard. We report our findings regarding these parallelization approaches and present promising computational results. version:1
arxiv-1704-05123 | Resolution-Exact Planner for Thick Non-Crossing 2-Link Robots | http://arxiv.org/abs/1704.05123 | id:1704.05123 author:Chee K. Yap, Zhongdi Luo, Ching-Hsiang Hsu category:cs.CG cs.RO  published:2017-04-17 summary:We consider the path planning problem for a 2-link robot amidst polygonal obstacles. Our robot is parametrizable by the lengths $\ell_1, \ell_2>0$ of its two links, the thickness $\tau \ge 0$ of the links, and an angle $\kappa$ that constrains the angle between the 2 links to be strictly greater than $\kappa$. The case $\tau>0$ and $\kappa \ge 0$ corresponds to "thick non-crossing" robots. This results in a novel 4DOF configuration space ${\mathbb R}^2\times ({\mathbb T}\setminus\Delta(\kappa))$ where ${\mathbb T}$ is the torus and $\Delta(\kappa)$ the diagonal band of width $\kappa$. We design a resolution-exact planner for this robot using the framework of Soft Subdivision Search (SSS). First, we provide an analysis of the space of forbidden angles, leading to a soft predicate for classifying configuration boxes. We further exploit the T/R splitting technique which was previously introduced for self-crossing thin 2-link robots. Our open-source implementation in Core Library achieves real-time performance for a suite of combinatorially non-trivial obstacle sets. Experimentally, our algorithm is significantly better than any of the state-of-art sampling algorithms we looked at, in timing and in success rate. version:1
arxiv-1704-05112 | Making data center computations fast, but not so furious | http://arxiv.org/abs/1704.05112 | id:1704.05112 author:Daniel Porto, João Loff, Rui Duarte, Luis Ceze, Rodrigo Rodrigues category:cs.DC  published:2017-04-17 summary:We propose an aggressive computational sprinting variant for data center environments. While most of previous work on computational sprinting focuses on maximizing the sprinting process while ensuring non-faulty conditions, we take advantage of the existing replication in data centers to push the system beyond its safety limits. In this paper we outline this vision, we survey existing techniques for achieving it, and we present some design ideas for future work in this area. version:1
arxiv-1704-05090 | Communication Modalities for Supervised Teleoperation in Highly Dexterous Tasks - Does one size fit all? | http://arxiv.org/abs/1704.05090 | id:1704.05090 author:Tian Zhou, Maria E. Cabrera, Juan P. Wachs category:cs.RO  published:2017-04-17 summary:This study tries to explain the connection between communication modalities and levels of supervision in teleoperation during a dexterous task, like surgery. This concept is applied to two surgical related tasks: incision and peg transfer. It was found that as the complexity of the task escalates, the combination linking human supervision with a more expressive modality shows better performance than other combinations of modalities and control. More specifically, in the peg transfer task, the combination of speech modality and action level supervision achieves shorter task completion time (77.1 +- 3.4 s) with fewer mistakes (0.20 +- 0.17 pegs dropped). version:1
arxiv-1704-05044 | A Study on Performance and Power Efficiency of Dense Non-Volatile Caches in Multi-Core Systems | http://arxiv.org/abs/1704.05044 | id:1704.05044 author:Amin Jadidi, Mohammad Arjomand, Mahmut T. Kandemir, Chita R. Das category:cs.AR  published:2017-04-17 summary:In this paper, we present a novel cache design based on Multi-Level Cell Spin-Transfer Torque RAM (MLC STTRAM) that can dynamically adapt the set capacity and associativity to use efficiently the full potential of MLC STTRAM. We exploit the asymmetric nature of the MLC storage scheme to build cache lines featuring heterogeneous performances, that is, half of the cache lines are read-friendly, while the other is write-friendly. Furthermore, we propose to opportunistically deactivate ways in underutilized sets to convert MLC to Single-Level Cell (SLC) mode, which features overall better performance and lifetime. Our ultimate goal is to build a cache architecture that combines the capacity advantages of MLC and performance/energy advantages of SLC. Our experiments show an improvement of 43% in total numbers of conflict misses, 27% in memory access latency, 12% in system performance, and 26% in LLC access energy, with a slight degradation in cache lifetime (about 7%) compared to an SLC cache. version:1
arxiv-1703-07948 | Fast Stochastic Variance Reduced Gradient Method with Momentum Acceleration for Machine Learning | http://arxiv.org/abs/1703.07948 | id:1703.07948 author:Fanhua Shang, Yuanyuan Liu, James Cheng, Jiacheng Zhuo category:cs.LG cs.AI math.OC stat.ML  published:2017-03-23 summary:Recently, research on accelerated stochastic gradient descent methods (e.g., SVRG) has made exciting progress (e.g., linear convergence for strongly convex problems). However, the best-known methods (e.g., Katyusha) requires at least two auxiliary variables and two momentum parameters. In this paper, we propose a fast stochastic variance reduction gradient (FSVRG) method, in which we design a novel update rule with the Nesterov's momentum and incorporate the technique of growing epoch size. FSVRG has only one auxiliary variable and one momentum weight, and thus it is much simpler and has much lower per-iteration complexity. We prove that FSVRG achieves linear convergence for strongly convex problems and the optimal $\mathcal{O}(1/T^2)$ convergence rate for non-strongly convex problems, where $T$ is the number of outer-iterations. We also extend FSVRG to directly solve the problems with non-smooth component functions, such as SVM. Finally, we empirically study the performance of FSVRG for solving various machine learning problems such as logistic regression, ridge regression, Lasso and SVM. Our results show that FSVRG outperforms the state-of-the-art stochastic methods, including Katyusha. version:2
arxiv-1704-05017 | Morpheo: Traceable Machine Learning on Hidden data | http://arxiv.org/abs/1704.05017 | id:1704.05017 author:Mathieu Galtier, Camille Marini category:cs.AI cs.CR cs.DC stat.ML  published:2017-04-17 summary:Morpheo is a transparent and secure machine learning platform collecting and analysing large datasets. It aims at building state-of-the art prediction models in various fields where data are sensitive. Indeed, it offers strong privacy of data and algorithm, by preventing anyone to read the data, apart from the owner and the chosen algorithms. Computations in Morpheo are orchestrated by a blockchain infrastructure, thus offering total traceability of operations. Morpheo aims at building an attractive economic ecosystem around data prediction by channelling crypto-money from prediction requests to useful data and algorithms providers. Morpheo is designed to handle multiple data sources in a transfer learning approach in order to mutualize knowledge acquired from large datasets for applications with smaller but similar datasets. version:1
arxiv-1704-05016 | CNN Feature boosted SeqSLAM for Real-Time Loop Closure Detection | http://arxiv.org/abs/1704.05016 | id:1704.05016 author:Dongdong Bai, Chaoqun Wang, Bo Zhang, Xiaodong Yi, Xuejun Yang category:cs.RO  published:2017-04-17 summary:Loop closure detection (LCD) is an indispensable part of simultaneous localization and mapping systems (SLAM); it enables robots to produce a consistent map by recognizing previously visited places. When robots operate over extended periods, robustness to viewpoint and condition changes as well as satisfactory real-time performance become essential requirements for a practical LCD system. This paper presents an approach to directly utilize the outputs at the intermediate layer of a pre-trained convolutional neural network (CNN) as image descriptors. The matching location is determined by matching the image sequences through a method called SeqCNNSLAM. The utility of SeqCNNSLAM is comprehensively evaluated in terms of viewpoint and condition invariance. Experiments show that SeqCNNSLAM outperforms state-of-the-art LCD systems, such as SeqSLAM and Change Removal, in most cases. To allow for the real-time performance of SeqCNNSLAM, an acceleration method, A-SeqCNNSLAM, is established. This method exploits the location relationship between the matching images of adjacent images to reduce the matching range of the current image. Results demonstrate that acceleration of 4-6 is achieved with minimal accuracy degradation, and the method's runtime satisfies the real-time demand. To extend the applicability of A-SeqCNNSLAM to new environments, a method called O-SeqCNNSLAM is established for the online adjustment of the parameters of A-SeqCNNSLAM. version:1
arxiv-1511-02455 | (Yet) Another Theoretical Model of Thinking | http://arxiv.org/abs/1511.02455 | id:1511.02455 author:Patrick Virie category:cs.AI  published:2015-11-08 summary:This paper presents a theoretical, idealized model of the thinking process with the following characteristics: 1) the model can produce complex thought sequences and can be generalized to new inputs, 2) it can receive and maintain input information indefinitely for the generation of thoughts and later use, and 3) it supports learning while executing. The crux of the model lies within the concept of internal consistency, or the generated thoughts should always be consistent with the inputs from which they are created. Its merit, apart from the capability to generate new creative thoughts from an internal mechanism, depends on the potential to help training to generalize better. This is consequently enabled by separating input information into several parts to be handled by different processing components with a focus mechanism to fetch information for each. This modularized view with the focus binds the model with the computationally capable Turing machines. And as a final remark, this paper constructively shows that the computational complexity of the model is at least, if not surpass, that of a universal Turing machine. version:4
arxiv-1602-08032 | Time-Space Trade-offs in Population Protocols | http://arxiv.org/abs/1602.08032 | id:1602.08032 author:Dan Alistarh, James Aspnes, David Eisenstat, Rati Gelashvili, Ronald L. Rivest category:cs.DC  published:2016-02-25 summary:Population protocols are a popular model of distributed computing, in which randomly-interacting agents with little computational power cooperate to jointly perform computational tasks. Inspired by developments in molecular computation, and in particular DNA computing, recent algorithmic work has focused on the complexity of solving simple yet fundamental tasks in the population model, such as leader election (which requires stabilization to a single agent in a special "leader" state), and majority (in which agents must stabilize to a decision as to which of two possible initial states had higher initial count). Known results point towards an inherent trade-off between the time complexity of such algorithms, and the space complexity, i.e. size of the memory available to each agent. In this paper, we explore this trade-off and provide new upper and lower bounds for majority and leader election. First, we prove a unified lower bound, which relates the space available per node with the time complexity achievable by a protocol: for instance, our result implies that any protocol solving either of these tasks for $n$ agents using $O( \log \log n )$ states must take $\Omega( n / \rm{polylog} n )$ expected time. This is the first result to characterize time complexity for protocols which employ super-constant number of states per node, and proves that fast, poly-logarithmic running times require protocols to have relatively large space costs. On the positive side, we give algorithms showing that fast, poly-logarithmic stabilization time can be achieved using $O( \log^2 n )$ space per node, in the case of both tasks. Overall, our results highlight a time complexity separation between $O(\log \log n)$ and $\Theta( \log^2 n )$ state space size for both majority and leader election in population protocols, and introduce new techniques, which should be applicable more broadly. version:7
arxiv-1704-04966 | Larger is Better: The Effect of Learning Rates Enjoyed by Stochastic Optimization with Progressive Variance Reduction | http://arxiv.org/abs/1704.04966 | id:1704.04966 author:Fanhua Shang category:cs.LG cs.AI math.OC stat.ML  published:2017-04-17 summary:In this paper, we propose a simple variant of the original stochastic variance reduction gradient (SVRG), where hereafter we refer to as the variance reduced stochastic gradient descent (VR-SGD). Different from the choices of the snapshot point and starting point in SVRG and its proximal variant, Prox-SVRG, the two vectors of each epoch in VR-SGD are set to the average and last iterate of the previous epoch, respectively. This setting allows us to use much larger learning rates or step sizes than SVRG, e.g., 3/(7L) for VR-SGD vs 1/(10L) for SVRG, and also makes our convergence analysis more challenging. In fact, a larger learning rate enjoyed by VR-SGD means that the variance of its stochastic gradient estimator asymptotically approaches zero more rapidly. Unlike common stochastic methods such as SVRG and proximal stochastic methods such as Prox-SVRG, we design two different update rules for smooth and non-smooth objective functions, respectively. In other words, VR-SGD can tackle non-smooth and/or non-strongly convex problems directly without using any reduction techniques such as quadratic regularizers. Moreover, we analyze the convergence properties of VR-SGD for strongly convex problems, which show that VR-SGD attains a linear convergence rate. We also provide the convergence guarantees of VR-SGD for non-strongly convex problems. Experimental results show that the performance of VR-SGD is significantly better than its counterparts, SVRG and Prox-SVRG, and it is also much better than the best known stochastic method, Katyusha. version:1
arxiv-1704-04912 | Pseudorehearsal in actor-critic agents | http://arxiv.org/abs/1704.04912 | id:1704.04912 author:Marochko Vladimir, Leonard Johard, Manuel Mazzara category:cs.AI  published:2017-04-17 summary:Catastrophic forgetting has a serious impact in reinforcement learning, as the data distribution is generally sparse and non-stationary over time. The purpose of this study is to investigate whether pseudorehearsal can increase performance of an actor-critic agent with neural-network based policy selection and function approximation in a pole balancing task and compare different pseudorehearsal approaches. We expect that pseudorehearsal assists learning even in such very simple problems, given proper initialization of the rehearsal parameters. version:1
arxiv-1705-01013 | Quantum Mechanical Approach to Modelling Reliability of Sensor Reports | http://arxiv.org/abs/1705.01013 | id:1705.01013 author:Zichang He, Wen Jiang category:cs.OH cs.AI cs.CV  published:2017-04-17 summary:Dempster-Shafer evidence theory is wildly applied in multi-sensor data fusion. However, lots of uncertainty and interference exist in practical situation, especially in the battle field. It is still an open issue to model the reliability of sensor reports. Many methods are proposed based on the relationship among collected data. In this letter, we proposed a quantum mechanical approach to evaluate the reliability of sensor reports, which is based on the properties of a sensor itself. The proposed method is used to modify the combining of evidences. version:1
arxiv-1704-05392 | Synergy of all-purpose static solver and temporal reasoning tools in dynamic integrated expert systems | http://arxiv.org/abs/1704.05392 | id:1704.05392 author:Galina Rybina, Alexey Mozgachev, Dmitry Demidov category:cs.AI  published:2017-04-16 summary:The paper discusses scientific and technological problems of dynamic integrated expert systems development. Extensions of problem-oriented methodology for dynamic integrated expert systems development are considered. Attention is paid to the temporal knowledge representation and processing. version:1
arxiv-1704-04810 | A Novel Experimental Platform for In-Vessel Multi-Chemical Molecular Communications | http://arxiv.org/abs/1704.04810 | id:1704.04810 author:Nariman Farsad, David Pan, Andrea Goldsmith category:cs.ET cs.AI cs.IT cs.LG math.IT  published:2017-04-16 summary:This work presents a new multi-chemical experimental platform for molecular communication where the transmitter can release different chemicals. This platform is designed to be inexpensive and accessible, and it can be expanded to simulate different environments including the cardiovascular system and complex network of pipes in industrial complexes and city infrastructures. To demonstrate the capabilities of the platform, we implement a time-slotted binary communication system where a bit-0 is represented by an acid pulse, a bit-1 by a base pulse, and information is carried via pH signals. The channel model for this system, which is nonlinear and has long memories, is unknown. Therefore, we devise novel detection algorithms that use techniques from machine learning and deep learning to train a maximum-likelihood detector. Using these algorithms the bit error rate improves by an order of magnitude relative to the approach used in previous works. Moreover, our system achieves a data rate that is an order of magnitude higher than any of the previous molecular communication platforms. version:1
arxiv-1704-04797 | Setting Up Pepper For Autonomous Navigation And Personalized Interaction With Users | http://arxiv.org/abs/1704.04797 | id:1704.04797 author:Vittorio Perera, Tiago Pereira, Jonathan Connell, Manuela Veloso category:cs.RO  published:2017-04-16 summary:In this paper we present our work with the Pepper robot, a service robot from SoftBank Robotics. We had two main goals in this work: improving the autonomy of this robot by increasing its awareness of the environment; and enhance the robot ability to interact with its users. To achieve this goals, we used ROS, a modern open-source framework for developing robotics software, to provide Pepper with state of the art localization and navigation capabilities. Furthermore, we contribute an architecture for effective human interaction based on cloud services. Our architecture improves Pepper speech recognition capabilities by connecting it to the IBM Bluemix Speech Recognition service and enable the robot to recognize its user via an in-house face recognition web-service. We show examples of our successful integration of ROS and IBM services with Pepper's own software. As a result, we were able to make Pepper move autonomously in a environment with humans and obstacles. We were also able to have Pepper execute spoken commands from known users as well as newly introduced users that were enrolled in the robot list of trusted users via a multi-modal interface. version:1
arxiv-1502-05745 | Polylogarithmic-Time Leader Election in Population Protocols Using Polylogarithmic States | http://arxiv.org/abs/1502.05745 | id:1502.05745 author:Dan Alistarh, Rati Gelashvili category:cs.DC  published:2015-02-19 summary:Population protocols are networks of finite-state agents, interacting randomly, and updating their states using simple rules. Despite their extreme simplicity, these systems have been shown to cooperatively perform complex computational tasks, such as simulating register machines to compute standard arithmetic functions. The election of a unique leader agent is a key requirement in such computational constructions. Yet, the fastest currently known population protocol for electing a leader only has linear stabilization time, and, it has recently been shown that no population protocol using a constant number of states per node may overcome this linear bound. In this paper, we give the first population protocol for leader election with polylogarithmic stabilization time, using polylogarithmic memory states per node. The protocol structure is quite simple: each node has an associated value, and is either a leader (still in contention) or a minion (following some leader). A leader keeps incrementing its value and "defeats" other leaders in one-to-one interactions, and will drop from contention and become a minion if it meets a leader with higher value. Importantly, a leader also drops out if it meets a minion with higher absolute value. While these rules are quite simple, the proof that this algorithm achieves polylogarithmic stabilization time is non-trivial. In particular, the argument combines careful use of concentration inequalities with anti-concentration bounds, showing that the leaders' values become spread apart as the execution progresses, which in turn implies that straggling leaders get quickly eliminated. We complement our analysis with empirical results, showing that our protocol stabilizes extremely fast, even for large network sizes. version:3
arxiv-1704-04782 | A Security Monitoring Framework For Virtualization Based HEP Infrastructures | http://arxiv.org/abs/1704.04782 | id:1704.04782 author:A. Gomez Ramirez, M. Martinez Pedreira, C. Grigoras, L. Betev, C. Lara, U. Kebschull for the category:cs.DC cs.AI cs.CR hep-ex  published:2017-04-16 summary:High Energy Physics (HEP) distributed computing infrastructures require automatic tools to monitor, analyze and react to potential security incidents. These tools should collect and inspect data such as resource consumption, logs and sequence of system calls for detecting anomalies that indicate the presence of a malicious agent. They should also be able to perform automated reactions to attacks without administrator intervention. We describe a novel framework that accomplishes these requirements, with a proof of concept implementation for the ALICE experiment at CERN. We show how we achieve a fully virtualized environment that improves the security by isolating services and Jobs without a significant performance impact. We also describe a collected dataset for Machine Learning based Intrusion Prevention and Detection Systems on Grid computing. This dataset is composed of resource consumption measurements (such as CPU, RAM and network traffic), logfiles from operating system services, and system call data collected from production Jobs running in an ALICE Grid test site and a big set of malware. This malware was collected from security research sites. Based on this dataset, we will proceed to develop Machine Learning algorithms able to detect malicious Jobs. version:1
arxiv-1704-04775 | Approximating the Backbone in the Weighted Maximum Satisfiability Problem | http://arxiv.org/abs/1704.04775 | id:1704.04775 author:He Jiang, Jifeng Xuan, Yan Hu category:cs.AI  published:2017-04-16 summary:The weighted Maximum Satisfiability problem (weighted MAX-SAT) is a NP-hard problem with numerous applications arising in artificial intelligence. As an efficient tool for heuristic design, the backbone has been applied to heuristics design for many NP-hard problems. In this paper, we investigated the computational complexity for retrieving the backbone in weighted MAX-SAT and developed a new algorithm for solving this problem. We showed that it is intractable to retrieve the full backbone under the assumption that . Moreover, it is intractable to retrieve a fixed fraction of the backbone as well. And then we presented a backbone guided local search (BGLS) with Walksat operator for weighted MAX-SAT. BGLS consists of two phases: the first phase samples the backbone information from local optima and the backbone phase conducts local search under the guideline of backbone. Extensive experimental results on the benchmark showed that BGLS outperforms the existing heuristics in both solution quality and runtime. version:1
arxiv-1702-08153 | HPDedup: A Hybrid Prioritized Data Deduplication Mechanism for Primary Storage in the Cloud | http://arxiv.org/abs/1702.08153 | id:1702.08153 author:Huijun Wu, Chen Wang, Yinjin Fu, Sherif Sakr, Liming Zhu, Kai Lu category:cs.DC  published:2017-02-27 summary:Eliminating duplicate data in primary storage of clouds increases the cost-efficiency of cloud service providers as well as reduces the cost of users for using cloud services. Existing primary deduplication techniques either use inline caching to exploit locality in primary workloads or use post-processing deduplication running in system idle time to avoid the negative impact on I/O performance. However, neither of them works well in the cloud servers running multiple services or applications for the following two reasons: Firstly, the temporal locality of duplicate data writes may not exist in some primary storage workloads thus inline caching often fails to achieve good deduplication ratio. Secondly, the post-processing deduplication allows duplicate data to be written into disks, therefore does not provide the benefit of I/O deduplication and requires high peak storage capacity. This paper presents HPDedup, a Hybrid Prioritized data Deduplication mechanism to deal with the storage system shared by applications running in co-located virtual machines or containers by fusing an inline and a post-processing process for exact deduplication. In the inline deduplication phase, HPDedup gives a fingerprint caching mechanism that estimates the temporal locality of duplicates in data streams from different VMs or applications and prioritizes the cache allocation for these streams based on the estimation. HPDedup also allows different deduplication threshold for streams based on their spatial locality to reduce the disk fragmentation. The post-processing phase removes duplicates whose fingerprints are not able to be cached due to the weak temporal locality from disks. Our experimental results show that HPDedup clearly outperforms the state-of-the-art primary storage deduplication techniques in terms of inline cache efficiency and primary deduplication efficiency. version:2
arxiv-1704-04719 | FML-based Prediction Agent and Its Application to Game of Go | http://arxiv.org/abs/1704.04719 | id:1704.04719 author:Chang-Shing Lee, Mei-Hui Wang, Chia-Hsiu Kao, Sheng-Chi Yang, Yusuke Nojima, Ryosuke Saga, Nan Shuo, Naoyuki Kubota category:cs.AI  published:2017-04-16 summary:In this paper, we present a robotic prediction agent including a darkforest Go engine, a fuzzy markup language (FML) assessment engine, an FML-based decision support engine, and a robot engine for game of Go application. The knowledge base and rule base of FML assessment engine are constructed by referring the information from the darkforest Go engine located in NUTN and OPU, for example, the number of MCTS simulations and winning rate prediction. The proposed robotic prediction agent first retrieves the database of Go competition website, and then the FML assessment engine infers the winning possibility based on the information generated by darkforest Go engine. The FML-based decision support engine computes the winning possibility based on the partial game situation inferred by FML assessment engine. Finally, the robot engine combines with the human-friendly robot partner PALRO, produced by Fujisoft incorporated, to report the game situation to human Go players. Experimental results show that the FML-based prediction agent can work effectively. version:1
arxiv-1611-04255 | Efficient Communications in Training Large Scale Neural Networks | http://arxiv.org/abs/1611.04255 | id:1611.04255 author:Linnan Wang, Wei Wu, George Bosilca, Richard Vuduc, Zenglin Xu category:cs.DC  published:2016-11-14 summary:We consider the problem of how to reduce the cost of communication that is required for the parallel training of a neural network. The state-of-the-art method, Bulk Synchronous Parallel Stochastic Gradient Descent (BSP-SGD), requires many collective communication operations, like broadcasts of parameters or reductions for sub-gradient aggregations, which for large messages quickly dominates overall execution time and limits parallel scalability. To address this problem, we develop a new technique for collective operations, referred to as Linear Pipelining (LP). It is tuned to the message sizes that arise in BSP-SGD, and works effectively on multi-GPU systems. Theoretically, the cost of LP is invariant to $P$, where $P$ is the number of GPUs, while the cost of more conventional Minimum Spanning Tree (MST) scales like $O(\log P)$. LP also demonstrate up to 2x faster bandwidth than Bidirectional Exchange (BE) techniques that are widely adopted by current MPI implementations. We apply these collectives to BSP-SGD, showing that the proposed implementations reduce communication bottlenecks in practice while preserving the attractive convergence properties of BSP-SGD. version:2
arxiv-1704-04684 | Generic LSH Families for the Angular Distance Based on Johnson-Lindenstrauss Projections and Feature Hashing LSH | http://arxiv.org/abs/1704.04684 | id:1704.04684 author:Luis Argerich, Natalia Golmar category:cs.DS cs.AI cs.IR  published:2017-04-15 summary:In this paper we propose the creation of generic LSH families for the angular distance based on Johnson-Lindenstrauss projections. We show that feature hashing is a valid J-L projection and propose two new LSH families based on feature hashing. These new LSH families are tested on both synthetic and real datasets with very good results and a considerable performance improvement over other LSH families. While the theoretical analysis is done for the angular distance, these families can also be used in practice for the euclidean distance with excellent results [2]. Our tests using real datasets show that the proposed LSH functions work well for the euclidean distance. version:1
arxiv-1704-04677 | Kinematically Redundant Octahedral Motion Platform for Virtual Reality Simulations | http://arxiv.org/abs/1704.04677 | id:1704.04677 author:Georg Nawratil, Arvin Rasoulzadeh category:cs.RO  published:2017-04-15 summary:We propose a novel design of a parallel manipulator of Stewart Gough type for virtual reality application of single individuals; i.e. an omni-directional treadmill is mounted on the motion platform in order to improve VR immersion by giving feedback to the human body. For this purpose we modify the well-known octahedral manipulator in a way that it has one degree of kinematical redundancy; namely an equiform reconfigurability of the base. The instantaneous kinematics and singularities of this mechanism are studied, where especially "unavoidable singularities" are characterized. These are poses of the motion platform, which can only be realized by singular configurations of the mechanism despite its kinematic redundancy. version:1
arxiv-1704-04672 | A Novel Potential Field Controller for Use on Aerial Robots | http://arxiv.org/abs/1704.04672 | id:1704.04672 author:Alexander C. Woods, Hung M. La category:cs.RO  published:2017-04-15 summary:Unmanned Aerial Vehicles (UAV), commonly known as drones, have many potential uses in real world applications. Drones require advanced planning and navigation algorithms to enable them to safely move through and interact with the world around them. This paper presents an extended potential field controller (ePFC) which enables an aerial robot, or drone, to safely track a dynamic target location while simultaneously avoiding any obstacles in its path. The ePFC outperforms a traditional potential field controller (PFC) with smoother tracking paths and shorter settling times. The proposed ePFC's stability is evaluated by Lyapunov approach, and its performance is simulated in a Matlab environment. Finally, the controller is implemented on an experimental platform in a laboratory environment which demonstrates the effectiveness of the controller. version:1
arxiv-1704-04663 | Autonomous Robotic System using Non-Destructive Evaluation methods for Bridge Deck Inspection | http://arxiv.org/abs/1704.04663 | id:1704.04663 author:Tuan Le, Spencer Gibb, Hung Manh La, Logan Falk, Tony Berendsen category:cs.RO  published:2017-04-15 summary:Bridge condition assessment is important to maintain the quality of highway roads for public transport. Bridge deterioration with time is inevitable due to aging material, environmental wear and in some cases, inadequate maintenance. Non-destructive evaluation (NDE) methods are preferred for condition assessment for bridges, concrete buildings, and other civil structures. Some examples of NDE methods are ground penetrating radar (GPR), acoustic emission, and electrical resistivity (ER). NDE methods provide the ability to inspect a structure without causing any damage to the structure in the process. In addition, NDE methods typically cost less than other methods, since they do not require inspection sites to be evacuated prior to inspection, which greatly reduces the cost of safety related issues during the inspection process. In this paper, an autonomous robotic system equipped with three different NDE sensors is presented. The system employs GPR, ER, and a camera for data collection. The system is capable of performing real-time, cost-effective bridge deck inspection, and is comprised of a mechanical robot design and machine learning and pattern recognition methods for automated steel rebar picking to provide realtime condition maps of the corrosive deck environments. version:1
arxiv-1704-04651 | The Reactor: A Sample-Efficient Actor-Critic Architecture | http://arxiv.org/abs/1704.04651 | id:1704.04651 author:Audrunas Gruslys, Mohammad Gheshlaghi Azar, Marc G. Bellemare, Remi Munos category:cs.AI  published:2017-04-15 summary:In this work we present a new reinforcement learning agent, called Reactor (for Retrace-actor), based on an off-policy multi-step return actor-critic architecture. The agent uses a deep recurrent neural network for function approximation. The network outputs a target policy {\pi} (the actor), an action-value Q-function (the critic) evaluating the current policy {\pi}, and an estimated behavioral policy {\hat \mu} which we use for off-policy correction. The agent maintains a memory buffer filled with past experiences. The critic is trained by the multi-step off-policy Retrace algorithm and the actor is trained by a novel {\beta}-leave-one-out policy gradient estimate (which uses both the off-policy corrected return and the estimated Q-function). The Reactor is sample-efficient thanks to the use of memory replay, and numerical efficient since it uses multi-step returns. Also both acting and learning can be parallelized. We evaluated our algorithm on 57 Atari 2600 games and demonstrate that it achieves state-of-the-art performance. version:1
arxiv-1704-04599 | A novel approach for fast mining frequent itemsets use N-list structure based on MapReduce | http://arxiv.org/abs/1704.04599 | id:1704.04599 author:Arkan A. G. Al-Hamodi, Songfeng Lu category:cs.DC cs.DB 68Wxx  68P05  published:2017-04-15 summary:Frequent Pattern Mining is a one field of the most significant topics in data mining. In recent years, many algorithms have been proposed for mining frequent itemsets. A new algorithm has been presented for mining frequent itemsets based on N-list data structure called Prepost algorithm. The Prepost algorithm is enhanced by implementing compact PPC-tree with the general tree. Prepost algorithm can only find a frequent itemsets with required (pre-order and post-order) for each node. In this chapter, we improved prepost algorithm based on Hadoop platform (HPrepost), proposed using the Mapreduce programming model. The main goals of proposed method are efficient mining frequent itemsets requiring less running time and memory usage. We have conduct experiments for the proposed scheme to compare with another algorithms. With dense datasets, which have a large average length of transactions, HPrepost is more effective than frequent itemsets algorithms in terms of execution time and memory usage for all min-sup. Generally, our algorithm outperforms algorithms in terms of runtime and memory usage with small thresholds and large datasets. version:1
arxiv-1704-04588 | Data aggregation routing protocols in wireless sensor networks: a taxonomy | http://arxiv.org/abs/1704.04588 | id:1704.04588 author:Saeid Pourroostaei Ardakani category:cs.DC cs.NI  published:2017-04-15 summary:Routing in Wireless Sensor Network (WSN) aims to interconnect sensor nodes via single or multi-hop paths. The routes are established to forward data packets from sensor nodes to the sink. Establishing a single path to report each data packet results in increasing energy consumption in WSN, hence, data aggregation routing is used to combine data packets and consequently reduce the number of transmissions. This reduces the routing overhead by eliminating redundant and meaningless data. There are two models for data aggregation routing in WSN: mobile agent and client/server. This paper describes data aggregation routing and classifies then the routing protocols according to the network architecture and routing models. The key issues of the data aggregation routing models (client/server and mobile agent) are highlighted and discussed. version:1
arxiv-1704-04585 | Dynamic Path Planning and Replanning for Mobile Robots using RRT* | http://arxiv.org/abs/1704.04585 | id:1704.04585 author:Devin Connell, Hung Manh La category:cs.RO  published:2017-04-15 summary:It is necessary for a mobile robot to be able to efficiently plan a path from its starting, or current, location to a desired goal location. This is a trivial task when the environment is static. However, the operational environment of the robot is rarely static, and it often has many moving obstacles. The robot may encounter one, or many, of these unknown and unpredictable moving obstacles. The robot will need to decide how to proceed when one of these obstacles is obstructing it's path. A method of dynamic replanning using RRT* is presented. The robot will modify it's current plan when an unknown random moving obstacle obstructs the path. Various experimental results show the effectiveness of the proposed method. version:1
arxiv-1704-04574 | Securing a UAV Using Individual Characteristics From an EEG Signal | http://arxiv.org/abs/1704.04574 | id:1704.04574 author:Ashutosh Singandhupe, Hung Manh La, David Feil-Seifer, Pei Huang, Linke Guo, Ming Li category:cs.RO  published:2017-04-15 summary:Unmanned aerial vehicles (UAVs) have gained much attention in recent years for both commercial and military applications. The progress in this field has gained much popularity and the research has encompassed various fields of scientific domain. Cyber securing a UAV communication has been one of the active research field since the attack on Predator UAV video stream hijacking in 2009. Since UAVs rely heavily on on-board autopilot to function, it is important to develop an autopilot system that is robust to possible cyber attacks. In this work, we present a biometric system to encrypt the UAV communication by generating a key which is derived from Beta component of the EEG signal of a user. We have developed a safety mechanism that would be activated in case the communication of the UAV from the ground control station gets attacked. This system has been validated on a commercial UAV under malicious attack conditions during which we implement a procedure where the UAV return safely to a "home" position. version:1
arxiv-1606-06269 | Founded Semantics and Constraint Semantics of Logic Rules | http://arxiv.org/abs/1606.06269 | id:1606.06269 author:Yanhong A. Liu, Scott D. Stoller category:cs.LO cs.AI cs.DB cs.PL  published:2016-06-20 summary:This paper describes a simple new semantics for logic rules, founded semantics, and its straightforward extension to another simple new semantics, constraint semantics. The new semantics support unrestricted negation, as well as unrestricted existential and universal quantifications. They are uniquely expressive and intuitive by allowing assumptions about the predicates and rules to be specified explicitly. They are completely declarative and easy to understand and relate cleanly to prior semantics. In addition, founded semantics can be computed in linear time in the size of the ground program. version:3
arxiv-1704-04560 | User-transparent Distributed TensorFlow | http://arxiv.org/abs/1704.04560 | id:1704.04560 author:Abhinav Vishnu, Joseph Manzano, Charles Siegel, Jeff Daily category:cs.DC  published:2017-04-15 summary:Deep Learning (DL) algorithms have become the {\em de facto} choice for data analysis. Several DL implementations -- primarily limited to a single compute node -- such as Caffe, TensorFlow, Theano and Torch have become readily available. Distributed DL implementations capable of execution on large scale systems are becoming important to address the computational needs of large data produced by scientific simulations and experiments. Yet, the adoption of distributed DL implementations faces significant impediments: 1) most implementations require DL analysts to modify their code significantly -- which is a show-stopper, 2) several distributed DL implementations are geared towards cloud computing systems -- which is inadequate for execution on massively parallel systems such as supercomputers. This work addresses each of these problems. We provide a distributed memory DL implementation by incorporating required changes in the TensorFlow runtime itself. This dramatically reduces the entry barrier for using a distributed TensorFlow implementation. We use Message Passing Interface (MPI) -- which provides performance portability, especially since MPI specific changes are abstracted from users. Lastly -- and arguably most importantly -- we make our implementation available for broader use, under the umbrella of Machine Learning Toolkit for Extreme Scale (MaTEx) at {\texttt http://hpc.pnl.gov/matex}. We refer to our implementation as MaTEx-TensorFlow. version:1
arxiv-1704-04408 | Incremental learning of high-level concepts by imitation | http://arxiv.org/abs/1704.04408 | id:1704.04408 author:Mina Alibeigi, Majid Nili Ahmadabadi, Babak Nadjar Araabi category:cs.AI cs.RO  published:2017-04-14 summary:Nowadays, robots become a companion in everyday life. To be well-accepted by humans, robots should efficiently understand meanings of their partners' motions and body language, and respond accordingly. Learning concepts by imitation brings them this ability in a user-friendly way. This paper presents a fast and robust model for Incremental Learning of Concepts by Imitation (ILoCI). In ILoCI, observed multimodal spatio-temporal demonstrations are incrementally abstracted and generalized based on both their perceptual and functional similarities during the imitation. In this method, perceptually similar demonstrations are abstracted by a dynamic model of mirror neuron system. An incremental method is proposed to learn their functional similarities through a limited number of interactions with the teacher. Learning all concepts together by the proposed memory rehearsal enables robot to utilize the common structural relations among concepts which not only expedites the learning process especially at the initial stages, but also improves the generalization ability and the robustness against discrepancies between observed demonstrations. Performance of ILoCI is assessed using standard LASA handwriting benchmark data set. The results show efficiency of ILoCI in concept acquisition, recognition and generation in addition to its robustness against variability in demonstrations. version:1
arxiv-1704-04389 | Encoding Cardinality Constraints using Generalized Selection Networks | http://arxiv.org/abs/1704.04389 | id:1704.04389 author:Michał Karpiński, Marek Piotrów category:cs.DS cs.DC  published:2017-04-14 summary:Boolean cardinality constraints state that at most (at least, or exactly) $k$ out of $n$ propositional literals can be true. We propose a new class of selection networks that can be used for an efficient encoding of them. Several comparator networks have been proposed recently for encoding cardinality constraints and experiments have proved their efficiency. Those were based mainly on the odd-even or pairwise comparator networks. We use similar ideas, but we extend the model of comparator networks so that the basic components are not only comparators (2-sorters) but more general $m$-sorters, for $m \geq 2$. The inputs are organized into $m$ columns, in which elements are recursively selected and, after that, columns are merged using an idea of multi-way merging. We present two algorithms parametrized by $m \geq 2$. We call those networks $m$-Wise Selection Network and $m$-Odd-Even Selection Network. We give detailed construction of the mergers when $m=4$. The construction can be directly applied to any values of $k$ and $n$. The proposed encoding of sorters is standard, therefore the arc-consistency is preserved. We prove correctness of the constructions and present the theoretical and experimental evaluation, which show that the new encodings are competitive to the other state-of-art encodings. version:1
arxiv-1704-04379 | Ultrafast photonic reinforcement learning based on laser chaos | http://arxiv.org/abs/1704.04379 | id:1704.04379 author:Makoto Naruse, Yuta Terashima, Atsushi Uchida, Song-Ju Kim category:physics.optics cs.AI cs.ET  published:2017-04-14 summary:Reinforcement learning involves decision making in dynamic and uncertain environments, and constitutes one important element of artificial intelligence (AI). In this paper, we experimentally demonstrate that the ultrafast chaotic oscillatory dynamics of lasers efficiently solve the multi-armed bandit problem (MAB), which requires decision making concerning a class of difficult trade-offs called the exploration-exploitation dilemma. To solve the MAB, a certain degree of randomness is required for exploration purposes. However, pseudo-random numbers generated using conventional electronic circuitry encounter severe limitations in terms of their data rate and the quality of randomness due to their algorithmic foundations. We generate laser chaos signals using a semiconductor laser sampled at a maximum rate of 100 GSample/s, and combine it with a simple decision-making principle called tug-of-war with a variable threshold, to ensure ultrafast, adaptive and accurate decision making at a maximum adaptation speed of 1 GHz. We found that decision-making performance was maximized with an optimal sampling interval, and we highlight the exact coincidence between the negative autocorrelation inherent in laser chaos and decision-making performance. This study paves the way for a new realm of ultrafast photonics in the age of AI, where the ultrahigh bandwidth of photons can provide new value. version:1
arxiv-1704-04341 | Environment-Independent Task Specifications via GLTL | http://arxiv.org/abs/1704.04341 | id:1704.04341 author:Michael L. Littman, Ufuk Topcu, Jie Fu, Charles Isbell, Min Wen, James MacGlashan category:cs.AI  published:2017-04-14 summary:We propose a new task-specification language for Markov decision processes that is designed to be an improvement over reward functions by being environment independent. The language is a variant of Linear Temporal Logic (LTL) that is extended to probabilistic specifications in a way that permits approximations to be learned in finite time. We provide several small environments that demonstrate the advantages of our geometric LTL (GLTL) language and illustrate how it can be used to specify standard reinforcement-learning tasks straightforwardly. version:1
arxiv-1704-04322 | Belief State Planning for Autonomously Navigating Urban Intersections | http://arxiv.org/abs/1704.04322 | id:1704.04322 author:Maxime Bouton, Akansel Cosgun, Mykel J. Kochenderfer category:cs.RO  published:2017-04-14 summary:Urban intersections represent a complex environment for autonomous vehicles with many sources of uncertainty. The vehicle must plan in a stochastic environment with potentially rapid changes in driver behavior. Providing an efficient strategy to navigate through urban intersections is a difficult task. This paper frames the problem of navigating unsignalized intersections as a partially observable Markov decision process (POMDP) and solves it using a Monte Carlo sampling method. Empirical results in simulation show that the resulting policy outperforms a threshold-based heuristic strategy on several relevant metrics that measure both safety and efficiency. version:1
arxiv-1702-07802 | Near-Data Scheduling for Data Centers with Multiple Levels of Data Locality | http://arxiv.org/abs/1702.07802 | id:1702.07802 author:Ali Yekkehkhany category:cs.DC  published:2017-02-24 summary:Data locality is a fundamental issue for data-parallel applications. Considering MapReduce in Hadoop, the map task scheduling part requires an efficient algorithm which takes data locality into consideration; otherwise, the system may become unstable under loads inside the system's capacity region and jobs may experience longer completion times which are not of interest. The data chunk needed for any map task can be in memory, on a local disk, in a local rack, in the same cluster or even in another data center. Hence, unless there has been much work on improving the speed of data center networks, different levels of service rates still exist for a task depending on where its data chunk is saved and from which server it receives service. Most of the theoretical work on load balancing is for systems with two levels of data locality including the Pandas algorithm by Xie et al. and the JSQ-MW algorithm by Wang et al., where the former is both throughput and heavy-traffic optimal, while the latter is only throughput optimal, but heavy-traffic optimal in only a special traffic load. We show that an extension of the JSQ-MW algorithm for a system with thee levels of data locality is throughput optimal, but not heavy-traffic optimal for all loads, only for a special traffic scenario. Furthermore, we show that the Pandas algorithm is not even throughput optimal for a system with three levels of data locality. We then propose a novel algorithm, Balanced-Pandas, which is both throughput and heavy-traffic optimal. To the best of our knowledge, this is the first theoretical work on load balancing for a system with more than two levels of data locality. This is more challenging than two levels of data locality as a dilemma between performance and throughput emerges. version:2
arxiv-1704-04213 | Managing Service-Heterogeneity using Osmotic Computing | http://arxiv.org/abs/1704.04213 | id:1704.04213 author:Vishal Sharma, Kathiravan Srinivasan, Dushantha Nalin K. Jayakody, Omer Rana, Ravinder Kumar category:cs.DC  published:2017-04-13 summary:Computational resource provisioning that is closer to a user is becoming increasingly important, with a rise in the number of devices making continuous service requests and with the significant recent take up of latency-sensitive applications, such as streaming and real-time data processing. Fog computing provides a solution to such types of applications by bridging the gap between the user and public/private cloud infrastructure via the inclusion of a "fog" layer. Such approach is capable of reducing the overall processing latency, but the issues of redundancy, cost-effectiveness in utilizing such computing infrastructure and handling services on the basis of a difference in their characteristics remain. This difference in characteristics of services because of variations in the requirement of computational resources and processes is termed as service heterogeneity. A potential solution to these issues is the use of Osmotic Computing -- a recently introduced paradigm that allows division of services on the basis of their resource usage, based on parameters such as energy, load, processing time on a data center vs. a network edge resource. Service provisioning can then be divided across different layers of a computational infrastructure, from edge devices, in-transit nodes, and a data center, and supported through an Osmotic software layer. In this paper, a fitness-based Osmosis algorithm is proposed to provide support for osmotic computing by making more effective use of existing Fog server resources. The proposed approach is capable of efficiently distributing and allocating services by following the principle of osmosis. The results are presented using numerical simulations demonstrating gains in terms of lower allocation time and a higher probability of services being handled with high resource utilization. version:1
arxiv-1704-04000 | Dempster-Shafer Belief Function - A New Interpretation | http://arxiv.org/abs/1704.04000 | id:1704.04000 author:Mieczysław Kłopotek category:cs.AI  published:2017-04-13 summary:We develop our interpretation of the joint belief distribution and of evidential updating that matches the following basic requirements: * there must exist an efficient method for reasoning within this framework * there must exist a clear correspondence between the contents of the knowledge base and the real world * there must be a clear correspondence between the reasoning method and some real world process * there must exist a clear correspondence between the results of the reasoning process and the results of the real world process corresponding to the reasoning process. version:1
arxiv-1704-03991 | Architectural Techniques to Enable Reliable and Scalable Memory Systems | http://arxiv.org/abs/1704.03991 | id:1704.03991 author:Prashant J. Nair category:cs.AR  published:2017-04-13 summary:High capacity and scalable memory systems play a vital role in enabling our desktops, smartphones, and pervasive technologies like Internet of Things (IoT). Unfortunately, memory systems are becoming increasingly prone to faults. This is because we rely on technology scaling to improve memory density, and at small feature sizes, memory cells tend to break easily. Today, memory reliability is seen as the key impediment towards using high-density devices, adopting new technologies, and even building the next Exascale supercomputer. To ensure even a bare-minimum level of reliability, present-day solutions tend to have high performance, power and area overheads. Ideally, we would like memory systems to remain robust, scalable, and implementable while keeping the overheads to a minimum. This dissertation describes how simple cross-layer architectural techniques can provide orders of magnitude higher reliability and enable seamless scalability for memory systems while incurring negligible overheads. version:1
arxiv-1704-03955 | Shape-independent Hardness Estimation Using Deep Learning and a GelSight Tactile Sensor | http://arxiv.org/abs/1704.03955 | id:1704.03955 author:Wenzhen Yuan, Chenzhuo Zhu, Andrew Owens, Mandayam A. Srinivasan, Edward H. Adelson category:cs.RO  published:2017-04-13 summary:Hardness is among the most important attributes of an object that humans learn about through touch. However, approaches for robots to estimate hardness are limited, due to the lack of information provided by current tactile sensors. In this work, we address these limitations by introducing a novel method for hardness estimation, based on the GelSight tactile sensor, and the method does not require accurate control of contact conditions or the shape of objects. A GelSight has a soft contact interface, and provides high resolution tactile images of contact geometry, as well as contact force and slip conditions. In this paper, we try to use the sensor to measure hardness of objects with multiple shapes, under a loosely controlled contact condition. The contact is made manually or by a robot hand, while the force and trajectory are unknown and uneven. We analyze the data using a deep constitutional (and recurrent) neural network. Experiments show that the neural net model can estimate the hardness of objects with different shapes and hardness ranging from 8 to 87 in Shore 00 scale. version:1
arxiv-1610-04213 | Reset-free Trial-and-Error Learning for Robot Damage Recovery | http://arxiv.org/abs/1610.04213 | id:1610.04213 author:Konstantinos Chatzilygeroudis, Vassilis Vassiliades, Jean-Baptiste Mouret category:cs.RO cs.AI  published:2016-10-13 summary:The high probability of hardware failures prevents many advanced robots (e.g., legged robots) from being confidently deployed in real-world situations (e.g., post-disaster rescue). Instead of attempting to diagnose the failures, robots could adapt by trial-and-error in order to be able to complete their tasks. In that case, damage recovery can be seen as a Reinforcement Learning (RL) problem. However, the best RL algorithms for robotics require resetting the robot and the environment to an initial state after each episode, that is, the robot is not learning autonomously. In addition, most of the RL methods for robotics do not scale well with complex robots (e.g., walking robots) and either cannot be used at all or take too long to converge to a solution (e.g., hours of learning). In this paper, we introduce a novel learning algorithm called "Reset-free Trial and-Error" (RTE) that (1) breaks the complexity by pre-generating hundreds of possible behaviors with a dynamics simulator of the intact robot, and (2) allows complex robots to quickly recover from damage while completing their tasks and taking the environment into account. We evaluate our algorithm on a simulated wheeled robot, a simulated six-legged robot, and a real six-legged walking robot that are damaged in several ways (e.g., a missing leg, a shortened leg, faulty motor, etc.) and whose objective is to reach a sequence of targets in an arena. Our experiments show that the robots can recover most of their locomotion abilities in an environment with obstacles, and without any human intervention. Overall, this new algorithm makes it possible to contemplate sending robots to places that are truly too dangerous for humans and from which robots cannot be rescued. version:2
arxiv-1704-05915 | User-driven Intelligent Interface on the Basis of Multimodal Augmented Reality and Brain-Computer Interaction for People with Functional Disabilities | http://arxiv.org/abs/1704.05915 | id:1704.05915 author:S. Stirenko, Yu. Gordienko, T. Shemsedinov, O. Alienin, Yu. Kochura, N. Gordienko, A. Rojbi, J. R. López Benito, E. Artetxe González category:cs.HC cs.AI cs.DC  published:2017-04-12 summary:The analysis of the current integration attempts of some modes and use cases of user-machine interaction is presented. The new concept of the user-driven intelligent interface is proposed on the basis of multimodal augmented reality and brain-computer interaction for various applications: in disabilities studies, education, home care, health care, etc. The several use cases of multimodal augmentation are presented. The perspectives of the better human comprehension by the immediate feedback through neurophysical channels by means of brain-computer interaction are outlined. It is shown that brain-computer interface (BCI) technology provides new strategies to overcome limits of the currently available user interfaces, especially for people with functional disabilities. The results of the previous studies of the low end consumer and open-source BCI-devices allow us to conclude that combination of machine learning (ML), multimodal interactions (visual, sound, tactile) with BCI will profit from the immediate feedback from the actual neurophysical reactions classified by ML methods. In general, BCI in combination with other modes of AR interaction can deliver much more information than these types of interaction themselves. Even in the current state the combined AR-BCI interfaces could provide the highly adaptable and personal services, especially for people with functional disabilities. version:1
arxiv-1704-03931 | Healthcare Robotics | http://arxiv.org/abs/1704.03931 | id:1704.03931 author:Laurel D. Riek category:cs.RO cs.HC  published:2017-04-12 summary:Robots have the potential to be a game changer in healthcare: improving health and well-being, filling care gaps, supporting care givers, and aiding health care workers. However, before robots are able to be widely deployed, it is crucial that both the research and industrial communities work together to establish a strong evidence-base for healthcare robotics, and surmount likely adoption barriers. This article presents a broad contextualization of robots in healthcare by identifying key stakeholders, care settings, and tasks; reviewing recent advances in healthcare robotics; and outlining major challenges and opportunities to their adoption. version:1
arxiv-1704-03767 | Parallelized Kendall's Tau Coefficient Computation via SIMD Vectorized Sorting On Many-Integrated-Core Processors | http://arxiv.org/abs/1704.03767 | id:1704.03767 author:Yongchao Liu, Tony Pan, Oded Green, Srinivas Aluru category:cs.DC cs.AI  published:2017-04-12 summary:Pairwise association measure is an important operation in data analytics. Kendall's tau coefficient is one widely used correlation coefficient identifying non-linear relationships between ordinal variables. In this paper, we investigated a parallel algorithm accelerating all-pairs Kendall's tau coefficient computation via single instruction multiple data (SIMD) vectorized sorting on Intel Xeon Phis by taking advantage of many processing cores and 512-bit SIMD vector instructions. To facilitate workload balancing and overcome on-chip memory limitation, we proposed a generic framework for symmetric all-pairs computation by building provable bijective functions between job identifier and coordinate space. Performance evaluation demonstrated that our algorithm on one 5110P Phi achieves two orders-of-magnitude speedups over 16-threaded MATLAB and three orders-of-magnitude speedups over sequential R, both running on high-end CPUs. Besides, our algorithm exhibited rather good distributed computing scalability with respect to number of Phis. Source code and datasets are publicly available at http://lightpcc.sourceforge.net. version:1
arxiv-1508-03599 | Efficient Redundancy Techniques for Latency Reduction in Cloud Systems | http://arxiv.org/abs/1508.03599 | id:1508.03599 author:Gauri Joshi, Emina Soljanin, Gregory Wornell category:cs.DC cs.IT math.IT  published:2015-08-14 summary:In cloud computing systems, assigning a task to multiple servers and waiting for the earliest copy to finish is an effective method to combat the variability in response time of individual servers, and reduce latency. But adding redundancy may result in higher cost of computing resources, as well as an increase in queueing delay due to higher traffic load. This work helps understand when and how redundancy gives a cost-efficient reduction in latency. For a general task service time distribution, we compare different redundancy strategies in terms of the number of redundant tasks, and time when they are issued and canceled. We get the insight that the log-concavity of the task service time creates a dichotomy of when adding redundancy helps. If the service time distribution is log-convex (i.e. log of the tail probability is convex) then adding maximum redundancy reduces both latency and cost. And if it is log-concave (i.e. log of the tail probability is concave), then less redundancy, and early cancellation of redundant tasks is more effective. Using these insights, we design a general redundancy strategy that achieves a good latency-cost trade-off for an arbitrary service time distribution. This work also generalizes and extends some results in the analysis of fork-join queues. version:3
arxiv-1704-03764 | NG2C: Pretenuring N-Generational GC for HotSpot Big Data Applications | http://arxiv.org/abs/1704.03764 | id:1704.03764 author:Rodrigo Bruno, Luís Oliveira, Paulo Ferreira category:cs.DC  published:2017-04-12 summary:Big Data applications suffer from unpredictable and unacceptably high pause times due to Garbage Collection (GC). This is the case in latency-sensitive applications such as on-line credit-card fraud detection, graph-based computing for analysis on social networks, etc. Such pauses compromise latency requirements of the whole application stack and result from applications' aggressive buffering/caching of data, exposing an ill-suited GC design, which assumes that most objects will die young and does not consider that applications hold large amounts of middle-lived data in memory. To avoid such pauses, we propose NG2C, a new GC algorithm that combines pretenuring with an N-Generational heap. By being able to allocate objects into different generations, NG2C is able to group objects with similar lifetime profiles in the same generation. By allocating objects with similar lifetime profiles close to each other, i.e. in the same generation, we avoid object promotion (copying between generations) and heap fragmentation (which leads to heap compactions) both responsible for most of the duration of HotSpot GC pause times. NG2C is implemented for the OpenJDK 8 HotSpot Java Virtual Machine, as an extension of the Garbage First GC. We evaluate NG2C using Cassandra, Lucene, and GraphChi with three different GCs: Garbage First (G1), Concurrent Mark Sweep (CMS), and NG2C. Results show that NG2C decreases the worst observable GC pause time by up to 94.8% for Cassandra, 85.0% for Lucene and 96.45% for GraphChi, when compared to current collectors (G1 and CMS). In addition, NG2C has no negative impact on application throughput or memory usage. version:1
arxiv-1702-05967 | Practical, Linear-time, Fully Distributed Algorithms for Irregular Gather and Scatter | http://arxiv.org/abs/1702.05967 | id:1702.05967 author:Jesper Larsson Träff category:cs.DC  published:2017-02-20 summary:We present new, simple, fully distributed, practical algorithms with linear time communication cost for irregular gather and scatter operations in which processors contribute or consume possibly different amounts of data. In a linear cost transmission model with start-up latency $\alpha$ and cost per unit $\beta$, the new algorithms take time $3 {\log_2 p} \alpha+\beta \sum_{i\neq r}m_i$ where $p$ is the number of processors, $m_i$ the amount of data for processor $i, 0\leq i<p$, and processor $r, 0\leq r<p$ a root processor determined by the algorithm. For a fixed, externally given root processor $r$, there is an additive penalty of at most $\beta(M_{d'}-m_{r_{d'}}-\sum_{0\leq j<d'}M_j)$ time steps where each $M_j$ is the total amount of data in a tree of $2^j$ different processors with roots $r_j$ as constructed by the algorithm. The worst-case penalty is less than $\beta \sum_{i\neq r}m_i$ time steps. The algorithms have attractive properties for implementing the operations for MPI (the Message-Passing Interface). Standard algorithms using fixed trees take time either $ {\log_2 p} (\alpha+\beta \sum_{i\neq r} m_i)$ in the worst case, or $\sum_{i\neq r}(\alpha+\beta m_i)$. We have used the new algorithms to give prototype implementations for the MPI_Gatherv and MPI_Scatterv collectives of MPI, and present benchmark results from a small and a medium-large InfiniBand cluster. In order to structure the experimental evaluation we formulate new performance guidelines for irregular collectives that can be used to assess the performance in relation to the corresponding regular collectives. We show that the new algorithms can fulfill these performance expectations with a large margin, and that standard implementations do not. version:3
arxiv-1704-03723 | Beliefs in Markov Trees - From Local Computations to Local Valuation | http://arxiv.org/abs/1704.03723 | id:1704.03723 author:Mieczysław A. Kłopotek category:cs.AI  published:2017-04-12 summary:This paper is devoted to expressiveness of hypergraphs for which uncertainty propagation by local computations via Shenoy/Shafer method applies. It is demonstrated that for this propagation method for a given joint belief distribution no valuation of hyperedges of a hypergraph may provide with simpler hypergraph structure than valuation of hyperedges by conditional distributions. This has vital implication that methods recovering belief networks from data have no better alternative for finding the simplest hypergraph structure for belief propagation. A method for recovery tree-structured belief networks has been developed and specialized for Dempster-Shafer belief functions version:1
arxiv-1704-03696 | Optimal Repair Layering for Erasure-Coded Data Centers: From Theory to Practice | http://arxiv.org/abs/1704.03696 | id:1704.03696 author:Yuchong Hu, Xiaolu Li, Mi Zhang, Patrick P. C. Lee, Xiaoyang Zhang, Pan Zhou, Dan Feng category:cs.DC  published:2017-04-12 summary:Repair performance in hierarchical data centers is often bottlenecked by cross-rack network transfer. Recent theoretical results show that the cross-rack repair bandwidth can be minimized through repair layering, whose idea is to partition a repair operation into inner-rack and cross-rack layers. However, how repair layering should be implemented and deployed in practice remains an open issue. In this paper, we address this issue by proposing a practical repair layering framework called DoubleR. We design two families of practical double regenerating codes (DRC), which not only minimize the cross-rack repair bandwidth, but also have several practical properties that improve state-of-the-art regenerating codes. We implement and deploy DoubleR atop Hadoop Distributed File System (HDFS), and show that DoubleR maintains the theoretical guarantees of DRC and improves the repair performance of regenerating codes in both node recovery and degraded read operations. version:1
arxiv-1704-03667 | Stigmergy-based modeling to discover urban activity patterns from positioning data | http://arxiv.org/abs/1704.03667 | id:1704.03667 author:Antonio L. Alfeo, Mario G. C. A. Cimino, Sara Egidi, Bruno Lepri, Alex Pentland, Gigliola Vaglini category:cs.AI cs.SI physics.soc-ph H.2.8; I.5.2  published:2017-04-12 summary:Positioning data offer a remarkable source of information to analyze crowds urban dynamics. However, discovering urban activity patterns from the emergent behavior of crowds involves complex system modeling. An alternative approach is to adopt computational techniques belonging to the emergent paradigm, which enables self-organization of data and allows adaptive analysis. Specifically, our approach is based on stigmergy. By using stigmergy each sample position is associated with a digital pheromone deposit, which progressively evaporates and aggregates with other deposits according to their spatiotemporal proximity. Based on this principle, we exploit positioning data to identify high density areas (hotspots) and characterize their activity over time. This characterization allows the comparison of dynamics occurring in different days, providing a similarity measure exploitable by clustering techniques. Thus, we cluster days according to their activity behavior, discovering unexpected urban activity patterns. As a case study, we analyze taxi traces in New York City during 2015. version:1
arxiv-1704-03612 | Finding Modes by Probabilistic Hypergraphs Shifting | http://arxiv.org/abs/1704.03612 | id:1704.03612 author:Yang Wang, Lin Wu category:cs.AI  published:2017-04-12 summary:In this paper, we develop a novel paradigm, namely hypergraph shift, to find robust graph modes by probabilistic voting strategy, which are semantically sound besides the self-cohesiveness requirement in forming graph modes. Unlike the existing techniques to seek graph modes by shifting vertices based on pair-wise edges (i.e, an edge with $2$ ends), our paradigm is based on shifting high-order edges (hyperedges) to deliver graph modes. Specifically, we convert the problem of seeking graph modes as the problem of seeking maximizers of a novel objective function with the aim to generate good graph modes based on sifting edges in hypergraphs. As a result, the generated graph modes based on dense subhypergraphs may more accurately capture the object semantics besides the self-cohesiveness requirement. We also formally prove that our technique is always convergent. Extensive empirical studies on synthetic and real world data sets are conducted on clustering and graph matching. They demonstrate that our techniques significantly outperform the existing techniques. version:1
arxiv-1701-03913 | Modeling and control of a cable-driven series elastic actuator | http://arxiv.org/abs/1701.03913 | id:1701.03913 author:Wulin Zou, Ningbo Yu category:cs.SY cs.RO  published:2017-01-14 summary:Series elastic actuators (SEA) are playing an increasingly important role in the fields of physical human-robot interaction. This paper focuses on the modeling and control of a cable-driven SEA. First, the scheme of the cable-driven SEA has been proposed, and a velocity controlled DC motor has been used as its power source. Based on this, the model of the cable-driven SEA has been built up. Further, a two degrees of freedom (2-DOF) control approach has been employed to control the output torque. Simulation results have shown that the 2-DOF method has achieved better robust performance than the PD method. version:3
arxiv-1704-03574 | CASP Solutions for Planning in Hybrid Domains | http://arxiv.org/abs/1704.03574 | id:1704.03574 author:Marcello Balduccini, Daniele Magazzeni, Marco Maratea, Emily LeBlanc category:cs.AI  published:2017-04-12 summary:CASP is an extension of ASP that allows for numerical constraints to be added in the rules. PDDL+ is an extension of the PDDL standard language of automated planning for modeling mixed discrete-continuous dynamics. In this paper, we present CASP solutions for dealing with PDDL+ problems, i.e., encoding from PDDL+ to CASP, and extensions to the algorithm of the EZCSP CASP solver in order to solve CASP programs arising from PDDL+ domains. An experimental analysis, performed on well-known linear and non-linear variants of PDDL+ domains, involving various configurations of the EZCSP solver, other CASP solvers, and PDDL+ planners, shows the viability of our solution. version:1
arxiv-1704-03538 | Toward a Distributed Knowledge Discovery system for Grid systems | http://arxiv.org/abs/1704.03538 | id:1704.03538 author:Nhien-An Le-Khac, Lamine Aouad, M-Tahar Kechadi category:cs.DC  published:2017-04-11 summary:During the last decade or so, we have had a deluge of data from not only science fields but also industry and commerce fields. Although the amount of data available to us is constantly increasing, our ability to process it becomes more and more difficult. Efficient discovery of useful knowledge from these datasets is therefore becoming a challenge and a massive economic need. This led to the need of developing large-scale data mining (DM) techniques to deal with these huge datasets either from science or economic applications. In this chapter, we present a new DDM system combining dataset-driven and architecture-driven strategies. Data-driven strategies will consider the size and heterogeneity of the data, while architecture driven will focus on the distribution of the datasets. This system is based on a Grid middleware tools that integrate appropriate large data manipulation operations. Therefore, this allows more dynamicity and autonomicity during the mining, integrating and processing phases version:1
arxiv-1704-03402 | Next Generation Business Intelligence and Analytics: A Survey | http://arxiv.org/abs/1704.03402 | id:1704.03402 author:Quoc Duy Vo, Jaya Thomas, Shinyoung Cho, Pradipta De, Bong Jun Choi, Lee Sael category:cs.AI  published:2017-04-11 summary:Business Intelligence and Analytics (BI&A) is the process of extracting and predicting business-critical insights from data. Traditional BI focused on data collection, extraction, and organization to enable efficient query processing for deriving insights from historical data. With the rise of big data and cloud computing, there are many challenges and opportunities for the BI. Especially with the growing number of data sources, traditional BI\&A are evolving to provide intelligence at different scales and perspectives - operational BI, situational BI, self-service BI. In this survey, we review the evolution of business intelligence systems in full scale from back-end architecture to and front-end applications. We focus on the changes in the back-end architecture that deals with the collection and organization of the data. We also review the changes in the front-end applications, where analytic services and visualization are the core components. Using a uses case from BI in Healthcare, which is one of the most complex enterprises, we show how BI\&A will play an important role beyond the traditional usage. The survey provides a holistic view of Business Intelligence and Analytics for anyone interested in getting a complete picture of the different pieces in the emerging next generation BI\&A solutions. version:1
arxiv-1704-03383 | Portable, high-performance containers for HPC | http://arxiv.org/abs/1704.03383 | id:1704.03383 author:Lucas Benedicic, Felipe A. Cruz, Alberto Madonna, Kean Mariotti category:cs.DC  published:2017-04-11 summary:Building and deploying software on high-end computing systems is a challenging task. High performance applications have to reliably run across multiple platforms and environments, and make use of site-specific resources while resolving complicated software-stack dependencies. Containers are a type of lightweight virtualization technology that attempt to solve this problem by packaging applications and their environments into standard units of software that are: portable, easy to build and deploy, have a small footprint, and low runtime overhead. In this work we present an extension to the container runtime of Shifter that provides containerized applications with a mechanism to access GPU accelerators and specialized networking from the host system, effectively enabling performance portability of containers across HPC resources. The presented extension makes possible to rapidly deploy high-performance software on supercomputers from containerized applications that have been developed, built, and tested in non-HPC commodity hardware, e.g. the laptop or workstation of a researcher. version:1
arxiv-1704-03738 | Counterexample Guided Inductive Optimization | http://arxiv.org/abs/1704.03738 | id:1704.03738 author:Rodrigo F. Araujo, Higo F. Albuquerque, Iury V. de Bessa, Lucas C. Cordeiro, Joao Edgar C. Filho category:cs.AI cs.LO  published:2017-04-11 summary:This paper describes three variants of a counterexample guided inductive optimization (CEGIO) approach based on Satisfiability Modulo Theories (SMT) solvers. In particular, CEGIO relies on iterative executions to constrain a verification procedure, in order to perform inductive generalization, based on counterexamples extracted from SMT solvers. CEGIO is able to successfully optimize a wide range of functions, including non-linear and non-convex optimization problems based on SMT solvers, in which data provided by counterexamples are employed to guide the verification engine, thus reducing the optimization domain. The present algorithms are evaluated using a large set of benchmarks typically employed for evaluating optimization techniques. Experimental results show the efficiency and effectiveness of the proposed algorithms, which find the optimal solution in all evaluated benchmarks, while traditional techniques are usually trapped by local minima. version:1
arxiv-1703-08228 | Automatically Tuning the GCC Compiler to Optimize the Performance of Applications Running on Embedded Systems | http://arxiv.org/abs/1703.08228 | id:1703.08228 author:Craig Blackmore, Oliver Ray, Kerstin Eder category:cs.DC cs.PF D.3.4  published:2017-02-23 summary:This paper introduces a novel method for automatically tuning the selection of compiler flags to optimize the performance of software intended to run on embedded hardware platforms. We begin by developing our approach on code compiled by the GNU C Compiler (GCC) for the ARM Cortex-M3 (CM3) processor; and we show how our method outperforms the industry standard -O3 optimization level across a diverse embedded benchmark suite. First we quantify the potential gains by using existing iterative compilation approaches that time-intensively search for optimal configurations for each benchmark. Then we adapt iterative compilation to output a single configuration that optimizes performance across the entire benchmark suite. Although this is a time-consuming process, our approach constructs an optimized variation of -O3, which we call -Ocm3, that realizes nearly two thirds of known available gains on the CM3 and significantly outperforms a more complex state-of-the-art predictive method in cross-validation experiments. Finally, we demonstrate our method on additional platforms by constructing two more optimization levels that find even more significant speed-ups on the ARM Cortex-A8 and 8-bit AVR processors. version:2
arxiv-1704-03342 | Beliefs and Probability in Bacchus' l.p. Logic: A~3-Valued Logic Solution to Apparent Counter-intuition | http://arxiv.org/abs/1704.03342 | id:1704.03342 author:Mieczysław A. Kłopotek category:cs.AI  published:2017-04-11 summary:Fundamental discrepancy between first order logic and statistical inference (global versus local properties of universe) is shown to be the obstacle for integration of logic and probability in L.p. logic of Bacchus. To overcome the counterintuitiveness of L.p. behaviour, a 3-valued logic is proposed. version:1
arxiv-1704-03329 | A Domain Specific Language for Performance Portable Molecular Dynamics Algorithms | http://arxiv.org/abs/1704.03329 | id:1704.03329 author:William R. Saunders, James Grant, Eike H. Müller category:cs.DC cs.SE physics.comp-ph  published:2017-04-11 summary:Developers of Molecular Dynamics (MD) codes face significant challenges when adapting existing simulation packages to new hardware. In a continuously diversifying hardware landscape it becomes increasingly difficult for scientists to be experts both in their own domain (physics/chemistry/biology) and specialists in the low level parallelisation and optimisation of their codes. To address this challenge, we describe a "Separation of Concerns" approach for the development of parallel and optimised MD codes: the science specialist writes code at a high abstraction level in a domain specific language (DSL), which is then translated into efficient computer code by a scientific programmer. In a related context, an abstraction for the solution of partial differential equations with grid based methods has recently been implemented in the (Py)OP2 library. Inspired by this approach, we develop a Python code generation system for molecular dynamics simulations on different parallel architectures, including massively parallel distributed memory systems and GPUs. We demonstrate the efficiency of the auto-generated code by studying its performance and scalability on different hardware and compare it to other state-of-the-art simulation packages. With growing data volumes the extraction of physically meaningful information from the simulation becomes increasingly challenging and requires equally efficient implementations. A particular advantage of our approach is the easy expression of such analysis algorithms. We consider two popular methods for deducing the crystalline structure of a material from the local environment of each atom, show how they can be expressed in our abstraction and implement them in the code generation framework. version:1
arxiv-1704-02427 | Gathering in Dynamic Rings | http://arxiv.org/abs/1704.02427 | id:1704.02427 author:Giuseppe Antonio Di Luna, Paola Flocchini, Linda Pagli, Giuseppe Prencipe, Nicola Santoro, Giovanni Viglietta category:cs.DC  published:2017-04-08 summary:The gathering problem requires a set of mobile agents, arbitrarily positioned at different nodes of a network to group within finite time at the same location, not fixed in advanced. The extensive existing literature on this problem shares the same fundamental assumption: the topological structure does not change during the rendezvous or the gathering; this is true also for those investigations that consider faulty nodes. In other words, they only consider static graphs. In this paper we start the investigation of gathering in dynamic graphs, that is networks where the topology changes continuously and at unpredictable locations. We study the feasibility of gathering mobile agents, identical and without explicit communication capabilities, in a dynamic ring of anonymous nodes; the class of dynamics we consider is the classic 1-interval-connectivity. We focus on the impact that factors such as chirality (i.e., a common sense of orientation) and cross detection (i.e., the ability to detect, when traversing an edge, whether some agent is traversing it in the other direction), have on the solvability of the problem. We provide a complete characterization of the classes of initial configurations from which the gathering problem is solvable in presence and in absence of cross detection and of chirality. The feasibility results of the characterization are all constructive: we provide distributed algorithms that allow the agents to gather. In particular, the protocols for gathering with cross detection are time optimal. We also show that cross detection is a powerful computational element. We prove that, without chirality, knowledge of the ring size is strictly more powerful than knowledge of the number of agents; on the other hand, with chirality, knowledge of n can be substituted by knowledge of k, yielding the same classes of feasible initial configurations. version:2
arxiv-1704-03324 | Gang-GC: Locality-aware Parallel Data Placement Optimizations for Key-Value Storages | http://arxiv.org/abs/1704.03324 | id:1704.03324 author:Duarte Patrício, José Simão, Luís Veiga category:cs.PL cs.DC  published:2017-04-11 summary:Many cloud applications rely on fast and non-relational storage to aid in the processing of large amounts of data. Managed runtimes are now widely used to support the execution of several storage solutions of the NoSQL movement, particularly when dealing with big data key-value store-driven applications. The benefits of these runtimes can however be limited by modern parallel throughput-oriented GC algorithms, where related objects have the potential to be dispersed in memory, either in the same or different generations. In the long run this causes more page faults and degradation of locality on system-level memory caches. We propose, Gang-CG, an extension to modern heap layouts and to a parallel GC algorithm to promote locality between groups of related objects. This is done without extensive profiling of the applications and in a way that is transparent to the programmer, without the need to use specialized data structures. The heap layout and algorithmic extensions were implemented over the Parallel Scavenge garbage collector of the HotSpot JVM\@. Using microbenchmarks that capture the architecture of several key-value stores databases, we show negligible overhead in frequent operations such as the allocation of new objects and improvements to the access speed of data, supported by lower misses in system-level memory caches. Overall, we show a 6\% improvement in the average time of read and update operations and an average decrease of 12.4\% in page faults. version:1
arxiv-1704-03319 | Speeding up Consensus by Chasing Fast Decisions | http://arxiv.org/abs/1704.03319 | id:1704.03319 author:Balaji Arun, Sebastiano Peluso, Roberto Palmieri, Giuliano Losa, Binoy Ravindran category:cs.DC  published:2017-04-11 summary:This paper proposes CAESAR, a novel multi-leader Generalized Consensus protocol for geographically replicated sites. The main goal of CAESAR is to overcome one of the major limitations of existing approaches, which is the significant performance degradation when application workload produces conflicting requests. CAESAR does that by changing the way a fast decision is taken: its ordering protocol does not reject a fast decision for a client request if a quorum of nodes reply with different dependency sets for that request. The effectiveness of CAESAR is demonstrated through an evaluation study performed on Amazon's EC2 infrastructure using 5 geo-replicated sites. CAESAR outperforms other multi-leader (e.g., EPaxos) competitors by as much as 1.7x in the presence of 30% conflicting requests, and single-leader (e.g., Multi-Paxos) by up to 3.5x. version:1
arxiv-1704-03275 | Scavenger 0.1: A Theorem Prover Based on Conflict Resolution | http://arxiv.org/abs/1704.03275 | id:1704.03275 author:Daniyar Itegulov, John Slaney, Bruno Woltzenlogel Paleo category:cs.LO cs.AI cs.FL  published:2017-04-11 summary:This paper introduces Scavenger, the first theorem prover for pure first-order logic without equality based on the new conflict resolution calculus. Conflict resolution has a restricted resolution inference rule that resembles (a first-order generalization of) unit propagation as well as a rule for assuming decision literals and a rule for deriving new clauses by (a first-order generalization of) conflict-driven clause learning. version:1
arxiv-1704-02380 | Exploring an Infinite Space with Finite Memory Scouts | http://arxiv.org/abs/1704.02380 | id:1704.02380 author:Lihi Cohen, Yuval Emek, Oren Louidor, Jara Uitto category:math.PR cs.DC cs.DS math.CO 60G50  68Q80  published:2017-04-07 summary:Consider a small number of scouts exploring the infinite $d$-dimensional grid with the aim of hitting a hidden target point. Each scout is controlled by a probabilistic finite automaton that determines its movement (to a neighboring grid point) based on its current state. The scouts, that operate under a fully synchronous schedule, communicate with each other (in a way that affects their respective states) when they share the same grid point and operate independently otherwise. Our main research question is: How many scouts are required to guarantee that the target admits a finite mean hitting time? Recently, it was shown that $d + 1$ is an upper bound on the answer to this question for any dimension $d \geq 1$ and the main contribution of this paper comes in the form of proving that this bound is tight for $d \in \{ 1, 2 \}$. version:2
arxiv-1704-03168 | FMMU: A Hardware-Automated Flash Map Management Unit for Scalable Performance of NAND Flash-Based SSDs | http://arxiv.org/abs/1704.03168 | id:1704.03168 author:Yeong-Jae Woo, Sang Lyul Min category:cs.AR  published:2017-04-11 summary:NAND flash-based Solid State Drives (SSDs), which are widely used from embedded systems to enterprise servers, are enhancing performance by exploiting the parallelism of NAND flash memories. To cope with the performance improvement of SSDs, storage systems have rapidly adopted the host interface for SSDs from Serial-ATA, which is used for existing hard disk drives, to high-speed PCI express. Since NAND flash memory does not allow in-place updates, it requires special software called Flash Translation Layer (FTL), and SSDs are equipped with embedded processors to run FTL. Existing SSDs increase the clock frequency of embedded processors or increase the number of embedded processors in order to prevent FTL from acting as bottleneck of SSD performance, but these approaches are not scalable. This paper proposes a hardware-automated Flash Map Management Unit, called FMMU, that handles the address translation process dominating the execution time of the FTL by hardware automation. FMMU provides methods for exploiting the parallelism of flash memory by processing outstanding requests in a non-blocking manner while reducing the number of flash operations. The experimental results show that the FMMU reduces the FTL execution time in the map cache hit case and the miss case by 44% and 37%, respectively, compared with the existing software-based approach operating in 4-core. FMMU also prevents FTL from acting as a performance bottleneck for up to 32-channel, 8-way SSD using PCIe 3.0 x32 host interface. version:1
arxiv-1704-03103 | Minkowski Operations of Sets with Application to Robot Localization | http://arxiv.org/abs/1704.03103 | id:1704.03103 author:Benoit Desrochers, Luc Jaulin category:cs.RO cs.AI cs.CG cs.SY interval analysis  published:2017-04-11 summary:This papers shows that using separators, which is a pair of two complementary contractors, we can easily and efficiently solve the localization problem of a robot with sonar measurements in an unstructured environment. We introduce separators associated with the Minkowski sum and the Minkowski difference in order to facilitate the resolution. A test-case is given in order to illustrate the principle of the approach. version:1
arxiv-1611-04934 | HPAT: High Performance Analytics with Scripting Ease-of-Use | http://arxiv.org/abs/1611.04934 | id:1611.04934 author:Ehsan Totoni, Todd A. Anderson, Tatiana Shpeisman category:cs.DC  published:2016-11-15 summary:Big data analytics requires high programmer productivity and high performance simultaneously on large-scale clusters. However, current big data analytics frameworks (e.g. Apache Spark) have prohibitive runtime overheads since they are library-based. We introduce a novel auto-parallelizing compiler approach that exploits the characteristics of the data analytics domain such as the map/reduce parallel pattern and is robust, unlike previous auto-parallelization methods. Using this approach, we build High Performance Analytics Toolkit (HPAT), which parallelizes high-level scripting (Julia) programs automatically, generates efficient MPI/C++ code, and provides resiliency. Furthermore, it provides automatic optimizations for scripting programs, such as fusion of array operations. Thus, HPAT is 369x to 2033x faster than Spark on the Cori supercomputer and 20x to 256x times on Amazon AWS. version:2
arxiv-1704-03048 | Matching Media Contents with User Profiles by means of the Dempster-Shafer Theory | http://arxiv.org/abs/1704.03048 | id:1704.03048 author:Luigi Troiano, Irene Díaz, Ciro Gaglione category:cs.AI  published:2017-04-10 summary:The media industry is increasingly personalizing the offering of contents in attempt to better target the audience. This requires to analyze the relationships that goes established between users and content they enjoy, looking at one side to the content characteristics and on the other to the user profile, in order to find the best match between the two. In this paper we suggest to build that relationship using the Dempster-Shafer's Theory of Evidence, proposing a reference model and illustrating its properties by means of a toy example. Finally we suggest possible applications of the model for tasks that are common in the modern media industry. version:1
arxiv-1507-04047 | Parallelization Strategies for Spatial Agent-Based Models | http://arxiv.org/abs/1507.04047 | id:1507.04047 author:Nuno Fachada, Vitor V. Lopes, Rui C. Martins, Agostinho C. Rosa category:cs.DC  published:2015-07-14 summary:Agent-based modeling (ABM) is a bottom-up modeling approach, where each entity of the system being modeled is uniquely represented as an independent decision-making agent. Large scale emergent behavior in ABMs is population sensitive. As such, the number of agents in a simulation should be able to reflect the reality of the system being modeled, which can be in the order of millions or billions of individuals in certain domains. A natural solution to reach acceptable scalability in commodity multi-core processors consists of decomposing models such that each component can be independently processed by a different thread in a concurrent manner. In this paper we present a multithreaded Java implementation of the PPHPC ABM, with two goals in mind: 1) compare the performance of this implementation with an existing NetLogo implementation; and, 2) study how different parallelization strategies impact simulation performance on a shared memory architecture. Results show that: 1) model parallelization can yield considerable performance gains; 2) distinct parallelization strategies offer specific trade-offs in terms of performance and simulation reproducibility; and, 3) PPHPC is a valid reference model for comparing distinct implementations or parallelization strategies, from both performance and statistical accuracy perspectives. version:5
arxiv-1704-02770 | Massively parallel implementation and approaches to simulate quantum dynamics using Krylov subspace techniques | http://arxiv.org/abs/1704.02770 | id:1704.02770 author:Marlon Brenes, Vipin Kerala Varma, Antonello Scardicchio, Ivan Girotto category:physics.comp-ph cond-mat.dis-nn cond-mat.str-el cs.DC  published:2017-04-10 summary:We have developed an application and implemented parallel algorithms in order to provide a computational framework suitable for massively parallel supercomputers to study the unitary dynamics of quantum systems. We use renowned parallel libraries such as PETSc/SLEPc combined with high-performance computing approaches in order to overcome the large memory requirements to be able to study systems whose Hilbert space dimension comprises over 9 billion independent quantum states. Moreover, we provide descriptions on the parallel approach used for the three most important stages of the simulation: handling the Hilbert subspace basis, constructing a matrix representation for a generic Hamiltonian operator and the time evolution of the system by means of the Krylov subspace methods. We employ our setup to study the evolution of quasidisordered and clean many-body systems, focussing on the return probability and related dynamical exponents: the large system sizes accessible provide novel insights into their thermalization properties. version:1
arxiv-1704-02716 | Formal approaches to a definition of agents | http://arxiv.org/abs/1704.02716 | id:1704.02716 author:Martin Biehl category:cs.AI cs.IT cs.MA math.IT 92B20  published:2017-04-10 summary:This thesis contributes to the formalisation of the notion of an agent within the class of finite multivariate Markov chains. Agents are seen as entities that act, perceive, and are goal-directed. We present a new measure that can be used to identify entities (called $\iota$-entities), some general requirements for entities in multivariate Markov chains, as well as formal definitions of actions and perceptions suitable for such entities. The intuition behind $\iota$-entities is that entities are spatiotemporal patterns for which every part makes every other part more probable. The measure, complete local integration (CLI), is formally investigated in general Bayesian networks. It is based on the specific local integration (SLI) which is measured with respect to a partition. CLI is the minimum value of SLI over all partitions. We prove that $\iota$-entities are blocks in specific partitions of the global trajectory. These partitions are the finest partitions that achieve a given SLI value. We also establish the transformation behaviour of SLI under permutations of nodes in the network. We go on to present three conditions on general definitions of entities. These are not fulfilled by sets of random variables i.e.\ the perception-action loop, which is often used to model agents, is too restrictive. We propose that any general entity definition should in effect specify a subset (called an an entity-set) of the set of all spatiotemporal patterns of a given multivariate Markov chain. The set of $\iota$-entities is such a set. Importantly the perception-action loop also induces an entity-set. We then propose formal definitions of actions and perceptions for arbitrary entity-sets. These specialise to standard notions in case of the perception-action loop entity-set. Finally we look at some very simple examples. version:1
arxiv-1309-5301 | Well-Structured Futures and Cache Locality | http://arxiv.org/abs/1309.5301 | id:1309.5301 author:Maurice Herlihy, Zhiyu Liu category:cs.DC  published:2013-09-20 summary:In fork-join parallelism, a sequential program is split into a directed acyclic graph of tasks linked by directed dependency edges, and the tasks are executed, possibly in parallel, in an order consistent with their dependencies. A popular and effective way to extend fork-join parallelism is to allow threads to create futures. A thread creates a future to hold the results of a computation, which may or may not be executed in parallel. That result is returned when some thread touches that future, blocking if necessary until the result is ready. Recent research has shown that while futures can, of course, enhance parallelism in a structured way, they can have a deleterious effect on cache locality. In the worst case, futures can incur $\Omega(P T_\infty + t T_\infty)$ deviations, which implies $\Omega(C P T_\infty + C t T_\infty)$ additional cache misses, where $C$ is the number of cache lines, $P$ is the number of processors, $t$ is the number of touches, and $T_\infty$ is the \emph{computation span}. Since cache locality has a large impact on software performance on modern multicores, this result is troubling. In this paper, however, we show that if futures are used in a simple, disciplined way, then the situation is much better: if each future is touched only once, either by the thread that created it, or by a thread to which the future has been passed from the thread that created it, then parallel executions with work stealing can incur at most $O(C P T^2_\infty)$ additional cache misses, a substantial improvement. This structured use of futures is characteristic of many (but not all) parallel applications. version:3
arxiv-1704-02696 | Implementing a Cloud Platform for Autonomous Driving | http://arxiv.org/abs/1704.02696 | id:1704.02696 author:Shaoshan Liu, Jie Tang, Chao Wang, Quan Wang, Jean-Luc Gaudiot category:cs.DC cs.RO  published:2017-04-10 summary:Autonomous driving clouds provide essential services to support autonomous vehicles. Today these services include but not limited to distributed simulation tests for new algorithm deployment, offline deep learning model training, and High-Definition (HD) map generation. These services require infrastructure support including distributed computing, distributed storage, as well as heterogeneous computing. In this paper, we present the details of how we implement a unified autonomous driving cloud infrastructure, and how we support these services on top of this infrastructure. version:1
arxiv-1704-02683 | A Secure Key Agreement Protocol for Dynamic Group | http://arxiv.org/abs/1704.02683 | id:1704.02683 author:Muhammad Bilal, Shin-Gak Kang category:cs.CR cs.DC cs.NI  published:2017-04-10 summary:To accomplish secure group communication, it is essential to share a unique cryptographic key among group members. The underlying challenges to group key agreement are scalability, efficiency, and security. In a dynamic group environment, the rekeying process is more frequent; therefore, it is more crucial to design an efficient group key agreement protocol. Moreover, with the emergence of various group-based services, it is becoming common for several multicast groups to coexist in the same network. These multicast groups may have several shared users; a join or leave request by a single user can trigger regeneration of multiple group keys. Under the given circumstances the rekeying process becomes a challenging task. In this work, we propose a novel methodology for group key agreement which exploits the state vectors of group members. The state vector is a set of randomly generated nonce instances which determine the logical link between group members and which empowers the group member to generate multiple cryptographic keys independently. Using local knowledge of a secret nonce, each member can generate and share a large number of secure keys, indicating that SGRS inherently provides a considerable amount of secure subgroup multicast communication using subgroup multicasting keys derived from local state vectors. The resulting protocol is secure and efficient in terms of both communication and computation. version:1
arxiv-1609-09224 | Auto-scaling Web Applications in Clouds: A Taxonomy and Survey | http://arxiv.org/abs/1609.09224 | id:1609.09224 author:Chenhao Qu, Rodrigo N. Calheiros, Rajkumar Buyya category:cs.DC  published:2016-09-29 summary:Web application providers have been migrating their applications to cloud data centers, attracted by the emerging cloud computing paradigm. One of the appealing features of the cloud is elasticity. It allows cloud users to acquire or release computing resources on-demand, which enables web application providers to automatically scale the resources provisioned to their applications without human intervention under a dynamic workload to minimize resource cost while satisfying Quality of Service (QoS) requirements. In this paper, we comprehensively analyze the challenges that remain in auto-scaling web applications in clouds and review the developments in this field. We present a taxonomy of auto-scalers according to the identified challenges and key properties. We analyze the surveyed works and map them to the taxonomy to identify the weaknesses in this field. Moreover, based on the analysis, we propose new future directions. version:5
arxiv-1704-02677 | Banshee: Bandwidth-Efficient DRAM Caching Via Software/Hardware Cooperation | http://arxiv.org/abs/1704.02677 | id:1704.02677 author:Xiangyao Yu, Christopher J. Hughes, Nadathur Satish, Onur Mutlu, Srinivas Devadas category:cs.AR  published:2017-04-10 summary:Putting the DRAM on the same package with a processor enables several times higher memory bandwidth than conventional off-package DRAM. Yet, the latency of in-package DRAM is not appreciably lower than that of off-package DRAM. A promising use of in-package DRAM is as a large cache. Unfortunately, most previous DRAM cache designs mainly optimize for hit latency and do not consider off-chip bandwidth efficiency as a first-class design constraint. Hence, as we show in this paper, these designs are suboptimal for use with in-package DRAM. We propose a new DRAM cache design, Banshee, that optimizes for both in- and off-package DRAM bandwidth efficiency without degrading access latency. The key ideas are to eliminate the in-package DRAM bandwidth overheads due to costly tag accesses through virtual memory mechanism and to incorporate a bandwidth-aware frequency-based replacement policy that is biased to reduce unnecessary traffic to off-package DRAM. Our extensive evaluation shows that Banshee provides significant performance improvement and traffic reduction over state-of-the-art latency-optimized DRAM cache designs. version:1
arxiv-1701-04679 | Self-regulating Supply-Demand Systems | http://arxiv.org/abs/1701.04679 | id:1701.04679 author:Evangelos Pournaras, Mark Yao, Dirk Helbing category:cs.SY cs.DC  published:2017-01-16 summary:Supply-demand systems in Smart City sectors such as energy, transportation, telecommunication, are subject of unprecedented technological transformations by the Internet of Things. Usually, supply-demand systems involve actors that produce and consume resources, e.g. energy, and they are regulated such that supply meets demand, or demand meets available supply. Mismatches of supply and demand may increase operational costs, can cause catastrophic damage in infrastructure, for instance power blackouts, and may even lead to social unrest and security threats. Long-term, operationally offline and top-down regulatory decision-making by governmental officers, policy makers or system operators may turn out to be ineffective for matching supply-demand under new dynamics and opportunities that Internet of Things technologies bring to supply-demand systems, for instance, interactive cyber-physical systems and software agents running locally in physical assets to monitor and apply automated control actions in real-time. e.g. power flow redistributions by smart transformers to improve the Smart Grid reliability. Existing work on online regulatory mechanisms of matching supply-demand either focuses on game-theoretic solutions with assumptions that cannot be easily met in real-world systems or assume centralized management entities and local access to global information. This paper contributes a generic decentralized self-regulatory framework, which, in contrast to related work, is shaped around standardized control system concepts and Internet of Things technologies for an easier adoption and applicability. The framework involves a decentralized combinatorial optimization mechanism that matches supply-demand under different regulatory scenarios. version:2
arxiv-1704-02632 | MapReduce Scheduler: A 360-degree view | http://arxiv.org/abs/1704.02632 | id:1704.02632 author:Rajdeep Das, Rohit Pratap Singh, Ripon Patgiri category:cs.DC  published:2017-04-09 summary:Undoubtedly, the MapReduce is the most powerful programming paradigm in distributed computing. The enhancement of the MapReduce is essential and it can lead the computing faster. Therefore, here are many scheduling algorithms to discuss based on their characteristics. Moreover, there are many shortcoming to discover in this field. In this article, we present the state-of-the-art scheduling algorithm to enhance the understanding of the algorithms. The algorithms are presented systematically such that there can be many future possibilities in scheduling algorithm through this article. In this paper, we provide in-depth insight on the MapReduce scheduling algorithm. In addition, we discuss various issues of MapReduce scheduler developed for large-scale computing as well as heterogeneous environment. version:1
arxiv-1704-02630 | A Distributed Control Framework for a Team of Unmanned Aerial Vehicles for Dynamic Wildfire Tracking | http://arxiv.org/abs/1704.02630 | id:1704.02630 author:Huy X. Pham, Hung M. La, David Feil-Seifer, Matthew Deans category:cs.RO  published:2017-04-09 summary:Wildland fire fighting is a very dangerous job, and the lack of information of the fire front is one of main reasons that causes many accidents. Using unmanned aerial vehicle (UAV) to cover wildfire is promising because it can replace human in hazardous fire tracking and save operation costs significantly. In this paper we propose a distributed control framework designed for a team of UAVs that can closely monitor a wildfire in open space, and precisely track its development. The UAV team, designed for flexible deployment, can effectively avoid in-flight collision as well as cooperate well with other neighbors. Experimental results are conducted to demonstrate the capabilites of the UAV team in covering a spreading wildfire. version:1
arxiv-1704-01759 | A Multi-view Context-aware Approach to Android Malware Detection and Malicious Code Localization | http://arxiv.org/abs/1704.01759 | id:1704.01759 author:Annamalai Narayanan, Mahinthan Chandramohan, Lihui Chen, Yang Liu category:cs.CR cs.AI cs.SE  published:2017-04-06 summary:Existing Android malware detection approaches use a variety of features such as security sensitive APIs, system calls, control-flow structures and information flows in conjunction with Machine Learning classifiers to achieve accurate detection. Each of these feature sets provides a unique semantic perspective (or view) of apps' behaviours with inherent strengths and limitations. Meaning, some views are more amenable to detect certain attacks but may not be suitable to characterise several other attacks. Most of the existing malware detection approaches use only one (or a selected few) of the aforementioned feature sets which prevent them from detecting a vast majority of attacks. Addressing this limitation, we propose MKLDroid, a unified framework that systematically integrates multiple views of apps for performing comprehensive malware detection and malicious code localisation. The rationale is that, while a malware app can disguise itself in some views, disguising in every view while maintaining malicious intent will be much harder. MKLDroid uses a graph kernel to capture structural and contextual information from apps' dependency graphs and identify malice code patterns in each view. Subsequently, it employs Multiple Kernel Learning (MKL) to find a weighted combination of the views which yields the best detection accuracy. Besides multi-view learning, MKLDroid's unique and salient trait is its ability to locate fine-grained malice code portions in dependency graphs (e.g., methods/classes). Through our large-scale experiments on several datasets (incl. wild apps), we demonstrate that MKLDroid outperforms three state-of-the-art techniques consistently, in terms of accuracy while maintaining comparable efficiency. In our malicious code localisation experiments on a dataset of repackaged malware, MKLDroid was able to identify all the malice classes with 94% average recall. version:2
arxiv-1704-02468 | Basic Formal Properties of A Relational Model of The Mathematical Theory of Evidence | http://arxiv.org/abs/1704.02468 | id:1704.02468 author:Mieczysław A. Kłopotek, Sławomir T. Wierzchoń category:cs.AI  published:2017-04-08 summary:The paper presents a novel view of the Dempster-Shafer belief function as a measure of diversity in relational data bases. It is demonstrated that under the interpretation The Dempster rule of evidence combination corresponds to the join operator of the relational database theory. This rough-set based interpretation is qualitative in nature and can represent a number of belief function operators. The interpretation has the property that Given a definition of the belief measure of objects in the interpretation domain we can perform operations in this domain and the measure of the resulting object is derivable from measures of component objects via belief operator. We demonstrated this property for Dempster rule of combination, marginalization, Shafer's conditioning, independent variables, Shenoy's notion of conditional independence of variables. The interpretation is based on rough sets (in connection with decision tables), but differs from previous interpretations of this type in that it counts the diversity rather than frequencies in a decision table. version:1
arxiv-1704-02436 | Approximation Algorithms for Barrier Sweep Coverage | http://arxiv.org/abs/1704.02436 | id:1704.02436 author:Barun Gorain, Partha Sarathi Mandal category:cs.DC  published:2017-04-08 summary:Time-varying coverage, namely sweep coverage is a recent development in the area of wireless sensor networks, where a small number of mobile sensors sweep or monitor comparatively large number of locations periodically. In this article we study barrier sweep coverage with mobile sensors where the barrier is considered as a finite length continuous curve on a plane. The coverage at every point on the curve is time-variant. We propose an optimal solution for sweep coverage of a finite length continuous curve. Usually energy source of a mobile sensor is battery with limited power, so energy restricted sweep coverage is a challenging problem for long running applications. We propose an energy restricted sweep coverage problem where every mobile sensors must visit an energy source frequently to recharge or replace its battery. We propose a $\frac{13}{3}$-approximation algorithm for this problem. The proposed algorithm for multiple curves achieves the best possible approximation factor 2 for a special case. We propose a 5-approximation algorithm for the general problem. As an application of the barrier sweep coverage problem for a set of line segments, we formulate a data gathering problem. In this problem a set of mobile sensors is arbitrarily monitoring the line segments one for each. A set of data mules periodically collects the monitoring data from the set of mobile sensors. We prove that finding the minimum number of data mules to collect data periodically from every mobile sensor is NP-hard and propose a 3-approximation algorithm to solve it. version:1
arxiv-1704-02418 | Proceedings Tenth Workshop on Programming Language Approaches to Concurrency- and Communication-cEntric Software | http://arxiv.org/abs/1704.02418 | id:1704.02418 author:Vasco T. Vasconcelos, Philipp Haller category:cs.PL cs.DC cs.SE  published:2017-04-08 summary:PLACES 2017 (full title: Programming Language Approaches to Concurrency- and Communication-cEntric Software) is the tenth edition of the PLACES workshop series. After the first PLACES, which was affiliated to DisCoTec in 2008, the workshop has been part of ETAPS every year since 2009 and is now an established part of the ETAPS satellite events. PLACES 2017 was held on 29th April in Uppsala, Sweden. The workshop series was started in order to promote the application of novel programming language ideas to the increasingly important problem of developing software for systems in which concurrency and communication are intrinsic aspects. This includes software for both multi-core systems and large-scale distributed and/or service-oriented systems. The scope of PLACES includes new programming language features, whole new programming language designs, new type systems, new semantic approaches, new program analysis techniques, and new implementation mechanisms. This volume consists of the papers accepted for presentation at the workshop. version:1
arxiv-1704-02397 | Practical Synchronous Byzantine Consensus | http://arxiv.org/abs/1704.02397 | id:1704.02397 author:Ling Ren, Kartik Nayak, Ittai Abraham, Srinivas Devadas category:cs.DC cs.CR  published:2017-04-07 summary:We present new protocols for Byzantine state machine replication and Byzantine agreement in the synchronous and authenticated setting. The celebrated PBFT state machine replication protocol tolerates $f$ Byzantine faults in an asynchronous setting using $3f+1$ replicas, and has since been studied or deployed by numerous works. In this work, we improve the Byzantine fault tolerance to $n=2f+1$ by utilizing the synchrony assumption. The key challenge is to ensure a quorum intersection at one \emph{honest} replica. Our solution is to rely on the synchrony assumption to form a \emph{post-commit} quorum of size $2f+1$, which intersects at $f+1$ replicas with any \emph{pre-commit} quorums of size $f+1$. Our protocol also solves synchronous authenticated Byzantine agreement in fewer rounds than the best existing solution (Katz and Koo, 2006). A challenge in this direction is to handle non-simultaneous termination, which we solve by introducing a notion of \emph{virtual} participation after termination. Our protocols may be applied to build practical synchronous Byzantine fault tolerant systems and improve cryptographic protocols such as secure multiparty computation and cryptocurrencies when synchrony can be assumed. version:1
arxiv-1704-02375 | AppLP: A Dialogue on Applications of Logic Programming | http://arxiv.org/abs/1704.02375 | id:1704.02375 author:David S. Warren, Yanhong A. Liu category:cs.PL cs.AI cs.LO cs.SE  published:2017-04-07 summary:This document describes the contributions of the 2016 Applications of Logic Programming Workshop (AppLP), which was held on October 17 and associated with the International Conference on Logic Programming (ICLP) in Flushing, New York City. version:1
arxiv-1604-00693 | Pareto Optimality and Strategy Proofness in Group Argument Evaluation (Extended Version) | http://arxiv.org/abs/1604.00693 | id:1604.00693 author:Edmond Awad, Martin Caminada, Gabriella Pigozzi, Mikołaj Podlaszewski, Iyad Rahwan category:cs.AI  published:2016-04-03 summary:An inconsistent knowledge base can be abstracted as a set of arguments and a defeat relation among them. There can be more than one consistent way to evaluate such an argumentation graph. Collective argument evaluation is the problem of aggregating the opinions of multiple agents on how a given set of arguments should be evaluated. It is crucial not only to ensure that the outcome is logically consistent, but also satisfies measures of social optimality and immunity to strategic manipulation. This is because agents have their individual preferences about what the outcome ought to be. In the current paper, we analyze three previously introduced argument-based aggregation operators with respect to Pareto optimality and strategy proofness under different general classes of agent preferences. We highlight fundamental trade-offs between strategic manipulability and social optimality on one hand, and classical logical criteria on the other. Our results motivate further investigation into the relationship between social choice and argumentation theory. The results are also relevant for choosing an appropriate aggregation operator given the criteria that are considered more important, as well as the nature of agents' preferences. version:2
arxiv-1704-02341 | HiFrames: High Performance Data Frames in a Scripting Language | http://arxiv.org/abs/1704.02341 | id:1704.02341 author:Ehsan Totoni, Wajih Ul Hassan, Todd A. Anderson, Tatiana Shpeisman category:cs.DC  published:2017-04-07 summary:Data frames in scripting languages are essential abstractions for processing structured data. However, existing data frame solutions are either not distributed (e.g., Pandas in Python) and therefore have limited scalability, or they are not tightly integrated with array computations (e.g., Spark SQL). This paper proposes a novel compiler-based approach where we integrate data frames into the High Performance Analytics Toolkit (HPAT) to build HiFrames. It provides expressive and flexible data frame APIs which are tightly integrated with array operations. HiFrames then automatically parallelizes and compiles relational operations along with other array computations in end-to-end data analytics programs, and generates efficient MPI/C++ code. We demonstrate that HiFrames is significantly faster than alternatives such as Spark SQL on clusters, without forcing the programmer to switch to embedded SQL for part of the program. HiFrames is 3.6x to 70x faster than Spark SQL for basic relational operations, and can be up to 20,000x faster for advanced analytics operations, such as weighted moving averages (WMA), that the map-reduce paradigm cannot handle effectively. HiFrames is also 5x faster than Spark SQL for TPCx-BB Q26 on 64 nodes of Cori supercomputer. version:1
arxiv-1704-02278 | GLoP: Enabling Massively Parallel Incident Response Through GPU Log Processing | http://arxiv.org/abs/1704.02278 | id:1704.02278 author:Xavier Bellekens, Christos Tachtatzis, Robert Atkinson, Craig Renfrew, Tony Kirkham category:cs.DC cs.CR D.4.6; K.6.5  published:2017-04-07 summary:Large industrial systems that combine services and applications, have become targets for cyber criminals and are challenging from the security, monitoring and auditing perspectives. Security log analysis is a key step for uncovering anomalies, detecting intrusion, and enabling incident response. The constant increase of link speeds, threats and users, produce large volumes of log data and become increasingly difficult to analyse on a Central Processing Unit (CPU). This paper presents a massively parallel Graphics Processing Unit (GPU) LOg Processing (GLoP) library and can also be used for Deep Packet Inspection (DPI), using a prefix matching technique, harvesting the full power of off-the-shelf technologies. GLoP implements two different algorithm using different GPU memory and is compared against CPU counterpart implementations. The library can be used for processing nodes with single or multiple GPUs as well as GPU cloud farms. The results show throughput of 20Gbps and demonstrate that modern GPUs can be utilised to increase the operational speed of large scale log processing scenarios, saving precious time before and after an intrusion has occurred. version:1
arxiv-1704-02272 | A Highly-Efficient Memory-Compression Scheme for GPU-Accelerated Intrusion Detection Systems | http://arxiv.org/abs/1704.02272 | id:1704.02272 author:Xavier Bellekens, Christos Tachtatzis, Robert Atkinson, Craig Renfrew, Tony Kirkham category:cs.DC cs.CR D.4.6; K.6.5  published:2017-04-07 summary:Pattern Matching is a computationally intensive task used in many research fields and real world applications. Due to the ever-growing volume of data to be processed, and increasing link speeds, the number of patterns to be matched has risen significantly. In this paper we explore the parallel capabilities of modern General Purpose Graphics Processing Units (GPGPU) applications for high speed pattern matching. A highly compressed failure-less Aho-Corasick algorithm is presented for Intrusion Detection Systems on off-the-shelf hardware. This approach maximises the bandwidth for data transfers between the host and the Graphics Processing Unit (GPU). Experiments are performed on multiple alphabet sizes, demonstrating the capabilities of the library to be used in different research fields, while sustaining an adequate throughput for intrusion detection systems or DNA sequencing. The work also explores the performance impact of adequate prefix matching for alphabet sizes and varying pattern numbers achieving speeds up to 8Gbps and low memory consumption for intrusion detection systems. version:1
arxiv-1610-01297 | Robust Quaternion-based Cooperative Manipulation without Force/Torque Information | http://arxiv.org/abs/1610.01297 | id:1610.01297 author:Christos K. Verginis, Matteo Mastellaro, Dimos V. Dimarogonas category:cs.RO  published:2016-10-05 summary:This paper proposes a task-space control protocol for the collaborative manipulation of a single object by N robotic agents. The proposed methodology is decentralized in the sense that each agent utilizes information associated with its own and the object's dynamic/kinematic parameters and no on-line communication takes place. Moreover, no feedback of the contact forces/torques is required, therefore employment of corresponding sensors is avoided. An adaptive version of the control scheme is also introduced, where the agents' and object's dynamic parameters are considered unknown. We also use unit quaternions to represent the object's orientation. In addition, load sharing coefficients between the agents are employed and internal force regulation is guaranteed. Finally, experimental studies with two robotic arms verify the validity and effectiveness of the proposed control protocol. version:4
arxiv-1704-02114 | Improving content marketing processes with the approaches by artificial intelligence | http://arxiv.org/abs/1704.02114 | id:1704.02114 author:Utku Kose, Selcuk Sert category:cs.AI cs.SI  published:2017-04-07 summary:Content marketing is todays one of the most remarkable approaches in the context of marketing processes of companies. Value of this kind of marketing has improved in time, thanks to the latest developments regarding to computer and communication technologies. Nowadays, especially social media based platforms have a great importance on enabling companies to design multimedia oriented, interactive content. But on the other hand, there is still something more to do for improved content marketing approaches. In this context, objective of this study is to focus on intelligent content marketing, which can be done by using artificial intelligence. Artificial Intelligence is todays one of the most remarkable research fields and it can be used easily as multidisciplinary. So, this study has aimed to discuss about its potential on improving content marketing. In detail, the study has enabled readers to improve their awareness about the intersection point of content marketing and artificial intelligence. Furthermore, the authors have introduced some example models of intelligent content marketing, which can be achieved by using current Web technologies and artificial intelligence techniques. version:1
arxiv-1704-02075 | On Sensing, Agility, and Computation Requirements for a Data-gathering Agile Robotic Vehicle | http://arxiv.org/abs/1704.02075 | id:1704.02075 author:Fangchang Ma, Sertac Karaman category:cs.RO cs.SY  published:2017-04-07 summary:We consider a robotic vehicle tasked with gathering information by visiting a set of spatially-distributed data sources, the locations of which are not known a priori, but are discovered on the fly. We assume a first-order robot dynamics involving drift and that the locations of the data sources are Poisson-distributed. In this setting, we characterize the performance of the robot in terms of its sensing, agility, and computation capabilities. More specifically, the robot's performance is characterized in terms of its ability to sense the target locations from a distance, to maneuver quickly, and to perform computations for inference and planning. We also characterize the performance of the robot in terms of the amount and distribution of information that can be acquired at each data source. The following are among our theoretical results: the distribution of the amount of information among the target locations immensely impacts the requirements for sensing targets from a distance; performance increases with increasing maneuvering capability, but with diminishing returns; and the computation requirements increase more rapidly for planning as opposed to inference, with both increasing sensing range and maneuvering ability. We provide computational experiments to validate our theoretical results. Finally, we demonstrate that these results can be utilized in the co-design of sensing, actuation, and computation capabilities of mobile robotic systems for an information-gathering mission. Our proof techniques establish novel connections between the fundamental problems of robotic information-gathering and the last-passage percolation problem of statistical mechanics, which may be of interest on its own right. version:1
arxiv-1704-02061 | Probabilistic Recurrence Relations for Work and Span of Parallel Algorithms | http://arxiv.org/abs/1704.02061 | id:1704.02061 author:Joseph Tassarotti category:cs.DS cs.DC  published:2017-04-07 summary:In this paper we present a method for obtaining tail-bounds for random variables satisfying certain probabilistic recurrences that arise in the analysis of randomized parallel divide and conquer algorithms. In such algorithms, some computation is initially done to process an input x, which is then randomly split into subproblems $h_1(x), ..., h_n(x)$, and the algorithm proceeds recursively in parallel on each subproblem. The total work on input x, W(x), then satisfies a probabilistic recurrence of the form $W(x) = a(x) + \sum_{i=1}^n W (h_i(x))$, and the span (the longest chain of sequential dependencies), satisfies $S(x) = b(x) + \max_{i=1}^n S(h_i(x))$, where a(x) and b(x) are the work and span to split x and combine the results of the recursive calls. Karp has previously presented methods for obtaining tail-bounds in the case when n = 1, and under certain stronger assumptions for the work-recurrence when n > 1, but left open the question of the span-recurrence. We first show how to extend his technique to handle the span-recurrence. We then show that in some cases, the work-recurrence can be bounded under simpler assumptions than Karp's by transforming it into a related span-recurrence and applying our first result. We demonstrate our results by deriving tail bounds for the work and span of quicksort and the height of a randomly generated binary search tree. version:1
arxiv-1608-00039 | Distributed Learning for Stochastic Generalized Nash Equilibrium Problems | http://arxiv.org/abs/1608.00039 | id:1608.00039 author:Chung-Kai Yu, Mihaela van der Schaar, Ali H. Sayed category:cs.GT cs.DC  published:2016-07-29 summary:This work examines a stochastic formulation of the generalized Nash equilibrium problem (GNEP) where agents are subject to randomness in the environment of unknown statistical distribution. We focus on fully-distributed online learning by agents and employ penalized individual cost functions to deal with coupled constraints. Three stochastic gradient strategies are developed with constant step-sizes. We allow the agents to use heterogeneous step-sizes and show that the penalty solution is able to approach the Nash equilibrium in a stable manner within $O(\mu_\text{max})$, for small step-size value $\mu_\text{max}$ and sufficiently large penalty parameters. The operation of the algorithm is illustrated by considering the network Cournot competition problem. version:3
arxiv-1704-01946 | From Data to City Indicators: A Knowledge Graph for Supporting Automatic Generation of Dashboards | http://arxiv.org/abs/1704.01946 | id:1704.01946 author:Henrique Santos, Victor Dantas, Vasco Furtado, Paulo Pinheiro, Deborah L. McGuinness category:cs.AI cs.CY I.2.4  published:2017-04-06 summary:In the context of Smart Cities, indicator definitions have been used to calculate values that enable the comparison among different cities. The calculation of an indicator values has challenges as the calculation may need to combine some aspects of quality while addressing different levels of abstraction. Knowledge graphs (KGs) have been used successfully to support flexible representation, which can support improved understanding and data analysis in similar settings. This paper presents an operational description for a city KG, an indicator ontology that support indicator discovery and data visualization and an application capable of performing metadata analysis to automatically build and display dashboards according to discovered indicators. We describe our implementation in an urban mobility setting. version:1
arxiv-1704-01144 | Design and Analysis of a Task-based Parallelization over a Runtime System of an Explicit Finite-Volume CFD Code with Adaptive Time Stepping | http://arxiv.org/abs/1704.01144 | id:1704.01144 author:Jean Marie Couteyen Carpaye, Jean Roman, Pierre Brenner category:cs.DC  published:2017-03-29 summary:FLUSEPA (Registered trademark in France No. 134009261) is an advanced simulation tool which performs a large panel of aerodynamic studies. It is the unstructured finite-volume solver developed by Airbus Safran Launchers company to calculate compressible, multidimensional, unsteady, viscous and reactive flows around bodies in relative motion. The time integration in FLUSEPA is done using an explicit temporal adaptive method. The current production version of the code is based on MPI and OpenMP. This implementation leads to important synchronizations that must be reduced. To tackle this problem, we present the study of a task-based parallelization of the aerodynamic solver of FLUSEPA using the runtime system StarPU and combining up to three levels of parallelism. We validate our solution by the simulation (using a finite-volume mesh with 80 million cells) of a take-off blast wave propagation for Ariane 5 launcher. version:2
arxiv-1704-01927 | Short Labeling Schemes for Topology Recognition in Wireless Tree Networks | http://arxiv.org/abs/1704.01927 | id:1704.01927 author:Barun Gorain, Andrzej Pelc category:cs.DC  published:2017-04-06 summary:We consider the problem of topology recognition in wireless (radio) networks modeled as undirected graphs. Topology recognition is a fundamental task in which every node of the network has to output a map of the underlying graph i.e., an isomorphic copy of it, and situate itself in this map. In wireless networks, nodes communicate in synchronous rounds. In each round a node can either transmit a message to all its neighbors, or stay silent and listen. At the receiving end, a node $v$ hears a message from a neighbor $w$ in a given round, if $v$ listens in this round, and if $w$ is its only neighbor that transmits in this round. Nodes have labels which are (not necessarily different) binary strings. The length of a labeling scheme is the largest length of a label. We concentrate on wireless networks modeled by trees, and we investigate two problems. \begin{itemize} \item What is the shortest labeling scheme that permits topology recognition in all wireless tree networks of diameter $D$ and maximum degree $\Delta$? \item What is the fastest topology recognition algorithm working for all wireless tree networks of diameter $D$ and maximum degree $\Delta$, using such a short labeling scheme? \end{itemize} We are interested in deterministic topology recognition algorithms. For the first problem, we show that the minimum length of a labeling scheme allowing topology recognition in all trees of maximum degree $\Delta \geq 3$ is $\Theta(\log\log \Delta)$. For such short schemes, used by an algorithm working for the class of trees of diameter $D\geq 4$ and maximum degree $\Delta \geq 3$, we show almost matching bounds on the time of topology recognition: an upper bound $O(D\Delta)$, and a lower bound $\Omega(D\Delta^{\epsilon})$, for any constant $\epsilon<1$. version:1
arxiv-1704-01889 | Conformative Filtering for Implicit Feedback Data | http://arxiv.org/abs/1704.01889 | id:1704.01889 author:Farhan Khawar, Nevin L. Zhang, Jinxing Yu category:cs.IR cs.AI  published:2017-04-06 summary:Implicit feedback is the simplest form of user feedback that can be used for item recommendation. It is easy to collect and domain independent. However, there is a lack of negative examples. Existing works circumvent this problem by making various assumptions regarding the unconsumed items, which fail to hold when the user did not consume an item because she was unaware of it. In this paper we propose Conformative Filtering (CoF) as a novel method for addressing the lack of negative examples in implicit feedback. The motivation is that if there is a large group of users who share the same taste and none of them consumed an item, then it is highly likely that the item is irrelevant to this taste. We use Hierarchical Latent Tree Analysis (HLTA) to identify taste-based user groups, and make recommendations for a user based on her memberships in the groups. Experiments on real-world datasets from different domains show that CoF has superior performance compared to other baselines and more than 10% improvement in Recall@5 and Recall@10 is observed. version:1
arxiv-1704-01886 | Landmark Guided Probabilistic Roadmap Queries | http://arxiv.org/abs/1704.01886 | id:1704.01886 author:Brian Paden, Yannik Nager, Emilio Frazzoli category:cs.RO cs.AI  published:2017-04-06 summary:A landmark based heuristic is investigated for reducing query phase run-time of the probabilistic roadmap (\PRM) motion planning method. The heuristic is generated by storing minimum spanning trees from a small number of vertices within the \PRM graph and using these trees to approximate the cost of a shortest path between any two vertices of the graph. The intermediate step of preprocessing the graph increases the time and memory requirements of the classical motion planning technique in exchange for speeding up individual queries making the method advantageous in multi-query applications. This paper investigates these trade-offs on \PRM graphs constructed in randomized environments as well as a practical manipulator simulation.We conclude that the method is preferable to Dijkstra's algorithm or the ${\rm A}^*$ algorithm with conventional heuristics in multi-query applications. version:1
arxiv-1704-01855 | A Service-Oriented Architecture for Assisting the Authoring of Semantic Crowd Maps | http://arxiv.org/abs/1704.01855 | id:1704.01855 author:Henrique Santos, Vasco Furtado category:cs.AI cs.CY I.2.4  published:2017-04-06 summary:Although there are increasingly more initiatives for the generation of semantic knowledge based on user participation, there is still a shortage of platforms for regular users to create applications on which semantic data can be exploited and generated automatically. We propose an architecture, called Semantic Maps (SeMaps), for assisting the authoring and hosting of applications in which the maps combine the aggregation of a Geographic Information System and crowd-generated content (called here crowd maps). In these systems, the digital map works as a blackboard for accommodating stories told by people about events they want to share with others typically participating in their social networks. SeMaps offers an environment for the creation and maintenance of sites based on crowd maps with the possibility for the user to characterize semantically that which s/he intends to mark on the map. The designer of a crowd map, by informing a linguistic expression that designates what has to be marked on the maps, is guided in a process that aims to associate a concept from a common-sense base to this linguistic expression. Thus, the crowd maps start to have dominion over common-sense inferential relations that define the meaning of the marker, and are able to make inferences about the network of linked data. This makes it possible to generate maps that have the power to perform inferences and access external sources (such as DBpedia) that constitute information that is useful and appropriate to the context of the map. In this paper we describe the architecture of SeMaps and how it was applied in a crowd map authoring tool. version:1
arxiv-1704-01806 | Human-Aware Sensor Network Ontology: Semantic Support for Empirical Data Collection | http://arxiv.org/abs/1704.01806 | id:1704.01806 author:Paulo Pinheiro, Deborah L. McGuinness, Henrique Santos category:cs.AI cs.CY I.2.4  published:2017-04-06 summary:Significant efforts have been made to understand and document knowledge related to scientific measurements. Many of those efforts resulted in one or more high-quality ontologies that describe some aspects of scientific measurements, but not in a comprehensive and coherently integrated manner. For instance, we note that many of these high-quality ontologies are not properly aligned, and more challenging, that they have different and often conflicting concepts and approaches for encoding knowledge about empirical measurements. As a result of this lack of an integrated view, it is often challenging for scientists to determine whether any two scientific measurements were taken in semantically compatible manners, thus making it difficult to decide whether measurements should be analyzed in combination or not. In this paper, we present the Human-Aware Sensor Network Ontology that is a comprehensive alignment and integration of a sensing infrastructure ontology and a provenance ontology. HASNetO has been under development for more than one year, and has been reviewed, shared and used by multiple scientific communities. The ontology has been in use to support the data management of a number of large-scale ecological monitoring activities (observations) and empirical experiments. version:1
arxiv-1704-01802 | Contextual Data Collection for Smart Cities | http://arxiv.org/abs/1704.01802 | id:1704.01802 author:Henrique Santos, Vasco Furtado, Paulo Pinheiro, Deborah L. McGuinness category:cs.AI cs.CY I.2.4  published:2017-04-06 summary:As part of Smart Cities initiatives, national, regional and local governments all over the globe are under the mandate of being more open regarding how they share their data. Under this mandate, many of these governments are publishing data under the umbrella of open government data, which includes measurement data from city-wide sensor networks. Furthermore, many of these data are published in so-called data portals as documents that may be spreadsheets, comma-separated value (CSV) data files, or plain documents in PDF or Word documents. The sharing of these documents may be a convenient way for the data provider to convey and publish data but it is not the ideal way for data consumers to reuse the data. For example, the problems of reusing the data may range from difficulty opening a document that is provided in any format that is not plain text, to the actual problem of understanding the meaning of each piece of knowledge inside of the document. Our proposal tackles those challenges by identifying metadata that has been regarded to be relevant for measurement data and providing a schema for this metadata. We further leverage the Human-Aware Sensor Network Ontology (HASNetO) to build an architecture for data collected in urban environments. We discuss the use of HASNetO and the supporting infrastructure to manage both data and metadata in support of the City of Fortaleza, a large metropolitan area in Brazil. version:1
arxiv-1704-01785 | Geometry of Policy Improvement | http://arxiv.org/abs/1704.01785 | id:1704.01785 author:Guido Montufar, Johannes Rauh category:cs.AI math.OC 68T05  90C40 G.3; I.2.8  published:2017-04-06 summary:We investigate the geometry of optimal memoryless time independent decision making in relation to the amount of information that the acting agent has about the state of the system. We show that the expected long term reward, discounted or per time step, is maximized by policies that randomize among at most $k$ actions whenever at most $k$ world states are consistent with the agent's observation. Moreover, we show that the expected reward per time step can be studied in terms of the expected discounted reward. Our main tool is a geometric version of the policy improvement lemma, which identifies a polyhedral cone of policy changes in which the state value function increases for all states. version:1
arxiv-1704-01742 | Transferrable Plausibility Model - A Probabilistic Interpretation of Mathematical Theory of Evidence | http://arxiv.org/abs/1704.01742 | id:1704.01742 author:Mieczysław Kłopotek category:cs.AI  published:2017-04-06 summary:This paper suggests a new interpretation of the Dempster-Shafer theory in terms of probabilistic interpretation of plausibility. A new rule of combination of independent evidence is shown and its preservation of interpretation is demonstrated. version:1
arxiv-1701-07790 | Game-Theoretic Modeling of Human Adaptation in Human-Robot Collaboration | http://arxiv.org/abs/1701.07790 | id:1701.07790 author:Stefanos Nikolaidis, Swaprava Nath, Ariel D. Procaccia, Siddhartha Srinivasa category:cs.RO  published:2017-01-26 summary:In human-robot teams, humans often start with an inaccurate model of the robot capabilities. As they interact with the robot, they infer the robot's capabilities and partially adapt to the robot, i.e., they might change their actions based on the observed outcomes and the robot's actions, without replicating the robot's policy. We present a game-theoretic model of human partial adaptation to the robot, where the human responds to the robot's actions by maximizing a reward function that changes stochastically over time, capturing the evolution of their expectations of the robot's capabilities. The robot can then use this model to decide optimally between taking actions that reveal its capabilities to the human and taking the best action given the information that the human currently has. We prove that under certain observability assumptions, the optimal policy can be computed efficiently. We demonstrate through a human subject experiment that the proposed model significantly improves human-robot team performance, compared to policies that assume complete adaptation of the human to the robot. version:2
arxiv-1704-01676 | Multi-Personality Partitioning for Heterogeneous Systems | http://arxiv.org/abs/1704.01676 | id:1704.01676 author:Anthony Gregerson, Aman Chadha, Katherine Morrow category:cs.DC cs.DS  published:2017-04-06 summary:Design flows use graph partitioning both as a precursor to place and route for single devices, and to divide netlists or task graphs among multiple devices. Partitioners have accommodated FPGA heterogeneity via multi-resource constraints, but have not yet exploited the corresponding ability to implement some computations in multiple ways (e.g., LUTs vs. DSP blocks), which could enable a superior solution. This paper introduces multi-personality graph partitioning, which incorporates aspects of resource mapping into partitioning. We present a modified multi-level KLFM partitioning algorithm that also performs heterogeneous resource mapping for nodes with multiple potential implementations (multiple personalities). We evaluate several variants of our multi-personality FPGA circuit partitioner using 21 circuits and benchmark graphs, and show that dynamic resource mapping improves cut size on average by 27% over static mapping for these circuits. We further show that it improves deviation from target resource utilizations by 50% over post-partitioning resource mapping. version:1
arxiv-1610-06050 | A 9.52 dB NCG FEC scheme and 164 bits/cycle low-complexity product decoder architecture | http://arxiv.org/abs/1610.06050 | id:1610.06050 author:Carlo Condo, Pascal Giard, François Leduc-Primeau, Gabi Sarkis, Warren J. Gross category:cs.AR cs.IT math.IT  published:2016-10-18 summary:Powerful Forward Error Correction (FEC) schemes are used in optical communications to achieve bit-error rates below $10^{-15}$. These FECs follow one of two approaches: concatenation of simpler hard-decision codes or usage of inherently powerful soft-decision codes. The first approach yields lower Net Coding Gains (NCGs), but can usually work at higher code rates and have lower complexity decoders. In this work, we propose a novel FEC scheme based on a product code and a post-processing technique. It can achieve an NCG of 9.52~dB at a BER of $10^{-15}$ and 9.96~dB at a BER of $10^{-18}$, an error-correction performance that sits between that of current hard-decision and soft-decision FECs. A decoder architecture is designed, tested on FPGA and synthesized in 65 nm CMOS technology: its 164 bits/cycle worst-case information throughput can reach 100 Gb/s at the achieved frequency of 609~MHz. Its complexity is shown to be lower than that of hard-decision decoders in literature, and an order of magnitude lower than the estimated complexity of soft-decision decoders. version:2
arxiv-1603-04610 | Time-optimal Coordination of Mobile Robots along Specified Paths | http://arxiv.org/abs/1603.04610 | id:1603.04610 author:Florent Altché, Xiangjun Qian, Arnaud de La Fortelle category:cs.RO  published:2016-03-15 summary:In this paper, we address the problem of time-optimal coordination of mobile robots under kinodynamic constraints along specified paths. We propose a novel approach based on time discretization that leads to a mixed-integer linear programming (MILP) formulation. This problem can be solved using general-purpose MILP solvers in a reasonable time, resulting in a resolution-optimal solution. Moreover, unlike previous work found in the literature, our formulation allows an exact linear modeling (up to the discretization resolution) of second-order dynamic constraints. Extensive simulations are performed to demonstrate the effectiveness of our approach. version:3
arxiv-1701-00696 | A pre-semantics for counterfactual conditionals and similar logics | http://arxiv.org/abs/1701.00696 | id:1701.00696 author:Karl Schlechta category:cs.AI math.LO  published:2016-12-06 summary:The elegant Stalnaker/Lewis semantics for counterfactual conditonals works with distances between models. But human beings certainly have no tables of models and distances in their head. We begin here an investigation using a more realistic picture, based on findings in neuroscience. We call it a pre-semantics, as its meaning is not a description of the world, but of the brain, whose structure is (partly) determined by the world it reasons about. In the final section, we reconsider the components, and postulate that there are no atomic pictures, we can always look inside. version:3
arxiv-1704-01383 | Finite-Time Stabilization of Longitudinal Control for Autonomous Vehicles via a Model-Free Approach | http://arxiv.org/abs/1704.01383 | id:1704.01383 author:Philip Polack, Brigitte d'Andréa-Novel, Michel Fliess, Arnaud de la Fortelle, Lghani Menhour category:cs.SY cs.AI math.OC  published:2017-04-05 summary:This communication presents a longitudinal model-free control approach for computing the wheel torque command to be applied on a vehicle. This setting enables us to overcome the problem of unknown vehicle parameters for generating a suitable control law. An important parameter in this control setting is made time-varying for ensuring finite-time stability. Several convincing computer simulations are displayed and discussed. Overshoots become therefore smaller. The driving comfort is increased and the robustness to time-delays is improved. version:1
arxiv-1704-01271 | A robust walking controller based on online step location and duration optimization for bipedal locomotion | http://arxiv.org/abs/1704.01271 | id:1704.01271 author:Majid Khadiv, Alexander Herzog, S. Ali A. Moosavian, Ludovic Righetti category:cs.RO  published:2017-04-05 summary:Step adjustment for humanoid robots has been shown to improve gait robustness, while timing adjustment is often neglected in control strategies. In this paper, a new walking controller is proposed that combines both step location and timing adjustment for generating robust gaits. In this approach, step location and timing are decided, based on the Divergent Component of Motion (DCM) measurement. We define the DCM offset as the offset between the DCM and landing location of the swing foot at landing time, and employ it to split state space into viable/non-viable parts. Constructing our walking controller based on the DCM offset, we can exploit the whole capability of a biped robot in terms of stepping to recover from disturbances. The proposed approach is comprised of two stages. In the first stage, the nominal step location and step duration for the next step(s) are decided. In this stage, the main goal is to schedule the gait variables far from constraint boundaries for a desired walking velocity. The second stage adapts at each control cycle the landing position and time of the swing foot. By using the DCM offset and a change of variable for the step timing, we can formulate the second stage of our controller as a small sized quadratic program without the need to preview several steps ahead. To map the adapted gait variables to the full robot, a hierarchical inverse dynamics is employed. Interestingly, our approach does not require precise control of the center of pressure and can also be used on robots with passive ankles or point feet. Simulation experiments show a significant improvement in robustness to various types of external disturbances, such as pushes and slippage, compared to state of the art preview controllers where step timing is not adjusted. In particular, we demonstrate robust walking behavior for a simulated robot with passive ankles. Keywords version:1
arxiv-1704-01252 | A General Framework for Multi-vehicle Cooperative Localization Using Pose Graph | http://arxiv.org/abs/1704.01252 | id:1704.01252 author:Xiaotong Shen, Hans Andersen, Wei Kang Leong, Hai Xun Kong, Marcelo H. Ang Jr., Daniela Rus category:cs.RO  published:2017-04-05 summary:When a vehicle observes another one, the two vehicles' poses are correlated by this spatial relative observation, which can be used in cooperative localization for further increasing localization accuracy and precision. To use spatial relative observations, we propose to add them into a pose graph for optimal pose estimation. Before adding them, we need to know the identities of the observed vehicles. The vehicle identification is formulated as a linear assignment problem, which can be solved efficiently. By using pose graph techniques and the start-of-the-art factor composition/decomposition method, our cooperative localization algorithm is robust against communication delay, packet loss, and out-of-sequence packet reception. We demonstrate the usability of our framework and effectiveness of our algorithm through both simulations and real-world experiments using three vehicles on the road. version:1
arxiv-1703-05614 | ParaGraphE: A Library for Parallel Knowledge Graph Embedding | http://arxiv.org/abs/1703.05614 | id:1703.05614 author:Xiao-Fan Niu, Wu-Jun Li category:cs.AI  published:2017-03-16 summary:Knowledge graph embedding aims at translating the knowledge graph into numerical representations by transforming the entities and relations into continuous low-dimensional vectors. Recently, many methods [1, 5, 3, 2, 6] have been proposed to deal with this problem, but existing single-thread implementations of them are time-consuming for large-scale knowledge graphs. Here, we design a unified parallel framework to parallelize these methods, which achieves a significant time reduction without influencing the accuracy. We name our framework as ParaGraphE, which provides a library for parallel knowledge graph embedding. The source code can be downloaded from https://github.com/LIBBLE/LIBBLE-MultiThread/tree/master/ParaGraphE . version:3
arxiv-1704-01189 | Scene-level Programming by Demonstration | http://arxiv.org/abs/1704.01189 | id:1704.01189 author:Zhen Zeng, Zheming Zhou, Zhiqiang Sui, Odest Chadwicke Jenkins category:cs.RO  published:2017-04-04 summary:Scene-level Programming by Demonstration (PbD) is faced with an important challenge - perceptual uncertainty. Addressing this problem, we present a scene-level PbD paradigm that programs robots to perform goal-directed manipulation in unstructured environments with grounded perception. Scene estimation is enabled by our discriminatively-informed generative scene estimation method (DIGEST). Given scene observations, DIGEST utilizes candidates from discriminative object detectors to generate and evaluate hypothesized scenes of object poses. Scene graphs are generated from the estimated object poses, which in turn is used in the PbD system for high-level task planning. We demonstrate that DIGEST performs better than existing method and is robust to false positive detections. Building a PbD system on DIGEST, we show experiments of programming a Fetch robot to set up a tray for delivery with various objects through demonstration of goal scenes. version:1
arxiv-1611-07399 | A Robust Force Control Approach for Underwater Vehicle Manipulator Systems | http://arxiv.org/abs/1611.07399 | id:1611.07399 author:Shahab Heshmati-alamdari, Alexandros Nikou, Kostas J. Kyriakopoulos, Dimos V. Dimarogonas category:cs.RO  published:2016-11-22 summary:In various interaction tasks using Underwater Vehicle Manipulator Systems (UVMSs) (e.g. sampling of the sea organisms, underwater welding), important factors such as: i) uncertainties and complexity of UVMS dynamic model ii) external disturbances (e.g. sea currents and waves) iii) imperfection and noises of measuring sensors iv) steady state performance as well as v) inferior overshoot of interaction force error, should be addressed during the force control design. Motivated by the above factors, this paper presents a model-free control protocol for force controlling of an Underwater Vehicle Manipulator System which is in contact with a compliant environment, without incorporating any knowledge of the UVMS's dynamic model, exogenous disturbances and sensor's noise model. Moreover, the transient and steady state response as well as reduction of overshooting force error are solely determined by certain designer-specified performance functions and are fully decoupled by the UVMS's dynamic model, the control gain selection, as well as the initial conditions. Finally, a simulation study clarifies the proposed method and verifies its efficiency. version:2
arxiv-1704-01127 | 0.5 Petabyte Simulation of a 45-Qubit Quantum Circuit | http://arxiv.org/abs/1704.01127 | id:1704.01127 author:Thomas Häner, Damian S. Steiger category:quant-ph cs.DC cs.ET  published:2017-04-04 summary:Near-term quantum computers will soon reach sizes that are challenging to directly simulate, even when employing the most powerful supercomputers. Yet, the ability to simulate these early devices using classical computers is crucial for calibration, validation, and benchmarking. In order to make use of the full potential of systems featuring multi- and many-core processors, we use automatic code generation and optimization of compute kernels, which also enables performance portability. We apply a scheduling algorithm to quantum supremacy circuits in order to reduce the required communication and simulate a 45-qubit circuit on the Cori II supercomputer using 8,192 nodes and 0.5 petabytes of memory. To our knowledge, this constitutes the largest quantum circuit simulation to this date. Our highly-tuned kernels in combination with the reduced communication requirements allow an improvement in time-to-solution over state-of-the-art simulators by more than an order of magnitude at every scale. version:1
arxiv-1407-6470 | New Trends in Parallel and Distributed Simulation: from Many-Cores to Cloud Computing | http://arxiv.org/abs/1407.6470 | id:1407.6470 author:Gabriele D'Angelo, Moreno Marzolla category:cs.DC cs.AR  published:2014-07-24 summary:Recent advances in computing architectures and networking are bringing parallel computing systems to the masses so increasing the number of potential users of these kinds of systems. In particular, two important technological evolutions are happening at the ends of the computing spectrum: at the "small" scale, processors now include an increasing number of independent execution units (cores), at the point that a mere CPU can be considered a parallel shared-memory computer; at the "large" scale, the Cloud Computing paradigm allows applications to scale by offering resources from a large pool on a pay-as-you-go model. Multi-core processors and Clouds both require applications to be suitably modified to take advantage of the features they provide. In this paper, we analyze the state of the art of parallel and distributed simulation techniques, and assess their applicability to multi-core architectures or Clouds. It turns out that most of the current approaches exhibit limitations in terms of usability and adaptivity which may hinder their application to these new computing architectures. We propose an adaptive simulation mechanism, based on the multi-agent system paradigm, to partially address some of those limitations. While it is unlikely that a single approach will work well on both settings above, we argue that the proposed adaptive mechanism has useful features which make it attractive both in a multi-core processor and in a Cloud system. These features include the ability to reduce communication costs by migrating simulation components, and the support for adding (or removing) nodes to the execution architecture at runtime. We will also show that, with the help of an additional support layer, parallel and distributed simulations can be executed on top of unreliable resources. version:2
arxiv-1611-01325 | Multi-level Simulation of Internet of Things on Smart Territories | http://arxiv.org/abs/1611.01325 | id:1611.01325 author:Gabriele D'Angelo, Stefano Ferretti, Vittorio Ghini category:cs.PF cs.DC cs.MA cs.NI  published:2016-11-04 summary:In this paper, a methodology is presented and employed for simulating the Internet of Things (IoT). The requirement for scalability, due to the possibly huge amount of involved sensors and devices, and the heterogeneous scenarios that might occur, impose resorting to sophisticated modeling and simulation techniques. In particular, multi-level simulation is regarded as a main framework that allows simulating large-scale IoT environments while keeping high levels of detail, when it is needed. We consider a use case based on the deployment of smart services in decentralized territories. A two level simulator is employed, which is based on a coarse agent-based, adaptive parallel and distributed simulation approach to model the general life of simulated entities. However, when needed a finer grained simulator (based on OMNeT++) is triggered on a restricted portion of the simulated area, which allows considering all issues concerned with wireless communications. Based on this use case, it is confirmed that the ad-hoc wireless networking technologies do represent a principle tool to deploy smart services over decentralized countrysides. Moreover, the performance evaluation confirms the viability of utilizing multi-level simulation for simulating large scale IoT environments. version:2
arxiv-1507-04928 | A Brain-like Cognitive Process with Shared Methods | http://arxiv.org/abs/1507.04928 | id:1507.04928 author:Kieran Greer category:cs.AI  published:2015-07-17 summary:This paper describes a new entropy-style of equation that may be useful in a general sense, but can be applied to a cognitive model with related processes. The model is based on the human brain, with automatic and distributed pattern activity. Methods for carrying out the different processes are suggested. The main purpose of this paper is to reaffirm earlier research on different knowledge-based and experience-based clustering techniques. The overall architecture has stayed essentially the same and so it is the localised processes or smaller details that have been updated. For example, a counting mechanism is used slightly differently, to measure a level of 'cohesion' instead of a 'correct' classification, over pattern instances. The introduction of features has further enhanced the architecture and the new entropy-style equation is proposed. While an earlier paper defined three levels of functional requirement, this paper re-defines the levels in a more human vernacular, with higher-level goals described in terms of action-result pairs. version:5
arxiv-1703-11005 | A simplicial complex model of dynamic epistemic logic for fault-tolerant distributed computing | http://arxiv.org/abs/1703.11005 | id:1703.11005 author:Eric Goubault, Sergio Rajsbaum category:cs.DC cs.MA  published:2017-03-31 summary:The usual epistemic S5 model for multi-agent systems is a Kripke graph, whose edges are labeled with the agents that do not distinguish between two states. We propose to uncover the higher dimensional information implicit in the Kripke graph, by using as a model its dual, a chromatic simplicial complex. For each state of the Kripke model there is a facet in the complex, with one vertex per agent. If an edge (u,v) is labeled with a set of agents S, the facets corresponding to u and v intersect in a simplex consisting of one vertex for each agent of S. Then we use dynamic epistemic logic to study how the simplicial complex epistemic model changes after the agents communicate with each other. We show that there are topological invariants preserved from the initial epistemic complex to the epistemic complex after an action model is applied, that depend on how reliable the communication is. In turn these topological properties determine the knowledge that the agents may gain after the communication happens. version:2
arxiv-1704-00978 | Converging High-Throughput and High-Performance Computing: A Case Study | http://arxiv.org/abs/1704.00978 | id:1704.00978 author:Alessio Angius, Danila Oleynik, Sergey Panitkin, Matteo Turilli, Kaushik De, Alexei Klimentov, Sarp H. Oral, Jack C. Wells, Shantenu Jha category:cs.DC cs.SE  published:2017-04-04 summary:The computing systems used by LHC experiments has historically consisted of the federation of hundreds to thousands of distributed resources, ranging from small to mid-size resource. In spite of the impressive scale of the existing distributed computing solutions, the federation of small to mid-size resources will be insufficient to meet projected future demands. This paper is a case study of how the ATLAS experiment has embraced Titan -- a DOE leadership facility in conjunction with traditional distributed high-throughput computing to reach sustained production scales of approximately 51M core-hours a years. The three main contributions of this paper are: (i) a critical evaluation of design and operational considerations to support the sustained, scalable and production usage of Titan; (ii) a preliminary characterization of a next generation executor for PanDA to support new workloads and advanced execution modes; and (iii) early lessons for how current and future experimental and observational systems can be integrated with production supercomputers and other platforms in a general and extensible manner. version:1
arxiv-1704-01399 | Geracao Automatica de Paineis de Controle para Analise de Mobilidade Urbana Utilizando Redes Complexas | http://arxiv.org/abs/1704.01399 | id:1704.01399 author:Victor Dantas, Henrique Santos, Carlos Caminha, Vasco Furtado category:cs.AI cs.SI  published:2017-04-04 summary:In this paper we describe an automatic generator to support the data scientist to construct, in a user-friendly way, dashboards from data represented as networks. The generator called SBINet (Semantic for Business Intelligence from Networks) has a semantic layer that, through ontologies, describes the data that represents a network as well as the possible metrics to be calculated in the network. Thus, with SBINet, the stages of the dashboard constructing process that uses complex network metrics are facilitated and can be done by users who do not necessarily know about complex networks. version:1
arxiv-1704-00961 | Adaptive Motion Gaming AI for Health Promotion | http://arxiv.org/abs/1704.00961 | id:1704.00961 author:Pujana Paliyawan, Takahiro Kusano, Yuto Nakagawa, Tomohiro Harada, Ruck Thawonmas category:cs.AI cs.CY cs.HC I.2.1; K.8.0  published:2017-04-04 summary:This paper presents a design of a non-player character (AI) for promoting balancedness in use of body segments when engaging in full-body motion gaming. In our experiment, we settle a battle between the proposed AI and a player by using FightingICE, a fighting game platform for AI development. A middleware called UKI is used to allow the player to control the game by using body motion instead of the keyboard and mouse. During gameplay, the proposed AI analyze health states of the player; it determines its next action by predicting how each candidate action, recommended by a Monte-Carlo tree search algorithm, will induce the player to move, and how the player's health tends to be affected. Our result demonstrates successful improvement in balancedness in use of body segments on 4 out of 5 subjects. version:1
arxiv-1704-00905 | Interacting With a Mobile Robot with a Natural Infrastructure-Less Interface | http://arxiv.org/abs/1704.00905 | id:1704.00905 author:Valeria Villani, Lorenzo Sabattini, Giuseppe Riggio, Alessio Levratti, Cristian Secchi, Cesare Fantuzzi category:cs.RO  published:2017-04-04 summary:In this paper we introduce a novel approach that enables users to interact with a mobile robot in a natural manner. The proposed interaction system does not require any specific infrastructure or device, but relies on commonly utilized objects while leaving the user's hands free. Specifically, we propose to utilize a smartwatch (or a sensorized wristband) for recognizing the motion of the user's forearm. Measurements of accelerations and angular velocities are exploited to recognize user's gestures and define velocity commands for the robot. The proposed interaction system is evaluated experimentally with different users controlling a mobile robot and compared to the use of a remote control device for the teleoperation of robots. Results show that the usability and effectiveness of the proposed natural interaction system based on the use of a smartwatch provide significant improvement in the human-robot interaction experience. version:1
arxiv-1704-00888 | A Discrete-Time Attitude Observer on SO(3) for Vision and GPS Fusion | http://arxiv.org/abs/1704.00888 | id:1704.00888 author:Alireza Khosravian, Tat-Jun Chin, Ian Reid, Robert Mahony category:cs.RO cs.SY  published:2017-04-04 summary:This paper proposes a discrete-time geometric attitude observer for fusing monocular vision with GPS velocity measurements. The observer takes the relative transformations obtained from processing monocular images with any visual odometry algorithm and fuses them with GPS velocity measurements. The objectives of this sensor fusion are twofold; first to mitigate the inherent drift of the attitude estimates of the visual odometry, and second, to estimate the orientation directly with respect to the North-East-Down frame. A key contribution of the paper is to present a rigorous stability analysis showing that the attitude estimates of the observer converge exponentially to the true attitude and to provide a lower bound for the convergence rate of the observer. Through experimental studies, we demonstrate that the observer effectively compensates for the inherent drift of the pure monocular vision based attitude estimation and is able to recover the North-East-Down orientation even if it is initialized with a very large attitude error. version:1
arxiv-1704-00878 | HAlign-II: efficient ultra-large multiple sequence alignment and phylogenetic tree reconstruction with distributed and parallel computing | http://arxiv.org/abs/1704.00878 | id:1704.00878 author:Shixiang Wan, Quan Zou category:cs.DC q-bio.QM  published:2017-04-04 summary:Multiple sequence alignment (MSA) plays a key role in biological sequence analyses, especially in phylogenetic tree construction. Extreme increase in next-generation sequencing results in shortage of efficient ultra-large biological sequence alignment approaches for coping with different sequence types. Distributed and parallel computing represents a crucial technique for accelerating ultra-large sequence analyses. Based on HAlign and Spark distributed computing system, we implement a highly cost-efficient and time-efficient HAlign-II tool to address ultra-large multiple biological sequence alignment and phylogenetic tree construction. After comparing with most available state-of-the-art methods, our experimental results indicate the following: 1) HAlign-II can efficiently carry out MSA and construct phylogenetic trees with ultra-large biological sequences; 2) HAlign-II shows extremely high memory efficiency and scales well with increases in computing resource; 3) HAlign-II provides a user-friendly web server based on our distributed computing infrastructure. HAlign-II with open-source codes and datasets was established at http://lab.malab.cn/soft/halign. version:1
arxiv-1704-00866 | Indirect Shared Control of Highly Automated Vehicles for Cooperative Driving between Driver and Automation | http://arxiv.org/abs/1704.00866 | id:1704.00866 author:Renjie Li, Yanan Li, Shengbo Eben Li, Etienne Burdet, Bo Cheng category:cs.RO  published:2017-04-04 summary:It is widely acknowledged that drivers should remain in the control loop of automated vehicles before they completely meet real-world operational conditions. This paper introduces an `indirect shared control' scheme for steer-by-wire vehicles, which allows the vehicle control authority to be continuously shared between the driver and automation through unphysical cooperation. This paper first balances the control objectives of the driver and automation in a weighted summation, and then models the driver's adaptive control behavior using a predictive control approach. The driver adaptation modeling enables off-line evaluations of indirect shared control systems and thus facilitates the design of the assistant controller. Unlike any conventional driver model for manual driving, this model assumes that the driver can learn and incorporate the controller strategy into his internal model for more accurate path following. To satisfy the driving demands in different scenarios, a sliding-window detector is designed to continuously monitor the driver intention and automatically switch the authority weights between the driver and automation. The simulation results illustrate the advantages of considering the driver adaptation in path-following and obstacle-avoidance tasks, and show the effectiveness of indirect shared control for cooperative driving. version:1
arxiv-1704-00853 | A History of Metaheuristics | http://arxiv.org/abs/1704.00853 | id:1704.00853 author:Kenneth Sorensen, Marc Sevaux, Fred Glover category:cs.AI  published:2017-04-04 summary:This chapter describes the history of metaheuristics in five distinct periods, starting long before the first use of the term and ending a long time in the future. version:1
arxiv-1704-00845 | The Cloudlet Bazaar Dynamic Markets for the Small Cloud | http://arxiv.org/abs/1704.00845 | id:1704.00845 author:Ranjan Pal, Sung-Han Lin, Leana Golubchik category:cs.DC cs.GT  published:2017-04-04 summary:Due to increasing concerns about privacy and data control as one of the factors, many small clouds (SCs) established by different providers are emerging in an attempt to meet demand locally. The flip-side of this approach is the problem of resource inelasticity faced by the SCs due to their relatively scarce resources (e.g., virtual machines), thereby leading to potential degradation of customer QoS and loss of revenue. A proposed solution to this problem recommends the sharing of resources between SCs to alleviate the resource inelasticity issues that might arise. However, effective borrowing of resources by an SC from its peers involves mutually satisfying the interests of the stakeholders in question, i.e., the SC customers, the SCs, and a regulatory agency (e.g., the federal government) overseeing the functioning of the SCs. In this paper, we model the 'stakeholder satisfaction problem' in SCs as a socially efficient dynamic market/ecosystem design task, where the market elements comprise the stakeholders, and the term 'social efficiency' implying the market reaching a utilitarian maximum social welfare state when in equilibrium. Our market design approach is based on Arrow and Hurwicz's disequilibrium process and uses the gradient play technique in game theory to iteratively converge upon efficient and stable market equilibria. We illustrate the stability and sustainability of SC markets via both theory and experiments. version:1
arxiv-1703-01697 | Principles and Examples of Plausible Reasoning and Propositional Plausible Logic | http://arxiv.org/abs/1703.01697 | id:1703.01697 author:David Billington category:cs.AI cs.LO I.2.4  published:2017-03-06 summary:Plausible reasoning concerns situations whose inherent lack of precision is not quantified; that is, there are no degrees or levels of precision, and hence no use of numbers like probabilities. A hopefully comprehensive set of principles that clarifies what it means for a formal logic to do plausible reasoning is presented. A new propositional logic, called Propositional Plausible Logic (PPL), is defined and applied to some important examples. PPL is the only non-numeric non-monotonic logic we know of that satisfies all the principles and correctly reasons with all the examples. Some important results about PPL are proved. version:2
arxiv-1704-00830 | Locally Self-Adjusting Skip Graphs | http://arxiv.org/abs/1704.00830 | id:1704.00830 author:Sikder Huq, Sukumar Ghosh category:cs.DC cs.DS  published:2017-04-03 summary:We present a distributed self-adjusting algorithm for skip graphs that minimizes the average routing costs between arbitrary communication pairs by performing topological adaptation to the communication pattern. Our algorithm is fully decentralized, conforms to the $\mathcal{CONGEST}$ model (i.e. uses $O(\log n)$ bit messages), and requires $O(\log n)$ bits of memory for each node, where $n$ is the total number of nodes. Upon each communication request, our algorithm first establishes communication by using the standard skip graph routing, and then locally and partially reconstructs the skip graph topology to perform topological adaptation. We propose a computational model for such algorithms, as well as a yardstick (working set property) to evaluate them. Our working set property can also be used to evaluate self-adjusting algorithms for other graph classes where multiple tree-like subgraphs overlap (e.g. hypercube networks). We derive a lower bound of the amortized routing cost for any algorithm that follows our model and serves an unknown sequence of communication requests. We show that the routing cost of our algorithm is at most a constant factor more than the amortized routing cost of any algorithm conforming to our computational model. We also show that the expected transformation cost for our algorithm is at most a logarithmic factor more than the amortized routing cost of any algorithm conforming to our computational model. version:1
arxiv-1703-10261 | Planning and Resilient Execution of Policies For Manipulation in Contact with Actuation Uncertainty | http://arxiv.org/abs/1703.10261 | id:1703.10261 author:Calder Phillips-Grafflin, Dmitry Berenson category:cs.RO  published:2017-03-29 summary:We propose a method for planning motion for robots with actuation uncertainty that incorporates contact with the environment and the compliance of the robot to reliably perform manipulation tasks. Our approach consists of two stages: (1) Generating partial policies using a sampling-based motion planner that uses particle-based models of uncertainty and simulation of contact and compliance; and (2) Resilient execution that updates the planned policies to account for unexpected behavior in execution which may arise from model or environment inaccuracy. We have tested our planner and policy execution in simulated SE(2) and SE(3) environments and Baxter robot. We show that our methods efficiently generate policies to perform manipulation tasks involving significant contact and compare against several simpler methods. Additionally, we show that our policy adaptation is resilient to significant changes during execution; e.g. adding a new obstacle to the environment. version:2
arxiv-1704-05904 | Realizing an optimization approach inspired from Piagets theory on cognitive development | http://arxiv.org/abs/1704.05904 | id:1704.05904 author:Utku Kose, Ahmet Arslan category:cs.AI math.OC  published:2017-04-03 summary:The objective of this paper is to introduce an artificial intelligence based optimization approach, which is inspired from Piagets theory on cognitive development. The approach has been designed according to essential processes that an individual may experience while learning something new or improving his / her knowledge. These processes are associated with the Piagets ideas on an individuals cognitive development. The approach expressed in this paper is a simple algorithm employing swarm intelligence oriented tasks in order to overcome single-objective optimization problems. For evaluating effectiveness of this early version of the algorithm, test operations have been done via some benchmark functions. The obtained results show that the approach / algorithm can be an alternative to the literature in terms of single-objective optimization. The authors have suggested the name: Cognitive Development Optimization Algorithm (CoDOA) for the related intelligent optimization approach. version:1
arxiv-1704-00797 | On the idea of a new artificial intelligence based optimization algorithm inspired from the nature of vortex | http://arxiv.org/abs/1704.00797 | id:1704.00797 author:Utku Kose, Ahmet Arslan category:cs.AI math.OC  published:2017-04-03 summary:In this paper, the idea of a new artificial intelligence based optimization algorithm, which is inspired from the nature of vortex, has been provided briefly. As also a bio-inspired computation algorithm, the idea is generally focused on a typical vortex flow / behavior in nature and inspires from some dynamics that are occurred in the sense of vortex nature. Briefly, the algorithm is also a swarm-oriented evolutional problem solution approach; because it includes many methods related to elimination of weak swarm members and trying to improve the solution process by supporting the solution space via new swarm members. In order have better idea about success of the algorithm; it has been tested via some benchmark functions. At this point, the obtained results show that the algorithm can be an alternative to the literature in terms of single-objective optimization solution ways. Vortex Optimization Algorithm (VOA) is the name suggestion by the authors; for this new idea of intelligent optimization approach. version:1
arxiv-1704-00795 | Design and development of a software system for swarm intelligence based research studies | http://arxiv.org/abs/1704.00795 | id:1704.00795 author:Utku Kose category:cs.AI cs.SE  published:2017-04-03 summary:This paper introduce a software system including widely-used Swarm Intelligence algorithms or approaches to be used for the related scientific research studies associated with the subject area. The programmatic infrastructure of the system allows working on a fast, easy-to-use, interactive platform to perform Swarm Intelligence based studies in a more effective, efficient and accurate way. In this sense, the system employs all of the necessary controls for the algorithms and it ensures an interactive platform on which computer users can perform studies on a wide spectrum of solution approaches associated with simple and also more advanced problems. version:1
arxiv-1411-0406 | GC-SROIQ(C) : Expressive Constraint Modelling and Grounded Circumscription for SROIQ | http://arxiv.org/abs/1411.0406 | id:1411.0406 author:Arjun Bhardwaj, Sangeetha category:cs.AI  published:2014-11-03 summary:Developments in semantic web technologies have promoted ontological encoding of knowledge from diverse domains. However, modelling many practical domains requires more expressive representations schemes than what the standard description logics(DLs) support. We extend the DL SROIQ with constraint networks and grounded circumscription. Applications of constraint modelling include embedding ontologies with temporal or spatial information, while grounded circumscription allows defeasible inference and closed world reasoning. This paper overcomes restrictions on existing constraint modelling approaches by introducing expressive constructs. Grounded circumscription allows concept and role minimization and is decidable for DL. We provide a general and intuitive algorithm for the framework of grounded circumscription that can be applied to a whole range of logics. We present the resulting logic: GC-SROIQ(C), and describe a tableau decision procedure for it. version:4
arxiv-1704-02914 | Kinematic analysis of geared robotic mechanism using matroid and T-T graph methods | http://arxiv.org/abs/1704.02914 | id:1704.02914 author:Amirinezhad S. Vahid, Uyguroğlu Mustafa category:cs.RO  published:2017-04-03 summary:In this paper, the kinematic structure of the geared robotic mechanism (GRM) is investigated with the aid of two different methods which are based on directed graphs and the methods are compared. One of the methods is Matroid Method developed by Talpasanu and the other method is Tsai-Tokad (T-T) Graph method developed by Uyguroglu and Demirel. It is shown that the kinematic structure of the geared robotic mechanism can be represented by directed graphs and angular velocity equations of the mechanisms can be systematically obtained from the graphs. The advantages and disadvantages of both methods are demonstrated relative to each other. version:1
arxiv-1703-10959 | Parallelism, Concurreny and Distribution in Constraint Handling Rules: A Survey (Draft) | http://arxiv.org/abs/1703.10959 | id:1703.10959 author:Thom Fruehwirth category:cs.DC cs.PL  published:2017-03-31 summary:Constraint Handling Rules is an effective concurrent declarative programming language and a versatile computational logic formalism. CHR programs consist of guarded reactive rules that transform multisets of constraints. One of the main features of CHR is its inherent concurrency. Intuitively, rules can be applied to parts of a multiset in parallel. In this comprehensive survey, we give an overview of concurrent and parallel as well as distributed CHR semantics, standard and more exotic, that have been proposed over the years at various levels of refinement. These semantics range from the abstract to the concrete. They are related by formal soundness results. Their correctness is established as correspondence between parallel and sequential computations. We present common concise sample CHR programs that have been widely used in experiments and benchmarks. We review parallel CHR implementations in software and hardware. The experimental results obtained show a consistent parallel speedup. Most implementations are available online. The CHR formalism can also be used to implement and reason with models for concurrency. To this end, the Software Transaction Model, the Actor Model, Colored Petri Nets and the Join-Calculus have been faithfully encoded in CHR. version:2
arxiv-1704-00534 | Controlling a triangular flexible formation of autonomous agents | http://arxiv.org/abs/1704.00534 | id:1704.00534 author:Hector Garcia de Marina, Zhiyong Sun, Ming Cao, Brian D. O. Anderson category:cs.SY cs.RO  published:2017-04-03 summary:In formation control, triangular formations consisting of three autonomous agents serve as a class of benchmarks that can be used to test and compare the performances of different controllers. We present an algorithm that combines the advantages of both position- and distance-based gradient descent control laws. For example, only two pairs of neighboring agents need to be controlled, agents can work in their own local frame of coordinates and the orientation of the formation with respect to a global frame of coordinates is not prescribed. We first present a novel technique based on adding artificial biases to neighboring agents' range sensors such that their eventual positions correspond to a collinear configuration. Right after, a small modification in the bias terms by introducing a prescribed rotation matrix will allow the control of the bearing of the neighboring agents. version:1
arxiv-1704-00513 | Optimizing Communication by Compression for Multi-GPU Scalable Breadth-First Searches | http://arxiv.org/abs/1704.00513 | id:1704.00513 author:Julian Romera category:cs.DC cs.DS cs.PF 68P30  05C50 H.3.4; I.2.8  published:2017-04-03 summary:The Breadth First Search (BFS) algorithm is the foundation and building block of many higher graph-based operations such as spanning trees, shortest paths and betweenness centrality. The importance of this algorithm increases each day due to it is a key requirement for many data structures which are becoming popular nowadays. When the BFS algorithm is parallelized by distributing the graph between several processors the interconnection network limits the performance. Hence, improvements on this area may benefit the overall performance of the algorithm. This work presents an alternative compression scheme for communications in distributed BFS processing. It focuses on BFS processors using General-Purpose Graphics Processing Units. version:1
arxiv-1606-08130 | Propagators and Solvers for the Algebra of Modular Systems | http://arxiv.org/abs/1606.08130 | id:1606.08130 author:Bart Bogaerts, Eugenia Ternovska, David Mitchell category:cs.AI cs.LO  published:2016-06-27 summary:To appear in the proceedings of LPAR 21. Solving complex problems can involve non-trivial combinations of distinct knowledge bases and problem solvers. The Algebra of Modular Systems is a knowledge representation framework that provides a method for formally specifying such systems in purely semantic terms. Formally, an expression of the algebra defines a class of structures. Many expressive formalism used in practice solve the model expansion task, where a structure is given on the input and an expansion of this structure in the defined class of structures is searched (this practice overcomes the common undecidability problem for expressive logics). In this paper, we construct a solver for the model expansion task for a complex modular systems from an expression in the algebra and black-box propagators or solvers for the primitive modules. To this end, we define a general notion of propagators equipped with an explanation mechanism, an extension of the alge- bra to propagators, and a lazy conflict-driven learning algorithm. The result is a framework for seamlessly combining solving technology from different domains to produce a solver for a combined system. version:2
arxiv-1602-08610 | Scalable Bayesian Rule Lists | http://arxiv.org/abs/1602.08610 | id:1602.08610 author:Hongyu Yang, Cynthia Rudin, Margo Seltzer category:cs.AI  published:2016-02-27 summary:We present an algorithm for building probabilistic rule lists that is two orders of magnitude faster than previous work. Rule list algorithms are competitors for decision tree algorithms. They are associative classifiers, in that they are built from pre-mined association rules. They have a logical structure that is a sequence of IF-THEN rules, identical to a decision list or one-sided decision tree. Instead of using greedy splitting and pruning like decision tree algorithms, we fully optimize over rule lists, striking a practical balance between accuracy, interpretability, and computational speed. The algorithm presented here uses a mixture of theoretical bounds (tight enough to have practical implications as a screening or bounding procedure), computational reuse, and highly tuned language libraries to achieve computational efficiency. Currently, for many practical problems, this method achieves better accuracy and sparsity than decision trees; further, in many cases, the computational time is practical and often less than that of decision trees. The result is a probabilistic classifier (which estimates P(y = 1 x) for each x) that optimizes the posterior of a Bayesian hierarchical model over rule lists. version:2
arxiv-1704-00411 | A Survey of Distributed Message Broker Queues | http://arxiv.org/abs/1704.00411 | id:1704.00411 author:Vineet John, Xia Liu category:cs.DC 68M14 C.1.4  published:2017-04-03 summary:This paper surveys the message brokers that are in vogue today for distributed communication. Their primary goal is to facilitate the construction of decentralized topologies without single points of failure, enabling fault tolerance and high availability. These characteristics make them optimal for usage within distributed architectures. However, there are multiple protocols built to achieve this, and it would be beneficial to have a empirical comparison between their features and performance to determine their real-world applicability. This paper focuses on two popular protocols (Kafka and AMQP) and explores the divergence in their features as well as their performance under varied testing workloads. version:1
arxiv-1703-10970 | Diversity of preferences can increase collective welfare in sequential exploration problems | http://arxiv.org/abs/1703.10970 | id:1703.10970 author:Pantelis P. Analytis, Hrvoje Stojic, Alexandros Gelastopoulos, Mehdi Moussaïd category:cs.AI cs.MA  published:2017-03-28 summary:In search engines, online marketplaces and other human-computer interfaces large collectives of individuals sequentially interact with numerous alternatives of varying quality. In these contexts, trial and error (exploration) is crucial for uncovering novel high-quality items or solutions, but entails a high cost for individual users. Self-interested decision makers, are often better off imitating the choices of individuals who have already incurred the costs of exploration. Although imitation makes sense at the individual level, it deprives the group of additional information that could have been gleaned by individual explorers. In this paper we show that in such problems, preference diversity can function as a welfare enhancing mechanism. It leads to a consistent increase in the quality of the consumed alternatives that outweighs the increased cost of search for the users. version:2
arxiv-1704-00325 | Structured Parallel Programming for Monte Carlo Tree Search | http://arxiv.org/abs/1704.00325 | id:1704.00325 author:S. Ali Mirsoleimani, Aske Plaat, Jaap van den Herik, Jos Vermaseren category:cs.AI  published:2017-04-02 summary:In this paper, we present a new algorithm for parallel Monte Carlo tree search (MCTS). It is based on the pipeline pattern and allows flexible management of the control flow of the operations in parallel MCTS. The pipeline pattern provides for the first structured parallel programming approach to MCTS. Moreover, we propose a new lock-free tree data structure for parallel MCTS which removes synchronization overhead. The Pipeline Pattern for Parallel MCTS algorithm (called 3PMCTS), scales very well to higher numbers of cores when compared to the existing methods. version:1
arxiv-1704-00264 | Potential Functions based Sampling Heuristic For Optimal Path Planning | http://arxiv.org/abs/1704.00264 | id:1704.00264 author:Ahmed Hussain Qureshi, Yasar Ayaz category:cs.RO cs.AI  published:2017-04-02 summary:Rapidly-exploring Random Tree Star(RRT*) is a recently proposed extension of Rapidly-exploring Random Tree (RRT) algorithm that provides a collision-free, asymptotically optimal path regardless of obstacle's geometry in a given environment. However, one of the limitations in the RRT* algorithm is slow convergence to optimal path solution. As a result, it consumes high memory as well as time due to a large number of iterations utilised in achieving optimal path solution. To overcome these limitations, we propose the Potential Function Based-RRT* (P-RRT*) that incorporates the Artificial Potential Field Algorithm in RRT*. The proposed algorithm allows a considerable decrease in the number of iterations and thus leads to more efficient memory utilization and an accelerated convergence rate. In order to illustrate the usefulness of the proposed algorithm in terms of space execution and convergence rate, this paper presents rigorous simulation based comparisons between the proposed techniques and RRT* under different environmental conditions. Moreover, both algorithms are also tested and compared under non-holonomic differential constraints. version:1
arxiv-1704-01014 | An Ontological Architecture for Orbital Debris Data | http://arxiv.org/abs/1704.01014 | id:1704.01014 author:Robert J. Rovetto category:cs.AI cs.DB  published:2017-04-01 summary:The orbital debris problem presents an opportunity for inter-agency and international cooperation toward the mutually beneficial goals of debris prevention, mitigation, remediation, and improved space situational awareness (SSA). Achieving these goals requires sharing orbital debris and other SSA data. Toward this, I present an ontological architecture for the orbital debris domain, taking steps in the creation of an orbital debris ontology (ODO). The purpose of this ontological system is to (I) represent general orbital debris and SSA domain knowledge, (II) structure, and standardize where needed, orbital data and terminology, and (III) foster semantic interoperability and data-sharing. In doing so I hope to (IV) contribute to solving the orbital debris problem, improving peaceful global SSA, and ensuring safe space travel for future generations. version:1
arxiv-1705-08508 | Vehicle Traffic Driven Camera Placement for Better Metropolis Security Surveillance | http://arxiv.org/abs/1705.08508 | id:1705.08508 author:Xiaobo Ma, Yihui He, Xiapu Luo, Jianfeng Li, Mengchen Zhao, Bo An, Xiaohong Guan category:cs.CY cs.AI cs.GT  published:2017-04-01 summary:Security surveillance is one of the most important issues in smart cities, especially in an era of terrorism. Deploying a number of (video) cameras is a common surveillance approach. Given the never-ending power offered by vehicles to metropolises, exploiting vehicle traffic to design camera placement strategies could potentially facilitate security surveillance. This article constitutes the first effort toward building the linkage between vehicle traffic and security surveillance, which is a critical problem for smart cities. We expect our study could influence the decision making of surveillance camera placement, and foster more research of principled ways of security surveillance beneficial to our physical-world life. version:1
arxiv-1704-00115 | Ontological Multidimensional Data Models and Contextual Data Qality | http://arxiv.org/abs/1704.00115 | id:1704.00115 author:Leopoldo Bertossi, Mostafa Milani category:cs.DB cs.AI  published:2017-04-01 summary:Data quality assessment and data cleaning are context-dependent activities. Motivated by this observation, we propose the Ontological Multidimensional Data Model (OMD model), which can be used to model and represent contexts as logic-based ontologies. The data under assessment is mapped into the context, for additional analysis, processing, and quality data extraction. The resulting contexts allow for the representation of dimensions, and multidimensional data quality assessment becomes possible. At the core of a multidimensional context we include a generalized multidimensional data model and a Datalog+/- ontology with provably good properties in terms of query answering. These main components are used to represent dimension hierarchies, dimensional constraints, dimensional rules, and define predicates for quality data specification. Query answering relies upon and triggers navigation through dimension hierarchies, and becomes the basic tool for the extraction of quality data. The OMD model is interesting per se, beyond applications to data quality. It allows for a logic-based, and computationally tractable representation of multidimensional data, extending previous multidimensional data models with additional expressive power and functionalities. version:1
arxiv-1703-10193 | An End-to-End System for Crowdsourced 3d Maps for Autonomous Vehicles: The Mapping Component | http://arxiv.org/abs/1703.10193 | id:1703.10193 author:Onkar Dabeer, Radhika Gowaikar, Slawomir K. Grzechnik, Mythreya J. Lakshman, Gerhard Reitmayr, Kiran Somasundaram, Ravi Teja Sukhavasi, Xinzhou Wu category:cs.RO  published:2017-03-29 summary:Autonomous vehicles rely on precise high definition (HD) 3d maps for navigation. This paper presents the mapping component of an end-to-end system for crowdsourcing precise 3d maps with semantically meaningful landmarks such as traffic signs (6 dof pose, shape and size) and traffic lanes (3d splines). The system uses consumer grade parts, and in particular, relies on a single front facing camera and a consumer grade GPS. Using real-time sign and lane triangulation on-device in the vehicle, with offline sign/lane clustering across multiple journeys and offline Bundle Adjustment across multiple journeys in the backend, we construct maps with mean absolute accuracy at sign corners of less than 20 cm from 25 journeys. To the best of our knowledge, this is the first end-to-end HD mapping pipeline in global coordinates in the automotive context using cost effective sensors. version:2
arxiv-1606-03737 | Detecção de comunidades em redes complexas para identificar gargalos e desperdício de recursos em sistemas de ônibus | http://arxiv.org/abs/1606.03737 | id:1606.03737 author:Carlos Caminha, Vasco Furtado, Vládia Pinheiro, Caio Ponte category:cs.AI cs.SI  published:2016-06-12 summary:We propose here a methodology to help to understand the shortcomings of public transportation in a city via the mining of complex networks representing the supply and demand of public transport. We show how to build these networks based upon data on smart card use in buses via the application of algorithms that estimate an OD and reconstruct the complete itinerary of the passengers. The overlapping of the two networks sheds light in potential overload and waste in the offer of resources that can be mitigated with strategies for balancing supply and demand. version:2
arxiv-1703-07417 | Approximating k-spanners in the LOCAL model | http://arxiv.org/abs/1703.07417 | id:1703.07417 author:Michael Dinitz, Yasamin Nazari category:cs.DS cs.DC math.CO  published:2017-03-21 summary:Graph spanners have been studied extensively, and have many applications in algorithms, distributed systems, and computer networks. For many of these application, we want distributed constructions of spanners, i.e., algorithms which use only local information. Dinitz and Krauthgamer (PODC 2011) provided a distributed approximation algorithm for 2-spanners in the LOCAL model with polylogarithmic running time, but the question of whether a similar algorithm exists for k-spanners with k > 2 remained open. In this paper, we show that a similar algorithm also works for cases where k > 2. version:2
arxiv-1703-10979 | Architecture of processing and analysis system for big astronomical data | http://arxiv.org/abs/1703.10979 | id:1703.10979 author:Ivan Kolosov, Sergey Gerasimov, Alexander Meshcheryakov category:astro-ph.IM cs.DC  published:2017-03-31 summary:This work explores the use of big data technologies deployed in the cloud for processing of astronomical data. We have applied Hadoop and Spark to the task of co-adding astronomical images. We compared the overhead and execution time of these frameworks. We conclude that performance of both frameworks is generally on par. The Spark API is more flexible, which allows one to easily construct astronomical data processing pipelines. version:1
arxiv-1703-10926 | EMULATOR vs REAL PHONE: Android Malware Detection Using Machine Learning | http://arxiv.org/abs/1703.10926 | id:1703.10926 author:Mohammed K. Alzaylaee, Suleiman Y. Yerima, Sakir Sezer category:cs.CR cs.AI  published:2017-03-31 summary:The Android operating system has become the most popular operating system for smartphones and tablets leading to a rapid rise in malware. Sophisticated Android malware employ detection avoidance techniques in order to hide their malicious activities from analysis tools. These include a wide range of anti-emulator techniques, where the malware programs attempt to hide their malicious activities by detecting the emulator. For this reason, countermeasures against antiemulation are becoming increasingly important in Android malware detection. Analysis and detection based on real devices can alleviate the problems of anti-emulation as well as improve the effectiveness of dynamic analysis. Hence, in this paper we present an investigation of machine learning based malware detection using dynamic analysis on real devices. A tool is implemented to automatically extract dynamic features from Android phones and through several experiments, a comparative analysis of emulator based vs. device based detection by means of several machine learning algorithms is undertaken. Our study shows that several features could be extracted more effectively from the on-device dynamic analysis compared to emulators. It was also found that approximately 24% more apps were successfully analysed on the phone. Furthermore, all of the studied machine learning based detection performed better when applied to features extracted from the on-device dynamic analysis. version:1
arxiv-1703-10731 | An analysis of budgeted parallel search on conditional Galton-Watson trees | http://arxiv.org/abs/1703.10731 | id:1703.10731 author:David Avis, Luc Devroye category:cs.DS cs.DC  published:2017-03-31 summary:Recently Avis and Jordan have demonstrated the efficiency of a simple technique called budgeting for the parallelization of a number of tree search algorithms. The idea is to limit the amount of work that a processor performs before it terminates its search and returns any unexplored nodes to a master process. This limit is set by a critical budget parameter which determines the overhead of the process. In this paper we study the behaviour of the budget parameter on conditional Galton-Watson trees obtaining asymptotically tight bounds on this overhead. We present empirical results to show that this bound is surprisingly accurate in practice. version:1
arxiv-1703-10725 | UNBIAS PUF: A Physical Implementation Bias Agnostic Strong PUF | http://arxiv.org/abs/1703.10725 | id:1703.10725 author:Wei-Che Wang, Zhuoqi Li, Joseph Skudlarek, Mario Larouche, Michael Chen, Puneet Gupta category:cs.AR  published:2017-03-31 summary:The Physical Unclonable Function (PUF) is a promising hardware security primitive because of its inherent uniqueness and low cost. To extract the device-specific variation from delay-based strong PUFs, complex routing constraints are imposed to achieve symmetric path delays; and systematic variations can severely compromise the uniqueness of the PUF. In addition, the metastability of the arbiter circuit of an Arbiter PUF can also degrade the quality of the PUF due to the induced instability. In this paper we propose a novel strong UNBIAS PUF that can be implemented purely by Register Transfer Language (RTL), such as verilog, without imposing any physical design constraints or delay characterization effort to solve the aforementioned issues. Efficient inspection bit prediction models for unbiased response extraction are proposed and validated. Our experimental results of the strong UNBIAS PUF show 5.9% intra-Fractional Hamming Distance (FHD) and 45.1% inter-FHD on 7 Field Programmable Gate Array (FPGA) boards without applying any physical layout constraints or additional XOR gates. The UNBIAS PUF is also scalable because no characterization cost is required for each challenge to compensate the implementation bias. The averaged intra-FHD measured at worst temperature and voltage variation conditions is 12%, which is still below the margin of practical Error Correction Code (ECC) with error reduction techniques for PUFs. version:1
arxiv-1703-10628 | Study on Resource Efficiency of Distributed Graph Processing | http://arxiv.org/abs/1703.10628 | id:1703.10628 author:Miguel E. Coimbra, Alexandre P. Francisco, Luis Veiga category:cs.DC cs.DS  published:2017-03-30 summary:Graphs may be used to represent many different problem domains -- a concrete example is that of detecting communities in social networks, which are represented as graphs. With big data and more sophisticated applications becoming widespread in recent years, graph processing has seen an emergence of requirements pertaining data volume and volatility. This multidisciplinary study presents a review of relevant distributed graph processing systems. Herein they are presented in groups defined by common traits (distributed processing paradigm, type of graph operations, among others), with an overview of each system's strengths and weaknesses. The set of systems is then narrowed down to a set of two, upon which quantitative analysis was performed. For this quantitative comparison of systems, focus was cast on evaluating the performance of algorithms for the problem of detecting communities. To help further understand the evaluations performed, a background is provided on graph clustering. version:1
arxiv-1703-10579 | Evaluating Complex Task through Crowdsourcing: Multiple Views Approach | http://arxiv.org/abs/1703.10579 | id:1703.10579 author:Lingyu Lyu, Mehmed Kantardzic category:cs.AI cs.HC  published:2017-03-30 summary:With the popularity of massive open online courses, grading through crowdsourcing has become a prevalent approach towards large scale classes. However, for getting grades for complex tasks, which require specific skills and efforts for grading, crowdsourcing encounters a restriction of insufficient knowledge of the workers from the crowd. Due to knowledge limitation of the crowd graders, grading based on partial perspectives becomes a big challenge for evaluating complex tasks through crowdsourcing. Especially for those tasks which not only need specific knowledge for grading, but also should be graded as a whole instead of being decomposed into smaller and simpler subtasks. We propose a framework for grading complex tasks via multiple views, which are different grading perspectives defined by experts for the task, to provide uniformity. Aggregation algorithm based on graders variances are used to combine the grades for each view. We also detect bias patterns of the graders, and debias them regarding each view of the task. Bias pattern determines how the behavior is biased among graders, which is detected by a statistical technique. The proposed approach is analyzed on a synthetic data set. We show that our model gives more accurate results compared to the grading approaches without different views and debiasing algorithm. version:1
arxiv-1703-08557 | Towards a Functional System Architecture for Automated Vehicles | http://arxiv.org/abs/1703.08557 | id:1703.08557 author:Simon Ulbrich, Andreas Reschka, Jens Rieken, Susanne Ernst, Gerrit Bagschik, Frank Dierkes, Marcus Nolte, Markus Maurer category:cs.SY cs.RO  published:2017-03-24 summary:This paper presents a functional system architecture for an automated vehicle. It provides an overall, generic structure that is independent of a specific implementation of a particular vehicle project. Yet, it has been inspired and cross-checked with a real world automated driving implementation in the Stadtpilot project at the Technische Universit\"at Braunschweig. The architecture entails aspects like environment and self perception, planning and control, localization, map provision, Vehicle-To-X-communication, and interaction with human operators. version:2
arxiv-1703-10446 | Gelly-Scheduling: Distributed Graph Processing for Network Service Placement | http://arxiv.org/abs/1703.10446 | id:1703.10446 author:Miguel E. Coimbra, Alexandre P. Francisco, Luis Veiga category:cs.DC cs.DS  published:2017-03-30 summary:Community network micro-clouds (CNMCs) have seen an increase in the last fifteen years. Their members contact nodes which operate Internet proxies, web servers, user file storage and video streaming services, to name a few. Detecting communities of nodes with properties (such as co-location) and assessing node eligibility for service placement is thus a key-factor in optimizing the experience of users. We present an approach for community finding using a label propagation graph algorithm to address the multi-objective challenge of optimizing service placement in CNMCs. Herein we: i) highlight the applicability of leader election heuristics which are important for service placement in community networks and scheduler-dependent scenarios; ii) present a novel decentralized solution designed as a scalable alternative for the problem of service placement, which has mostly seen computational approaches based on centralization. version:1
arxiv-1703-10435 | On the Implementation of a Scalable Simulator for Multiscale Hybrid-Mixed Methods | http://arxiv.org/abs/1703.10435 | id:1703.10435 author:Antonio Tadeu A. Gomes, Weslley S. Pereira, Frederic Valentin, Diego Paredes category:cs.DC math.NA 65N30 D.1.3; F.2.1  published:2017-03-30 summary:The family of Multiscale Hybrid-Mixed (MHM) finite element methods has received considerable attention from the mathematics and engineering community in the last few years. The MHM methods allow solving highly heterogeneous problems on coarse meshes while providing solutions with high-order precision. It embeds independent local problems which are responsible for upscaling unresolved scales into the numerical solution. These local contributions are brought together through a global problem defined on the skeleton of the coarse partition. Since the local problems are completely independent, they can be easily computed in parallel. In this paper, we present two simulator prototypes specifically crafted for the MHM methods, which adopt two different implementation strategies: (i) a multi-programming language approach, each language tackling different simulation issues; and (ii) a classical, single-programming language approach. Specifically, we use C++ for numerical computation of the global and local problems in a modular way; for process distribution in the simulator, we adopt the Erlang concurrent language in the first approach, and the MPI standard in the second approach. The aim of exploring these different approaches is twofold: (i) allow for the deployment of the simulator both in high-performance computing (with MPI) and in cloud computing environments (with Erlang); and (ii) pave the way for further exploration of quality attributes related to software productivity and fault-tolerance, which are key to Exascale systems. We present a performance evaluation of the two simulator prototypes taking into account their efficiency. version:1
arxiv-1702-08736 | Analysing Congestion Problems in Multi-agent Reinforcement Learning | http://arxiv.org/abs/1702.08736 | id:1702.08736 author:Roxana Rădulescu, Peter Vrancx, Ann Nowé category:cs.MA cs.AI 68T05 I.2.11  published:2017-02-28 summary:Congestion problems are omnipresent in today's complex networks and represent a challenge in many research domains. In the context of Multi-agent Reinforcement Learning (MARL), approaches like difference rewards and resource abstraction have shown promising results in tackling such problems. Resource abstraction was shown to be an ideal candidate for solving large-scale resource allocation problems in a fully decentralized manner. However, its performance and applicability strongly depends on some, until now, undocumented assumptions. Two of the main congestion benchmark problems considered in the literature are: the Beach Problem Domain and the Traffic Lane Domain. In both settings the highest system utility is achieved when overcrowding one resource and keeping the rest at optimum capacity. We analyse how abstract grouping can promote this behaviour and how feasible it is to apply this approach in a real-world domain (i.e., what assumptions need to be satisfied and what knowledge is necessary). We introduce a new test problem, the Road Network Domain (RND), where the resources are no longer independent, but rather part of a network (e.g., road network), thus choosing one path will also impact the load on other paths having common road segments. We demonstrate the application of state-of-the-art MARL methods for this new congestion model and analyse their performance. RND allows us to highlight an important limitation of resource abstraction and show that the difference rewards approach manages to better capture and inform the agents about the dynamics of the environment. version:2
arxiv-1703-10429 | An Empirical Approach for Modeling Fuzzy Geographical Descriptors | http://arxiv.org/abs/1703.10429 | id:1703.10429 author:Alejandro Ramos-Soto, Jose M. Alonso, Ehud Reiter, Kees van Deemter, Albert Gatt category:cs.AI  published:2017-03-30 summary:We present a novel heuristic approach that defines fuzzy geographical descriptors using data gathered from a survey with human subjects. The participants were asked to provide graphical interpretations of the descriptors `north' and `south' for the Galician region (Spain). Based on these interpretations, our approach builds fuzzy descriptors that are able to compute membership degrees for geographical locations. We evaluated our approach in terms of efficiency and precision. The fuzzy descriptors are meant to be used as the cornerstones of a geographical referring expression generation algorithm that is able to linguistically characterize geographical locations and regions. This work is also part of a general research effort that intends to establish a methodology which reunites the empirical studies traditionally practiced in data-to-text and the use of fuzzy sets to model imprecision and vagueness in words and expressions for text generation purposes. version:1
arxiv-1703-10337 | Online Adaptation for Humanoids Walking On Uncertain Surfaces | http://arxiv.org/abs/1703.10337 | id:1703.10337 author:Majid Khadiv, S. Ali. A. Moosavian, Aghil Yousefi-Koma, Hessam Maleki, Majid Sadedel category:cs.RO  published:2017-03-30 summary:In this paper, an online adaptation algorithm for bipedal walking on uneven surfaces with height uncertainty is proposed. In order to generate walking patterns on flat terrains, the trajectories in the task space are planned to satisfy the dynamic balance and slippage avoidance constraints, and also to guarantee smooth landing of the swing foot. To ensure smooth landing of the swing foot on surfaces with height uncertainty, the preplanned trajectories in the task space should be adapted. The proposed adaptation algorithm consists of two stages. In the first stage, once the swing foot reaches its maximum height, the supervisory control is initiated until the touch is detected. After the detection, the trajectories in the task space are modified to guarantee smooth landing. In the second stage, this modification is preserved during the Double Support Phase (DSP), and released in the next Single Support Phase (SSP). Effectiveness of the proposed online adaptation algorithm is experimentally verified through realization of the walking patterns on the SURENA III humanoid robot, designed and fabricated at CAST. The walking is tested on a surface with various flat obstacles, where the swing foot is prone to either land on the ground soon or late. version:1
arxiv-1703-10318 | SC-Share: Performance Driven Resource Sharing Markets for the Small Cloud | http://arxiv.org/abs/1703.10318 | id:1703.10318 author:Sung-Han Lin, Ranjan Pal, Marco Paolieri, Leana Golubchik category:cs.DC  published:2017-03-30 summary:Small-scale clouds (SCs) often suffer from resource under-provisioning during peak demand, leading to inability to satisfy service level agreements (SLAs) and consequent loss of customers. One approach to address this problem is for a set of autonomous SCs to share resources among themselves in a cost-induced cooperative fashion, thereby increasing their individual capacities (when needed) without having to significantly invest in more resources. A central problem (in this context) is how to properly share resources (for a price) to achieve profitable service while maintaining customer SLAs. To address this problem, in this paper, we propose the SC-Share framework that utilizes two interacting models: (i) a stochastic performance model that estimates the achieved performance characteristics under given SLA requirements, and (ii) a market-based game-theoretic model that (as shown empirically) converges to efficient resource sharing decisions at market equilibrium. Our results include extensive evaluations that illustrate the utility of the proposed framework. version:1
arxiv-1703-10316 | Efficient Parallel Translating Embedding For Knowledge Graphs | http://arxiv.org/abs/1703.10316 | id:1703.10316 author:Denghui Zhang, Manling Li, Yantao Jia, Yuanzhuo Wang category:cs.AI I.2.4  published:2017-03-30 summary:Knowledge graph embedding aims to embed entities and relations of knowledge graphs into low-dimensional vector spaces. Translating embedding methods regard relations as the translation from head entities to tail entities, which achieve the state-of-the-art results among knowledge graph embedding methods. However, a major limitation of these methods is the time consuming training process, which may take several days or even weeks for large knowledge graphs, and result in great difficulty in practical applications. In this paper, we propose an efficient parallel framework for translating embedding methods, called ParTrans-X, which enables the methods to be paralleled without locks by utilizing the distinguished structures of knowledge graphs. Experiments on two datasets with three typical translating embedding methods, i.e., TransE [3], TransH [17], and a more efficient variant TransE- AdaGrad [10] validate that ParTrans-X can speed up the training process by more than an order of magnitude. version:1
arxiv-1703-10272 | Fast and Flexible Data Analytics with F2 | http://arxiv.org/abs/1703.10272 | id:1703.10272 author:Robert Grandl, Arjun Singhvi, Aditya Akella category:cs.DC  published:2017-03-29 summary:Existing data analytics frameworks are intrinsically compute-centric in nature. Their computation structure is complex and determined early, and they take decisions that bind early to this structure. This impacts expressiveness, job performance, and cluster efficiency. We present F2, a new analytics framework that separates computation from data management, making the latter an equal first-class entity. We argue that this separation enables more flexibility in expressing analytics jobs and enables data driven optimizations. Furthermore, it enables a new kind of "tasks" with loose semantics that can multiplex their execution across different sets of data and multiple jobs. version:1
arxiv-1703-10254 | Bandit-Based Model Selection for Deformable Object Manipulation | http://arxiv.org/abs/1703.10254 | id:1703.10254 author:Dale McConachie, Dmitry Berenson category:cs.RO cs.AI  published:2017-03-29 summary:We present a novel approach to deformable object manipulation that does not rely on highly-accurate modeling. The key contribution of this paper is to formulate the task as a Multi-Armed Bandit problem, with each arm representing a model of the deformable object. To "pull" an arm and evaluate its utility, we use the arm's model to generate a velocity command for the gripper(s) holding the object and execute it. As the task proceeds and the object deforms, the utility of each model can change. Our framework estimates these changes and balances exploration of the model set with exploitation of high-utility models. We also propose an approach based on Kalman Filtering for Non-stationary Multi-armed Normal Bandits (KF-MANB) to leverage the coupling between models to learn more from each arm pull. We demonstrate that our method outperforms previous methods on synthetic trials, and performs competitively on several manipulation tasks in simulation. version:1
arxiv-1703-10251 | Dialectical Rough Sets, Parthood and Figures of Opposition | http://arxiv.org/abs/1703.10251 | id:1703.10251 author:A. Mani category:math.LO cs.AI cs.IT cs.LO math.IT  published:2017-03-29 summary:In one perspective, the central problem pursued in this research is that of the inverse problem in the context of general rough sets. The problem is about the existence of rough basis for given approximations in a context. Granular operator spaces were recently introduced by the present author as an optimal framework for anti-chain based algebraic semantics of general rough sets and the inverse problem. In the framework, various subtypes of crisp and non crisp objects are identifiable that may be missed in more restrictive formalism. This is also because in the latter cases the concept of complementation and negation are taken for granted. This opens the door for a general approach to dialectical rough sets building on previous work of the present author and figures of opposition. In this paper dialectical rough logics are developed from a semantic perspective, concept of dialectical predicates is formalized, connection with dialethias and glutty negation established, parthood analyzed and studied from the point of view of classical and dialectical figures of opposition. Potential semantics through dialectical counting based on these figures are proposed building on earlier work by the present author. Her methods become more geometrical and encompass parthood as a primary relation (as opposed to roughly equivalent objects) for algebraic semantics. Dialectical counting strategies over anti chains (a specific form of dialectical structure) for semantics are also proposed. version:1
arxiv-1703-10242 | I CAN HAS SUPERCOMPUTER? A Novel Approach to Teaching Parallel and Distributed Computing Concepts Using a Meme-Based Programming Language | http://arxiv.org/abs/1703.10242 | id:1703.10242 author:David Richie, James Ross category:cs.DC cs.PL  published:2017-03-29 summary:A novel approach is presented to teach the parallel and distributed computing concepts of synchronization and remote memory access. The single program multiple data (SPMD) partitioned global address space (PGAS) model presented in this paper uses a procedural programming language appealing to undergraduate students. We propose that the amusing nature of the approach may engender creativity and interest using these concepts later in more sober environments. Specifically, we implement parallel extensions to LOLCODE within a source-to-source compiler sufficient for the development of parallel and distributed algorithms normally implemented using conventional high-performance computing languages and APIs. version:1
arxiv-1703-08561 | AutonoVi: Autonomous Vehicle Planning with Dynamic Maneuvers and Traffic Constraints | http://arxiv.org/abs/1703.08561 | id:1703.08561 author:Andrew Best, Sahil Narang, Daniel Barber, Dinesh Manocha category:cs.RO cs.MA  published:2017-03-24 summary:We present AutonoVi:, a novel algorithm for autonomous vehicle navigation that supports dynamic maneuvers and satisfies traffic constraints and norms. Our approach is based on optimization-based maneuver planning that supports dynamic lane-changes, swerving, and braking in all traffic scenarios and guides the vehicle to its goal position. We take into account various traffic constraints, including collision avoidance with other vehicles, pedestrians, and cyclists using control velocity obstacles. We use a data-driven approach to model the vehicle dynamics for control and collision avoidance. Furthermore, our trajectory computation algorithm takes into account traffic rules and behaviors, such as stopping at intersections and stoplights, based on an arc-spline representation. We have evaluated our algorithm in a simulated environment and tested its interactive performance in urban and highway driving scenarios with tens of vehicles, pedestrians, and cyclists. These scenarios include jaywalking pedestrians, sudden stops from high speeds, safely passing cyclists, a vehicle suddenly swerving into the roadway, and high-density traffic where the vehicle must change lanes to progress more effectively. version:2
arxiv-1703-10139 | Bio-inspired Tensegrity Soft Modular Robots | http://arxiv.org/abs/1703.10139 | id:1703.10139 author:D. Zappetti, S. Mintchev, J. Shintake, D. Floreano category:cs.RO  published:2017-03-29 summary:In this paper, we introduce a design principle to develop novel soft modular robots based on tensegrity structures and inspired by the cytoskeleton of living cells. We describe a novel strategy to realize tensegrity structures using planar manufacturing techniques, such as 3D printing. We use this strategy to develop icosahedron tensegrity structures with programmable variable stiffness that can deform in a three-dimensional space. We also describe a tendon-driven contraction mechanism to actively control the deformation of the tensegrity mod-ules. Finally, we validate the approach in a modular locomotory worm as a proof of concept. version:1
arxiv-1703-10098 | Rational Choice and Artificial Intelligence | http://arxiv.org/abs/1703.10098 | id:1703.10098 author:Tshilidzi Marwala category:cs.AI q-fin.GN  published:2017-03-29 summary:The theory of rational choice assumes that when people make decisions they do so in order to maximize their utility. In order to achieve this goal they ought to use all the information available and consider all the choices available to choose an optimal choice. This paper investigates what happens when decisions are made by artificially intelligent machines in the market rather than human beings. Firstly, the expectations of the future are more consistent if they are made by an artificially intelligent machine and the decisions are more rational and thus marketplace becomes more rational. version:1
arxiv-1704-00045 | Comparison of ontology alignment algorithms across single matching task via the McNemar test | http://arxiv.org/abs/1704.00045 | id:1704.00045 author:Majid Mohammadi, Amir Ahooye Atashin, Wout Hofman, Yaohua Tan category:cs.AI  published:2017-03-29 summary:Ontology alignment is widely used to find the correspondences between different ontologies in diverse fields. After discovering the alignment by methods, several performance scores are available to evaluate them. The scores require the produced alignment by a method and the reference alignment containing the underlying actual correspondences of the given ontologies. The current trend in alignment evaluation is to put forward a new score and to compare various alignments by juxtaposing their performance scores. However, it is substantially provocative to select one performance score among others for comparison. On top of that, claiming if one method has a better performance than one another can not be substantiated by solely comparing the scores. In this paper, we propose the statistical procedures which enable us to theoretically favor one method over one another. The McNemar test is considered as a reliable and suitable means for comparing two ontology alignment methods over one matching task. The test applies to a 2 x 2 contingency table which can be constructed in two different ways based on the alignments, each of which has their own merits/pitfalls. The ways of the contingency table construction and various apposite statistics from the McNemar test are elaborated in minute detail. In the case of having more than two alignment methods for comparison, the family-wise error rate is expected to happen. Thus, the ways of preventing such an error are also discussed. A directed graph visualizes the outcome of the McNemar test in the presence of multiple alignment methods. From this graph, it is readily understood if one method is better than one another or if their differences are imperceptible. Our investigation on the methods participated in the anatomy track of OAEI 2016 demonstrates that AML and CroMatcher are the top two methods and DKP-AOM and Alin are the bottom two ones. version:1
arxiv-1703-10049 | Flight Tour Planning with Recharging Optimization for Battery-operated Autonomous Drones | http://arxiv.org/abs/1703.10049 | id:1703.10049 author:Chien-Ming Tseng, Chi-Kin Chau, Khaled Elbassioni, Majid Khonji category:cs.RO cs.DS  published:2017-03-29 summary:Autonomous drones (also known as unmanned aerial vehicles) have several advantages over ground vehicles, including agility, swiftness, and energy-efficiency, and hence are convenient for light-weight delivery and substitutions for manned missions in remote operations. It is expected that autonomous drones will be deployed in diverse applications in near future. Typical drones are electric vehicles, powered by on-board batteries. This paper presents several contributions for automated battery-operated drone management systems: (1) We conduct an empirical study to model the battery performance of drones, considering various flight scenarios. (2) We study a joint problem of flight tour planning with recharging optimization for drones with an objective to complete a tour mission for a set of sites of interest. This problem captures diverse applications of delivery and remote operations by drones. (3) We implemented our optimization algorithms in an intelligent drone management system. version:1
arxiv-1612-05767 | Computability of Perpetual Exploration in Highly Dynamic Rings | http://arxiv.org/abs/1612.05767 | id:1612.05767 author:Marjorie Bournat, Swan Dubois, Franck Petit category:cs.DC  published:2016-12-17 summary:We consider systems made of autonomous mobile robots evolving in highly dynamic discrete environment i.e., graphs where edges may appear and disappear unpredictably without any recurrence, stability, nor periodicity assumption. Robots are uniform (they execute the same algorithm), they are anonymous (they are devoid of any observable ID), they have no means allowing them to communicate together, they share no common sense of direction, and they have no global knowledge related to the size of the environment. However, each of them is endowed with persistent memory and is able to detect whether it stands alone at its current location. A highly dynamic environment is modeled by a graph such that its topology keeps continuously changing over time. In this paper, we consider only dynamic graphs in which nodes are anonymous, each of them is infinitely often reachable from any other one, and such that its underlying graph (i.e., the static graph made of the same set of nodes and that includes all edges that are present at least once over time) forms a ring of arbitrary size. In this context, we consider the fundamental problem of perpetual exploration: each node is required to be infinitely often visited by a robot. This paper analyzes the computability of this problem in (fully) synchronous settings, i.e., we study the deterministic solvability of the problem with respect to the number of robots. We provide three algorithms and two impossibility results that characterize, for any ring size, the necessary and sufficient number of robots to perform perpetual exploration of highly dynamic rings. version:2
arxiv-1703-08981 | MURS: Mitigating Memory Pressure in Service-oriented Data Processing Systems | http://arxiv.org/abs/1703.08981 | id:1703.08981 author:Xuanhua Shi, Xiong Zhang, Ligang He, Hai Jin, Zhixiang Ke, Song Wu category:cs.DC  published:2017-03-27 summary:Although a data processing system often works as a batch processing system, many enterprises deploy such a system as a service, which we call the service-oriented data processing system. It has been shown that in-memory data processing systems suffer from serious memory pressure. The situation becomes even worse for the service-oriented data processing systems due to various reasons. For example, in a service-oriented system, multiple submitted tasks are launched at the same time and executed in the same context in the resources, comparing with the batch processing mode where the tasks are processed one by one. Therefore, the memory pressure will affect all submitted tasks, including the tasks that only incur the light memory pressure when they are run alone. In this paper, we find that the reason why memory pressure arises is because the running tasks produce massive long-living data objects in the limited memory space. Our studies further reveal that the long-living data objects are generated by the API functions that are invoked by the in-memory processing frameworks. Based on these findings, we propose a method to classify the API functions based on the memory usage rate. Further, we design a scheduler called MURS to mitigate the memory pressure. We implement MURS in Spark and conduct the experiments to evaluate the performance of MURS. The results show that when comparing to Spark, MURS can 1) decrease the execution time of the submitted jobs by up to 65.8\%, 2) mitigate the memory pressure in the server by decreasing the garbage collection time by up to 81\%, and 3) reduce the data spilling, and hence disk I/O, by approximately 90\%. version:2
arxiv-1703-09962 | Spaceprint: a Mobility-based Fingerprinting Scheme for Public Spaces | http://arxiv.org/abs/1703.09962 | id:1703.09962 author:Mitra Baratchi, Geert Heijenk, Maarten van Steen category:cs.AI  published:2017-03-29 summary:In this paper, we address the problem of how automated situation-awareness can be achieved by learning real-world situations from ubiquitously generated mobility data. Without semantic input about the time and space where situations take place, this turns out to be a fundamental challenging problem. Uncertainties also introduce technical challenges when data is generated in irregular time intervals, being mixed with noise, and errors. Purely relying on temporal patterns observable in mobility data, in this paper, we propose Spaceprint, a fully automated algorithm for finding the repetitive pattern of similar situations in spaces. We evaluate this technique by showing how the latent variables describing the category, and the actual identity of a space can be discovered from the extracted situation patterns. Doing so, we use different real-world mobility datasets with data about the presence of mobile entities in a variety of spaces. We also evaluate the performance of this technique by showing its robustness against uncertainties. version:1
arxiv-1701-06800 | Linear-Time Data Dissemination in Dynamic Networks | http://arxiv.org/abs/1701.06800 | id:1701.06800 author:Manfred Schwarz, Martin Zeiner, Ulrich Schmid category:cs.DC 05C05  05C20  68R10  published:2017-01-24 summary:Broadcasting and convergecasting are pivotal services in distributed systems, in particular, in wireless ad-hoc and sensor networks, which are characterized by time- varying communication graphs. We study the question of whether it is possible to disseminate data available locally at some process to all n processes in sparsely connected synchronous dynamic networks with directed links in linear time. Recently, Charron-Bost, F\"ugger and Nowak proved an upper bound of O(n log n) rounds for the case where every communication graph is an arbitrary directed rooted tree. We present a new formalism, which not only facilitates a concise proof of this result, but also allows us to prove that O(n) data dissemination is possible when the number of leaves of the rooted trees are bounded by a constant. In the special case of rooted chains, only (n-1) rounds are needed. Our approach can also be adapted for undirected networks, where only (n-1)/2 rounds in the case of arbitrary chain graphs are needed. version:2
arxiv-1703-09934 | Towards Teleoperation with Human-like Dynamics: Human Use of Elastic Tools | http://arxiv.org/abs/1703.09934 | id:1703.09934 author:Manuel Aiple, André Schiele category:cs.HC cs.RO  published:2017-03-29 summary:Variable stiffness actuators undergo lower peak force in contacts compared to their rigid counterparts, and are thus safer for human-robot interaction. Furthermore, they can store energy in their elastic element and can release it later to achieve human-like dynamic movements. However, it is not clear how to integrate them in teleoperator systems so that they can be controlled intuitively by a human. We performed an experiment to study human use of elastic tools to determine how a teleoperator system with an elastic slave would need to be designed. For this, we had 13 untrained participants hammer with an elastic tool under different stiffness conditions, asking them to try to find the best timing for a backward-forward swing motion in order to achieve the strongest impact. We found that the participants generally executed the task efficiently after a few trials and they converged to very similar solutions. The stiffness influenced the performance slightly, a stiffness between 2.3 Nm/rad and 4.1 Nm/rad showing the best results. We conclude that humans intuitively know how to efficiently use elastic tools for hammering type tasks. This could facilitate the control of teleoperator systems with elastic slave manipulators for tasks requiring explosive movements like hammering. version:1
arxiv-1703-09923 | On Convergence Property of Implicit Self-paced Objective | http://arxiv.org/abs/1703.09923 | id:1703.09923 author:Zilu Ma, Shiqi Liu, Deyu Meng category:cs.AI  published:2017-03-29 summary:Self-paced learning (SPL) is a new methodology that simulates the learning principle of humans/animals to start learning easier aspects of a learning task, and then gradually take more complex examples into training. This new-coming learning regime has been empirically substantiated to be effective in various computer vision and pattern recognition tasks. Recently, it has been proved that the SPL regime has a close relationship to a implicit self-paced objective function. While this implicit objective could provide helpful interpretations to the effectiveness, especially the robustness, insights under the SPL paradigms, there are still no theoretical results strictly proved to verify such relationship. To this issue, in this paper, we provide some convergence results on this implicit objective of SPL. Specifically, we prove that the learning process of SPL always converges to critical points of this implicit objective under some mild conditions. This result verifies the intrinsic relationship between SPL and this implicit objective, and makes the previous robustness analysis on SPL complete and theoretically rational. version:1
arxiv-1407-5917 | Distributed Computing by Mobile Robots: Uniform Circle Formation | http://arxiv.org/abs/1407.5917 | id:1407.5917 author:Paola Flocchini, Giuseppe Prencipe, Nicola Santoro, Giovanni Viglietta category:cs.DC cs.CG cs.MA  published:2014-07-22 summary:Consider a set of $n$ simple autonomous mobile robots (asynchronous, no common coordinate system, no identities, no central coordination, no direct communication, no memory of the past, non-rigid, deterministic) initially in distinct locations, moving freely in the plane and able to sense the positions of the other robots. We study the primitive task of the robots arranging themselves on the vertices of a regular $n$-gon not fixed in advance (Uniform Circle Formation). In the literature, the existing algorithmic contributions are limited to conveniently restricted sets of initial configurations of the robots and to more powerful robots. The question of whether such simple robots could deterministically form a uniform circle has remained open. In this paper, we constructively prove that indeed the Uniform Circle Formation problem is solvable for any initial configuration in which the robots are in distinct locations, without any additional assumption (if two robots are in the same location, the problem is easily seen to be unsolvable). In addition to closing a long-standing problem, the result of this paper also implies that, for pattern formation, asynchrony is not a computational handicap, and that additional powers such as chirality and rigidity are computationally irrelevant. version:6
arxiv-1701-02388 | Stoic Ethics for Artificial Agents | http://arxiv.org/abs/1701.02388 | id:1701.02388 author:Gabriel Murray category:cs.AI  published:2017-01-09 summary:We present a position paper advocating the notion that Stoic philosophy and ethics can inform the development of ethical A.I. systems. This is in sharp contrast to most work on building ethical A.I., which has focused on Utilitarian or Deontological ethical theories. We relate ethical A.I. to several core Stoic notions, including the dichotomy of control, the four cardinal virtues, the ideal Sage, Stoic practices, and Stoic perspectives on emotion or affect. More generally, we put forward an ethical view of A.I. that focuses more on internal states of the artificial agent rather than on external actions of the agent. We provide examples relating to near-term A.I. systems as well as hypothetical superintelligent agents. version:2
arxiv-1703-05468 | Database Learning: Toward a Database that Becomes Smarter Every Time | http://arxiv.org/abs/1703.05468 | id:1703.05468 author:Yongjoo Park, Ahmad Shahab Tajik, Michael Cafarella, Barzan Mozafari category:cs.DB cs.AI  published:2017-03-16 summary:In today's databases, previous query answers rarely benefit answering future queries. For the first time, to the best of our knowledge, we change this paradigm in an approximate query processing (AQP) context. We make the following observation: the answer to each query reveals some degree of knowledge about the answer to another query because their answers stem from the same underlying distribution that has produced the entire dataset. Exploiting and refining this knowledge should allow us to answer queries more analytically, rather than by reading enormous amounts of raw data. Also, processing more queries should continuously enhance our knowledge of the underlying distribution, and hence lead to increasingly faster response times for future queries. We call this novel idea---learning from past query answers---Database Learning. We exploit the principle of maximum entropy to produce answers, which are in expectation guaranteed to be more accurate than existing sample-based approximations. Empowered by this idea, we build a query engine on top of Spark SQL, called Verdict. We conduct extensive experiments on real-world query traces from a large customer of a major database vendor. Our results demonstrate that Verdict supports 73.7% of these queries, speeding them up by up to 23.0x for the same accuracy level compared to existing AQP systems. version:2
arxiv-1703-09756 | Admire framework: Distributed data mining on data grid platforms | http://arxiv.org/abs/1703.09756 | id:1703.09756 author:Nhien-An Le-Khac, M-Tahar Kechadi, Joe Carthy category:cs.DC  published:2017-03-28 summary:In this paper, we present the ADMIRE architecture; a new framework for developing novel and innovative data mining techniques to deal with very large and distributed heterogeneous datasets in both commercial and academic applications. The main ADMIRE components are detailed as well as its interfaces allowing the user to efficiently develop and implement their data mining applications techniques on a Grid platform such as Globus ToolKit, DGET, etc. version:1
arxiv-1703-09707 | Accelerating gravitational microlensing simulations using the Xeon Phi coprocessor | http://arxiv.org/abs/1703.09707 | id:1703.09707 author:Bin Chen, Ronald Kantowski, Xinyu Dai, Eddie Baron, Paul Van der Mark category:astro-ph.IM astro-ph.HE cs.DC  published:2017-03-28 summary:Recently Graphics Processing Units (GPUs) have been used to speed up very CPU-intensive gravitational microlensing simulations. In this work, we use the Xeon Phi coprocessor to accelerate such simulations and compare its performance on a microlensing code with that of NVIDIA's GPUs. For the selected set of parameters evaluated in our experiment, we find that the speedup by Intel's Knights Corner coprocessor is comparable to that by NVIDIA's Fermi family of GPUs with compute capability 2.0, but less significant than GPUs with higher compute capabilities such as the Kepler. However, the very recently released second generation Xeon Phi, Knights Landing, is about 5.8 times faster than the Knights Corner, and about 2.9 times faster than the Kepler GPU used in our simulations. We conclude that the Xeon Phi is a very promising alternative to GPUs for modern high performance microlensing simulations. version:1
arxiv-1703-09620 | Universal Reasoning, Rational Argumentation and Human-Machine Interaction | http://arxiv.org/abs/1703.09620 | id:1703.09620 author:Christoph Benzmüller category:cs.AI F.4; I.2.3; I.2.4  published:2017-03-28 summary:Classical higher-order logic, when utilized as a meta-logic in which various other (classical and non-classical) logics can be shallowly embedded, is well suited for realising a universal logic reasoning approach. Universal logic reasoning in turn, as envisioned already by Leibniz, may support the rigorous formalisation and deep logical analysis of rational arguments within machines. A respective universal logic reasoning framework is described and a range of exemplary applications are discussed. In the future, universal logic reasoning in combination with appropriate, controlled forms of rational argumentation may serve as a communication layer between humans and intelligent machines. version:1
arxiv-1703-09542 | Palgol: A High-Level DSL for Vertex-Centric Graph Processing with Remote Data Access | http://arxiv.org/abs/1703.09542 | id:1703.09542 author:Yongzhe Zhang, Hsiang-Shang Ko, Zhenjiang Hu category:cs.DC  published:2017-03-28 summary:Pregel is a popular parallel computing model for dealing with large-scale graphs. However, it can be tricky to implement graph algorithms correctly and efficiently in Pregel's vertex-centric model, as programmers need to carefully restructure an algorithm in terms of supersteps and message passing, which are low-level and detached from the algorithm descriptions. Some domain-specific languages (DSLs) have been proposed to provide more intuitive ways to implement graph algorithms, but none of them can flexibly describe remote access (reading or writing attributes of other vertices through references), causing a still wide range of algorithms hard to implement. To address this problem, we design and implement Palgol, a more declarative and powerful DSL which supports remote access. In particular, programmers can use a more declarative syntax called global field access to directly read data on remote vertices. By structuring supersteps in a high-level vertex-centric computation model and analyzing the logic patterns of global field access, we provide a novel algorithm for compiling Palgol programs to efficient Pregel code. We demonstrate the power of Palgol by using it to implement a bunch of practical Pregel algorithms and compare them with hand-written code. The evaluation result shows that the efficiency of Palgol is comparable with that of hand-written code. version:1
arxiv-1703-09513 | Mining Best Closed Itemsets for Projection-antimonotonic Constraints in Polynomial Time | http://arxiv.org/abs/1703.09513 | id:1703.09513 author:Aleksey Buzmakov, Sergei O. Kuznetsov, Amedeo Napoli category:cs.AI  published:2017-03-28 summary:The exponential explosion of the set of patterns is one of the main challenges in pattern mining. This challenge is approached by introducing a constraint for pattern selection. One of the first constraints proposed in pattern mining is support (frequency) of a pattern in a dataset. Frequency is an anti-monotonic function, i.e., given an infrequent pattern, all its superpatterns are not frequent. However, many other constraints for pattern selection are neither monotonic nor anti-monotonic, which makes it difficult to generate patterns satisfying these constraints. In order to deal with nonmonotonic constraints we introduce the notion of "projection antimonotonicity" and SOFIA algorithm that allow generating best patterns for a class of nonmonotonic constraints. Cosine interest, robustness, stability of closed itemsets, and the associated delta-measure are among these constraints. SOFIA starts from light descriptions of transactions in dataset (a small set of items in the case of itemset description) and then iteratively adds more information to these descriptions (more items with indication of tidsets they describe). version:1
arxiv-1703-10105 | Exploiting Data Reduction Principles in Cloud-Based Data Management for Cryo-Image Data | http://arxiv.org/abs/1703.10105 | id:1703.10105 author:Kashish Ara Shakil, Ari Ora, Mansaf Alam, Shabih Shakeel category:cs.DC  published:2017-03-28 summary:Cloud computing is a cost-effective way for start-up life sciences laboratories to store and manage their data. However, in many instances the data stored over the cloud could be redundant which makes cloud-based data management inefficient and costly because one has to pay for every byte of data stored over the cloud. Here, we tested efficient management of data generated by an electron cryo microscopy (cryoEM) lab on a cloud-based environment. The test data was obtained from cryoEM repository EMPIAR. All the images were subjected to an in-house parallelized version of principal component analysis. An efficient cloud-based MapReduce modality was used for parallelization. We showed that large data in order of terabytes could be efficiently reduced to its minimal essential self in a cost-effective scalable manner. Furthermore, on-spot instance on Amazon EC2 was shown to reduce costs by a margin of about 27 percent. This approach could be scaled to data of any large volume and type. version:1
arxiv-1702-00785 | Evaluation of Automated Vehicles Encountering Pedestrians at Unsignalized Crossings | http://arxiv.org/abs/1702.00785 | id:1702.00785 author:Baiming Chen, Ding Zhao, Huei Peng category:cs.MA cs.RO cs.SY  published:2017-02-02 summary:Interactions between vehicles and pedestrians have always been a major problem in traffic safety. Experienced human drivers are able to analyze the environment and choose driving strategies that will help them avoid crashes. What is not yet clear, however, is how automated vehicles will interact with pedestrians. This paper proposes a new method for evaluating the safety and feasibility of the driving strategy of automated vehicles when encountering unsignalized crossings. MobilEye sensors installed on buses in Ann Arbor, Michigan, collected data on 2,973 valid crossing events. A stochastic interaction model was then created using a multivariate Gaussian mixture model. This model allowed us to simulate the movements of pedestrians reacting to an oncoming vehicle when approaching unsignalized crossings, and to evaluate the passing strategies of automated vehicles. A simulation was then conducted to demonstrate the evaluation procedure. version:3
arxiv-1703-09368 | Learning and inference in knowledge-based probabilistic model for medical diagnosis | http://arxiv.org/abs/1703.09368 | id:1703.09368 author:Jingchi Jiang, Chao Zhao, Yi Guan, Qiubin Yu category:cs.AI  published:2017-03-28 summary:Based on a weighted knowledge graph to represent first-order knowledge and combining it with a probabilistic model, we propose a methodology for the creation of a medical knowledge network (MKN) in medical diagnosis. When a set of symptoms is activated for a specific patient, we can generate a ground medical knowledge network composed of symptom nodes and potential disease nodes. By Incorporating a Boltzmann machine into the potential function of a Markov network, we investigated the joint probability distribution of the MKN. In order to deal with numerical symptoms, a multivariate inference model is presented that uses conditional probability. In addition, the weights for the knowledge graph were efficiently learned from manually annotated Chinese Electronic Medical Records (CEMRs). In our experiments, we found numerically that the optimum choice of the quality of disease node and the expression of symptom variable can improve the effectiveness of medical diagnosis. Our experimental results comparing a Markov logic network and the logistic regression algorithm on an actual CEMR database indicate that our method holds promise and that MKN can facilitate studies of intelligent diagnosis. version:1
arxiv-1703-08515 | Mean-Field Controllability and Decentralized Stabilization of Markov Chains, Part II: Asymptotic Controllability and Polynomial Feedbacks | http://arxiv.org/abs/1703.08515 | id:1703.08515 author:Shiba Biswal, Karthik Elamvazhuthi, Spring Berman category:cs.SY cs.RO math.OC  published:2017-03-24 summary:This paper, the second of a two-part series, presents a method for mean-field feedback stabilization of a swarm of agents on a finite state space whose time evolution is modeled as a continuous time Markov chain (CTMC). The resulting (mean-field) control problem is that of controlling a nonlinear system with desired global stability properties. We first prove that any probability distribution with a strongly connected support can be stabilized using time-invariant inputs. Secondly, we show the asymptotic controllability of all possible probability distributions, including distributions that assign zero density to some states and which do not necessarily have a strongly connected support. Lastly, we demonstrate that there always exists a globally asymptotically stabilizing decentralized density feedback law with the additional property that the control inputs are zero at equilibrium, whenever the graph is strongly connected and bidirected. Then the problem of synthesizing closed-loop polynomial feedback is framed as a optimization problem using state-of-the-art sum-of-squares optimization tools. The optimization problem searches for polynomial feedback laws that make the candidate Lyapunov function a stability certificate for the resulting closed-loop system. Our methodology is tested for two cases on a five vertex graph, and the stabilization properties of the constructed control laws are validated with numerical simulations of the corresponding system of ordinary differential equations. version:3
arxiv-1605-01824 | Persistent AUV Operations Using a Robust Reactive Mission and Path Planning (RRMPP) Architecture | http://arxiv.org/abs/1605.01824 | id:1605.01824 author:Somaiyeh Mahmoud. Zadeh, David M. W Powers, Karl Sammut, Adham Atyabi, Amirmehdi Yazdani category:cs.RO  published:2016-05-06 summary:Providing a higher level of decision autonomy and accompanying prompt changes of an uncertain environment is a true challenge of AUVs autonomous operations. The proceeding approach introduces a robust reactive structure that accommodates an AUV's mission planning, task-time management in a top level and incorporates environmental changes by a synchronic motion planning in a lower level. The proposed architecture is developed in a hierarchal modular format and a bunch of evolutionary algorithms are employed by each module to investigate the efficiency and robustness of the structure in different mission scenarios while water current data, uncertain static-mobile/motile obstacles, and vehicles Kino-dynamic constraints are taken into account. The motion planner is facilitated with online re-planning capability to refine the vehicle's trajectory based on local variations of the environment. A small computational load is devoted for re-planning procedure since the upper layer mission planner renders an efficient overview of the operation area that AUV should fly thru. Numerical simulations are carried out to investigate robustness and performance of the architecture in different situations of a real-world underwater environment. Analysis of the simulation results claims the remarkable capability of the proposed model in accurate mission task-time-threat management while guarantying a secure deployment during the mission. version:3
arxiv-1703-08243 | Mean-Field Controllability and Decentralized Stabilization of Markov Chains, Part I: Global Controllability and Rational Feedbacks | http://arxiv.org/abs/1703.08243 | id:1703.08243 author:Karthik Elamvazhuthi, Vaibhav Deshmukh, Matthias Kawski, Spring Berman category:cs.SY cs.RO math.OC  published:2017-03-23 summary:In this paper, we study the controllability and stabilizability properties of the Kolmogorov forward equation of a continuous time Markov chain (CTMC) evolving on a finite state space, using the transition rates as the control parameters. Firstly, we prove small-time local and global controllability from and to strictly positive equilibrium configurations when the underlying graph is strongly connected. Secondly, we show that there always exists a locally exponentially stabilizing decentralized linear (density-)feedback law that takes zero valu at equilibrium and respects the graph structure, provided that the transition rates are allowed to be negative and the desired target density lies in the interior of the set of probability densities. For bidirected graphs, that is, graphs where a directed edge in one direction implies an edge in the opposite direction, we show that this linear control law can be realized using a decentralized rational feedback law of the form k(x) = a(x) + b(x)f(x)/g(x) that also respects the graph structure and control constraints (positivity and zero at equilibrium). This enables the possibility of using Linear Matrix Inequality (LMI) based tools to algorithmically construct decentralized density feedback controllers for stabilization of a robotic swarm to a target task distribution with no task-switching at equilibrium, as we demonstrate with several numerical examples. version:3
arxiv-1703-09316 | On Data Flow Management: the Multilevel Analysis of Data Center Total Cost | http://arxiv.org/abs/1703.09316 | id:1703.09316 author:Katarzyna Mazur, Bogdan Ksiezopolski category:cs.NI cs.DC  published:2017-03-27 summary:Information management is one of the most significant issues in nowadays data centers. Selection of appropriate software, security mechanisms and effective energy consumption management together with caring for the environment enforces a profound analysis of the considered system. Besides these factors, financial analysis of data center maintenance is another important aspect that needs to be considered. Data centers are mission-critical components of all large enterprises and frequently cost hundreds of millions of dollars to build, yet few high-level executives understand the true cost of operating such facilities. Costs are typically spread across the IT, networking, and facilities, which makes management of these costs and assessment of alternatives difficult. This paper deals with a research on multilevel analysis of data center management and presents an approach to estimate the true total costs of operating data center physical facilities, taking into account the proper management of the information flow. version:1
arxiv-1703-09264 | Redesigning OP2 Compiler to Use HPX Runtime Asynchronous Techniques | http://arxiv.org/abs/1703.09264 | id:1703.09264 author:Zahra Khatami, Hartmut Kaiser, J. Ramanujam category:cs.DC  published:2017-03-27 summary:Maximizing parallelism level in applications can be achieved by minimizing overheads due to load imbalances and waiting time due to memory latencies. Compiler optimization is one of the most effective solutions to tackle this problem. The compiler is able to detect the data dependencies in an application and is able to analyze the specific sections of code for parallelization potential. However, all of these techniques provided with a compiler are usually applied at compile time, so they rely on static analysis, which is insufficient for achieving maximum parallelism and producing desired application scalability. One solution to address this challenge is the use of runtime methods. This strategy can be implemented by delaying certain amount of code analysis to be done at runtime. In this research, we improve the parallel application performance generated by the OP2 compiler by leveraging HPX, a C++ runtime system, to provide runtime optimizations. These optimizations include asynchronous tasking, loop interleaving, dynamic chunk sizing, and data prefetching. The results of the research were evaluated using an Airfoil application which showed a 40-50% improvement in parallel performance. version:1
arxiv-1703-09257 | AdiosStMan: Parallelizing Casacore Table Data System Using Adaptive IO System | http://arxiv.org/abs/1703.09257 | id:1703.09257 author:Ruonan Wang, Christopher Harris, Andreas Wicenec category:cs.DC astro-ph.IM  published:2017-03-27 summary:In this paper, we investigate the Casacore Table Data System (CTDS) used in the casacore and CASA libraries, and methods to parallelize it. CTDS provides a storage manager plugin mechanism for third-party devel- opers to design and implement their own CTDS storage managers. Hav- ing this in mind, we looked into various storage backend techniques that can possibly enable parallel I/O for CTDS by implementing new storage managers. After carrying on benchmarks showing the excellent parallel I/O throughput of the Adaptive IO System (ADIOS), we implemented an ADIOS based parallel CTDS storage manager. We then applied the CASA MSTransform frequency split task to verify the ADIOS Storage Manager. We also ran a series of performance tests to examine the I/O throughput in a massively parallel scenario. version:1
arxiv-1703-08955 | Analysis of Different Approaches of Parallel Block Processing for K-Means Clustering Algorithm | http://arxiv.org/abs/1703.08955 | id:1703.08955 author:C Rashmi category:cs.DC  published:2017-03-27 summary:Distributed Computation has been a recent trend in engineering research. Parallel Computation is widely used in different areas of Data Mining, Image Processing, Simulating Models, Aerodynamics and so forth. One of the major usage of Parallel Processing is widely implemented for clustering the satellite images of size more than dimension of 1000x1000 in a legacy system. This paper mainly focuses on the different approaches of parallel block processing such as row-shaped, column-shaped and square-shaped. These approaches are applied for classification problem. These approaches is applied to the K-Means clustering algorithm as this is widely used for the detection of features for high resolution orthoimagery satellite images. The different approaches are analyzed, which lead to reduction in execution time and resulted the influence of improvement in performance measurement compared to sequential K-Means Clustering algorithm. version:1
arxiv-1701-00335 | Analysis of a Stochastic Model of Replication in Large Distributed Storage Systems: A Mean-Field Approach | http://arxiv.org/abs/1701.00335 | id:1701.00335 author:Wen Sun, Véronique Simon, Sébastien Monnet, Philippe Robert, Pierre Sens category:cs.DC  published:2017-01-02 summary:Distributed storage systems such as Hadoop File System or Google File System (GFS) ensure data availability and durability using replication. This paper is focused on the analysis of the efficiency of replication mechanism that determines the location of the copies of a given file at some server. The variability of the loads of the nodes of the network is investigated for several policies. Three replication mechanisms are tested against simulations in the context of a real implementation of a such a system: Random, Least Loaded and Power of Choice. The simulations show that some of these policies may lead to quite unbalanced situations: if $\beta$ is the average number of copies per node it turns out that, at equilibrium, the load of the nodes may exhibit a high variability. It is shown in this paper that a simple variant of a power of choice type algorithm has a striking effect on the loads of the nodes: at equilibrium, the distribution of the load of a node has a bounded support, most of nodes have a load less than $2\beta$ which is an interesting property for the design of the storage space of these systems. Mathematical models are introduced and investigated to explain this interesting phenomenon. The analysis of these systems turns out to be quite complicated mainly because of the large dimensionality of the state spaces involved. Our study relies on probabilistic methods, mean-field analysis, to analyze the asymptotic behavior of an arbitrary node of the network when the total number of nodes gets large. An additional ingredient is the use of stochastic calculus with marked Poisson point processes to establish some of our results. version:2
arxiv-1703-08944 | Intelligent bidirectional rapidly-exploring random trees for optimal motion planning in complex cluttered environments | http://arxiv.org/abs/1703.08944 | id:1703.08944 author:Ahmed Hussain Qureshi, Yasar Ayaz category:cs.RO cs.AI  published:2017-03-27 summary:The sampling based motion planning algorithm known as Rapidly-exploring Random Trees (RRT) has gained the attention of many researchers due to their computational efficiency and effectiveness. Recently, a variant of RRT called RRT* has been proposed that ensures asymptotic optimality. Subsequently its bidirectional version has also been introduced in the literature known as Bidirectional-RRT* (B-RRT*). We introduce a new variant called Intelligent Bidirectional-RRT* (IB-RRT*) which is an improved variant of the optimal RRT* and bidirectional version of RRT* (B-RRT*) algorithms and is specially designed for complex cluttered environments. IB-RRT* utilizes the bidirectional trees approach and introduces intelligent sample insertion heuristic for fast convergence to the optimal path solution using uniform sampling heuristics. The proposed algorithm is evaluated theoretically and experimental results are presented that compares IB-RRT* with RRT* and B-RRT*. Moreover, experimental results demonstrate the superior efficiency of IB-RRT* in comparison with RRT* and B-RRT in complex cluttered environments. version:1
arxiv-1703-08930 | Alternative Modes of Interaction in Proximal Human-in-the-Loop Operation of Robots | http://arxiv.org/abs/1703.08930 | id:1703.08930 author:Tathagata Chakraborti, Sarath Sreedharan, Anagha Kulkarni, Subbarao Kambhampati category:cs.RO cs.HC  published:2017-03-27 summary:Ambiguity and noise in natural language instructions create a significant barrier towards adopting autonomous systems into safety critical workflows involving humans and machines. In this paper, we propose to build on recent advances in electrophysiological monitoring methods and augmented reality technologies, to develop alternative modes of communication between humans and robots involved in large-scale proximal collaborative tasks. We will first introduce augmented reality techniques for projecting a robot's intentions to its human teammate, who can interact with these cues to engage in real-time collaborative plan execution with the robot. We will then look at how electroencephalographic (EEG) feedback can be used to monitor human response to both discrete events, as well as longer term affective states while execution of a plan. These signals can be used by a learning agent, a.k.a an affective robot, to modify its policy. We will present an end-to-end system capable of demonstrating these modalities of interaction. We hope that the proposed system will inspire research in augmenting human-robot interactions with alternative forms of communications in the interests of safety, productivity, and fluency of teaming, particularly in engineered settings such as the factory floor or the assembly line in the manufacturing industry where the use of such wearables can be enforced. version:1
arxiv-1703-09794 | Probabilistic Models for Computerized Adaptive Testing | http://arxiv.org/abs/1703.09794 | id:1703.09794 author:Martin Plajner category:cs.CY cs.AI  published:2017-03-26 summary:In this paper we follow our previous research in the area of Computerized Adaptive Testing (CAT). We present three different methods for CAT. One of them, the item response theory, is a well established method, while the other two, Bayesian and neural networks, are new in the area of educational testing. In the first part of this paper, we present the concept of CAT and its advantages and disadvantages. We collected data from paper tests performed with grammar school students. We provide the summary of data used for our experiments in the second part. Next, we present three different model types for CAT. They are based on the item response theory, Bayesian networks, and neural networks. The general theory associated with each type is briefly explained and the utilization of these models for CAT is analyzed. Future research is outlined in the concluding part of the paper. It shows many interesting research paths that are important not only for CAT but also for other areas of artificial intelligence. version:1
arxiv-1703-08862 | Socially Aware Motion Planning with Deep Reinforcement Learning | http://arxiv.org/abs/1703.08862 | id:1703.08862 author:Yu Fan Chen, Michael Everett, Miao Liu, Jonathan P. How category:cs.RO cs.AI cs.HC  published:2017-03-26 summary:For robotic vehicles to navigate safely and efficiently in pedestrian-rich environments, it is important to model subtle human behaviors and navigation rules. However, while instinctive to humans, socially compliant navigation is still difficult to quantify due to the stochasticity in people's behaviors. Existing works are mostly focused on using feature-matching techniques to describe and imitate human paths, but often do not generalize well since the feature values can vary from person to person, and even run to run. This work notes that while it is challenging to directly specify the details of what to do (precise mechanisms of human navigation), it is straightforward to specify what not to do (violations of social norms). Specifically, using deep reinforcement learning, this work develops a time-efficient navigation policy that respects common social norms. The proposed method is shown to enable fully autonomous navigation of a robotic vehicle moving at human walking speed in an environment with many pedestrians. version:1
arxiv-1609-03784 | A Fast Proximal Gradient Algorithm for Decentralized Composite Optimization over Directed Networks | http://arxiv.org/abs/1609.03784 | id:1609.03784 author:Jinshan Zeng, Tao He, Mingwen Wang category:cs.DC math.OC  published:2016-09-13 summary:This paper proposes a fast decentralized algorithm for solving a consensus optimization problem defined in a directed networked multi-agent system, where the local objective functions have the smooth+nonsmooth composite form, and are possibly nonconvex. Examples of such problems include decentralized compressed sensing and constrained quadratic programming problems, as well as many decentralized regularization problems. We extend the existing algorithms PG-EXTRA and ExtraPush to a new algorithm PG-ExtraPush for composite consensus optimization over a directed network. This algorithm takes advantage of the proximity operator like in PG-EXTRA to deal with the nonsmooth term, and employs the push-sum protocol like in ExtraPush to tackle the bias introduced by the directed network. With a proper step size, we show that PG-ExtraPush converges to an optimal solution at a linear rate under some regular assumptions. We conduct a series of numerical experiments to show the effectiveness of the proposed algorithm. Specifically, with a proper step size, PG-ExtraPush performs linear rates in most of cases, even in some nonconvex cases, and is significantly faster than Subgradient-Push, even if the latter uses a hand-optimized step size. The established theoretical results are also verified by the numerical results. version:4
arxiv-1610-09962 | An Experimental Survey on Big Data Frameworks | http://arxiv.org/abs/1610.09962 | id:1610.09962 author:Wissem Inoubli, Sabeur Aridhi, Haithem Mezni, Alexander Jung category:cs.DC  published:2016-10-31 summary:Recently, increasingly large amounts of data are generated from a variety of sources. Existing data processing technologies are not suitable to cope with the huge amounts of generated data. Yet, many research works focus on Big Data, a buzzword referring to the processing of massive volumes of (unstructured) data. Recently proposed frameworks for Big Data applications help to store, analyze and process the data. In this paper, we discuss the challenges of Big Data and we survey existing Big Data frameworks. We also present an experimental evaluation and a comparative study of the most popular Big Data frameworks. This survey is concluded with a presentation of best practices related to the use of studied frameworks in several application domains such as machine learning, graph processing and real-world applications. version:2
arxiv-1703-08762 | Team Formation for Scheduling Educational Material in Massive Online Classes | http://arxiv.org/abs/1703.08762 | id:1703.08762 author:Sanaz Bahargam, Dóra Erdos, Azer Bestavros, Evimaria Terzi category:cs.AI  published:2017-03-26 summary:Whether teaching in a classroom or a Massive Online Open Course it is crucial to present the material in a way that benefits the audience as a whole. We identify two important tasks to solve towards this objective, 1 group students so that they can maximally benefit from peer interaction and 2 find an optimal schedule of the educational material for each group. Thus, in this paper, we solve the problem of team formation and content scheduling for education. Given a time frame d, a set of students S with their required need to learn different activities T and given k as the number of desired groups, we study the problem of finding k group of students. The goal is to teach students within time frame d such that their potential for learning is maximized and find the best schedule for each group. We show this problem to be NP-hard and develop a polynomial algorithm for it. We show our algorithm to be effective both on synthetic as well as a real data set. For our experiments, we use real data on students' grades in a Computer Science department. As part of our contribution, we release a semi-synthetic dataset that mimics the properties of the real data. version:1
arxiv-1704-06192 | The Design, Implementation, and Deployment of a System to Transparently Compress Hundreds of Petabytes of Image Files for a File-Storage Service | http://arxiv.org/abs/1704.06192 | id:1704.06192 author:Daniel Reiter Horn, Ken Elkabany, Chris Lesniewski-Laas, Keith Winstein category:cs.MM cs.DC cs.GR cs.NI  published:2017-03-26 summary:We report the design, implementation, and deployment of Lepton, a fault-tolerant system that losslessly compresses JPEG images to 77% of their original size on average. Lepton replaces the lowest layer of baseline JPEG compression-a Huffman code-with a parallelized arithmetic code, so that the exact bytes of the original JPEG file can be recovered quickly. Lepton matches the compression efficiency of the best prior work, while decoding more than nine times faster and in a streaming manner. Lepton has been released as open-source software and has been deployed for a year on the Dropbox file-storage backend. As of February 2017, it had compressed more than 203 PiB of user JPEG files, saving more than 46 PiB. version:1
arxiv-1703-08736 | A New Paradigm for Robotic Dust Collection: Theorems, User Studies, and a Field Study | http://arxiv.org/abs/1703.08736 | id:1703.08736 author:Rachel M. Holladay, Siddhartha S. Srinivasa category:cs.RO  published:2017-03-25 summary:We pioneer a new future in robotic dust collection by introducing passive dust-collecting robots that, unlike their predecessors, do not require locomotion to collect dust. While previous research has exclusively focused on active dust-collecting robots, we show that these robots fail with respect to practical and theoretical aspects, as well as human factors. By contrast, passive robots, through their unconstrained versatility, shine brilliantly in all three metrics. We present a mathematical formalism of both paradigms followed by a user study and field study. version:1
arxiv-1505-05697 | A Fast Network-Decomposition Algorithm and its Applications to Constant-Time Distributed Computation | http://arxiv.org/abs/1505.05697 | id:1505.05697 author:Leonid Barenboim, Michael Elkin, Cyril Gavoille category:cs.DC cs.DS  published:2015-05-21 summary:A partition $(C_1,C_2,...,C_q)$ of $G = (V,E)$ into clusters of strong (respectively, weak) diameter $d$, such that the supergraph obtained by contracting each $C_i$ is $\ell$-colorable is called a strong (resp., weak) $(d, \ell)$-network-decomposition. Network-decompositions were introduced in a seminal paper by Awerbuch, Goldberg, Luby and Plotkin in 1989. Awerbuch et al. showed that strong $(exp\{O(\sqrt{ \log n \log \log n})\}, exp\{O(\sqrt{ \log n \log \log n})\})$-network-decompositions can be computed in distributed deterministic time $exp\{O(\sqrt{ \log n \log \log n})\}$. The result of Awerbuch et al. was improved by Panconesi and Srinivasan in 1992: in the latter result $d = \ell = exp\{O(\sqrt{\log n})\}$, and the running time is $exp\{O(\sqrt{\log n})\}$ as well. Much more recently Barenboim (2012) devised a distributed randomized constant-time algorithm for computing strong network decompositions with $d = O(1)$. However, the parameter $\ell$ in his result is $O(n^{1/2 + \epsilon})$. In this paper we drastically improve the result of Barenboim and devise a distributed randomized constant-time algorithm for computing strong $(O(1), O(n^{\epsilon}))$-network-decompositions. As a corollary we derive a constant-time randomized $O(n^{\epsilon})$-approximation algorithm for the distributed minimum coloring problem, improving the previously best-known $O(n^{1/2 + \epsilon})$ approximation guarantee. We also derive other improved distributed algorithms for a variety of problems. Most notably, for the extremely well-studied distributed minimum dominating set problem currently there is no known deterministic polylogarithmic-time algorithm. We devise a {deterministic} polylogarithmic-time approximation algorithm for this problem, addressing an open problem of Lenzen and Wattenhofer (2010). version:2
arxiv-1703-08702 | Randomized Load Balancing on Networks with Stochastic Inputs | http://arxiv.org/abs/1703.08702 | id:1703.08702 author:Leran Cai, Thomas Sauerwald category:cs.DC cs.DS G.3  published:2017-03-25 summary:Iterative load balancing algorithms for indivisible tokens have been studied intensively in the past. Complementing previous worst-case analyses, we study an average-case scenario where the load inputs are drawn from a fixed probability distribution. For cycles, tori, hypercubes and expanders, we obtain almost matching upper and lower bounds on the discrepancy, the difference between the maximum and the minimum load. Our bounds hold for a variety of probability distributions including the uniform and binomial distribution but also distributions with unbounded range such as the Poisson and geometric distribution. For graphs with slow convergence like cycles and tori, our results demonstrate a substantial difference between the convergence in the worst- and average-case. An important ingredient in our analysis is new upper bound on the t-step transition probability of a general Markov chain, which is derived by invoking the evolving set process. version:1
arxiv-1704-01049 | A simulated annealing approach to optimal storing in a multi-level warehouse | http://arxiv.org/abs/1704.01049 | id:1704.01049 author:Alexander Eckrot, Carina Geldhauser, Jan Jurczyk category:cs.AI  published:2017-03-25 summary:We propose a simulated annealing algorithm specifically tailored to optimise total retrieval times in a multi-level warehouse under complex pre-batched picking constraints. Experiments on real data from a picker-to-parts order picking process in the warehouse of a European manufacturer show that optimal storage assignments do not necessarily display features presumed in heuristics, such as clustering of positively correlated items or ordering of items by picking frequency. In an experiment run on more than 4000 batched orders with 1 to 150 items per batch, the storage assignment suggested by the algorithm produces a 21\% reduction in the total retrieval time with respect to a frequency-based storage assignment. version:1
arxiv-1703-08525 | An Algorithmic Approach to the Asynchronous Computability Theorem | http://arxiv.org/abs/1703.08525 | id:1703.08525 author:Vikram Saraph, Maurice Herlihy, Eli Gafni category:cs.DC  published:2017-03-24 summary:The asynchronous computability theorem (ACT) uses concepts from combinatorial topology to characterize which tasks have wait-free solutions in read-write memory. A task can be expressed as a relation between two chromatic simplicial complexes. The theorem states that a task has a protocol (algorithm) if and only if there is a certain chromatic simplicial map compatible with that relation. While the original proof of the ACT relied on an involved combinatorial argument, Borowsky and Gafni later proposed an alternative proof that relied on a algorithmic construction, termed the "convergence algorithm". The description of this algorithm was incomplete, and presented without proof. In this paper, we give the first complete description, along with a proof of correctness. version:1
arxiv-1703-08469 | Virtualization technology for distributed time sensitive domains | http://arxiv.org/abs/1703.08469 | id:1703.08469 author:Carlos Antonio Perea-Gómez category:cs.DC cs.OS  published:2017-03-24 summary:This paper reports on the state of the art of virtualization technology for both general purpose domains as well as real-time domains. There exits no entirely instantaneous data transmission/transfer. There always exist a delay while transmitting data, either in the processing or in the medium itself. However most systems are designed to function appropriately with a delay tolerance. This delay, inevitably, is affected when operating with an extra layer, the virtualization. For real time systems it is crucial to know the temporal limits in order not to surpass them. Introducing virtualization in the real-time domain therefore requires deeper analysis by making use of techniques that will offer results with deterministic execution times. The study of time in systems and its behaviour under various possible circumstances is hence a key for properly assessing this technology applied to both domains, especially the real-time domain. version:1
arxiv-1703-08397 | Reasoning by Cases in Structured Argumentation | http://arxiv.org/abs/1703.08397 | id:1703.08397 author:Mathieu Beirlaen, Jesse Heyninck, Christian Straßer category:cs.AI 68T27 I.2.3; I.2.4  published:2017-03-24 summary:We extend the $ASPIC^+$ framework for structured argumentation so as to allow applications of the reasoning by cases inference scheme for defeasible arguments. Given an argument with conclusion `$A$ or $B$', an argument based on $A$ with conclusion $C$, and an argument based on $B$ with conclusion $C$, we allow the construction of an argument with conclusion $C$. We show how our framework leads to different results than other approaches in non-monotonic logic for dealing with disjunctive information, such as disjunctive default theory or approaches based on the OR-rule (which allows to derive a defeasible rule `If ($A$ or $B$) then $C$', given two defeasible rules `If $A$ then $C$' and `If $B$ then $C$'). We raise new questions regarding the subtleties of reasoning defeasibly with disjunctive information, and show that its formalization is more intricate than one would presume. version:1
arxiv-1703-08376 | A duality-based approach for distributed min-max optimization with application to demand side management | http://arxiv.org/abs/1703.08376 | id:1703.08376 author:Ivano Notarnicola, Mauro Franceschelli, Giuseppe Notarstefano category:cs.DC cs.SY  published:2017-03-24 summary:In this paper we consider a distributed optimization scenario in which a set of processors aims at minimizing the maximum of a collection of "separable convex functions" subject to local constraints. This set-up is motivated by peak-demand minimization problems in smart grids. Here, the goal is to minimize the peak value over a finite horizon with: (i) the demand at each time instant being the sum of contributions from different devices, and (ii) the local states at different time instants being coupled through local dynamics. The min-max structure and the double coupling (through the devices and over the time horizon) makes this problem challenging in a distributed set-up (e.g., well-known distributed dual decomposition approaches cannot be applied). We propose a distributed algorithm based on the combination of duality methods and properties from min-max optimization. Specifically, we derive a series of equivalent problems by introducing ad-hoc slack variables and by going back and forth from primal and dual formulations. On the resulting problem we apply a dual subgradient method, which turns out to be a distributed algorithm. We prove the correctness of the proposed algorithm and show its effectiveness via numerical computations. version:1
arxiv-1703-08370 | A randomized primal distributed algorithm for partitioned and big-data non-convex optimization | http://arxiv.org/abs/1703.08370 | id:1703.08370 author:Ivano Notarnicola, Giuseppe Notarstefano category:cs.DC cs.NA  published:2017-03-24 summary:In this paper we consider a distributed optimization scenario in which the aggregate objective function to minimize is partitioned, big-data and possibly non-convex. Specifically, we focus on a set-up in which the dimension of the decision variable depends on the network size as well as the number of local functions, but each local function handled by a node depends only on a (small) portion of the entire optimization variable. This problem set-up has been shown to appear in many interesting network application scenarios. As main paper contribution, we develop a simple, primal distributed algorithm to solve the optimization problem, based on a randomized descent approach, which works under asynchronous gossip communication. We prove that the proposed asynchronous algorithm is a proper, ad-hoc version of a coordinate descent method and thus converges to a stationary point. To show the effectiveness of the proposed algorithm, we also present numerical simulations on a non-convex quadratic program, which confirm the theoretical results. version:1
arxiv-1703-08348 | Video Streaming in Distributed Erasure-coded Storage Systems: Stall Duration Analysis | http://arxiv.org/abs/1703.08348 | id:1703.08348 author:Abubakr O. Al-Abbasi, Vaneet Aggarwal category:cs.NI cs.DC cs.IT cs.MM math.IT  published:2017-03-24 summary:The demand for global video has been burgeoning across industries. With the expansion and improvement of video streaming services, cloud-based video is evolving into a necessary feature of any successful business for reaching internal and external audiences. This paper considers video streaming over distributed systems where the video segments are encoded using an erasure code for better reliability thus being the first work to our best knowledge that considers video streaming over erasure-coded distributed cloud systems. The download time of each coded chunk of each video segment is characterized and ordered statistics over the choice of the erasure-coded chunks is used to obtain the playback time of different video segments. Using the playback times, bounds on the moment generating function on the stall duration is used to bound the mean stall duration. Moment generating function based bounds on the ordered statistics are also used to bound the stall duration tail probability which determines the probability that the stall time is greater than a pre-defined number. These two metrics, mean stall duration and the stall duration tail probability, are important quality of experience (QoE) measures for the end users. Based on these metrics, we formulate an optimization problem to jointly minimize the convex combination of both the QoE metrics averaged over all requests over the placement and access of the video content. The non-convex problem is solved using an efficient iterative algorithm. Numerical results show significant improvement in QoE metrics for cloud-based video as compared to the considered baselines. version:1
arxiv-1703-08337 | Taming Tail Latency for Erasure-coded, Distributed Storage Systems | http://arxiv.org/abs/1703.08337 | id:1703.08337 author:Vaneet Aggarwal, Abubakr O. Al-Abbasi, Jingxian Fan, Tian Lan category:cs.DC cs.IT cs.NI math.IT  published:2017-03-24 summary:Distributed storage systems are known to be susceptible to long tails in response time. In modern online storage systems such as Bing, Facebook, and Amazon, the long tails of the service latency are of particular concern. with 99.9th percentile response times being orders of magnitude worse than the mean. As erasure codes emerge as a popular technique to achieve high data reliability in distributed storage while attaining space efficiency, taming tail latency still remains an open problem due to the lack of mathematical models for analyzing such systems. To this end, we propose a framework for quantifying and optimizing tail latency in erasure-coded storage systems. In particular, we derive upper bounds on tail latency in closed form for arbitrary service time distribution and heterogeneous files. Based on the model, we formulate an optimization problem to jointly minimize the weighted latency tail probability of all files over the placement of files on the servers, and the choice of servers to access the requested files. The non-convex problem is solved using an efficient, alternating optimization algorithm. Numerical results show significant reduction of tail latency for erasure-coded storage systems with a realistic workload. version:1
arxiv-1703-08280 | LRC: Dependency-Aware Cache Management for Data Analytics Clusters | http://arxiv.org/abs/1703.08280 | id:1703.08280 author:Yinghao Yu, Wei Wang, Jun Zhang, Khaled Ben Letaief category:cs.DC  published:2017-03-24 summary:Memory caches are being aggressively used in today's data-parallel systems such as Spark, Tez, and Piccolo. However, prevalent systems employ rather simple cache management policies--notably the Least Recently Used (LRU) policy--that are oblivious to the application semantics of data dependency, expressed as a directed acyclic graph (DAG). Without this knowledge, memory caching can at best be performed by "guessing" the future data access patterns based on historical information (e.g., the access recency and/or frequency), which frequently results in inefficient, erroneous caching with low hit ratio and a long response time. In this paper, we propose a novel cache replacement policy, Least Reference Count (LRC), which exploits the application-specific DAG information to optimize the cache management. LRC evicts the cached data blocks whose reference count is the smallest. The reference count is defined, for each data block, as the number of dependent child blocks that have not been computed yet. We demonstrate the efficacy of LRC through both empirical analysis and cluster deployments against popular benchmarking workloads. Our Spark implementation shows that, compared with LRU, LRC speeds up typical applications by 60%. version:1
arxiv-1703-08262 | Supervisor Synthesis of POMDP based on Automata Learning | http://arxiv.org/abs/1703.08262 | id:1703.08262 author:Xiaobin Zhang, Bo Wu, Hai Lin category:cs.SY cs.AI cs.FL  published:2017-03-24 summary:As a general and thus popular model for autonomous systems, partially observable Markov decision process (POMDP) can capture uncertainties from different sources like sensing noises, actuation errors, and uncertain environments. However, its comprehensiveness makes the planning and control in POMDP difficult. Traditional POMDP planning problems target to find the optimal policy to maximize the expectation of accumulated rewards. But for safety critical applications, guarantees of system performance described by formal specifications are desired, which motivates us to consider formal methods to synthesize supervisor for POMDP. With system specifications given by Probabilistic Computation Tree Logic (PCTL), we propose a supervisory control framework with a type of deterministic finite automata (DFA), za-DFA, as the controller form. While the existing work mainly relies on optimization techniques to learn fixed-size finite state controllers (FSCs), we develop an $L^*$ learning based algorithm to determine both space and transitions of za-DFA. Membership queries and different oracles for conjectures are defined. The learning algorithm is sound and complete. An example is given in detailed steps to illustrate the supervisor synthesis algorithm. version:1
arxiv-1703-07726 | \$1 Today or \$2 Tomorrow? The Answer is in Your Facebook Likes | http://arxiv.org/abs/1703.07726 | id:1703.07726 author:Tao Ding, Warren K. Bickel, Shimei Pan category:cs.AI cs.CY cs.SI  published:2017-03-22 summary:In economics and psychology, delay discounting is often used to characterize how individuals choose between a smaller immediate reward and a larger delayed reward. People with higher delay discounting rate (DDR) often choose smaller but more immediate rewards (a "today person"). In contrast, people with a lower discounting rate often choose a larger future rewards (a "tomorrow person"). Since the ability to modulate the desire of immediate gratification for long term rewards plays an important role in our decision-making, the lower discounting rate often predicts better social, academic and health outcomes. In contrast, the higher discounting rate is often associated with problematic behaviors such as alcohol/drug abuse, pathological gambling and credit card default. Thus, research on understanding and moderating delay discounting has the potential to produce substantial societal benefits. version:3
arxiv-1703-08219 | Flare: Native Compilation for Heterogeneous Workloads in Apache Spark | http://arxiv.org/abs/1703.08219 | id:1703.08219 author:Grégory M. Essertel, Ruby Y. Tahboub, James M. Decker, Kevin J. Brown, Kunle Olukotun, Tiark Rompf category:cs.DB cs.DC cs.PF cs.PL  published:2017-03-23 summary:The need for modern data analytics to combine relational, procedural, and map-reduce-style functional processing is widely recognized. State-of-the-art systems like Spark have added SQL front-ends and relational query optimization, which promise an increase in expressiveness and performance. But how good are these extensions at extracting high performance from modern hardware platforms? While Spark has made impressive progress, we show that for relational workloads, there is still a significant gap compared with best-of-breed query engines. And when stepping outside of the relational world, query optimization techniques are ineffective if large parts of a computation have to be treated as user-defined functions (UDFs). We present Flare: a new back-end for Spark that brings performance closer to the best SQL engines, without giving up the added expressiveness of Spark. We demonstrate order of magnitude speedups both for relational workloads such as TPC-H, as well as for a range of machine learning kernels that combine relational and iterative functional processing. Flare achieves these results through (1) compilation to native code, (2) replacing parts of the Spark runtime system, and (3) extending the scope of optimization and code generation to large classes of UDFs. version:1
arxiv-1703-08212 | Speeding up TestU01 with the use of HTCondor | http://arxiv.org/abs/1703.08212 | id:1703.08212 author:Joshua Beizer category:cs.DC  published:2017-03-23 summary:Testing random number generators is a very important task that, in the resent past, has taken upwards of twelve hours when testing with the current agship testing suite TestU01. Through this paper we will discuss the possible performance increases to the existing random number generator testing suite TestU01 that are available by offering the executable to an HTCondor pool to execute on. We will see that with a few modifications we are able to decrease the running time of a sample run of Big Crush from about five and a half hours to only five and a half minutes. We will also see that not only the time taken for the testing to complete is shortened, but also the amount of time the user is unable to use their testing computer is reduced to almost none. Additionally, during this paper we will look at the standard implementation of TestU01 and how it compares with a preexisting Parallel version of TestU01. We will be comparing the performance of the standard version of TestU01 with the parallel version so that we have a performance baseline to test our own modifications against. Finally, this paper will also discuss the use of the distributed computing system HTCondor, and cover some basic instructions related to setting up and using HTCondor. HTCondor is already known to increase the performance of a networked group of computers by allowing super users to utilize additional resources from other lesser users idle workstation. We will relate the model recommended for HTCondor to a standard computer lab found at a University and explain why they are the perfect candidates for the system. version:1
arxiv-1608-07200 | Bulk-synchronous pseudo-streaming algorithms for many-core accelerators | http://arxiv.org/abs/1608.07200 | id:1608.07200 author:Jan-Willem Buurlage, Tom Bannink, Abe Wits category:cs.DC  published:2016-08-25 summary:The bulk-synchronous parallel (BSP) model provides a framework for writing parallel programs with predictable performance. In this paper we extend the BSP model to support what we will call pseudo-streaming algorithms for accelerators. We also generalize the BSP cost function to these algorithms, so that it is possible to predict the running time for programs targeting many-core accelerators and to identify possible bottlenecks. Several examples of algorithms within this new framework will be explored. We extend the BSPlib standard by proposing a small number of new BSP primitives to create and use streams in a portable way. We will introduce a software library called Epiphany BSP that implements these ideas for the Parallella development board. Finally we will give experimental results for pseudo-streaming algorithms on the Parallella platform. version:2
arxiv-1703-08041 | Resolving the Complexity of Some Fundamental Problems in Computational Social Choice | http://arxiv.org/abs/1703.08041 | id:1703.08041 author:Palash Dey category:cs.DS cs.AI cs.MA  published:2017-03-23 summary:This thesis is in the area called computational social choice which is an intersection area of algorithms and social choice theory. version:1
arxiv-1703-08015 | Sparse geometries handling in lattice-Boltzmann method implementation for graphic processors | http://arxiv.org/abs/1703.08015 | id:1703.08015 author:Tadeusz Tomczak, Roman G. Szafran category:cs.DC  published:2017-03-23 summary:We describe a high-performance implementation of the lattice-Boltzmann method (LBM) for sparse geometries on graphic processors. In our implementation we cover the whole geometry with a uniform mesh of small tiles and carry out calculations for each tile independently with a proper data synchronization at tile edges. For this method we provide both the theoretical analysis of complexity and the results for real implementations for 2D and 3D geometries. Based on the theoretical model, we show that tiles offer significantly smaller bandwidth overhead than solutions based on indirect addressing. For 2-dimensional lattice arrangements a reduction of memory usage is also possible, though at the cost of diminished performance. We reached the performance of 682 MLUPS on GTX Titan (72\% of peak theoretical memory bandwidth) for D3Q19 lattice arrangement and double precision data. version:1
arxiv-1703-07929 | Diversification-Based Learning in Computing and Optimization | http://arxiv.org/abs/1703.07929 | id:1703.07929 author:Fred Glover, Jin-Kao Hao category:cs.AI  published:2017-03-23 summary:Diversification-Based Learning (DBL) derives from a collection of principles and methods introduced in the field of metaheuristics that have broad applications in computing and optimization. We show that the DBL framework goes significantly beyond that of the more recent Opposition-based learning (OBL) framework introduced in Tizhoosh (2005), which has become the focus of numerous research initiatives in machine learning and metaheuristic optimization. We unify and extend earlier proposals in metaheuristic search (Glover, 1997, Glover and Laguna, 1997) to give a collection of approaches that are more flexible and comprehensive than OBL for creating intensification and diversification strategies in metaheuristic search. We also describe potential applications of DBL to various subfields of machine learning and optimization. version:1
arxiv-1701-08709 | Diversification Methods for Zero-One Optimization | http://arxiv.org/abs/1701.08709 | id:1701.08709 author:Fred Glover category:cs.AI  published:2017-01-30 summary:We introduce new diversification methods for zero-one optimization that significantly extend strategies previously introduced in the setting of metaheuristic search. Our methods incorporate easily implemented strategies for partitioning assignments of values to variables, accompanied by processes called augmentation and shifting which create greater flexibility and generality. We then show how the resulting collection of diversified solutions can be further diversified by means of permutation mappings, which equally can be used to generate diversified collections of permutations for applications such as scheduling and routing. These methods can be applied to non-binary vectors by the use of binarization procedures and by Diversification-Based Learning (DBL) procedures which also provide connections to applications in clustering and machine learning. Detailed pseudocode and numerical illustrations are provided to show the operation of our methods and the collections of solutions they create. version:2
arxiv-1703-07890 | User Experience of the CoSTAR System for Instruction of Collaborative Robots | http://arxiv.org/abs/1703.07890 | id:1703.07890 author:Chris Paxton, Felix Jonathan, Andrew Hundt, Bilge Mutlu, Gregory D. Hager category:cs.RO  published:2017-03-23 summary:How can we enable novice users to create effective task plans for collaborative robots? Must there be a tradeoff between generalizability and ease of use? To answer these questions, we conducted a user study with the CoSTAR system, which integrates perception and reasoning into a Behavior Tree-based task plan editor. In our study, we ask novice users to perform simple pick-and-place assembly tasks under varying perception and planning capabilities. Our study shows that users found Behavior Trees to be an effective way of specifying task plans. Furthermore, users were also able to more quickly, effectively, and generally author task plans with the addition of CoSTAR's planning, perception, and reasoning capabilities. Despite these improvements, concepts associated with these capabilities were rated by users as less usable, and our results suggest a direction for further refinement. version:1
arxiv-1703-07887 | Combining Neural Networks and Tree Search for Task and Motion Planning in Challenging Environments | http://arxiv.org/abs/1703.07887 | id:1703.07887 author:Chris Paxton, Vasumathi Raman, Gregory D. Hager, Marin Kobilarov category:cs.RO  published:2017-03-22 summary:We consider task and motion planning in complex dynamic environments for problems expressed in terms of a set of Linear Temporal Logic (LTL) constraints, and a reward function. We propose a methodology based on reinforcement learning that employs deep neural networks to learn low-level control policies as well as task-level option policies. A major challenge in this setting, both for neural network approaches and classical planning, is the need to explore future worlds of a complex and interactive environment. To this end, we integrate Monte Carlo Tree Search with hierarchical neural net control policies trained on expressive LTL specifications. This paper investigates the ability of neural networks to learn both LTL constraints and control policies in order to generate task plans in complex environments. We demonstrate our approach in a simulated autonomous driving setting, where a vehicle must drive down a road in traffic, avoid collisions, and navigate an intersection, all while obeying given rules of the road. version:1
arxiv-1612-06476 | Computational Complexity of Testing Proportional Justified Representation | http://arxiv.org/abs/1612.06476 | id:1612.06476 author:Haris Aziz, Shenwei Huang category:cs.GT cs.AI 91A12  68Q15 F.2; J.4  published:2016-12-20 summary:We consider a committee voting setting in which each voter approves of a subset of candidates and based on the approvals, a target number of candidates are selected. Aziz et al. (2015) proposed two representation axioms called justified representation and extended justified representation. Whereas the former can be tested as well as achieved in polynomial time, the latter property is coNP-complete to test and no polynomial-time algorithm is known to achieve it. Interestingly, S{\'a}nchez-Fern{\'a}ndez et~al. (2016) proposed an intermediate property called proportional justified representation that admits a polynomial-time algorithm to achieve. The complexity of testing proportional justified representation has remained an open problem. In this paper, we settle the complexity by proving that testing proportional justified representation is coNP-complete. We complement the complexity result by showing that the problem admits efficient algorithms if any of the following parameters are bounded: (1) number of voters (2) number of candidates (3) maximum number of candidates approved by a voter (4) maximum number of voters approving a given candidate. version:2
arxiv-1701-08567 | Decision structure of risky choice | http://arxiv.org/abs/1701.08567 | id:1701.08567 author:Lamb Wubin, Naixin Ren category:q-fin.EC cs.AI  published:2017-01-30 summary:As we know, there is a controversy about the decision making under risk between economists and psychologists. We discuss to build a unified theory of risky choice, which would explain both of compensatory and non-compensatory theories. For risky choice, according to cognition ability, we argue that people could not build a continuous and accurate subjective probability world, but several order concepts, such as small, middle and large probability. People make decisions based on information, experience, imagination and other things. All of these things are so huge that people have to prepare some strategies. That is, people have different strategies when facing to different situations. The distributions of these things have different decision structures. More precisely, decision making is a process of simplifying the decision structure. However, the process of decision structure simplifying is not stuck in a rut, but through different path when facing problems repeatedly. It is why preference reversal always happens when making decisions. The most efficient way to simplify the decision structure is calculating expected value or making decisions based on one or two dimensions. We also argue that the deliberation time at least has four parts, which are consist of substitution time, first order time, second order time and calculation time. Decision structure also can simply explain the phenomenon of paradoxes and anomalies. JEL Codes: C10, D03, D81 version:2
arxiv-1703-07736 | Circular formation control of fixed-wing UAVs with constant speeds | http://arxiv.org/abs/1703.07736 | id:1703.07736 author:Hector Garcia de Marina, Zhiyong Sun, Murat Bronz, Gautier Hattenberger category:cs.RO cs.SY  published:2017-03-22 summary:In this paper we propose an algorithm for stabilizing circular formations of fixed-wing UAVs with constant speeds. The algorithm is based on the idea of tracking circles with different radii in order to control the inter-vehicle phases with respect to a target circumference. We prove that the desired equilibrium is exponentially stable and thanks to the guidance vector field that guides the vehicles, the algorithm can be extended to other closed trajectories. One of the main advantages of this approach is that the algorithm guarantees the confinement of the team in a specific area, even when communications or sensing among vehicles are lost. We show the effectiveness of the algorithm with an actual formation flight of three aircraft. The algorithm is ready to use for the general public in the open-source Paparazzi autopilot. version:1
arxiv-1401-7528 | A Monte-Carlo Approach to Lifespan Failure Performance Analysis of the Network Fabric in Modular Data Centers | http://arxiv.org/abs/1401.7528 | id:1401.7528 author:Reza Farrahi Moghaddam, Vahid Asghari, Fereydoun Farrahi Moghaddam, Yves Lemieux, Mohamed Cheriet category:cs.PF cs.DC cs.NI 62N05  68M15  90B25  published:2014-01-29 summary:Data centers have been evolved from a passive element of compute infrastructure to become an active, core part of any ICT solution. In particular, modular data centers (MDCs), which are a promising design approach to improve resiliency of data centers, can play a key role in deploying ICT infrastructure in remote and inhospitable environments in order to take advantage of low temperatures and hydro- and wind-electric capabilities. This is because of capability of the modular data centers to survive even in lack of continuous on-site maintenance and support. The most critical part of a data center is its network fabric that could impede the whole system even if all other components are fully functional, assuming that other analyses has been already performed to ensure the reliability of the underlying infrastructure and support systems. In this work, a complete failure analysis of modular data centers using failure models of various components including servers, switches, and links is performed using a proposed Monte-Carlo approach. The proposed Monte-Carlo approach, which is based on the concept of snapshots, allows us to effectively calculate the performance of a design along its lifespan even up to the terminal stages. To show the capabilities of the proposed approach, various network topologies, such as FatTree, BCube, MDCube, and their modifications are considered. The performance and also the lifespan of each topology design in presence of failures of their components are studied against the topology parameters. version:3
arxiv-1703-07725 | Memos: Revisiting Hybrid Memory Management in Modern Operating System | http://arxiv.org/abs/1703.07725 | id:1703.07725 author:Lei Liu, Mengyao Xie, Hao Yang category:cs.OS cs.AR  published:2017-03-22 summary:The emerging hybrid DRAM-NVM architecture is challenging the existing memory management mechanism in operating system. In this paper, we introduce memos, which can schedule memory resources over the entire memory hierarchy including cache, channels, main memory comprising DRAM and NVM simultaneously. Powered by our newly designed kernel-level monitoring module and page migration engine, memos can dynamically optimize the data placement at the memory hierarchy in terms of the on-line memory patterns, current resource utilization and feature of memory medium. Our experimental results show that memos can achieve high memory utilization, contributing to system throughput by 19.1% and QoS by 23.6% on average. Moreover, memos can reduce the NVM side memory latency by 3~83.3%, energy consumption by 25.1~99%, and benefit the NVM lifetime significantly (40X improvement on average). version:1
arxiv-1503-03974 | Hyper Temporal Networks | http://arxiv.org/abs/1503.03974 | id:1503.03974 author:Carlo Comin, Roberto Posenato, Romeo Rizzi category:cs.DS cs.AI  published:2015-03-13 summary:Simple Temporal Networks (STNs) provide a powerful and general tool for representing conjunctions of maximum delay constraints over ordered pairs of temporal variables. In this paper we introduce Hyper Temporal Networks (HyTNs), a strict generalization of STNs, to overcome the limitation of considering only conjunctions of constraints but maintaining a practical efficiency in the consistency check of the instances. In a Hyper Temporal Network a single temporal hyperarc constraint may be defined as a set of two or more maximum delay constraints which is satisfied when at least one of these delay constraints is satisfied. HyTNs are meant as a light generalization of STNs offering an interesting compromise. On one side, there exist practical pseudo-polynomial time algorithms for checking consistency and computing feasible schedules for HyTNs. On the other side, HyTNs offer a more powerful model accommodating natural constraints that cannot be expressed by STNs like Trigger off exactly delta min before (after) the occurrence of the first (last) event in a set., which are used to represent synchronization events in some process aware information systems/workflow models proposed in the literature. version:3
arxiv-1612-01855 | Communication-Avoiding Parallel Algorithms for Solving Triangular Systems of Linear Equations | http://arxiv.org/abs/1612.01855 | id:1612.01855 author:Tobias Wicky, Edgar Solomonik, Torsten Hoefler category:cs.DC cs.DS G.4  published:2016-12-06 summary:We present a new parallel algorithm for solving triangular systems with multiple right hand sides (TRSM). TRSM is used extensively in numerical linear algebra computations, both to solve triangular linear systems of equations as well as to compute factorizations with triangular matrices, such as Cholesky, LU, and QR. Our algorithm achieves better theoretical scalability than known alternatives, while maintaining numerical stability, via selective use of triangular matrix inversion. We leverage the fact that triangular inversion and matrix multiplication are more parallelizable than the standard TRSM algorithm. By only inverting triangular blocks along the diagonal of the initial matrix, we generalize the usual way of TRSM computation and the full matrix inversion approach. This flexibility leads to an efficient algorithm for any ratio of the number of right hand sides to the triangular matrix dimension. We provide a detailed communication cost analysis for our algorithm as well as for the recursive triangular matrix inversion. This cost analysis makes it possible to determine optimal block sizes and processor grids a priori. Relative to the best known algorithms for TRSM, our approach can require asymptotically fewer messages, while performing optimal amounts of computation and communication in terms of words sent. version:2
arxiv-1608-03960 | A Conflict-Free Replicated JSON Datatype | http://arxiv.org/abs/1608.03960 | id:1608.03960 author:Martin Kleppmann, Alastair R. Beresford category:cs.DC cs.DB  published:2016-08-13 summary:Many applications model their data in a general-purpose storage format such as JSON. This data structure is modified by the application as a result of user input. Such modifications are well understood if performed sequentially on a single copy of the data, but if the data is replicated and modified concurrently on multiple devices, it is unclear what the semantics should be. In this paper we present an algorithm and formal semantics for a JSON data structure that automatically resolves concurrent modifications such that no updates are lost, and such that all replicas converge towards the same state (a conflict-free replicated datatype or CRDT). It supports arbitrarily nested list and map types, which can be modified by insertion, deletion and assignment. The algorithm performs all merging client-side and does not depend on ordering guarantees from the network, making it suitable for deployment on mobile devices with poor network connectivity, in peer-to-peer networks, and in messaging systems with end-to-end encryption. version:2
arxiv-1703-07562 | Snafu: Function-as-a-Service (FaaS) Runtime Design and Implementation | http://arxiv.org/abs/1703.07562 | id:1703.07562 author:Josef Spillner category:cs.DC C.2.4; H.3.5; D.1.1  published:2017-03-22 summary:Snafu, or Snake Functions, is a modular system to host, execute and manage language-level functions offered as stateless (micro-)services to diverse external triggers. The system interfaces resemble those of commercial FaaS providers but its implementation provides distinct features which make it overall useful to research on FaaS and prototyping of FaaS-based applications. This paper argues about the system motivation in the presence of already existing alternatives, its design and architecture, the open source implementation and collected metrics which characterise the system. version:1
arxiv-1703-06659 | A Flexible Privacy-preserving Framework for Singular Value Decomposition under Internet of Things Environment | http://arxiv.org/abs/1703.06659 | id:1703.06659 author:Shuo Chen, Rongxing Lu, Jie Zhang category:cs.DC cs.CR  published:2017-03-20 summary:The singular value decomposition (SVD) is a widely used matrix factorization tool which underlies plenty of useful applications, e.g. recommendation system, abnormal detection and data compression. Under the environment of emerging Internet of Things (IoT), there would be an increasing demand for data analysis to better human's lives and create new economic growth points. Moreover, due to the large scope of IoT, most of the data analysis work should be done in the network edge, i.e. handled by fog computing. However, the devices which provide fog computing may not be trustable while the data privacy is often the significant concern of the IoT application users. Thus, when performing SVD for data analysis purpose, the privacy of user data should be preserved. Based on the above reasons, in this paper, we propose a privacy-preserving fog computing framework for SVD computation. The security and performance analysis shows the practicability of the proposed framework. Furthermore, since different applications may utilize the result of SVD operation in different ways, three applications with different objectives are introduced to show how the framework could flexibly achieve the purposes of different applications, which indicates the flexibility of the design. version:2
arxiv-1703-07491 | SUM: Sequential Scene Understanding and Manipulation | http://arxiv.org/abs/1703.07491 | id:1703.07491 author:Zhiqiang Sui, Zheming Zhou, Zhen Zeng, Odest Chadwicke Jenkins category:cs.RO  published:2017-03-22 summary:In order to perform autonomous sequential manipulation tasks, perception in cluttered scenes remains a critical challenge for robots. In this paper, we propose a probabilistic approach for robust sequential scene estimation and manipulation - Sequential Scene Understanding and Manipulation(SUM). SUM considers uncertainty due to discriminative object detection and recognition in the generative estimation of the most likely object poses maintained over time to achieve a robust estimation of the scene under heavy occlusions and unstructured environment. Our method utilizes candidates from discriminative object detector and recognizer to guide the generative process of sampling scene hypothesis, and each scene hypotheses is evaluated against the observations. Also SUM maintains beliefs of scene hypothesis over robot physical actions for better estimation and against noisy detections. We conduct extensive experiments to show that our approach is able to perform robust estimation and manipulation. version:1
arxiv-1703-07469 | RobustFill: Neural Program Learning under Noisy I/O | http://arxiv.org/abs/1703.07469 | id:1703.07469 author:Jacob Devlin, Jonathan Uesato, Surya Bhupatiraju, Rishabh Singh, Abdel-rahman Mohamed, Pushmeet Kohli category:cs.AI  published:2017-03-21 summary:The problem of automatically generating a computer program from some specification has been studied since the early days of AI. Recently, two competing approaches for automatic program learning have received significant attention: (1) neural program synthesis, where a neural network is conditioned on input/output (I/O) examples and learns to generate a program, and (2) neural program induction, where a neural network generates new outputs directly using a latent program representation. Here, for the first time, we directly compare both approaches on a large-scale, real-world learning task. We additionally contrast to rule-based program synthesis, which uses hand-crafted semantics to guide the program generation. Our neural models use a modified attention RNN to allow encoding of variable-sized sets of I/O pairs. Our best synthesis model achieves 92% accuracy on a real-world test set, compared to the 34% accuracy of the previous best neural synthesis approach. The synthesis model also outperforms a comparable induction model on this task, but we more importantly demonstrate that the strength of each approach is highly dependent on the evaluation metric and end-user application. Finally, we show that we can train our neural models to remain very robust to the type of noise expected in real-world data (e.g., typos), while a highly-engineered rule-based system fails entirely. version:1
arxiv-1703-07385 | High-Fidelity Solar Power Income Modeling for Solar-Electric UAVs: Development and Flight Test Based Verification | http://arxiv.org/abs/1703.07385 | id:1703.07385 author:Philipp Oettershagen category:cs.RO  published:2017-03-21 summary:Solar power models are a crucial element of solar-powered UAV design and performance analysis. During the conceptual design phase, their accuracy directly relates to the accuracy of the predicted performance metrics and thus the final design characteristics of the solar-powered UAV. Likewise, during the operations phase of a solar-powered UAV accurate solar power income models are required to predict and assess the solar power system performance. However, the existing literature on solar-powered UAVs uses highly simplified solar power models. This technical report therefore, first, introduces a high-fidelity solar power model that takes into account the exact aircraft attitude, aircraft geometry, and physical effects such as temperature and the sun radiation's angle-of-incidence that influence the overall solar power system efficiency. Second, models that require a reduced set of input data and are thus more appropriate for the initial design phase of solar-powered UAVs are derived from the high-fidelity model. Third, the models are compared and verified against flight data from a 28-hour continuous day/night solar-powered flight. The results indicate that our high-fidelity model allows a prediction of the average solar power income with an error of less than 5% whereas previous models were only accurate to about 18%. version:1
arxiv-1703-07384 | Ontology Based Pivoted normalization using Vector Based Approach for information Retrieval | http://arxiv.org/abs/1703.07384 | id:1703.07384 author:Vishal Jain, Dr. Mayank Singh category:cs.IR cs.AI  published:2017-03-21 summary:The proposed methodology is procedural i.e. it follows finite number of steps that extracts relevant documents according to users query. It is based on principles of Data Mining for analyzing web data. Data Mining first adapts integration of data to generate warehouse. Then, it extracts useful information with the help of algorithm. The task of representing extracted documents is done by using Vector Based Statistical Approach that represents each document in set of Terms. version:1
arxiv-1703-07381 | Improving Statistical Multimedia Information Retrieval Model by using Ontology | http://arxiv.org/abs/1703.07381 | id:1703.07381 author:Gagandeep Singh Narula, Vishal Jain category:cs.IR cs.AI  published:2017-03-21 summary:A typical IR system that delivers and stores information is affected by problem of matching between user query and available content on web. Use of Ontology represents the extracted terms in form of network graph consisting of nodes, edges, index terms etc. The above mentioned IR approaches provide relevance thus satisfying users query. The paper also emphasis on analyzing multimedia documents and performs calculation for extracted terms using different statistical formulas. The proposed model developed reduces semantic gap and satisfies user needs efficiently. version:1
arxiv-1703-07373 | FaSTrack: a Modular Framework for Fast and Guaranteed Safe Motion Planning | http://arxiv.org/abs/1703.07373 | id:1703.07373 author:Sylvia L. Herbert, Mo Chen, SooJean Han, Somil Bansal, Jaime F. Fisac, Claire J. Tomlin category:cs.RO  published:2017-03-21 summary:Fast and safe navigation of dynamical systems through a priori unknown cluttered environments is vital to many applications of autonomous systems. However, trajectory planning for autonomous systems is computationally intensive, often requiring simplified dynamics that sacrifice safety and dynamic feasibility in order to plan efficiently. Conversely, safe trajectories can be computed using more sophisticated dynamic models, but this is typically too slow to be used for real-time planning. We propose a new algorithm FaSTrack: Fast and Safe Tracking for High Dimensional systems. A path or trajectory planner using simplified dynamics to plan quickly can be incorporated into the FaSTrack framework, which provides a safety controller for the vehicle along with a guaranteed tracking error bound. This bound captures all possible deviations due to high dimensional dynamics and external disturbances. Note that FaSTrack is modular and can be used with most current path or trajectory planners. We demonstrate this framework using a 10D nonlinear quadrotor model tracking a 3D path obtained from an RRT planner. version:1
arxiv-1703-07309 | Phytoplankton Hotspot Prediction With an Unsupervised Spatial Community Model | http://arxiv.org/abs/1703.07309 | id:1703.07309 author:Arnold Kalmbach, Yogesh Girdhar, Heidi M. Sosik, Gregory Dudek category:cs.RO stat.AP  published:2017-03-21 summary:Many interesting natural phenomena are sparsely distributed and discrete. Locating the hotspots of such sparsely distributed phenomena is often difficult because their density gradient is likely to be very noisy. We present a novel approach to this search problem, where we model the co-occurrence relations between a robot's observations with a Bayesian nonparametric topic model. This approach makes it possible to produce a robust estimate of the spatial distribution of the target, even in the absence of direct target observations. We apply the proposed approach to the problem of finding the spatial locations of the hotspots of a specific phytoplankton taxon in the ocean. We use classified image data from Imaging FlowCytobot (IFCB), which automatically measures individual microscopic cells and colonies of cells. Given these individual taxon-specific observations, we learn a phytoplankton community model that characterizes the co-occurrence relations between taxa. We present experiments with simulated robot missions drawn from real observation data collected during a research cruise traversing the US Atlantic coast. Our results show that the proposed approach outperforms nearest neighbor and k-means based methods for predicting the spatial distribution of hotspots from in-situ observations. version:1
arxiv-1703-00835 | Autonomous Skill-centric Testing using Deep Learning | http://arxiv.org/abs/1703.00835 | id:1703.00835 author:Simon Hangl, Sebastian Stabinger, Justus Piater category:cs.RO  published:2017-03-02 summary:Software testing is an important tool to ensure software quality. However, testing in robotics is a hard task due to dynamic environments and the expensive development and time-consuming execution of test cases. Most testing approaches use model-based and / or simulation-based testing to overcome these problems. We propose a model-free skill-centric testing approach in which a robot autonomously executes skills in the real world and compares it to previous experiences. The robot selects specific skills in order to identify errors in the software by maximising the expected information gain. We use deep learning to model the sensor data observed during previous successful executions of a skill and to detect irregularities. This information is connected to functional profiling data such that certain misbehaviour can be related to specific functions. We evaluate our approach in simulation and in experiments with a KUKA LWR 4+ robot by purposefully introducing bugs to the software. We demonstrate that these bugs can be detected with high accuracy and without the need for the implementation of specific tests or models. version:2
arxiv-1608-02682 | Exact Structure Learning of Bayesian Networks by Optimal Path Extension | http://arxiv.org/abs/1608.02682 | id:1608.02682 author:Subhadeep Karan, Jaroslaw Zola category:cs.AI  published:2016-08-09 summary:Bayesian networks are probabilistic graphical models often used in big data analytics. The problem of exact structure learning is to find a network structure that is optimal under certain scoring criteria. The problem is known to be NP-hard and the existing methods are both computationally and memory intensive. In this paper, we introduce a new approach for exact structure learning. Our strategy is to leverage relationship between a partial network structure and the remaining variables to constraint the number of ways in which the partial network can be optimally extended. Via experimental results, we show that the method provides up to three times improvement in runtime, and orders of magnitude reduction in memory consumption over the current best algorithms. version:3
arxiv-1703-06207 | Cooperating with Machines | http://arxiv.org/abs/1703.06207 | id:1703.06207 author:Jacob W. Crandall, Mayada Oudah, Tennom, Fatimah Ishowo-Oloko, Sherief Abdallah, Jean-François Bonnefon, Manuel Cebrian, Azim Shariff, Michael A. Goodrich, Iyad Rahwan category:cs.AI  published:2017-03-17 summary:Since Alan Turing envisioned Artificial Intelligence (AI) [1], a major driving force behind technical progress has been competition with human cognition. Historical milestones have been frequently associated with computers matching or outperforming humans in difficult cognitive tasks (e.g. face recognition [2], personality classification [3], driving cars [4], or playing video games [5]), or defeating humans in strategic zero-sum encounters (e.g. Chess [6], Checkers [7], Jeopardy! [8], Poker [9], or Go [10]). In contrast, less attention has been given to developing autonomous machines that establish mutually cooperative relationships with people who may not share the machine's preferences. A main challenge has been that human cooperation does not require sheer computational power, but rather relies on intuition [11], cultural norms [12], emotions and signals [13, 14, 15, 16], and pre-evolved dispositions toward cooperation [17], common-sense mechanisms that are difficult to encode in machines for arbitrary contexts. Here, we combine a state-of-the-art machine-learning algorithm with novel mechanisms for generating and acting on signals to produce a new learning algorithm that cooperates with people and other machines at levels that rival human cooperation in a variety of two-player repeated stochastic games. This is the first general-purpose algorithm that is capable, given a description of a previously unseen game environment, of learning to cooperate with people within short timescales in scenarios previously unanticipated by algorithm designers. This is achieved without complex opponent modeling or higher-order theories of mind, thus showing that flexible, fast, and general human-machine cooperation is computationally achievable using a non-trivial, but ultimately simple, set of algorithmic mechanisms. version:2
arxiv-1703-07150 | PriMaL: A Privacy-Preserving Machine Learning Method for Event Detection in Distributed Sensor Networks | http://arxiv.org/abs/1703.07150 | id:1703.07150 author:Stefano Bennati, Catholijn M. Jonker category:cs.DC cs.CR  published:2017-03-21 summary:This paper introduces PriMaL, a general PRIvacy-preserving MAchine-Learning method for reducing the privacy cost of information transmitted through a network. Distributed sensor networks are often used for automated classification and detection of abnormal events in high-stakes situations, e.g. fire in buildings, earthquakes, or crowd disasters. Such networks might transmit privacy-sensitive information, e.g. GPS location of smartphones, which might be disclosed if the network is compromised. Privacy concerns might slow down the adoption of the technology, in particular in the scenario of social sensing where participation is voluntary, thus solutions are needed which improve privacy without compromising on the event detection accuracy. PriMaL is implemented as a machine-learning layer that works on top of an existing event detection algorithm. Experiments are run in a general simulation framework, for several network topologies and parameter values. The privacy footprint of state-of-the-art event detection algorithms is compared within the proposed framework. Results show that PriMaL is able to reduce the privacy cost of a distributed event detection algorithm below that of the corresponding centralized algorithm, within the bounds of some assumptions about the protocol. Moreover the performance of the distributed algorithm is not statistically worse than that of the centralized algorithm. version:1
arxiv-1703-07116 | Interest-Driven Discovery of Local Process Models | http://arxiv.org/abs/1703.07116 | id:1703.07116 author:Niek Tax, Benjamin Dalmas, Natalia Sidorova, Wil M P van der Aalst, Sylvie Norre category:cs.DB cs.AI  published:2017-03-21 summary:Local Process Models (LPM) describe structured fragments of process behavior occurring in the context of less structured business processes. Traditional LPM discovery aims to generate a collection of process models that describe highly frequent behavior, but these models do not always provide useful answers for questions posed by process analysts aiming at business process improvement. We propose a framework for goal-driven LPM discovery, based on utility functions and constraints. We describe four scopes on which these utility functions and constrains can be defined, and show that utility functions and constraints on different scopes can be combined to form composite utility functions/constraints. Finally, we demonstrate the applicability of our approach by presenting several actionable business insights discovered with LPM discovery on two real life data sets. version:1
arxiv-1703-06321 | Solving the Goddard problem by an influence diagram | http://arxiv.org/abs/1703.06321 | id:1703.06321 author:Jiří Vomlel, Václav Kratochvíl category:cs.AI 68T37 I.2  published:2017-03-18 summary:Influence diagrams are a decision-theoretic extension of probabilistic graphical models. In this paper we show how they can be used to solve the Goddard problem. We present results of numerical experiments with this problem and compare the solutions provided by influence diagrams with the optimal solution. version:2
arxiv-1703-07075 | Pseudorehearsal in value function approximation | http://arxiv.org/abs/1703.07075 | id:1703.07075 author:Vladimir Marochko, Leonard Johard, Manuel Mazzara category:cs.AI  published:2017-03-21 summary:Catastrophic forgetting is of special importance in reinforcement learning, as the data distribution is generally non-stationary over time. We study and compare several pseudorehearsal approaches for Q-learning with function approximation in a pole balancing task. We have found that pseudorehearsal seems to assist learning even in such very simple problems, given proper initialization of the rehearsal parameters. version:1
arxiv-1610-00700 | Footstep and Motion Planning in Semi-unstructured Environments Using Randomized Possibility Graphs | http://arxiv.org/abs/1610.00700 | id:1610.00700 author:Michael X. Grey, Aaron D. Ames, C. Karen Liu category:cs.RO  published:2016-10-01 summary:Traversing environments with arbitrary obstacles poses significant challenges for bipedal robots. In some cases, whole body motions may be necessary to maneuver around an obstacle, but most existing footstep planners can only select from a discrete set of predetermined footstep actions; they are unable to utilize the continuum of whole body motion that is truly available to the robot platform. Existing motion planners that can utilize whole body motion tend to struggle with the complexity of large-scale problems. We introduce a planning method, called the "Randomized Possibility Graph", which uses high-level approximations of constraint manifolds to rapidly explore the "possibility" of actions, thereby allowing lower-level motion planners to be utilized more efficiently. We demonstrate simulations of the method working in a variety of semi-unstructured environments. In this context, "semi-unstructured" means the walkable terrain is flat and even, but there are arbitrary 3D obstacles throughout the environment which may need to be stepped over or maneuvered around using whole body motions. version:3
arxiv-1703-06939 | Distributed Constraint Problems for Utilitarian Agents with Privacy Concerns, Recast as POMDPs | http://arxiv.org/abs/1703.06939 | id:1703.06939 author:Julien Savaux, Julien Vion, Sylvain Piechowiak, René Mandiau, Toshihiro Matsui, Katsutoshi Hirayama, Makoto Yokoo, Shakre Elmane, Marius Silaghi category:cs.AI  published:2017-03-20 summary:Privacy has traditionally been a major motivation for distributed problem solving. Distributed Constraint Satisfaction Problem (DisCSP) as well as Distributed Constraint Optimization Problem (DCOP) are fundamental models used to solve various families of distributed problems. Even though several approaches have been proposed to quantify and preserve privacy in such problems, none of them is exempt from limitations. Here we approach the problem by assuming that computation is performed among utilitarian agents. We introduce a utilitarian approach where the utility of each state is estimated as the difference between the reward for reaching an agreement on assignments of shared variables and the cost of privacy loss. We investigate extensions to solvers where agents integrate the utility function to guide their search and decide which action to perform, defining thereby their policy. We show that these extended solvers succeed in significantly reducing privacy loss without significant degradation of the solution quality. version:1
arxiv-1703-06597 | Artificial Intelligence and Economic Theories | http://arxiv.org/abs/1703.06597 | id:1703.06597 author:Tshilidzi Marwala, Evan Hurwitz category:cs.AI  published:2017-03-20 summary:The advent of artificial intelligence has changed many disciplines such as engineering, social science and economics. Artificial intelligence is a computational technique which is inspired by natural intelligence such as the swarming of birds, the working of the brain and the pathfinding of the ants. These techniques have impact on economic theories. This book studies the impact of artificial intelligence on economic theories, a subject that has not been extensively studied. The theories that are considered are: demand and supply, asymmetrical information, pricing, rational choice, rational expectation, game theory, efficient market hypotheses, mechanism design, prospect, bounded rationality, portfolio theory, rational counterfactual and causality. The benefit of this book is that it evaluates existing theories of economics and update them based on the developments in artificial intelligence field. version:1
arxiv-1703-06590 | Proceedings International Workshop on Formal Engineering approaches to Software Components and Architectures | http://arxiv.org/abs/1703.06590 | id:1703.06590 author:Jan Kofroň, Jana Tumova category:cs.SE cs.DC  published:2017-03-20 summary:These are the proceedings of the 14th International Workshop on Formal Engineering approaches to Software Components and Architectures (FESCA). The workshop was held on April 22, 2017 in Uppsala (Sweden) as a satellite event to the European Joint Conference on Theory and Practice of Software (ETAPS'17). The aim of the FESCA workshop is to bring together junior researchers from formal methods, software engineering, and industry interested in the development and application of formal modelling approaches as well as associated analysis and reasoning techniques with practical benefits for software engineering. In recent years, the growing importance of functional correctness and the increased relevance of system quality properties (e.g. performance, reliability, security) have stimulated the emergence of analytical and modelling techniques for the design and development of software systems. With the increasing complexity and utilization of today's software systems, FESCA aims at addressing two research questions: (1) what role is played by the software design phase in the systematic addressing of the analytical and modelling challenges, and (2) how can formal and semi-formal techniques be effectively applied to make the issues easier to address automatically, with lower human intervention. version:1
arxiv-1703-06578 | Towards Probabilistic Formal Modeling of Robotic Cell Injection Systems | http://arxiv.org/abs/1703.06578 | id:1703.06578 author:Muhammad Usama Sardar, Osman Hasan category:cs.LO cs.CE cs.RO  published:2017-03-20 summary:Cell injection is a technique in the domain of biological cell micro-manipulation for the delivery of small volumes of samples into the suspended or adherent cells. It has been widely applied in various areas, such as gene injection, in-vitro fertilization (IVF), intracytoplasmic sperm injection (ISCI) and drug development. However, the existing manual and semi-automated cell injection systems require lengthy training and suffer from high probability of contamination and low success rate. In the recently introduced fully automated cell injection systems, the injection force plays a vital role in the success of the process since even a tiny excessive force can destroy the membrane or tissue of the biological cell. Traditionally, the force control algorithms are analyzed using simulation, which is inherently non-exhaustive and incomplete in terms of detecting system failures. Moreover, the uncertainties in the system are generally ignored in the analysis. To overcome these limitations, we present a formal analysis methodology based on probabilistic model checking to analyze a robotic cell injection system utilizing the impedance force control algorithm. The proposed methodology, developed using the PRISM model checker, allowed to find a discrepancy in the algorithm, which was not found by any of the previous analysis using the traditional methods. version:1
arxiv-1703-06577 | The Unheralded Value of the Multiway Rendezvous: Illustration with the Production Cell Benchmark | http://arxiv.org/abs/1703.06577 | id:1703.06577 author:Hubert Garavel, Wendelin Serwe category:cs.PL cs.DC  published:2017-03-20 summary:The multiway rendezvous introduced in Theoretical CSP is a powerful paradigm to achieve synchronization and communication among a group of (possibly more than two) processes. We illustrate the advantages of this paradigm on the production cell benchmark, a model of a real metal processing plant, for which we propose a compositional software controller, which is written in LNT and LOTOS, and makes intensive use of the multiway rendezvous. version:1
arxiv-1703-06571 | Formalizing Memory Accesses and Interrupts | http://arxiv.org/abs/1703.06571 | id:1703.06571 author:Reto Achermann, Lukas Humbel, David Cock, Timothy Roscoe category:cs.OS cs.AR  published:2017-03-20 summary:The hardware/software boundary in modern heterogeneous multicore computers is increasingly complex, and diverse across different platforms. A single memory access by a core or DMA engine traverses multiple hardware translation and caching steps, and the destination memory cell or register often appears at different physical addresses for different cores. Interrupts pass through a complex topology of interrupt controllers and remappers before delivery to one or more cores, each with specific constraints on their configurations. System software must not only correctly understand the specific hardware at hand, but also configure it appropriately at runtime. We propose a formal model of address spaces and resources in a system that allows us to express and verify invariants of the system's runtime configuration, and illustrate (and motivate) it with several real platforms we have encountered in the process of OS implementation. version:1
arxiv-1701-00180 | A scalable approach for tree segmentation within small-footprint airborne LiDAR data | http://arxiv.org/abs/1701.00180 | id:1701.00180 author:Hamid Hamraz, Marco A. Contreras, Jun Zhang category:cs.DC cs.CE  published:2017-01-01 summary:This paper presents a distributed approach that scales up to segment tree crowns within a LiDAR point cloud representing an arbitrarily large forested area. The approach uses a single-processor tree segmentation algorithm as a building block in order to process the data delivered in the shape of tiles in parallel. The distributed processing is performed in a master-slave manner, in which the master maintains the global map of the tiles and coordinates the slaves that segment tree crowns within and across the boundaries of the tiles. A minimal bias was introduced to the number of detected trees because of trees lying across the tile boundaries, which was quantified and adjusted for. Theoretical and experimental analyses of the runtime of the approach revealed a near linear speedup. The estimated number of trees categorized by crown class and the associated error margins as well as the height distribution of the detected trees aligned well with field estimations, verifying that the distributed approach works correctly. The approach enables providing information of individual tree locations and point cloud segments for a forest-level area in a timely manner, which can be used to create detailed remotely sensed forest inventories. Although the approach was presented for tree segmentation within LiDAR point clouds, the idea can also be generalized to scale up processing other big spatial datasets. Highlights: - A scalable distributed approach for tree segmentation was developed and theoretically analyzed. - ~2 million trees in a 7440 ha forest was segmented in 2.5 hours using 192 cores. - 2% false positive trees were identified as a result of the distributed run. - The approach can be used to scale up processing other big spatial data version:2
arxiv-1703-06503 | CLTune: A Generic Auto-Tuner for OpenCL Kernels | http://arxiv.org/abs/1703.06503 | id:1703.06503 author:Cedric Nugteren, Valeriu Codreanu category:cs.PF cs.AI cs.DC  published:2017-03-19 summary:This work presents CLTune, an auto-tuner for OpenCL kernels. It evaluates and tunes kernel performance of a generic, user-defined search space of possible parameter-value combinations. Example parameters include the OpenCL workgroup size, vector data-types, tile sizes, and loop unrolling factors. CLTune can be used in the following scenarios: 1) when there are too many tunable parameters to explore manually, 2) when performance portability across OpenCL devices is desired, or 3) when the optimal parameters change based on input argument values (e.g. matrix dimensions). The auto-tuner is generic, easy to use, open-source, and supports multiple search strategies including simulated annealing and particle swarm optimisation. CLTune is evaluated on two GPU case-studies inspired by the recent successes in deep learning: 2D convolution and matrix-multiplication (GEMM). For 2D convolution, we demonstrate the need for auto-tuning by optimizing for different filter sizes, achieving performance on-par or better than the state-of-the-art. For matrix-multiplication, we use CLTune to explore a parameter space of more than two-hundred thousand configurations, we show the need for device-specific tuning, and outperform the clBLAS library on NVIDIA, AMD and Intel GPUs. version:1
arxiv-1703-06471 | Multi-Timescale, Gradient Descent, Temporal Difference Learning with Linear Options | http://arxiv.org/abs/1703.06471 | id:1703.06471 author:Peeyush Kumar, Doina Precup category:cs.AI  published:2017-03-19 summary:Deliberating on large or continuous state spaces have been long standing challenges in reinforcement learning. Temporal Abstraction have somewhat made this possible, but efficiently planing using temporal abstraction still remains an issue. Moreover using spatial abstractions to learn policies for various situations at once while using temporal abstraction models is an open problem. We propose here an efficient algorithm which is convergent under linear function approximation while planning using temporally abstract actions. We show how this algorithm can be used along with randomly generated option models over multiple time scales to plan agents which need to act real time. Using these randomly generated option models over multiple time scales are shown to reduce number of decision epochs required to solve the given task, hence effectively reducing the time needed for deliberation. version:1
arxiv-1703-06416 | A Passivity-Based Distributed Reference Governor for Constrained Robotic Networks | http://arxiv.org/abs/1703.06416 | id:1703.06416 author:Tam Nguyen, Takeshi Hatanaka, Mamoru Doi, Emanuele Garone, Masayuki Fujita category:cs.MA cs.DC cs.RO cs.SY  published:2017-03-19 summary:This paper focuses on a passivity-based distributed reference governor (RG) applied to a pre-stabilized mobile robotic network. The novelty of this paper lies in the method used to solve the RG problem, where a passivity-based distributed optimization scheme is proposed. In particular, the gradient descent method minimizes the global objective function while the dual ascent method maximizes the Hamiltonian. To make the agents converge to the agreed optimal solution, a proportional-integral consensus estimator is used. This paper proves the convergence of the state estimates of the RG to the optimal solution through passivity arguments, considering the physical system static. Then, the effectiveness of the scheme considering the dynamics of the physical system is demonstrated through simulations and experiments. version:1
arxiv-1703-06409 | Internet of Things: An Overview | http://arxiv.org/abs/1703.06409 | id:1703.06409 author:Farzad Khodadadi, Amir Vahid Dastjerdi, Rajkumar Buyya category:cs.DC cs.NI  published:2017-03-19 summary:As technology proceeds and the number of smart devices continues to grow substantially, need for ubiquitous context-aware platforms that support interconnected, heterogeneous, and distributed network of devices has given rise to what is referred today as Internet-of-Things. However, paving the path for achieving aforementioned objectives and making the IoT paradigm more tangible requires integration and convergence of different knowledge and research domains, covering aspects from identification and communication to resource discovery and service integration. Through this chapter, we aim to highlight researches in topics including proposed architectures, security and privacy, network communication means and protocols, and eventually conclude by providing future directions and open challenges facing the IoT development. version:1
arxiv-1703-06391 | Multirole Logic (Extended Abstract) | http://arxiv.org/abs/1703.06391 | id:1703.06391 author:Hongwei Xi, Hanwen Wu category:math.LO cs.DC cs.LO cs.PL  published:2017-03-19 summary:We identify multirole logic as a new form of logic in which conjunction/disjunction is interpreted as an ultrafilter on the power set of some underlying set (of roles) and the notion of negation is generalized to endomorphisms on this underlying set. We formalize both multirole logic (MRL) and linear multirole logic (LMRL) as natural generalizations of classical logic (CL) and classical linear logic (CLL), respectively, and also present a filter-based interpretation for intuitionism in multirole logic. Among various meta-properties established for MRL and LMRL, we obtain one named multiparty cut-elimination stating that every cut involving one or more sequents (as a generalization of a (binary) cut involving exactly two sequents) can be eliminated, thus extending the celebrated result of cut-elimination by Gentzen. version:1
arxiv-1703-06387 | An opportunistic linear-convex algorithm for localization in mobile robot networks | http://arxiv.org/abs/1703.06387 | id:1703.06387 author:Sam Safavi, Usman Khan category:cs.RO cs.SY  published:2017-03-19 summary:In this paper, we develop a \textcolor{black}{\emph{distributed}} algorithm to localize a network of robots moving arbitrarily in a bounded region. In the case of such mobile networks, the main challenge is that the robots may not be able to find nearby robots to implement a distributed algorithm. We address this issue by providing an opportunistic algorithm that only implements a location update when there are nearby robots and does not update otherwise. We assume that each robot measures a noisy version of its motion and the distances to the nearby robots. To localize a network of mobile robots in~$\mathbb{R}^m$, we provide a simple \emph{linear} update, which is based on barycentric coordinates and is linear-convex. We abstract the corresponding localization algorithm as a Linear Time-Varying (LTV) system and show that it asymptotically converges to the true locations~of~the robots. We first focus on the noiseless case, where the distance and motion vectors are known (measured) perfectly, and provide sufficient conditions on the convergence of the algorithm. We then evaluate the performance of the algorithm in the presence of noise and provide modifications to counter the undesirable effects of noise. \textcolor{black}{We further show that our algorithm precisely tracks a mobile network as long as there is at least one known beacon (a node whose location is perfectly known). version:1
arxiv-1703-06354 | Goal Conflict in Designing an Autonomous Artificial System | http://arxiv.org/abs/1703.06354 | id:1703.06354 author:Mark Muraven category:cs.AI  published:2017-03-18 summary:Research on human self-regulation has shown that people hold many goals simultaneously and have complex self-regulation mechanisms to deal with this goal conflict. Artificial autonomous systems may also need to find ways to cope with conflicting goals. Indeed, the intricate interplay among different goals may be critical to the design as well as long-term safety and stability of artificial autonomous systems. I discuss some of the critical features of the human self-regulation system and how it might be applied to an artificial system. Furthermore, the implications of goal conflict for the reliability and stability of artificial autonomous systems and ensuring their alignment with human goals and ethics is examined. version:1
arxiv-1703-06320 | Hardware-Efficient Schemes of Quaternion Multiplying Units for 2D Discrete Quaternion Fourier Transform Processors | http://arxiv.org/abs/1703.06320 | id:1703.06320 author:Aleksandr Cariow, Galina Cariowa, Marina Chicheva category:cs.DS cs.AR  published:2017-03-18 summary:In this paper, we offer and discuss three efficient structural solutions for the hardware-oriented implementation of discrete quaternion Fourier transform basic operations with reduced implementation complexities. The first solution: a scheme for calculating sq product, the second solution: a scheme for calculating qt product, and the third solution: a scheme for calculating sqt product, where s is a so-called i-quaternion, t is an j-quaternion, and q is an usual quaternion. The direct multiplication of two usual quaternions requires 16 real multiplications (or two-operand multipliers in the case of fully parallel hardware implementation) and 12 real additions (or binary adders). At the same time, our solutions allow to design the computation units, which consume only 6 multipliers plus 6 two input adders for implementation of sq or qt basic operations and 9 binary multipliers plus 6 two-input adders and 4 four-input adders for implementation of sqt basic operation. version:1
arxiv-1411-7812 | Elections with Few Voters: Candidate Control Can Be Easy | http://arxiv.org/abs/1411.7812 | id:1411.7812 author:Jiehua Chen, Piotr Faliszewski, Rolf Niedermeier, Nimrod Talmon category:cs.AI cs.GT cs.MA  published:2014-11-28 summary:We study the computational complexity of candidate control in elections with few voters, that is, we consider the parameterized complexity of candidate control in elections with respect to the number of voters as a parameter. We consider both the standard scenario of adding and deleting candidates, where one asks whether a given candidate can become a winner (or, in the destructive case, can be precluded from winning) by adding or deleting few candidates, as well as a combinatorial scenario where adding/deleting a candidate automatically means adding or deleting a whole group of candidates. Considering several fundamental voting rules, our results show that the parameterized complexity of candidate control, with the number of voters as the parameter, is much more varied than in the setting with many voters. version:2
arxiv-1705-01080 | The N-Tuple Bandit Evolutionary Algorithm for Automatic Game Improvement | http://arxiv.org/abs/1705.01080 | id:1705.01080 author:Kamolwan Kunanusont, Raluca D. Gaina, Jialin Liu, Diego Perez-Liebana, Simon M. Lucas category:cs.AI  published:2017-03-18 summary:This paper describes a new evolutionary algorithm that is especially well suited to AI-Assisted Game Design. The approach adopted in this paper is to use observations of AI agents playing the game to estimate the game's quality. Some of best agents for this purpose are General Video Game AI agents, since they can be deployed directly on a new game without game-specific tuning; these agents tend to be based on stochastic algorithms which give robust but noisy results and tend to be expensive to run. This motivates the main contribution of the paper: the development of the novel N-Tuple Bandit Evolutionary Algorithm, where a model is used to estimate the fitness of unsampled points and a bandit approach is used to balance exploration and exploitation of the search space. Initial results on optimising a Space Battle game variant suggest that the algorithm offers far more robust results than the Random Mutation Hill Climber and a Biased Mutation variant, which are themselves known to offer competitive performance across a range of problems. Subjective observations are also given by human players on the nature of the evolved games, which indicate a preference towards games generated by the N-Tuple algorithm. version:1
arxiv-1703-06275 | Evolving Game Skill-Depth using General Video Game AI Agents | http://arxiv.org/abs/1703.06275 | id:1703.06275 author:Jialin Liu, Julian Togelius, Diego Perez-Liebana, Simon M. Lucas category:cs.AI  published:2017-03-18 summary:Most games have, or can be generalised to have, a number of parameters that may be varied in order to provide instances of games that lead to very different player experiences. The space of possible parameter settings can be seen as a search space, and we can therefore use a Random Mutation Hill Climbing algorithm or other search methods to find the parameter settings that induce the best games. One of the hardest parts of this approach is defining a suitable fitness function. In this paper we explore the possibility of using one of a growing set of General Video Game AI agents to perform automatic play-testing. This enables a very general approach to game evaluation based on estimating the skill-depth of a game. Agent-based play-testing is computationally expensive, so we compare two simple but efficient optimisation algorithms: the Random Mutation Hill-Climber and the Multi-Armed Bandit Random Mutation Hill-Climber. For the test game we use a space-battle game in order to provide a suitable balance between simulation speed and potential skill-depth. Results show that both algorithms are able to rapidly evolve game versions with significant skill-depth, but that choosing a suitable resampling number is essential in order to combat the effects of noise. version:1
arxiv-1703-03905 | DotDFS: A Grid-based high-throughput file transfer system | http://arxiv.org/abs/1703.03905 | id:1703.03905 author:Alireza Poshtkohi, M. B. Ghaznavi-Ghoushchi category:cs.DC  published:2017-03-11 summary:DotGrid platform is a Grid infrastructure integrated with a set of open and standard protocols recently implemented on the top of Microsoft .NET in Windows and MONO .NET in UNIX/Linux. DotGrid infrastructure along with its proposed protocols provides a right and solid approach to targeting other platforms, e.g., the native C/C++ runtime. In this paper, we propose a new file transfer protocol called DotDFS as a high-throughput distributed file transfer component for DotGrid. DotDFS introduces some open binary protocols for efficient file transfers on current Grid infrastructures. DotDFS protocol also provides mechanisms for multiple file streams to gain high-throughput file transfer similar to GridFTP protocol, but by proposing and implementing a new parallel TCP connection-oriented paradigm. In our LAN tests, we have achieved better results than Globus GridFTP implementation particularly in multiple TCP streams and directory tree transfers. Our LAN experiences in memory-to-memory tests show that DotDFS accesses to the 94% bottleneck bandwidth while GridFTP is accessing 91%. In LAN disk-to-disk tests, comparing DotDFS protocol with GridFTP protocol unveils a set of interesting and technical problems in GridFTP for both the nature of the protocol and its implementation by Globus. In the WAN experimental studies, we propose a new idea for analytical modeling of file transfer protocols like DotDFS inspired by sampling, experimentation and mathematical interpolation approaches. The cross-platform and open standard-based features of DotDFS provide a substantial framework for unifying data access and resource sharing in real heterogeneous Grid environments. version:2
arxiv-1703-06261 | Cooperative Localisation of a GPS-Denied UAV in 3-Dimensional Space Using Direction of Arrival Measurements | http://arxiv.org/abs/1703.06261 | id:1703.06261 author:James Russell, Mengbin Ye, Brian D. O. Anderson, Hatem Hmam, Peter Sarunic category:cs.RO cs.MA cs.SY  published:2017-03-18 summary:This paper presents a novel approach for localising a GPS (Global Positioning System)-denied Unmanned Aerial Vehicle (UAV) with the aid of a GPS-equipped UAV in three-dimensional space. The GPS-equipped UAV makes discrete-time broadcasts of its global coordinates. The GPS-denied UAV simultaneously receives the broadcast and takes direction of arrival (DOA) measurements towards the origin of the broadcast in its local coordinate frame (obtained via an inertial navigation system (INS)). The aim is to determine the difference between the local and global frames, described by a rotation and a translation. In the noiseless case, global coordinates were recovered exactly by solving a system of linear equations. When DOA measurements are contaminated with noise, rank relaxed semidefinite programming (SDP) and the Orthogonal Procrustes algorithm are employed. Simulations are provided and factors affecting accuracy, such as noise levels and number of measurements, are explored. version:1
arxiv-1703-06161 | Risk Proneness Estimation Method Developed in Relation to the Decision Taker that Controls the Robotic System | http://arxiv.org/abs/1703.06161 | id:1703.06161 author:Valery Vilisov category:cs.RO cs.HC  published:2017-03-17 summary:This work suggests the estimation method developed in relation to the position of the robotic system (RS) operator, showing his degree of risk proneness. The base models are: Hurwitz pessimism/optimism criterion and decision trees. The problem is solved using the reverse setting: we estimate pessimism/optimism parameter of the operator (decision taker) by observing what decisions he makes when controlling the RS. The solution context of such decision taker position estimation problems can be: using RS in emergency situations, in military actions and other situations connected with the uncertainty of the situation. version:1
