arxiv-1705-03127 | Word and Phrase Translation with word2vec | http://arxiv.org/abs/1705.03127 | id:1705.03127 author:Stefan Jansen category:cs.CL cs.AI  published:2017-05-09 summary:Word and phrase tables are key inputs to machine translations, but costly to produce. New unsupervised learning methods represent words and phrases in a high-dimensional vector space, and these monolingual embeddings have been shown to encode syntactic and semantic relationships between language elements. The information captured by these embeddings can be exploited for bilingual translation by learning a transformation matrix that allows to match relative positions across two monolingual vector spaces. This method aims to identify high-quality candidates for word and phrase translation more cost-effectively from unlabeled data. This paper expands the scope of previous attempts of bilingual translation to four languages (English, German, Spanish, and French). It shows how to process the source data, train a neural network to learn the high-dimensional embeddings for individual languages and expands the framework for testing their quality beyond the English language. Furthermore, it shows how to learn bilingual transformation matrices and obtain candidates for word and phrase translation, and assess their quality. version:3
arxiv-1705-04590 | Distributed-Memory Breadth-First Search on Massive Graphs | http://arxiv.org/abs/1705.04590 | id:1705.04590 author:Aydin Buluc, Scott Beamer, Kamesh Madduri, Krste Asanovic, David Patterson category:cs.DC  published:2017-05-10 summary:This chapter studies the problem of traversing large graphs using the breadth-first search order on distributed-memory supercomputers. We consider both the traditional level-synchronous top-down algorithm as well as the recently discovered direction optimizing algorithm. We analyze the performance and scalability trade-offs in using different local data structures such as CSR and DCSC, enabling in-node multithreading, and graph decompositions such as 1D and 2D decomposition. version:1
arxiv-1704-04374 | HPTT: A High-Performance Tensor Transposition C++ Library | http://arxiv.org/abs/1704.04374 | id:1704.04374 author:Paul Springer, Tong Su, Paolo Bientinesi category:cs.MS cs.DC cs.PF G.4; D.1.3  published:2017-04-14 summary:Recently we presented TTC, a domain-specific compiler for tensor transpositions. Despite the fact that the performance of the generated code is nearly optimal, due to its offline nature, TTC cannot be utilized in all the application codes in which the tensor sizes and the necessary tensor permutations are determined at runtime. To overcome this limitation, we introduce the open-source C++ library High-Performance Tensor Transposition (HPTT). Similar to TTC, HPTT incorporates optimizations such as blocking, multi-threading, and explicit vectorization; furthermore it decomposes any transposition into multiple loops around a so called micro-kernel. This modular design---inspired by BLIS---makes HPTT easy to port to different architectures, by only replacing the hand-vectorized micro-kernel (e.g., a 4x4 transpose). HPTT also offers an optional autotuning framework---guided by a performance model---that explores a vast search space of implementations at runtime (similar to FFTW). Across a wide range of different tensor transpositions and architectures (e.g., Intel Ivy Bridge, Intel Knights Landing, ARMv7, IBM Power7), HPTT attains a bandwidth comparable to that of SAXPY, and yields remarkable speedups over Eigen's tensor transposition implementation. Most importantly, the integration of HPTT into the Cyclops Tensor Framework (CTF) improves the overall performance of tensor contractions by up to 3.1x. version:2
arxiv-1705-03916 | Solving Distributed Constraint Optimization Problems Using Logic Programming | http://arxiv.org/abs/1705.03916 | id:1705.03916 author:Tiep Le, Tran Cao Son, Enrico Pontelli, William Yeoh category:cs.MA cs.AI  published:2017-05-10 summary:This paper explores the use of Answer Set Programming (ASP) in solving Distributed Constraint Optimization Problems (DCOPs). The paper provides the following novel contributions: (1) It shows how one can formulate DCOPs as logic programs; (2) It introduces ASP-DPOP, the first DCOP algorithm that is based on logic programming; (3) It experimentally shows that ASP-DPOP can be up to two orders of magnitude faster than DPOP (its imperative programming counterpart) as well as solve some problems that DPOP fails to solve, due to memory limitations; and (4) It demonstrates the applicability of ASP in a wide array of multi-agent problems currently modeled as DCOPs. Under consideration in Theory and Practice of Logic Programming (TPLP). version:1
arxiv-1705-03876 | Constant Space and Non-Constant Time in Distributed Computing | http://arxiv.org/abs/1705.03876 | id:1705.03876 author:Tuomo Lempiäinen, Jukka Suomela category:cs.DC cs.CC F.1.3; F.2.2  published:2017-05-10 summary:While the relationship of time and space is an established topic in traditional centralised complexity theory, this is not the case in distributed computing. We aim to remedy this by studying the time and space complexity of algorithms in a weak message-passing model of distributed computing. While a constant number of communication rounds implies a constant number of states visited during the execution, the other direction is not clear at all. We consider several graph families and show that indeed, there exist non-trivial graph problems that are solvable by constant-space algorithms but that require a non-constant running time. This provides us with a new complexity class for distributed computing and raises interesting questions about the existence of further combinations of time and space complexity. version:1
arxiv-1703-09845 | Bringing Salary Transparency to the World: Computing Robust Compensation Insights via LinkedIn Salary | http://arxiv.org/abs/1703.09845 | id:1703.09845 author:Krishnaram Kenthapadi, Stuart Ambler, Liang Zhang, Deepak Agarwal category:cs.SI cs.AI cs.IR  published:2017-03-29 summary:The recently launched LinkedIn Salary product has been designed to realize the vision of helping the world's professionals optimize their earning potential through salary transparency. We describe the overall design and architecture of the salary modeling system underlying this product. We focus on the unique data mining challenges in designing and implementing the system, and describe the modeling components such as outlier detection and Bayesian hierarchical smoothing that help to compute and present robust compensation insights to users. We report on extensive evaluation with nearly one year of anonymized compensation data collected from over one million LinkedIn users, thereby demonstrating the efficacy of the statistical models. We also highlight the lessons learned through the deployment of our system at LinkedIn. version:2
arxiv-1705-03834 | Tight Bounds for Asynchronous Collaborative Grid Exploration | http://arxiv.org/abs/1705.03834 | id:1705.03834 author:Sebastian Brandt, Jara Uitto, Roger Wattenhofer category:cs.DC F.2.2  published:2017-05-10 summary:Consider a small group of mobile agents whose goal is to locate a certain cell in a two-dimensional infinite grid. The agents operate in an asynchronous environment, where in each discrete time step, an arbitrary subset of the agents execute one atomic look-compute-move cycle. The protocol controlling each agent is determined by a (possibly distinct) finite automaton. The only means of communication is to sense the states of the agents sharing the same grid cell. Whenever an agent moves, the destination cell of the movement is chosen by the agent's automaton from the set of neighboring grid cells. We study the minimum number of agents required to locate the target cell within finite time and our main result states a tight lower bound for agents endowed with a global compass. Furthermore, we show that the lack of such a compass makes the problem strictly more difficult and present tight upper and lower bounds for this case. version:1
arxiv-1705-04530 | A Survey of Question Answering for Math and Science Problem | http://arxiv.org/abs/1705.04530 | id:1705.04530 author:Arindam Bhattacharya category:cs.AI  published:2017-05-10 summary:Turing test was long considered the measure for artificial intelligence. But with the advances in AI, it has proved to be insufficient measure. We can now aim to mea- sure machine intelligence like we measure human intelligence. One of the widely accepted measure of intelligence is standardized math and science test. In this paper, we explore the progress we have made towards the goal of making a machine smart enough to pass the standardized test. We see the challenges and opportunities posed by the domain, and note that we are quite some ways from actually making a system as smart as a even a middle school scholar. version:1
arxiv-1612-06090 | Performance Optimisation of Smoothed Particle Hydrodynamics Algorithms for Multi/Many-Core Architectures | http://arxiv.org/abs/1612.06090 | id:1612.06090 author:Fabio Baruffa, Luigi Iapichino, Nicolay J. Hammer, Vasileios Karakasis category:cs.DC astro-ph.IM physics.comp-ph  published:2016-12-19 summary:We describe a strategy for code modernisation of Gadget, a widely used community code for computational astrophysics. The focus of this work is on node-level performance optimisation, targeting current multi/many-core IntelR architectures. We identify and isolate a sample code kernel, which is representative of a typical Smoothed Particle Hydrodynamics (SPH) algorithm. The code modifications include threading parallelism optimisation, change of the data layout into Structure of Arrays (SoA), auto-vectorisation and algorithmic improvements in the particle sorting. We obtain shorter execution time and improved threading scalability both on Intel XeonR ($2.6 \times$ on Ivy Bridge) and Xeon PhiTM ($13.7 \times$ on Knights Corner) systems. First few tests of the optimised code result in $19.1 \times$ faster execution on second generation Xeon Phi (Knights Landing), thus demonstrating the portability of the devised optimisation solutions to upcoming architectures. version:2
arxiv-1705-03773 | Flexible and Creative Chinese Poetry Generation Using Neural Memory | http://arxiv.org/abs/1705.03773 | id:1705.03773 author:Jiyuan Zhang, Yang Feng, Dong Wang, Yang Wang, Andrew Abel, Shiyue Zhang, Andi Zhang category:cs.AI cs.CL  published:2017-05-10 summary:It has been shown that Chinese poems can be successfully generated by sequence-to-sequence neural models, particularly with the attention mechanism. A potential problem of this approach, however, is that neural models can only learn abstract rules, while poem generation is a highly creative process that involves not only rules but also innovations for which pure statistical models are not appropriate in principle. This work proposes a memory-augmented neural model for Chinese poem generation, where the neural model and the augmented memory work together to balance the requirements of linguistic accordance and aesthetic innovation, leading to innovative generations that are still rule-compliant. In addition, it is found that the memory mechanism provides interesting flexibility that can be used to generate poems with different styles. version:1
arxiv-1705-03751 | A Survey of Distant Supervision Methods using PGMs | http://arxiv.org/abs/1705.03751 | id:1705.03751 author:Gagan Madan category:cs.AI cs.CL  published:2017-05-10 summary:Relation Extraction refers to the task of populating a database with tuples of the form $r(e_1, e_2)$, where $r$ is a relation and $e_1$, $e_2$ are entities. Distant supervision is one such technique which tries to automatically generate training examples based on an existing KB such as Freebase. This paper is a survey of some of the techniques in distant supervision which primarily rely on Probabilistic Graphical Models (PGMs). version:1
arxiv-1705-03704 | Global-Local View: Scalable Consistency for Concurrent Data Types | http://arxiv.org/abs/1705.03704 | id:1705.03704 author:Deepthi Devaki Akkoorath, José Brandão, Annette Bieniusa, Carlos Baquero category:cs.DC  published:2017-05-10 summary:Concurrent linearizable access to shared objects can be prohibitively expensive in a high contention workload. Many applications apply ad-hoc techniques to eliminate the need of synchronous atomic updates, which may result in non-linearizable implementations. We propose a new programming model which leverages such patterns for concurrent access to objects in a shared memory system. In this model, each thread maintains different views on the shared object - a thread-local view and a global view. As the thread-local view is not shared, it can be updated without incurring synchronization costs. These local updates become visible to other threads only after the thread-local view is merged with the global view. This enables better performance at the expense of linearizability. We show that it is possible to maintain thread-local views and to perform merge efficiently for several data types and evaluate their performance and scalability compared to linearizable implementations. Further, we discuss the consistency semantics of the data types and the associated programming model. version:1
arxiv-1705-02515 | Epistemic Model Checking of Atomic Commitment Protocols with Byzantine Failures | http://arxiv.org/abs/1705.02515 | id:1705.02515 author:Omar Al-Bataineh category:cs.DC cs.LO  published:2017-05-06 summary:The notion of knowledge-based program introduced by Halpern and Fagin provides a useful formalism for designing, analysing, and optimising distributed systems. This paper formulates the two phase commit protocol as a knowledge-based program and then an iterative process of model checking and counter-example guided refinement is followed to find concrete implementations of the program for the case of perfect recall semantic in the Byzantine failures context with synchronous reliable communication. We model several different kinds of Byzantine failures and verify different strategies to fight and mitigate them. We address a number of questions that have not been considered in the prior literature, viz., under what circumstances a sender can know that its transmission has been successful, and under what circumstances an agent can know that the coordinator is cheating, and find concrete answers to these questions. The paper describes also a methodology based on temporal-epistemic model checking technology that can be followed to verify the shortest and longest execution time of a distributed protocol and the scenarios that lead to them. version:3
arxiv-1612-01845 | Transient Provisioning and Performance Evaluation for Cloud Computing Platforms: A Capacity Value Approach | http://arxiv.org/abs/1612.01845 | id:1612.01845 author:Brendan Patch, Thomas Taimre category:cs.DC  published:2016-12-06 summary:User demand on the computational resources of cloud computing platforms varies over time. These variations in demand can be predictable or unpredictable, resulting in `bursty' fluctuations in demand. Furthermore, demand can arrive in batches, and users whose demands are not met can be impatient. We demonstrate how to compute the expected revenue loss over a finite time horizon in the presence of all these model characteristics through the use of matrix analytic methods. We then illustrate how to use this knowledge to make frequent short term provisioning decisions --- transient provisioning. It is seen that taking each of the characteristics of fluctuating user demand (predictable, unpredictable, batchy) into account can result in a substantial reduction of losses. Moreover, our transient provisioning framework allows for a wide variety of system behaviors to be modeled and gives simple expressions for expected revenue loss which are straightforward to evaluate numerically. version:4
arxiv-1705-03669 | Mind the Gap: A Well Log Data Analysis | http://arxiv.org/abs/1705.03669 | id:1705.03669 author:Rui L. Lopes, Alípio Jorge category:cs.AI stat.ML  published:2017-05-10 summary:The main task in oil and gas exploration is to gain an understanding of the distribution and nature of rocks and fluids in the subsurface. Well logs are records of petro-physical data acquired along a borehole, providing direct information about what is in the subsurface. The data collected by logging wells can have significant economic consequences, due to the costs inherent to drilling wells, and the potential return of oil deposits. In this paper, we describe preliminary work aimed at building a general framework for well log prediction. First, we perform a descriptive and exploratory analysis of the gaps in the neutron porosity logs of more than a thousand wells in the North Sea. Then, we generate artificial gaps in the neutron logs that reflect the statistics collected before. Finally, we compare Artificial Neural Networks, Random Forests, and three algorithms of Linear Regression in the prediction of missing gaps on a well-by-well basis. version:1
arxiv-1705-06578 | An evidential Markov decision making model | http://arxiv.org/abs/1705.06578 | id:1705.06578 author:Zichang He, Wen Jiang category:cs.AI math.DS math.PR  published:2017-05-10 summary:The sure thing principle and the law of total probability are basic laws in classic probability theory. A disjunction fallacy leads to the violation of these two classical laws. In this paper, an Evidential Markov (EM) decision making model based on Dempster-Shafer (D-S) evidence theory and Markov modelling is proposed to address this issue and model the real human decision-making process. In an evidential framework, the states are extended by introducing an uncertain state which represents the hesitance of a decision maker. The classical Markov model can not produce the disjunction effect, which assumes that a decision has to be certain at one time. However, the state is allowed to be uncertain in the EM model before the final decision is made. An extra uncertainty degree parameter is defined by a belief entropy, named Deng entropy, to assignment the basic probability assignment of the uncertain state, which is the key to predict the disjunction effect. A classical categorization decision-making experiment is used to illustrate the effectiveness and validity of EM model. The disjunction effect can be well predicted and the free parameters are less compared with the existing models. version:1
arxiv-1705-03639 | Sparse Interacting Gaussian Processes: Efficiency and Optimality Theorems of Autonomous Crowd Navigation | http://arxiv.org/abs/1705.03639 | id:1705.03639 author:Pete Trautman category:cs.RO  published:2017-05-10 summary:We study the sparsity and optimality properties of crowd navigation and find that existing techniques do not satisfy both criteria simultaneously: either they achieve optimality with a prohibitive number of samples or tractability assumptions make them fragile to catastrophe. For example, if the human and robot are modeled independently, then tractability is attained but the planner is prone to overcautious or overaggressive behavior. For sampling based motion planning of joint human-robot cost functions, for $n_t$ agents and $T$ step lookahead, $\mathcal O(2^{2n_t T})$ samples are needed for coverage of the action space. Advanced approaches statically partition the action space into free-space and then sample in those convex regions. However, if the human is \emph{moving} into free-space, then the partition is misleading and sampling is unsafe: free space will soon be occupied. We diagnose the cause of these deficiencies---optimization happens over \emph{trajectory} space---and propose a novel solution: optimize over trajectory \emph{distribution} space by using a Gaussian process (GP) basis. We exploit the "kernel trick" of GPs, where a continuum of trajectories are captured with a mean and covariance function. By using the mean and covariance as proxies for a trajectory family we reason about collective trajectory behavior without resorting to sampling. The GP basis is sparse and optimal with respect to collision avoidance and robot and crowd intention and flexibility. GP sparsity leans heavily on the insight that joint action space decomposes into free regions; however, the decomposition contains feasible solutions only if the partition is dynamically generated. We call our approach \emph{$\mathcal O(2^{n_t})$-sparse interacting Gaussian processes}. version:1
arxiv-1705-03623 | Improving the Performance and Endurance of Persistent Memory with Loose-Ordering Consistency | http://arxiv.org/abs/1705.03623 | id:1705.03623 author:Youyou Lu, Jiwu Shu, Long Sun, Onur Mutlu category:cs.AR cs.OS  published:2017-05-10 summary:Persistent memory provides high-performance data persistence at main memory. Memory writes need to be performed in strict order to satisfy storage consistency requirements and enable correct recovery from system crashes. Unfortunately, adhering to such a strict order significantly degrades system performance and persistent memory endurance. This paper introduces a new mechanism, Loose-Ordering Consistency (LOC), that satisfies the ordering requirements at significantly lower performance and endurance loss. LOC consists of two key techniques. First, Eager Commit eliminates the need to perform a persistent commit record write within a transaction. We do so by ensuring that we can determine the status of all committed transactions during recovery by storing necessary metadata information statically with blocks of data written to memory. Second, Speculative Persistence relaxes the write ordering between transactions by allowing writes to be speculatively written to persistent memory. A speculative write is made visible to software only after its associated transaction commits. To enable this, our mechanism supports the tracking of committed transaction ID and multi-versioning in the CPU cache. Our evaluations show that LOC reduces the average performance overhead of memory persistence from 66.9% to 34.9% and the memory write traffic overhead from 17.1% to 3.4% on a variety of workloads. version:1
arxiv-1705-03598 | Performance Evaluation and Modeling of HPC I/O on Non-Volatile Memory | http://arxiv.org/abs/1705.03598 | id:1705.03598 author:Wei Liu, Kai Wu, Jialin Liu, Feng Chen, Dong Li category:cs.DC  published:2017-05-10 summary:HPC applications pose high demands on I/O performance and storage capability. The emerging non-volatile memory (NVM) techniques offer low-latency, high bandwidth, and persistence for HPC applications. However, the existing I/O stack are designed and optimized based on an assumption of disk-based storage. To effectively use NVM, we must re-examine the existing high performance computing (HPC) I/O sub-system to properly integrate NVM into it. Using NVM as a fast storage, the previous assumption on the inferior performance of storage (e.g., hard drive) is not valid any more. The performance problem caused by slow storage may be mitigated; the existing mechanisms to narrow the performance gap between storage and CPU may be unnecessary and result in large overhead. Thus fully understanding the impact of introducing NVM into the HPC software stack demands a thorough performance study. In this paper, we analyze and model the performance of I/O intensive HPC applications with NVM as a block device. We study the performance from three perspectives: (1) the impact of NVM on the performance of traditional page cache; (2) a performance comparison between MPI individual I/O and POSIX I/O; and (3) the impact of NVM on the performance of collective I/O. We reveal the diminishing effects of page cache, minor performance difference between MPI individual I/O and POSIX I/O, and performance disadvantage of collective I/O on NVM due to unnecessary data shuffling. We also model the performance of MPI collective I/O and study the complex interaction between data shuffling, storage performance, and I/O access patterns. version:1
arxiv-1705-03597 | Solving Multi-Objective MDP with Lexicographic Preference: An application to stochastic planning with multiple quantile objective | http://arxiv.org/abs/1705.03597 | id:1705.03597 author:Yan Li, Zhaohan Sun category:cs.AI  published:2017-05-10 summary:In most common settings of Markov Decision Process (MDP), an agent evaluate a policy based on expectation of (discounted) sum of rewards. However in many applications this criterion might not be suitable from two perspective: first, in risk aversion situation expectation of accumulated rewards is not robust enough, this is the case when distribution of accumulated reward is heavily skewed; another issue is that many applications naturally take several objective into consideration when evaluating a policy, for instance in autonomous driving an agent needs to balance speed and safety when choosing appropriate decision. In this paper, we consider evaluating a policy based on a sequence of quantiles it induces on a set of target states, our idea is to reformulate the original problem into a multi-objective MDP problem with lexicographic preference naturally defined. For computation of finding an optimal policy, we proposed an algorithm \textbf{FLMDP} that could solve general multi-objective MDP with lexicographic reward preference. version:1
arxiv-1705-03562 | Deep Episodic Value Iteration for Model-based Meta-Reinforcement Learning | http://arxiv.org/abs/1705.03562 | id:1705.03562 author:Steven Stenberg Hansen category:stat.ML cs.AI cs.LG  published:2017-05-09 summary:We present a new deep meta reinforcement learner, which we call Deep Episodic Value Iteration (DEVI). DEVI uses a deep neural network to learn a similarity metric for a non-parametric model-based reinforcement learning algorithm. Our model is trained end-to-end via back-propagation. Despite being trained using the model-free Q-learning objective, we show that DEVI's model-based internal structure provides `one-shot' transfer to changes in reward and transition structure, even for tasks with very high-dimensional state spaces. version:1
arxiv-1705-03550 | CORe50: a New Dataset and Benchmark for Continuous Object Recognition | http://arxiv.org/abs/1705.03550 | id:1705.03550 author:Vincenzo Lomonaco, Davide Maltoni category:cs.CV cs.AI cs.LG cs.RO  published:2017-05-09 summary:Continuous/Lifelong learning of high-dimensional data streams is a challenging research problem. In fact, fully retraining models each time new data become available is infeasible, due to computational and storage issues, while na\"ive incremental strategies have been shown to suffer from catastrophic forgetting. In the context of real-world object recognition applications (e.g., robotic vision), where continuous learning is crucial, very few datasets and benchmarks are available to evaluate and compare emerging techniques. In this work we propose a new dataset and benchmark CORe50, specifically designed for continuous object recognition, and introduce baseline approaches for different continuous learning scenarios. version:1
arxiv-1704-04566 | Distributed Formation Control of Nonlonolomic Mobile Robots by Bounded Feedback in the Presence of Obstacles | http://arxiv.org/abs/1704.04566 | id:1704.04566 author:Thang Nguyen, Hung M. La category:cs.RO  published:2017-04-15 summary:The problem of distributed formation control of nonholonomic mobile robots is addressed in this paper, in which the robots are designed to track a formation. Collision avoidance among agents is guaranteed using a control law based on a repulsive force. In an uncertain environment where obstacles exist, the construction of repulsive force and rotational direction enables agents to avoid and pass the obstacles. The control inputs of each robot are designed to be bounded. Numerical simulations with different formations are implemented to demonstrate the efficacy of the proposed scheme. version:2
arxiv-1705-03538 | Shape Formation by Programmable Particles | http://arxiv.org/abs/1705.03538 | id:1705.03538 author:Giuseppe A. Di Luna, Paola Flocchini, Nicola Santoro, Giovanni Viglietta, Yukiko Yamauchi category:cs.DC cs.RO  published:2017-05-09 summary:Shape formation is a basic distributed problem for systems of computational mobile entities. Intensively studied for systems of autonomous mobile robots, it has recently been investigated in the realm of programmable matter. Namely, it has been studied in the geometric Amoebot model, where the anonymous entities, called particles, operate on a hexagonal tessellation of the plane and have limited computational power (they have constant memory), strictly local interaction and communication capabilities (only with particles in neighboring nodes of the grid), and limited motorial capabilities (from a grid node to an empty neighboring node); their activation is controlled by an adversarial scheduler. Recent investigations have shown how, starting from a well-structured configuration in which the particles form a (not necessarily complete) triangle, the particles can form a large class of shapes. This result has been established under several assumptions: agreement on the clockwise direction (i.e., chirality), a sequential activation schedule, and randomization (i.e., particles can flip coins). In this paper we provide a characterization of which shapes can be formed deterministically starting from any simply connected initial configuration of $n$ particles. As a byproduct, if randomization is allowed, then any input shape can be formed from any initial (simply connected) shape by our deterministic algorithm, provided that $n$ is large enough. Our algorithm works without chirality, proving that chirality is computationally irrelevant for shape formation. Furthermore, it works under a strong adversarial scheduler, not necessarily sequential. We also consider the complexity of shape formation in terms of the total number of moves performed by the particles executing a universal shape formation algorithm, and we prove that our solution is asymptotically optimal, with $O(n^2)$ moves. version:1
arxiv-1705-03520 | Integral Policy Iterations for Reinforcement Learning Problems in Continuous Time and Space | http://arxiv.org/abs/1705.03520 | id:1705.03520 author:Jae Young Lee, Richard S. Sutton category:cs.AI cs.SY I.2.8  published:2017-05-09 summary:Policy iteration (PI) is a recursive process of policy evaluation and improvement to solve an optimal decision-making, e.g., reinforcement learning (RL) or optimal control problem and has served as the fundamental to develop RL methods. Motivated by integral PI (IPI) schemes in optimal control and RL methods in continuous time and space (CTS), this paper proposes on-policy IPI to solve the general RL problem in CTS, with its environment modeled by an ordinary differential equation (ODE). In such continuous domain, we also propose four off-policy IPI methods---two are the ideal PI forms that use advantage and Q-functions, respectively, and the other two are natural extensions of the existing off-policy IPI schemes to our general RL framework. Compared to the IPI methods in optimal control, the proposed IPI schemes can be applied to more general situations and do not require an initial stabilizing policy to run; they are also strongly relevant to the RL algorithms in CTS such as advantage updating, Q-learning, and value-gradient based (VGB) greedy policy improvement. Our on-policy IPI is basically model-based but can be made partially model-free; each off-policy method is also either partially or completely model-free. The mathematical properties of the IPI methods---admissibility, monotone improvement, and convergence towards the optimal solution---are all rigorously proven, together with the equivalence of on- and off-policy IPI. Finally, the IPI methods are simulated with an inverted-pendulum model to support the theory and verify the performance. version:1
arxiv-1705-03427 | Rapid Mixing of Local Graph Dynamics | http://arxiv.org/abs/1705.03427 | id:1705.03427 author:Laurent Massoulié, Rémi Varloot category:cs.DC math.PR  published:2017-05-09 summary:Graph dynamics arise naturally in many contexts. For instance in peer-to-peer networks, a participating peer may replace an existing connection with one neighbour by a new connection with a neighbour's neighbour. Several such local rewiring rules have been proposed to ensure that peer-to-peer networks achieve good connectivity properties (e.g. high expansion) in equilibrium. However it has remained an open question whether there existed such rules that also led to fast convergence to equilibrium. In this work we provide an affirmative answer: We exhibit a local rewiring rule that converges to equilibrium after each participating node has undergone only a number of rewirings that is poly-logarithmic in the system size. The proof involves consideration of the whole isoperimetric profile of the graph, and may be of independent interest. version:1
arxiv-1705-02667 | People on Media: Jointly Identifying Credible News and Trustworthy Citizen Journalists in Online Communities | http://arxiv.org/abs/1705.02667 | id:1705.02667 author:Subhabrata Mukherjee, Gerhard Weikum category:cs.AI cs.CL cs.IR cs.SI stat.ML  published:2017-05-07 summary:Media seems to have become more partisan, often providing a biased coverage of news catering to the interest of specific groups. It is therefore essential to identify credible information content that provides an objective narrative of an event. News communities such as digg, reddit, or newstrust offer recommendations, reviews, quality ratings, and further insights on journalistic works. However, there is a complex interaction between different factors in such online communities: fairness and style of reporting, language clarity and objectivity, topical perspectives (like political viewpoint), expertise and bias of community members, and more. This paper presents a model to systematically analyze the different interactions in a news community between users, news, and sources. We develop a probabilistic graphical model that leverages this joint interaction to identify 1) highly credible news articles, 2) trustworthy news sources, and 3) expert users who perform the role of "citizen journalists" in the community. Our method extends CRF models to incorporate real-valued ratings, as some communities have very fine-grained scales that cannot be easily discretized without losing information. To the best of our knowledge, this paper is the first full-fledged analysis of credibility, trust, and expertise in news communities. version:2
arxiv-1705-03381 | A note on the uniqueness of models in social abstract argumentation | http://arxiv.org/abs/1705.03381 | id:1705.03381 author:Leila Amgoud, Elise Bonzon, Marco Correia, Jorge Cruz, Jérôme Delobelle, Sébastien Konieczny, João Leite, Alexis Martin, Nicolas Maudet, Srdjan Vesic category:cs.AI  published:2017-05-09 summary:Social abstract argumentation is a principled way to assign values to conflicting (weighted) arguments. In this note we discuss the important property of the uniqueness of the model. version:1
arxiv-1705-03290 | Improving drug sensitivity predictions in precision medicine through active expert knowledge elicitation | http://arxiv.org/abs/1705.03290 | id:1705.03290 author:Iiris Sundin, Tomi Peltola, Muntasir Mamun Majumder, Pedram Daee, Marta Soare, Homayun Afrabandpey, Caroline Heckman, Samuel Kaski, Pekka Marttinen category:cs.AI cs.HC cs.LG stat.ML  published:2017-05-09 summary:Predicting the efficacy of a drug for a given individual, using high-dimensional genomic measurements, is at the core of precision medicine. However, identifying features on which to base the predictions remains a challenge, especially when the sample size is small. Incorporating expert knowledge offers a promising alternative to improve a prediction model, but collecting such knowledge is laborious to the expert if the number of candidate features is very large. We introduce a probabilistic model that can incorporate expert feedback about the impact of genomic measurements on the sensitivity of a cancer cell for a given drug. We also present two methods to intelligently collect this feedback from the expert, using experimental design and multi-armed bandit models. In a multiple myeloma blood cancer data set (n=51), expert knowledge decreased the prediction error by 8%. Furthermore, the intelligent approaches can be used to reduce the workload of feedback collection to less than 30% on average compared to a naive approach. version:1
arxiv-1705-03284 | Towards a complexity theory for the congested clique | http://arxiv.org/abs/1705.03284 | id:1705.03284 author:Janne H. Korhonen, Jukka Suomela category:cs.DC cs.CC  published:2017-05-09 summary:The congested clique model of distributed computing has been receiving attention as a model for densely connected distributed systems. While there has been significant progress on the side of upper bounds, we have very little in terms of lower bounds for the congested clique; indeed, it is now know that proving explicit congested clique lower bounds is as difficult as proving circuit lower bounds. In this work, we use various more traditional complexity-theoretic tools to build a clearer picture of the complexity landscape of the congested clique: -- Nondeterminism and beyond: We introduce the nondeterministic congested clique model (analogous to NP) and show that there is a natural canonical problem family that captures all problems solvable in constant time with nondeterministic algorithms. We further generalise these notions by introducing the constant-round decision hierarchy (analogous to the polynomial hierarchy). -- Non-constructive lower bounds: We lift the prior non-uniform counting arguments to a general technique for proving non-constructive uniform lower bounds for the congested clique. In particular, we prove a time hierarchy theorem for the congested clique, showing that there are decision problems of essentially all complexities, both in the deterministic and nondeterministic settings. -- Fine-grained complexity: We map out relationships between various natural problems in the congested clique model. version:1
arxiv-1705-02851 | Flat Parallelization | http://arxiv.org/abs/1705.02851 | id:1705.02851 author:Vitaly Aksenov, Petr Kuznetsov category:cs.DC  published:2017-05-08 summary:There are two intertwined factors that affect performance of concurrent data structures: the ability of processes to access the data in parallel and the cost of synchronization. It has been observed that for a large class of "concurrency-unfriendly" data structures, fine-grained parallelization does not pay off: an implementation based on a single global lock outperforms fine-grained solutions. The flat combining paradigm exploits this by ensuring that a thread holding the global lock sequentially combines requests and then executes the combined requests on behalf of concurrent threads. In this paper, we propose a synchronization technique that unites flat combining and parallel bulk updates borrowed from parallel algorithms designed for the PRAM model. The idea is that the combiner thread assigns waiting threads to perform concurrent requests in parallel. We foresee the technique to help in implementing efficient "concurrency-ambivalent" data structures, which can benefit from both parallelism and serialization, depending on the operational context. To validate the idea, we considered heap-based implementations of a priority queue. These data structures exhibit two important features: concurrent remove operations are likely to conflict and thus may benefit from combining, while concurrent insert operations can often be at least partly applied in parallel thus may benefit from parallel batching. We show that the resulting flat parallelization algorithm performs well compared to state-of-the-art priority queue implementations. version:2
arxiv-1705-03260 | Evidence for the size principle in semantic and perceptual domains | http://arxiv.org/abs/1705.03260 | id:1705.03260 author:Joshua C. Peterson, Thomas L. Griffiths category:cs.AI  published:2017-05-09 summary:Shepard's Universal Law of Generalization offered a compelling case for the first physics-like law in cognitive science that should hold for all intelligent agents in the universe. Shepard's account is based on a rational Bayesian model of generalization, providing an answer to the question of why such a law should emerge. Extending this account to explain how humans use multiple examples to make better generalizations requires an additional assumption, called the size principle: hypotheses that pick out fewer objects should make a larger contribution to generalization. The degree to which this principle warrants similarly law-like status is far from conclusive. Typically, evaluating this principle has not been straightforward, requiring additional assumptions. We present a new method for evaluating the size principle that is more direct, and apply this method to a diverse array of datasets. Our results provide support for the broad applicability of the size principle. version:1
arxiv-1705-03245 | Semi-Federated Scheduling of Parallel Real-Time Tasks on Multiprocessors | http://arxiv.org/abs/1705.03245 | id:1705.03245 author:Xu Jiang, Nan Guan, Xiang Long, Wang Yi category:cs.DC  published:2017-05-09 summary:Federated scheduling is a promising approach to schedule parallel real-time tasks on multi-cores, where each heavy task exclusively executes on a number of dedicated processors, while light tasks are treated as sequential sporadic tasks and share the remaining processors. However, federated scheduling suffers resource waste since a heavy task with processing capacity requirement $x + \epsilon$ (where $x$ is an integer and $0 < \epsilon < 1$) needs $x + 1$ dedicated processors. In the extreme case, almost half of the processing capacity is wasted. In this paper we propose the semi-federate scheduling approach, which only grants $x$ dedicated processors to a heavy task with processing capacity requirement $x + \epsilon$, and schedules the remaining $\epsilon$ part together with light tasks on shared processors. Experiments with randomly generated task sets show the semi-federated scheduling approach significantly outperforms not only federated scheduling, but also all existing approaches for scheduling parallel real-time tasks on multi-cores. version:1
arxiv-1705-02669 | Personalized Item Recommendation with Continuous Experience Evolution of Users using Brownian Motion | http://arxiv.org/abs/1705.02669 | id:1705.02669 author:Subhabrata Mukherjee, Stephan Guennemann, Gerhard Weikum category:cs.AI cs.CL cs.IR cs.SI stat.ML  published:2017-05-07 summary:Online review communities are dynamic as users join and leave, adopt new vocabulary, and adapt to evolving trends. Recent work has shown that recommender systems benefit from explicit consideration of user experience. However, prior work assumes a fixed number of discrete experience levels, whereas in reality users gain experience and mature continuously over time. This paper presents a new model that captures the continuous evolution of user experience, and the resulting language model in reviews and other posts. Our model is unsupervised and combines principles of Geometric Brownian Motion, Brownian Motion, and Latent Dirichlet Allocation to trace a smooth temporal progression of user experience and language model respectively. We develop practical algorithms for estimating the model parameters from data and for inference with our model (e.g., to recommend items). Extensive experiments with five real-world datasets show that our model not only fits data better than discrete-model baselines, but also outperforms state-of-the-art methods for predicting item ratings. version:2
arxiv-1705-03176 | Solving a Path Planning Problem in a Partially Known Environment using a Swarm Algorithm | http://arxiv.org/abs/1705.03176 | id:1705.03176 author:Eshwaran Vijaya Kumar, Mansimar Aneja, Dipti Deodhare category:cs.RO cs.AI  published:2017-05-09 summary:This paper proposes a path planning strategy for an Autonomous Ground Vehicle (AGV) navigating in a partially known environment. Global path planning is performed by first using a spatial database of the region to be traversed containing selected attributes such as height data and soil information from a suitable spatial database. The database is processed using a biomimetic swarm algorithm that is inspired by the nest building strategies followed by termites. Local path planning is performed online utilizing information regarding contingencies that affect the safe navigation of the AGV from various sensors. The simulation discussed has been implemented on the open source Player-Stage-Gazebo platform. version:1
arxiv-1705-03175 | Emotional Metaheuristics For in-situ Foraging Using Sensor Constrained Robot Swarms | http://arxiv.org/abs/1705.03175 | id:1705.03175 author:Eshwaran Vijaya Kumar, Debasish Ghose category:cs.RO cs.AI  published:2017-05-09 summary:We present a new social animal inspired emotional swarm intelligence technique. This technique is used to solve a variant of the popular collective robots problem called foraging. We show with a simulation study how simple interaction rules based on sensations like hunger and loneliness can lead to globally coherent emergent behavior which allows sensor constrained robots to solve the given problem version:1
arxiv-1707-09323 | Identifying the potential of Near Data Computing for Apache Spark | http://arxiv.org/abs/1707.09323 | id:1707.09323 author:Ahsan Javed Awan, Mats Brorsson, Vladimir Vlassov, Eduard Ayguade category:cs.DC  published:2017-05-09 summary:While cluster computing frameworks are continuously evolving to provide real-time data analysis capabilities, Apache Spark has managed to be at the forefront of big data analytics for being a unified framework for both, batch and stream data processing. There is also a renewed interest is Near Data Computing (NDC) due to technological advancement in the last decade. However, it is not known if NDC architectures can improve the performance of big data processing frameworks such as Apache Spark. In this position paper, we hypothesize in favour of NDC architecture comprising programmable logic based hybrid 2D integrated processing-in-memory and in-storage processing for Apache Spark, by extensive profiling of Apache Spark based workloads on Ivy Bridge Server. version:1
arxiv-1705-03162 | Accelerating solutions of PDEs with GPU-based swept time-space decomposition | http://arxiv.org/abs/1705.03162 | id:1705.03162 author:Daniel J Magee, Kyle E Niemeyer category:physics.comp-ph cs.DC cs.MS  published:2017-05-09 summary:The expedient design of precision components in aerospace and other high-tech industries requires simulations of physical phenomena often described by partial differential equations (PDEs) without exact solutions. Modern design problems require simulations with a level of resolution difficult to achieve in reasonable amounts of time---even in effectively parallelized solvers. Though the scale of the problem relative to available computing power is the greatest impediment to accelerating these applications, significant performance gains can be achieved through careful attention to the details of memory communication and access. The swept time-space decomposition rule reduces communication between subdomains by exhausting the domain of influence before communicating boundary values. Here we present a GPU implementation of the swept rule, which modifies the algorithm for improved performance on this processing architecture by prioritizing use of private (shared) memory, avoiding interblock communication, and overwriting unnecessary values. It shows significant improvement in the execution time of one-dimensional, finite-difference PDE solvers for scalar equations, producing speedups of 2-9x for a range of problem sizes, respectively, compared with simple GPU versions and 7-300x compared with parallel CPU versions. However, for a more sophisticated one-dimensional system of equations discretized with a second-order finite-volume scheme, the swept rule performs 1.2-1.9x worse than a basic implementation for all problem sizes. version:1
arxiv-1509-01920 | Risk-Averse Approximate Dynamic Programming with Quantile-Based Risk Measures | http://arxiv.org/abs/1509.01920 | id:1509.01920 author:Daniel R. Jiang, Warren B. Powell category:math.OC cs.AI  published:2015-09-07 summary:In this paper, we consider a finite-horizon Markov decision process (MDP) for which the objective at each stage is to minimize a quantile-based risk measure (QBRM) of the sequence of future costs; we call the overall objective a dynamic quantile-based risk measure (DQBRM). In particular, we consider optimizing dynamic risk measures where the one-step risk measures are QBRMs, a class of risk measures that includes the popular value at risk (VaR) and the conditional value at risk (CVaR). Although there is considerable theoretical development of risk-averse MDPs in the literature, the computational challenges have not been explored as thoroughly. We propose data-driven and simulation-based approximate dynamic programming (ADP) algorithms to solve the risk-averse sequential decision problem. We address the issue of inefficient sampling for risk applications in simulated settings and present a procedure, based on importance sampling, to direct samples toward the "risky region" as the ADP algorithm progresses. Finally, we show numerical results of our algorithms in the context of an application involving risk-averse bidding for energy storage. version:4
arxiv-1702-04849 | Theoretical and Practical Advances on Smoothing for Extensive-Form Games | http://arxiv.org/abs/1702.04849 | id:1702.04849 author:Christian Kroer, Kevin Waugh, Fatma Kilinc-Karzan, Tuomas Sandholm category:cs.GT cs.AI  published:2017-02-16 summary:Sparse iterative methods, in particular first-order methods, are known to be among the most effective in solving large-scale two-player zero-sum extensive-form games. The convergence rates of these methods depend heavily on the properties of the distance-generating function that they are based on. We investigate the acceleration of first-order methods for solving extensive-form games through better design of the dilated entropy function---a class of distance-generating functions related to the domains associated with the extensive-form games. By introducing a new weighting scheme for the dilated entropy function, we develop the first distance-generating function for the strategy spaces of sequential games that has no dependence on the branching factor of the player. This result improves the convergence rate of several first-order methods by a factor of $\Omega(b^dd)$, where $b$ is the branching factor of the player, and $d$ is the depth of the game tree. Thus far, counterfactual regret minimization methods have been faster in practice, and more popular, than first-order methods despite their theoretically inferior convergence rates. Using our new weighting scheme and practical tuning we show that, for the first time, the excessive gap technique can be made faster than the fastest counterfactual regret minimization algorithm, CFR+, in practice. version:2
arxiv-1705-02894 | Geometric GAN | http://arxiv.org/abs/1705.02894 | id:1705.02894 author:Jae Hyun Lim, Jong Chul Ye category:stat.ML cond-mat.dis-nn cs.AI cs.CV cs.LG  published:2017-05-08 summary:Generative Adversarial Nets (GANs) represent an important milestone for effective generative models, which has inspired numerous variants seemingly different from each other. One of the main contributions of this paper is to reveal a unified geometric structure in GAN and its variants. Specifically, we show that the adversarial generative model training can be decomposed into three geometric steps: separating hyperplane search, discriminator parameter update away from the separating hyperplane, and the generator update along the normal vector direction of the separating hyperplane. This geometric intuition reveals the limitations of the existing approaches and leads us to propose a new formulation called geometric GAN using SVM separating hyperplane that maximizes the margin. Our theoretical analysis shows that the geometric GAN converges to a Nash equilibrium between the discriminator and generator. In addition, extensive numerical results show that the superior performance of geometric GAN. version:2
arxiv-1705-03125 | Affinity Scheduling and the Applications on Data Center Scheduling with Data Locality | http://arxiv.org/abs/1705.03125 | id:1705.03125 author:Mohammadamir Kavousi category:cs.DC cs.PF  published:2017-05-09 summary:MapReduce framework is the de facto standard in Hadoop. Considering the data locality in data centers, the load balancing problem of map tasks is a special case of affinity scheduling problem. There is a huge body of work on affinity scheduling, proposing heuristic algorithms which try to increase data locality in data centers like Delay Scheduling and Quincy. However, not enough attention has been put on theoretical guarantees on throughput and delay optimality of such algorithms. In this work, we present and compare different algorithms and discuss their shortcoming and strengths. To the best of our knowledge, most data centers are using static load balancing algorithms which are not efficient in any ways and results in wasting the resources and causing unnecessary delays for users. version:1
arxiv-1705-03124 | A Mathematical Theory of Human Machine Teaming | http://arxiv.org/abs/1705.03124 | id:1705.03124 author:Pete Trautman category:cs.RO  published:2017-05-08 summary:We begin with a disquieting paradox: human machine teaming (HMT) often produces results worse than either the human or machine would produce alone. Critically, this failure is not a result of inferior human modeling or a suboptimal autonomy: even with perfect knowledge of human intention and perfect autonomy performance, prevailing teaming architectures still fail under trivial stressors~\cite{trautman-smc-2015}. This failure is instead a result of deficiencies at the \emph{decision fusion level}. Accordingly, \emph{efforts aimed solely at improving human prediction or improving autonomous performance will not produce acceptable HMTs: we can no longer model humans, machines and adversaries as distinct entities.} We thus argue for a strong but essential condition: HMTs should perform no worse than either member of the team alone, and this performance bound should be independent of environment complexity, human-machine interfacing, accuracy of the human model, or reliability of autonomy or human decision making. version:1
arxiv-1705-03102 | Scalable System Scheduling for HPC and Big Data | http://arxiv.org/abs/1705.03102 | id:1705.03102 author:Albert Reuther, Chansup Byun, William Arcand, David Bestor, Bill Bergeron, Matthew Hubbell, Michael Jones, Peter Michaleas, Andrew Prout, Antonio Rosa, Jeremy Kepner category:cs.DC  published:2017-05-08 summary:In the rapidly expanding field of parallel processing, job schedulers are the "operating systems" of modern big data architectures and supercomputing systems. Job schedulers allocate computing resources and control the execution of processes on those resources. Historically, job schedulers were the domain of supercomputers, and job schedulers were designed to run massive, long-running computations over days and weeks. More recently, big data workloads have created a need for a new class of computations consisting of many short computations taking seconds or minutes that process enormous quantities of data. For both supercomputers and big data systems, the efficiency of the job scheduler represents a fundamental limit on the efficiency of the system. Detailed measurement and modeling of the performance of schedulers are critical for maximizing the performance of a large-scale computing system. This paper presents a detailed feature analysis of 15 supercomputing and big data schedulers. For big data workloads, the scheduler latency is the most important performance characteristic of the scheduler. A theoretical model of the latency of these schedulers is developed and used to design experiments targeted at measuring scheduler latency. Detailed benchmarking of four of the most popular schedulers (Slurm, Son of Grid Engine, Mesos, and Hadoop YARN) are conducted. The theoretical model is compared with data and demonstrates that scheduler performance can be characterized by two key parameters: the marginal latency of the scheduler $t_s$ and a nonlinear exponent $\alpha_s$. For all four schedulers, the utilization of the computing system decreases to < 10\% for computations lasting only a few seconds. Multilevel schedulers that transparently aggregate short computations can improve utilization for these short computations to > 90\% for all four of the schedulers that were tested. version:1
arxiv-1705-03078 | An Anthropic Argument against the Future Existence of Superintelligent Artificial Intelligence | http://arxiv.org/abs/1705.03078 | id:1705.03078 author:Toby Pereira category:cs.AI  published:2017-05-08 summary:This paper uses anthropic reasoning to argue for a reduced likelihood that superintelligent AI will come into existence in the future. To make this argument, a new principle is introduced: the Super-Strong Self-Sampling Assumption (SSSSA), building on the Self-Sampling Assumption (SSA) and the Strong Self-Sampling Assumption (SSSA). SSA uses as its sample the relevant observers, whereas SSSA goes further by using observer-moments. SSSSA goes further still and weights each sample proportionally, according to the size of a mind in cognitive terms. SSSSA is required for human observer-samples to be typical, given by how much non-human animals outnumber humans. Given SSSSA, the assumption that humans experience typical observer-samples relies on a future where superintelligent AI does not dominate, which in turn reduces the likelihood of it being created at all. version:1
arxiv-1705-03454 | The Pragmatics of Indirect Commands in Collaborative Discourse | http://arxiv.org/abs/1705.03454 | id:1705.03454 author:Matthew Lamm, Mihail Eric category:cs.CL cs.AI  published:2017-05-08 summary:Today's artificial assistants are typically prompted to perform tasks through direct, imperative commands such as \emph{Set a timer} or \emph{Pick up the box}. However, to progress toward more natural exchanges between humans and these assistants, it is important to understand the way non-imperative utterances can indirectly elicit action of an addressee. In this paper, we investigate command types in the setting of a grounded, collaborative game. We focus on a less understood family of utterances for eliciting agent action, locatives like \emph{The chair is in the other room}, and demonstrate how these utterances indirectly command in specific game state contexts. Our work shows that models with domain-specific grounding can effectively realize the pragmatic reasoning that is necessary for more robust natural language interaction with robots. version:1
arxiv-1705-02970 | TaskUniVerse: A Task-Based Unified Interface for Versatile Parallel Execution | http://arxiv.org/abs/1705.02970 | id:1705.02970 author:Afshin Zafari category:cs.DC  published:2017-05-08 summary:Task based parallel programming has shown competitive outcomes in many aspects of parallel programming such as efficiency, performance, productivity and scalability. Different approaches are used by different software development frameworks to provide these outcomes to the programmer, while making the underlying hardware architecture transparent to her. However, since programs are not portable between these frameworks, using one framework or the other is still a vital decision by the programmer whose concerns are expandability, adaptivity, maintainability and interoperability of the programs. In this work, we propose a unified programming interface that a programmer can use for working with different task based parallel frameworks transparently. In this approach we abstract the common concepts of task based parallel programming and provide them to the programmer in a single programming interface uniformly for all frameworks. We have tested the interface by running programs which implement matrix operations within frameworks that are optimized for shared and distributed memory architectures and accelerators, while the cooperation between frameworks is configured externally with no need to modify the programs. Further possible extensions of the interface and future potential research are also described. version:1
arxiv-1705-03414 | A Distributed Learning Dynamics in Social Groups | http://arxiv.org/abs/1705.03414 | id:1705.03414 author:L. Elisa Celis, Peter M. Krafft, Nisheeth K. Vishnoi category:cs.LG cs.CY cs.DC cs.DS  published:2017-05-08 summary:We study a distributed learning process observed in human groups and other social animals. This learning process appears in settings in which each individual in a group is trying to decide over time, in a distributed manner, which option to select among a shared set of options. Specifically, we consider a stochastic dynamics in a group in which every individual selects an option in the following two-step process: (1) select a random individual and observe the option that individual chose in the previous time step, and (2) adopt that option if its stochastic quality was good at that time step. Various instantiations of such distributed learning appear in nature, and have also been studied in the social science literature. From the perspective of an individual, an attractive feature of this learning process is that it is a simple heuristic that requires extremely limited computational capacities. But what does it mean for the group -- could such a simple, distributed and essentially memoryless process lead the group as a whole to perform optimally? We show that the answer to this question is yes -- this distributed learning is highly effective at identifying the best option and is close to optimal for the group overall. Our analysis also gives quantitative bounds that show fast convergence of these stochastic dynamics. Prior to our work the only theoretical work related to such learning dynamics has been either in deterministic special cases or in the asymptotic setting. Finally, we observe that our infinite population dynamics is a stochastic variant of the classic multiplicative weights update (MWU) method. Consequently, we arrive at the following interesting converse: the learning dynamics on a finite population considered here can be viewed as a novel distributed and low-memory implementation of the classic MWU method. version:1
arxiv-1705-02908 | Machine Learning with World Knowledge: The Position and Survey | http://arxiv.org/abs/1705.02908 | id:1705.02908 author:Yangqiu Song, Dan Roth category:cs.AI cs.LG stat.ML  published:2017-05-08 summary:Machine learning has become pervasive in multiple domains, impacting a wide variety of applications, such as knowledge discovery and data mining, natural language processing, information retrieval, computer vision, social and health informatics, ubiquitous computing, etc. Two essential problems of machine learning are how to generate features and how to acquire labels for machines to learn. Particularly, labeling large amount of data for each domain-specific problem can be very time consuming and costly. It has become a key obstacle in making learning protocols realistic in applications. In this paper, we will discuss how to use the existing general-purpose world knowledge to enhance machine learning processes, by enriching the features or reducing the labeling work. We start from the comparison of world knowledge with domain-specific knowledge, and then introduce three key problems in using world knowledge in learning processes, i.e., explicit and implicit feature representation, inference for knowledge linking and disambiguation, and learning with direct or indirect supervision. Finally we discuss the future directions of this research topic. version:1
arxiv-1705-02899 | Teaching Concurrent Software Design: A Case Study Using Android | http://arxiv.org/abs/1705.02899 | id:1705.02899 author:Konstantin Läufer, George K. Thiruvathukal category:cs.SE cs.DC  published:2017-05-08 summary:In this article, we explore various parallel and distributed computing topics from a user-centric software engineering perspective. Specifically, in the context of mobile application development, we study the basic building blocks of interactive applications in the form of events, timers, and asynchronous activities, along with related software modeling, architecture, and design topics. version:1
arxiv-1705-02898 | Lower Bounds for Asymptotic Consensus in Dynamic Networks | http://arxiv.org/abs/1705.02898 | id:1705.02898 author:Matthias Függer, Thomas Nowak, Manfred Schwarz category:cs.DC  published:2017-05-08 summary:In this work we study the performance of asymptotic and approximate consensus algorithms in dynamic networks. The asymptotic consensus problem requires a set of agents to repeatedly set their outputs such that the outputs converge to a common value within the convex hull of initial values. This problem, and the related approximate consensus problem, are fundamental building blocks in distributed systems where exact consensus among agents is not required, e.g., man-made distributed control systems, and have applications in the analysis of natural distributed systems, such as flocking and opinion dynamics. We prove new nontrivial lower bounds on the contraction rates of asymptotic consensus algorithms, from which we deduce lower bounds on the time complexity of approximate consensus algorithms. In particular, the obtained bounds show optimality of asymptotic and approximate consensus algorithms presented in [Charron-Bost et al., ICALP'16] for certain classes of networks that include classical failure assumptions, and confine the search for optimal bounds in the general case. Central to our lower bound proofs is an extended notion of valency, the set of reachable limits of an asymptotic consensus algorithm starting from a given configuration. We further relate topological properties of valencies to the solvability of exact consensus, shedding some light on the relation of these three fundamental problems in dynamic networks. version:1
arxiv-1705-02843 | Block-Parallel IDA* for GPUs (Extended Manuscript) | http://arxiv.org/abs/1705.02843 | id:1705.02843 author:Satoru Horie, Alex Fukunaga category:cs.AI cs.DC  published:2017-05-08 summary:We investigate GPU-based parallelization of Iterative-Deepening A* (IDA*). We show that straightforward thread-based parallelization techniques which were previously proposed for massively parallel SIMD processors perform poorly due to warp divergence and load imbalance. We propose Block-Parallel IDA* (BPIDA*), which assigns the search of a subtree to a block (a group of threads with access to fast shared memory) rather than a thread. On the 15-puzzle, BPIDA* on a NVIDIA GRID K520 with 1536 CUDA cores achieves a speedup of 4.98 compared to a highly optimized sequential IDA* implementation on a Xeon E5-2670 core. version:1
arxiv-1705-02808 | Towards Reduced Instruction Sets for Synchronization | http://arxiv.org/abs/1705.02808 | id:1705.02808 author:Rati Gelashvili, Idit Keidar, Alexander Spiegelman, Roger Wattenhofer category:cs.DC  published:2017-05-08 summary:Contrary to common belief, a recent work by Ellen, Gelashvili, Shavit, and Zhu has shown that computability does not require multicore architectures to support "strong" synchronization instructions like compare-and-swap, as opposed to combinations of "weaker" instructions like decrement and multiply. However, this is the status quo, and in turn, most efficient concurrent data-structures heavily rely on compare-and-swap (e.g. for swinging pointers and in general, conflict resolution). We show that this need not be the case, by designing and implementing a concurrent linearizable Log data-structure (also known as a History object), supporting two operations: append(item), which appends the item to the log, and get-log(), which returns the appended items so far, in order. Readers are wait-free and writers are lock-free, and this data-structure can be used in a lock-free universal construction to implement any concurrent object with a given sequential specification. Our implementation uses atomic read, xor, decrement, and fetch-and-increment instructions supported on X86 architectures, and provides similar performance to a compare-and-swap-based solution on today's hardware. This raises a fundamental question about minimal set of synchronization instructions that the architectures have to support. version:1
arxiv-1704-07234 | Scaling Reliably: Improving the Scalability of the Erlang Distributed Actor Platform | http://arxiv.org/abs/1704.07234 | id:1704.07234 author:Phil Trinder, Natalia Chechina, Nikolaos Papaspyrou, Konstantinos Sagonas, Simon Thompson, Stephen Adams, Stavros Aronis, Robert Baker, Eva Bihari, Olivier Boudeville, Francesco Cesarini, Maurizio Di Stefano, Sverker Eriksson, Viktoria Fordos, Amir Ghaffari, Aggelos Giantsios, Rickard Green, Csaba Hoch, David Klaftenegger, Huiqing Li, Kenneth Lundin, Kenneth Mackenzie, Katerina Roukounaki, Yiannis Tsiouris, Kjell Winblad category:cs.PL cs.DC  published:2017-04-24 summary:Distributed actor languages are an effective means of constructing scalable reliable systems, and the Erlang programming language has a well-established and influential model. While Erlang model conceptually provides reliable scalability, it has some inherent scalability limits and these force developers to depart from the model at scale. This article establishes the scalability limits of Erlang systems, and reports the work to improve the language scalability. We systematically study the scalability limits of Erlang and address the issues at the virtual machine (VM), language, and tool levels. More specifically: (1) We have evolved the Erlang VM so that it can work effectively in large scale single-host multicore and NUMA architectures. We have made important architectural improvements to the Erlang/OTP. (2) We have designed and implemented Scalable Distributed (SD) Erlang libraries to address language-level scalability issues, and provided and validated a set of semantics for the new language constructs. (3) To make large Erlang systems easier to deploy, monitor, and debug we have developed and made open source releases of five complementary tools, some specific to SD Erlang. Throughout the article we use two case studies to investigate the capabilities of our new technologies and tools: a distributed hash table based Orbit calculation and Ant Colony Optimisation (ACO). Chaos Monkey experiments show that two versions of ACO survive random process failure and hence that SD Erlang preserves the Erlang reliability model. Even for programs with no global recovery data to maintain, SD Erlang partitions the network to reduce network traffic and hence improves performance of the Orbit and ACO benchmarks above 80 hosts. ACO measurements show that maintaining global recovery data dramatically limits scalability; however scalability is recovered by partitioning the recovery data. version:2
arxiv-1705-02772 | Scene Text Eraser | http://arxiv.org/abs/1705.02772 | id:1705.02772 author:Toshiki Nakamura, Anna Zhu, Keiji Yanai, Seiichi Uchida category:cs.CV cs.AI  published:2017-05-08 summary:The character information in natural scene images contains various personal information, such as telephone numbers, home addresses, etc. It is a high risk of leakage the information if they are published. In this paper, we proposed a scene text erasing method to properly hide the information via an inpainting convolutional neural network (CNN) model. The input is a scene text image, and the output is expected to be text erased image with all the character regions filled up the colors of the surrounding background pixels. This work is accomplished by a CNN model through convolution to deconvolution with interconnection process. The training samples and the corresponding inpainting images are considered as teaching signals for training. To evaluate the text erasing performance, the output images are detected by a novel scene text detection method. Subsequently, the same measurement on text detection is utilized for testing the images in benchmark dataset ICDAR2013. Compared with direct text detection way, the scene text erasing process demonstrates a drastically decrease on the precision, recall and f-score. That proves the effectiveness of proposed method for erasing the text in natural scene images. version:1
arxiv-1705-02734 | Out-of-Order Dataflow Scheduling for FPGA Overlays | http://arxiv.org/abs/1705.02734 | id:1705.02734 author:Siddhartha, Nachiket Kapre category:cs.AR  published:2017-05-08 summary:We exploit floating-point DSPs in the Arria10 FPGA and multi-pumping feature of the M20K RAMs to build a dataflow-driven soft processor fabric for large graph workloads. In this paper, we introduce the idea of out-of-order node scheduling across a large number of local nodes (thousands) per processor by combining an efficient node tagging scheme along with leading-one detector circuits. We use a static one-time node labeling algorithm to sort nodes based on criticality to organize local memory inside each soft processor. This translates to a small ~6% memory overhead. When compared to a memory-expensive FIFO-based first-come-first-serve approach used in previous studies, we deliver up to 50% performance improvement while eliminating the cost of the FIFOs. On the Arria10 10AX115S board, we can create an overlay design of up to 300 processors connected by high bandwidth Hoplite NoC at frequencies up to 250MHz. version:1
arxiv-1705-02732 | A Scalable, Low-Overhead Finite-State Machine Overlay for Rapid FPGA Application Development | http://arxiv.org/abs/1705.02732 | id:1705.02732 author:David Wilson, Greg Stitt category:cs.AR  published:2017-05-08 summary:Productivity issues such as lengthy compilation and limited code reuse have restricted usage of field-programmable gate arrays (FPGAs), despite significant technical advantages. Recent work into overlays -- virtual coarse-grained architectures implemented atop FPGAs -- has aimed to address these concerns through abstraction, but have mostly focused on pipelined applications with minimal control requirements. Although research has introduced overlays for finite-state machines, those architectures suffer from limited scalability and flexibility, which we address with a new overlay architecture using memory decomposition on transitional logic. Although our overlay provides modest average improvements of 15% to 29% fewer lookup tables for individual finite-state machines, for the more common usage of an overlay supporting different finite-state machines, our overlay achieves a 77% to 99% reduction in lookup tables. In addition, our overlay reduces compilation time to tenths of a second to enable rapid iterative-development methodologies. version:1
arxiv-1705-02730 | Resource-Aware Just-in-Time OpenCL Compiler for Coarse-Grained FPGA Overlays | http://arxiv.org/abs/1705.02730 | id:1705.02730 author:Abhishek Kumar Jain, Douglas L. Maskell, Suhaib A. Fahmy category:cs.AR  published:2017-05-08 summary:FPGA vendors have recently started focusing on OpenCL for FPGAs because of its ability to leverage the parallelism inherent to heterogeneous computing platforms. OpenCL allows programs running on a host computer to launch accelerator kernels which can be compiled at run-time for a specific architecture, thus enabling portability. However, the prohibitive compilation times (specifically the FPGA place and route times) are a major stumbling block when using OpenCL tools from FPGA vendors. The long compilation times mean that the tools cannot effectively use just-in-time (JIT) compilation or runtime performance scaling. Coarse-grained overlays represent a possible solution by virtue of their coarse granularity and fast compilation. In this paper, we present a methodology for run-time compilation of OpenCL kernels to a DSP block based coarse-grained overlay, rather than directly to the fine-grained FPGA fabric. The proposed methodology allows JIT compilation and on-demand resource-aware kernel replication to better utilize available overlay resources, raising the abstraction level while reducing compile times significantly. We further demonstrate that this approach can even be used for run-time compilation of OpenCL kernels on the ARM processor of the embedded heterogeneous Zynq device. version:1
arxiv-1705-02694 | Multimodal Affect Analysis for Product Feedback Assessment | http://arxiv.org/abs/1705.02694 | id:1705.02694 author:Amol S Patwardhan, Gerald M Knapp category:cs.HC cs.AI cs.CV cs.LG  published:2017-05-07 summary:Consumers often react expressively to products such as food samples, perfume, jewelry, sunglasses, and clothing accessories. This research discusses a multimodal affect recognition system developed to classify whether a consumer likes or dislikes a product tested at a counter or kiosk, by analyzing the consumer's facial expression, body posture, hand gestures, and voice after testing the product. A depth-capable camera and microphone system - Kinect for Windows - is utilized. An emotion identification engine has been developed to analyze the images and voice to determine affective state of the customer. The image is segmented using skin color and adaptive threshold. Face, body and hands are detected using the Haar cascade classifier. Canny edges are identified and the lip, body and hand contours are extracted using spatial filtering. Edge count and orientation around the mouth, cheeks, eyes, shoulders, fingers and the location of the edges are used as features. Classification is done by an emotion template mapping algorithm and training a classifier using support vector machines. The real-time performance, accuracy and feasibility for multimodal affect recognition in feedback assessment are evaluated. version:1
arxiv-1705-02689 | AirDraw: Leveraging Smart Watch Motion Sensors for Mobile Human Computer Interactions | http://arxiv.org/abs/1705.02689 | id:1705.02689 author:Seyed A Sajjadi, Danial Moazen, Ani Nahapetian category:cs.CV cs.AI cs.HC stat.ML  published:2017-05-07 summary:Wearable computing is one of the fastest growing technologies today. Smart watches are poised to take over at least of half the wearable devices market in the near future. Smart watch screen size, however, is a limiting factor for growth, as it restricts practical text input. On the other hand, wearable devices have some features, such as consistent user interaction and hands-free, heads-up operations, which pave the way for gesture recognition methods of text entry. This paper proposes a new text input method for smart watches, which utilizes motion sensor data and machine learning approaches to detect letters written in the air by a user. This method is less computationally intensive and less expensive when compared to computer vision approaches. It is also not affected by lighting factors, which limit computer vision solutions. The AirDraw system prototype developed to test this approach is presented. Additionally, experimental results close to 71% accuracy are presented. version:1
arxiv-1705-02687 | Finding Bottlenecks: Predicting Student Attrition with Unsupervised Classifier | http://arxiv.org/abs/1705.02687 | id:1705.02687 author:Seyed Sajjadi, Bruce Shapiro, Christopher McKinlay, Allen Sarkisyan, Carol Shubin, Efunwande Osoba category:stat.ML cs.AI cs.CY cs.LG stat.AP  published:2017-05-07 summary:With pressure to increase graduation rates and reduce time to degree in higher education, it is important to identify at-risk students early. Automated early warning systems are therefore highly desirable. In this paper, we use unsupervised clustering techniques to predict the graduation status of declared majors in five departments at California State University Northridge (CSUN), based on a minimal number of lower division courses in each major. In addition, we use the detected clusters to identify hidden bottleneck courses. version:1
arxiv-1705-02671 | Lightweight Robust Framework for Workload Scheduling in Clouds | http://arxiv.org/abs/1705.02671 | id:1705.02671 author:Muhammed Abdulazeez, Pawel Garncarek, Dariusz R. Kowalski, Prudence W. H. Wong category:cs.DC  published:2017-05-07 summary:Reliability, security and stability of cloud services without sacrificing too much resources have become a desired feature in the area of workload management in clouds. The paper proposes and evaluates a lightweight framework for scheduling a workload which part could be unreliable. This unreliability could be caused by various types of failures or attacks. Our framework for robust workload scheduling efficiently combines classic fault-tolerant and security tools, such as packet/job scanning, with workload scheduling, and it does not use any heavy resource-consuming tools, e.g., cryptography or non-linear optimization. More specifically, the framework uses a novel objective function to allocate jobs to servers and constantly decides which job to scan based on a formula associated with the objective function. We show how to set up the objective function and the corresponding scanning procedure to make the system provably stable, provided it satisfies a specific stability condition. As a result, we show that our framework assures cloud stability even if naive scanning-all and scanning-none strategies are not stable. We extend the framework to decentralized scheduling and evaluate it under several popular routing procedures. version:1
arxiv-1705-02670 | Metacontrol for Adaptive Imagination-Based Optimization | http://arxiv.org/abs/1705.02670 | id:1705.02670 author:Jessica B. Hamrick, Andrew J. Ballard, Razvan Pascanu, Oriol Vinyals, Nicolas Heess, Peter W. Battaglia category:cs.LG cs.AI  published:2017-05-07 summary:Many machine learning systems are built to solve the hardest examples of a particular task, which often makes them large and expensive to run---especially with respect to the easier examples, which might require much less computation. For an agent with a limited computational budget, this "one-size-fits-all" approach may result in the agent wasting valuable computation on easy examples, while not spending enough on hard examples. Rather than learning a single, fixed policy for solving all instances of a task, we introduce a metacontroller which learns to optimize a sequence of "imagined" internal simulations over predictive models of the world in order to construct a more informed, and more economical, solution. The metacontroller component is a model-free reinforcement learning agent, which decides both how many iterations of the optimization procedure to run, as well as which model to consult on each iteration. The models (which we call "experts") can be state transition models, action-value functions, or any other mechanism that provides information useful for solving the task, and can be learned on-policy or off-policy in parallel with the metacontroller. When the metacontroller, controller, and experts were trained with "interaction networks" (Battaglia et al., 2016) as expert models, our approach was able to solve a challenging decision-making problem under complex non-linear dynamics. The metacontroller learned to adapt the amount of computation it performed to the difficulty of the task, and learned how to choose which experts to consult by factoring in both their reliability and individual computational resource costs. This allowed the metacontroller to achieve a lower overall cost (task loss plus computational cost) than more traditional fixed policy approaches. These results demonstrate that our approach is a powerful framework for using... version:1
arxiv-1705-02668 | Credible Review Detection with Limited Information using Consistency Analysis | http://arxiv.org/abs/1705.02668 | id:1705.02668 author:Subhabrata Mukherjee, Sourav Dutta, Gerhard Weikum category:cs.AI cs.CL cs.IR cs.SI stat.ML  published:2017-05-07 summary:Online reviews provide viewpoints on the strengths and shortcomings of products/services, influencing potential customers' purchasing decisions. However, the proliferation of non-credible reviews -- either fake (promoting/ demoting an item), incompetent (involving irrelevant aspects), or biased -- entails the problem of identifying credible reviews. Prior works involve classifiers harnessing rich information about items/users -- which might not be readily available in several domains -- that provide only limited interpretability as to why a review is deemed non-credible. This paper presents a novel approach to address the above issues. We utilize latent topic models leveraging review texts, item ratings, and timestamps to derive consistency features without relying on item/user histories, unavailable for "long-tail" items/users. We develop models, for computing review credibility scores to provide interpretable evidence for non-credible reviews, that are also transferable to other domains -- addressing the scarcity of labeled data. Experiments on real-world datasets demonstrate improvements over state-of-the-art baselines. version:1
arxiv-1705-02636 | TrajectoryNet: An Embedded GPS Trajectory Representation for Point-based Classification Using Recurrent Neural Networks | http://arxiv.org/abs/1705.02636 | id:1705.02636 author:Xiang Jiang, Erico N de Souza, Ahmad Pesaranghader, Baifan Hu, Daniel L. Silver, Stan Matwin category:cs.CV cs.AI cs.LG I.2.6; H.2.8; I.2.1  published:2017-05-07 summary:Understanding and discovering knowledge from GPS (Global Positioning System) traces of human activities is an essential topic in mobility-based urban computing. We propose TrajectoryNet-a neural network architecture for point-based trajectory classification to infer real world human transportation modes from GPS traces. To overcome the challenge of capturing the underlying latent factors in the low-dimensional and heterogeneous feature space imposed by GPS data, we develop a novel representation that embeds the original feature space into another space that can be understood as a form of basis expansion. We also enrich the feature space via segment-based information and use Maxout activations to improve the predictive power of Recurrent Neural Networks (RNNs). We achieve over 98% classification accuracy when detecting four types of transportation modes, outperforming existing models without additional sensory data or location-based prior knowledge. version:1
arxiv-1705-02620 | A New Medical Diagnosis Method Based on Z-Numbers | http://arxiv.org/abs/1705.02620 | id:1705.02620 author:Dong Wu, Xiang Liu, Feng Xue, Hanqing Zheng, Yehang Shou, Wen Jiang category:cs.AI  published:2017-05-07 summary:How to handle uncertainty in medical diagnosis is an open issue. In this paper, a new decision making methodology based on Z-numbers is presented. Firstly, the experts' opinions are represented by Z-numbers. Z-number is an ordered pair of fuzzy numbers denoted as Z = (A, B). Then, a new method for ranking fuzzy numbers is proposed. And based on the proposed fuzzy number ranking method, a novel method is presented to transform the Z-numbers into Basic Probability Assignment (BPA). As a result, the information from different sources is combined by the Dempster' combination rule. The final decision making is more reasonable due to the advantage of information fusion. Finally, two experiments, risk analysis and medical diagnosis, are illustrated to show the efficiency of the proposed methodology. version:1
arxiv-1705-02610 | Static Timing Model Extraction for Combinational Circuits | http://arxiv.org/abs/1705.02610 | id:1705.02610 author:Bing Li, Christoph Knoth, Walter Schneider, Manuel Schmidt, Ulf Schlichtmann category:cs.AR B.7  published:2017-05-07 summary:For large circuits, static timing analysis (STA) needs to be performed in a hierarchical manner to achieve higher performance in arrival time propagation. In hierarchical STA, efficient and accurate timing models of sub-modules need to be created. We propose a timing model extraction method that significantly reduces the size of timing models without losing any accuracy by removing redundant timing information. Circuit components which do not contribute to the delay of any input to output pair are removed. The proposed method is deterministic. Compared to the original models, the numbers of edges and vertices of the resulting timing models are reduced by 84% and 85% on average, respectively, which are significantly more than the results achieved by other methods. version:1
arxiv-1705-02609 | Emptiness Problems for Distributed Automata | http://arxiv.org/abs/1705.02609 | id:1705.02609 author:Antti Kuusisto, Fabian Reiter category:cs.FL cs.DC C.2.4; F.1.1  published:2017-05-07 summary:We investigate the decidability of the emptiness problem for three classes of distributed automata. These devices operate on finite directed graphs, acting as networks of identical finite-state machines that communicate in an infinite sequence of synchronous rounds. The problem is shown to be decidable in LogSpace for a class of forgetful automata, where the nodes see the messages received from their neighbors but cannot remember their own state. When restricted to the appropriate families of graphs, these forgetful automata are equivalent to classical finite word automata, but strictly more expressive than finite tree automata. On the other hand, we also show that the emptiness problem is undecidable in general. This already holds for two heavily restricted classes of distributed automata: those that reject immediately if they receive more than one message per round, and those whose state diagram must be acyclic except for self-loops. version:1
arxiv-1705-02573 | A Certified-Complete Bimanual Manipulation Planner | http://arxiv.org/abs/1705.02573 | id:1705.02573 author:Puttichai Lertkultanon, Quang-Cuong Pham category:cs.RO  published:2017-05-07 summary:Planning motions for two robot arms to move an object collaboratively is a difficult problem, mainly because of the closed-chain constraint, which arises whenever two robot hands simultaneously grasp a single rigid object. In this paper, we propose a manipulation planning algorithm to bring an object from an initial stable placement (position and orientation of the object on the support surface) towards a goal stable placement. The key specificity of our algorithm is that it is certified-complete: for a given object and a given environment, we provide a certificate that the algorithm will find a solution to any bimanual manipulation query in that environment whenever one exists. Moreover, the certificate is constructive: at run-time, it can be used to quickly find a solution to a given query. The algorithm is tested in software and hardware on a number of large pieces of furniture. version:1
arxiv-1705-02553 | Experimental results : Reinforcement Learning of POMDPs using Spectral Methods | http://arxiv.org/abs/1705.02553 | id:1705.02553 author:Kamyar Azizzadenesheli, Alessandro Lazaric, Animashree Anandkumar category:cs.AI cs.LG stat.ML  published:2017-05-07 summary:We propose a new reinforcement learning algorithm for partially observable Markov decision processes (POMDP) based on spectral decomposition methods. While spectral methods have been previously employed for consistent learning of (passive) latent variable models such as hidden Markov models, POMDPs are more challenging since the learner interacts with the environment and possibly changes the future observations in the process. We devise a learning algorithm running through epochs, in each epoch we employ spectral techniques to learn the POMDP parameters from a trajectory generated by a fixed policy. At the end of the epoch, an optimization oracle returns the optimal memoryless planning policy which maximizes the expected reward based on the estimated POMDP model. We prove an order-optimal regret bound with respect to the optimal memoryless policy and efficient scaling with respect to the dimensionality of observation and action spaces. version:1
arxiv-1702-02455 | Deterministic Protocols in the SINR Model without Knowledge of Coordinates | http://arxiv.org/abs/1702.02455 | id:1702.02455 author:William K. Moses Jr., Shailesh Vaya category:cs.DC cs.DS F.2.2; G.2.2  published:2017-02-08 summary:Much work has been developed for studying the classical broadcasting problem in the SINR (Signal-to-Interference-plus-Noise-Ratio) model for wireless device transmission. The setting typically studied is when all radio nodes transmit a signal of the same strength. This work studies the challenging problem of devising a distributed algorithm for multi-broadcasting, assuming a subset of nodes are initially awake, for the SINR model when each device only has access to knowledge about the total number of nodes in the network $n$, the range from which each node's label is taken $[1,\dots,N]$, and the label of the device itself. Specifically, we assume no knowledge of the physical coordinates of devices and also no knowledge of neighborhood of each node. We present a deterministic protocol for this problem in $O(n \lg N \lg n)$ rounds, assuming we have no knowledge of either the physical coordinates of devices or neighborhood of each node. There is no known polynomial time deterministic algorithm in literature for this setting, and it remains the principle open problem in this domain. A lower bound of $\Omega(n \lg N)$ rounds is known for deterministic broadcasting without local knowledge. In addition to the above result, we present algorithms to achieve multi-broadcast in $O(n \lg N)$ rounds and create a backbone in $O(n \lg N)$ rounds, assuming that all nodes are initially awake. For a given backbone, messages can be exchanged between every pair of connected nodes in the backbone in $O(\lg N)$ rounds and between any node and its leader in the backbone in $O(\Delta \lg N)$ rounds. version:2
arxiv-1705-02522 | People on Drugs: Credibility of User Statements in Health Communities | http://arxiv.org/abs/1705.02522 | id:1705.02522 author:Subhabrata Mukherjee, Gerhard Weikum, Cristian Danescu-Niculescu-Mizil category:cs.AI cs.CL cs.IR cs.SI stat.ML  published:2017-05-06 summary:Online health communities are a valuable source of information for patients and physicians. However, such user-generated resources are often plagued by inaccuracies and misinformation. In this work we propose a method for automatically establishing the credibility of user-generated medical statements and the trustworthiness of their authors by exploiting linguistic cues and distant supervision from expert sources. To this end we introduce a probabilistic graphical model that jointly learns user trustworthiness, statement credibility, and language objectivity. We apply this methodology to the task of extracting rare or unknown side-effects of medical drugs --- this being one of the problems where large scale non-expert data has the potential to complement expert medical knowledge. We show that our method can reliably extract side-effects and filter out false statements, while identifying trustworthy users that are likely to contribute valuable medical information. version:1
arxiv-1705-02519 | Item Recommendation with Evolving User Preferences and Experience | http://arxiv.org/abs/1705.02519 | id:1705.02519 author:Subhabrata Mukherjee, Hemank Lamba, Gerhard Weikum category:cs.AI cs.CL cs.IR cs.SI stat.ML  published:2017-05-06 summary:Current recommender systems exploit user and item similarities by collaborative filtering. Some advanced methods also consider the temporal evolution of item ratings as a global background process. However, all prior methods disregard the individual evolution of a user's experience level and how this is expressed in the user's writing in a review community. In this paper, we model the joint evolution of user experience, interest in specific item facets, writing style, and rating behavior. This way we can generate individual recommendations that take into account the user's maturity level (e.g., recommending art movies rather than blockbusters for a cinematography expert). As only item ratings and review texts are observables, we capture the user's experience and interests in a latent model learned from her reviews, vocabulary and writing style. We develop a generative HMM-LDA model to trace user evolution, where the Hidden Markov Model (HMM) traces her latent experience progressing over time -- with solely user reviews and ratings as observables over time. The facets of a user's interest are drawn from a Latent Dirichlet Allocation (LDA) model derived from her reviews, as a function of her (again latent) experience level. In experiments with five real-world datasets, we show that our model improves the rating prediction over state-of-the-art baselines, by a substantial margin. We also show, in a use-case study, that our model performs well in the assessment of user experience levels. version:1
arxiv-1705-02518 | Exploring Latent Semantic Factors to Find Useful Product Reviews | http://arxiv.org/abs/1705.02518 | id:1705.02518 author:Subhabrata Mukherjee, Kashyap Popat, Gerhard Weikum category:cs.AI cs.CL cs.IR cs.SI stat.ML  published:2017-05-06 summary:Online reviews provided by consumers are a valuable asset for e-Commerce platforms, influencing potential consumers in making purchasing decisions. However, these reviews are of varying quality, with the useful ones buried deep within a heap of non-informative reviews. In this work, we attempt to automatically identify review quality in terms of its helpfulness to the end consumers. In contrast to previous works in this domain exploiting a variety of syntactic and community-level features, we delve deep into the semantics of reviews as to what makes them useful, providing interpretable explanation for the same. We identify a set of consistency and semantic factors, all from the text, ratings, and timestamps of user-generated reviews, making our approach generalizable across all communities and domains. We explore review semantics in terms of several latent factors like the expertise of its author, his judgment about the fine-grained facets of the underlying product, and his writing style. These are cast into a Hidden Markov Model -- Latent Dirichlet Allocation (HMM-LDA) based model to jointly infer: (i) reviewer expertise, (ii) item facets, and (iii) review helpfulness. Large-scale experiments on five real-world datasets from Amazon show significant improvement over state-of-the-art baselines in predicting and ranking useful reviews. version:1
arxiv-1705-00321 | Generative Neural Machine for Tree Structures | http://arxiv.org/abs/1705.00321 | id:1705.00321 author:Ganbin Zhou, Ping Luo, Rongyu Cao, Yijun Xiao, Fen Lin, Bo Chen, Qing He category:cs.AI cs.CL cs.LG  published:2017-04-30 summary:Tree structures are commonly used in the tasks of semantic analysis and understanding over the data of different modalities, such as natural language, 2D or 3D graphics and images, or Web pages. Previous studies model the tree structures in a bottom-up manner, where the leaf nodes (given in advance) are merged into internal nodes until they reach the root node. However, these models are not applicable when the leaf nodes are not explicitly specified ahead of prediction. Here, we introduce a neural machine for top-down generation of tree structures that aims to infer such tree structures without the specified leaf nodes. In this model, the history memories from ancestors are fed to a node to generate its (ordered) children in a recursive manner. This model can be utilized as a tree-structured decoder in the framework of "X to tree" learning, where X stands for any structure (e.g. chain, tree etc.) that can be represented as a latent vector. By transforming the dialogue generation problem into a sequence-to-tree task, we demonstrate the proposed X2Tree framework achieves a 11.15% increase of response acceptance ratio over the baseline methods. version:2
arxiv-1705-02477 | Metacognitive Learning Approach for Online Tool Condition Monitoring | http://arxiv.org/abs/1705.02477 | id:1705.02477 author:Mahardhika Pratama, Eric Dimla, Chow Yin Lai, Edwin Lughofer category:cs.AI  published:2017-05-06 summary:As manufacturing processes become increasingly automated, so should tool condition monitoring (TCM) as it is impractical to have human workers monitor the state of the tools continuously. Tool condition is crucial to ensure the good quality of products: Worn tools affect not only the surface quality but also the dimensional accuracy, which means higher reject rate of the products. Therefore, there is an urgent need to identify tool failures before it occurs on the fly. While various versions of intelligent tool condition monitoring have been proposed, most of them suffer from a cognitive nature of traditional machine learning algorithms. They focus on the how to learn process without paying attention to other two crucial issues: what to learn, and when to learn. The what to learn and the when to learn provide self regulating mechanisms to select the training samples and to determine time instants to train a model. A novel tool condition monitoring approach based on a psychologically plausible concept, namely the metacognitive scaffolding theory, is proposed and built upon a recently published algorithm, recurrent classifier (rClass). The learning process consists of three phases: what to learn, how to learn, when to learn and makes use of a generalized recurrent network structure as a cognitive component. Experimental studies with real-world manufacturing data streams were conducted where rClass demonstrated the highest accuracy while retaining the lowest complexity over its counterparts. version:1
arxiv-1705-02476 | PANFIS++: A Generalized Approach to Evolving Learning | http://arxiv.org/abs/1705.02476 | id:1705.02476 author:Mahardhika Pratama category:cs.AI  published:2017-05-06 summary:The concept of evolving intelligent system (EIS) provides an effective avenue for data stream mining because it is capable of coping with two prominent issues: online learning and rapidly changing environments. We note at least three uncharted territories of existing EISs: data uncertainty, temporal system dynamic, redundant data streams. This book chapter aims at delivering a concrete solution of this problem with the algorithmic development of a novel learning algorithm, namely PANFIS++. PANFIS++ is a generalized version of the PANFIS by putting forward three important components: 1) An online active learning scenario is developed to overcome redundant data streams. This module allows to actively select data streams for the training process, thereby expediting execution time and enhancing generalization performance, 2) PANFIS++ is built upon an interval type-2 fuzzy system environment, which incorporates the so-called footprint of uncertainty. This component provides a degree of tolerance for data uncertainty. 3) PANFIS++ is structured under a recurrent network architecture with a self-feedback loop. This is meant to tackle the temporal system dynamic. The efficacy of the PANFIS++ has been numerically validated through numerous real-world and synthetic case studies, where it delivers the highest predictive accuracy while retaining the lowest complexity. version:1
arxiv-1406-5301 | Low-Autocorrelation Binary Sequences: On Improved Merit Factors and Runtime Predictions to Achieve Them | http://arxiv.org/abs/1406.5301 | id:1406.5301 author:Borko Bošković, Franc Brglez, Janez Brest category:cs.DS cs.AI 68T20 I.2.8; G.1.6  published:2014-06-20 summary:The search for binary sequences with a high figure of merit, known as the low autocorrelation binary sequence ($labs$}) problem, represents a formidable computational challenge. To mitigate the computational constraints of the problem, we consider solvers that accept odd values of sequence length $L$ and return solutions for skew-symmetric binary sequences only -- with the consequence that not all best solutions under this constraint will be optimal for each $L$. In order to improve both, the search for best merit factor $and$ the asymptotic runtime performance, we instrumented three stochastic solvers, the first two are state-of-the-art solvers that rely on variants of memetic and tabu search ($lssMAts$ and $lssRRts$), the third solver ($lssOrel$) organizes the search as a sequence of independent contiguous self-avoiding walk segments. By adapting a rigorous statistical methodology to performance testing of all three combinatorial solvers, experiments show that the solver with the best asymptotic average-case performance, $lssOrel\_8 = 0.000032*1.1504^L$, has the best chance of finding solutions that improve, as $L$ increases, figures of merit reported to date. The same methodology can be applied to engineering new $labs$ solvers that may return merit factors even closer to the conjectured asymptotic value of 12.3248. version:6
arxiv-1608-05743 | A Scalable Framework for Wireless Distributed Computing | http://arxiv.org/abs/1608.05743 | id:1608.05743 author:Songze Li, Qian Yu, Mohammad Ali Maddah-Ali, A. Salman Avestimehr category:cs.IT cs.DC math.IT  published:2016-08-19 summary:We consider a wireless distributed computing system, in which multiple mobile users, connected wirelessly through an access point, collaborate to perform a computation task. In particular, users communicate with each other via the access point to exchange their locally computed intermediate computation results, which is known as data shuffling. We propose a scalable framework for this system, in which the required communication bandwidth for data shuffling does not increase with the number of users in the network. The key idea is to utilize a particular repetitive pattern of placing the dataset (thus a particular repetitive pattern of intermediate computations), in order to provide coding opportunities at both the users and the access point, which reduce the required uplink communication bandwidth from users to access point and the downlink communication bandwidth from access point to users by factors that grow linearly with the number of users. We also demonstrate that the proposed dataset placement and coded shuffling schemes are optimal (i.e., achieve the minimum required shuffling load) for both a centralized setting and a decentralized setting, by developing tight information-theoretic lower bounds. version:2
arxiv-1705-02403 | Group Marching Tree: Sampling-Based Approximately Optimal Motion Planning on GPUs | http://arxiv.org/abs/1705.02403 | id:1705.02403 author:Brian Ichter, Edward Schmerling, Marco Pavone category:cs.RO  published:2017-05-05 summary:This paper presents a novel approach, named the Group Marching Tree (GMT*) algorithm, to planning on GPUs at rates amenable to application within control loops, allowing planning in real-world settings via repeated computation of near-optimal plans. GMT*, like the Fast Marching Tree (FMT) algorithm, explores the state space with a "lazy" dynamic programming recursion on a set of samples to grow a tree of near-optimal paths. GMT*, however, alters the approach of FMT with approximate dynamic programming by expanding, in parallel, the group of all active samples with cost below an increasing threshold, rather than only the minimum cost sample. This group approximation enables low-level parallelism over the sample set and removes the need for sequential data structures, while the "lazy" collision checking limits thread divergence---all contributing to a very efficient GPU implementation. While this approach incurs some suboptimality, we prove that GMT* remains asymptotically optimal up to a constant multiplicative factor. We show solutions for complex planning problems under differential constraints can be found in ~10 ms on a desktop GPU and ~30 ms on an embedded GPU, representing a significant speed up over the state of the art, with only small losses in performance. Finally, we present a scenario demonstrating the efficacy of planning within the control loop (~100 Hz) towards operating in dynamic, uncertain settings. version:1
arxiv-1705-02245 | Data Readiness Levels | http://arxiv.org/abs/1705.02245 | id:1705.02245 author:Neil D. Lawrence category:cs.DB cs.AI cs.CY cs.LG  published:2017-05-05 summary:Application of models to data is fraught. Data-generating collaborators often only have a very basic understanding of the complications of collating, processing and curating data. Challenges include: poor data collection practices, missing values, inconvenient storage mechanisms, intellectual property, security and privacy. All these aspects obstruct the sharing and interconnection of data, and the eventual interpretation of data through machine learning or other approaches. In project reporting, a major challenge is in encapsulating these problems and enabling goals to be built around the processing of data. Project overruns can occur due to failure to account for the amount of time required to curate and collate. But to understand these failures we need to have a common language for assessing the readiness of a particular data set. This position paper proposes the use of data readiness levels: it gives a rough outline of three stages of data preparedness and speculates on how formalisation of these levels into a common language for data readiness could facilitate project management. version:1
arxiv-1705-03352 | Composition of Credal Sets via Polyhedral Geometry | http://arxiv.org/abs/1705.03352 | id:1705.03352 author:Jiřina Vejnarová, Václav Kratochvíl category:cs.AI 68T37 I.2  published:2017-05-05 summary:Recently introduced composition operator for credal sets is an analogy of such operators in probability, possibility, evidence and valuation-based systems theories. It was designed to construct multidimensional models (in the framework of credal sets) from a system of low- dimensional credal sets. In this paper we study its potential from the computational point of view utilizing methods of polyhedral geometry. version:1
arxiv-1705-02212 | Group invariance principles for causal generative models | http://arxiv.org/abs/1705.02212 | id:1705.02212 author:Michel Besserve, Naji Shajarisales, Bernhard Schölkopf, Dominik Janzing category:stat.ML cs.AI cs.LG math.ST stat.TH  published:2017-05-05 summary:The postulate of independence of cause and mechanism (ICM) has recently led to several new causal discovery algorithms. The interpretation of independence and the way it is utilized, however, varies across these methods. Our aim in this paper is to propose a group theoretic framework for ICM to unify and generalize these approaches. In our setting, the cause-mechanism relationship is assessed by comparing it against a null hypothesis through the application of random generic group transformations. We show that the group theoretic view provides a very general tool to study the structure of data generating mechanisms with direct applications to machine learning. version:1
arxiv-1705-02210 | SLDR-DL: A Framework for SLD-Resolution with Deep Learning | http://arxiv.org/abs/1705.02210 | id:1705.02210 author:Cheng-Hao Cai category:cs.AI cs.LG cs.LO  published:2017-05-05 summary:This paper introduces an SLD-resolution technique based on deep learning. This technique enables neural networks to learn from old and successful resolution processes and to use learnt experiences to guide new resolution processes. An implementation of this technique is named SLDR-DL. It includes a Prolog library of deep feedforward neural networks and some essential functions of resolution. In the SLDR-DL framework, users can define logical rules in the form of definite clauses and teach neural networks to use the rules in reasoning processes. version:1
arxiv-1705-02175 | Distributed Online Learning of Event Definitions | http://arxiv.org/abs/1705.02175 | id:1705.02175 author:Nikos Katzouris, Alexander Artikis, Georgios Paliouras category:cs.AI  published:2017-05-05 summary:Logic-based event recognition systems infer occurrences of events in time using a set of event definitions in the form of first-order rules. The Event Calculus is a temporal logic that has been used as a basis in event recognition applications, providing among others, direct connections to machine learning, via Inductive Logic Programming (ILP). OLED is a recently proposed ILP system that learns event definitions in the form of Event Calculus theories, in a single pass over a data stream. In this work we present a version of OLED that allows for distributed, online learning. We evaluate our approach on a benchmark activity recognition dataset and show that we can significantly reduce training times, exchanging minimal information between processing nodes. version:1
arxiv-1707-05364 | Modern Data Formats for Big Bioinformatics Data Analytics | http://arxiv.org/abs/1707.05364 | id:1707.05364 author:Shahzad Ahmed, M. Usman Ali, Javed Ferzund, Muhammad Atif Sarwar, Abbas Rehman, Atif Mehmood category:cs.DB cs.CY cs.DC  published:2017-05-05 summary:Next Generation Sequencing (NGS) technology has resulted in massive amounts of proteomics and genomics data. This data is of no use if it is not properly analyzed. ETL (Extraction, Transformation, Loading) is an important step in designing data analytics applications. ETL requires proper understanding of features of data. Data format plays a key role in understanding of data, representation of data, space required to store data, data I/O during processing of data, intermediate results of processing, in-memory analysis of data and overall time required to process data. Different data mining and machine learning algorithms require input data in specific types and formats. This paper explores the data formats used by different tools and algorithms and also presents modern data formats that are used on Big Data Platform. It will help researchers and developers in choosing appropriate data format to be used for a particular tool or algorithm. version:1
arxiv-1605-02669 | The GPU-based Parallel Ant Colony System | http://arxiv.org/abs/1605.02669 | id:1605.02669 author:Rafał Skinderowicz category:cs.DC cs.AI  published:2016-05-09 summary:The Ant Colony System (ACS) is, next to Ant Colony Optimization (ACO) and the MAX-MIN Ant System (MMAS), one of the most efficient metaheuristic algorithms inspired by the behavior of ants. In this article we present three novel parallel versions of the ACS for the graphics processing units (GPUs). To the best of our knowledge, this is the first such work on the ACS which shares many key elements of the ACO and the MMAS, but differences in the process of building solutions and updating the pheromone trails make obtaining an efficient parallel version for the GPUs a difficult task. The proposed parallel versions of the ACS differ mainly in their implementations of the pheromone memory. The first two use the standard pheromone matrix, and the third uses a novel selective pheromone memory. Computational experiments conducted on several Travelling Salesman Problem (TSP) instances of sizes ranging from 198 to 2392 cities showed that the parallel ACS on Nvidia Kepler GK104 GPU (1536 CUDA cores) is able to obtain a speedup up to 24.29x vs the sequential ACS running on a single core of Intel Xeon E5-2670 CPU. The parallel ACS with the selective pheromone memory achieved speedups up to 16.85x, but in most cases the obtained solutions were of significantly better quality than for the sequential ACS. version:2
arxiv-1612-02168 | Asynchronous approach in the plane: A deterministic polynomial algorithm | http://arxiv.org/abs/1612.02168 | id:1612.02168 author:Sébastien Bouchard, Marjorie Bournat, Yoann Dieudonné, Swan Dubois, Franck Petit category:cs.DS cs.DC  published:2016-12-07 summary:In this paper we study the task of approach of two mobile agents having the same limited range of vision and moving asynchronously in the plane. This task consists in getting them in finite time within each other's range of vision. The agents execute the same deterministic algorithm and are assumed to have a compass showing the cardinal directions as well as a unit measure. On the other hand, they do not share any global coordinates system (like GPS), cannot communicate and have distinct labels. Each agent knows its label but does not know the label of the other agent or the initial position of the other agent relative to its own. The route of an agent is a sequence of segments that are subsequently traversed in order to achieve approach. For each agent, the computation of its route depends only on its algorithm and its label. An adversary chooses the initial positions of both agents in the plane and controls the way each of them moves along every segment of the routes, in particular by arbitrarily varying the speeds of the agents. A deterministic approach algorithm is a deterministic algorithm that always allows two agents with any distinct labels to solve the task of approach regardless of the choices and the behavior of the adversary. The cost of a complete execution of an approach algorithm is the length of both parts of route travelled by the agents until approach is completed. Let $\Delta$ and $l$ be the initial distance separating the agents and the length of the shortest label, respectively. Assuming that $\Delta$ and $l$ are unknown to both agents, does there exist a deterministic approach algorithm always working at a cost that is polynomial in $\Delta$ and $l$? In this paper, we provide a positive answer to the above question by designing such an algorithm. version:3
arxiv-1704-03396 | Source-Sensitive Belief Change | http://arxiv.org/abs/1704.03396 | id:1704.03396 author:Shahab Ebrahimi category:cs.AI cs.LO  published:2017-04-11 summary:The AGM model is the most remarkable framework for modeling belief revision. However, it is not perfect in all aspects. Paraconsistent belief revision, multi-agent belief revision and non-prioritized belief revision are three different extensions to AGM to address three important criticisms applied to it. In this article, we propose a framework based on AGM that takes a position in each of these categories. Also, we discuss some features of our framework and study the satisfiability of AGM postulates in this new context. version:2
arxiv-1705-02127 | A Note on Hardness of Diameter Approximation | http://arxiv.org/abs/1705.02127 | id:1705.02127 author:Karl Bringmann, Sebastian Krinninger category:cs.DS cs.DC  published:2017-05-05 summary:We revisit the hardness of approximating the diameter of a network. In the CONGEST model, $ \tilde \Omega (n) $ rounds are necessary to compute the diameter [Frischknecht et al. SODA'12]. Abboud et al. DISC 2016 extended this result to sparse graphs and, at a more fine-grained level, showed that, for any integer $ 1 \leq \ell \leq \operatorname{polylog} (n) $, distinguishing between networks of diameter $ 4 \ell + 2 $ and $ 6 \ell + 1 $ requires $ \tilde \Omega (n) $ rounds. We slightly tighten this result by showing that even distinguishing between diameter $ 2 \ell + 1 $ and $ 3 \ell + 1 $ requires $ \tilde \Omega (n) $ rounds. The reduction of Abboud et al. is inspired by recent conditional lower bounds in the RAM model, where the orthogonal vectors problem plays a pivotal role. In our new lower bound, we make the connection to orthogonal vectors explicit, leading to a conceptually more streamlined exposition. This is suited for teaching both the lower bound in the CONGEST model and the conditional lower bound in the RAM model. version:1
arxiv-1705-04282 | Learning to see people like people | http://arxiv.org/abs/1705.04282 | id:1705.04282 author:Amanda Song, Linjie Li, Chad Atalla, Garrison Cottrell category:cs.CV cs.AI cs.LG  published:2017-05-05 summary:Humans make complex inferences on faces, ranging from objective properties (gender, ethnicity, expression, age, identity, etc) to subjective judgments (facial attractiveness, trustworthiness, sociability, friendliness, etc). While the objective aspects of face perception have been extensively studied, relatively fewer computational models have been developed for the social impressions of faces. Bridging this gap, we develop a method to predict human impressions of faces in 40 subjective social dimensions, using deep representations from state-of-the-art neural networks. We find that model performance grows as the human consensus on a face trait increases, and that model predictions outperform human groups in correlation with human averages. This illustrates the learnability of subjective social perception of faces, especially when there is high human consensus. Our system can be used to decide which photographs from a personal collection will make the best impression. The results are significant for the field of social robotics, demonstrating that robots can learn the subjective judgments defining the underlying fabric of human interaction. version:1
arxiv-1705-02017 | Distributed Formation Control for Autonomous Robots in Dynamic Environments | http://arxiv.org/abs/1705.02017 | id:1705.02017 author:Anh-Duc Dang, Hung M. La, Thang Nguyen, Joachim Horn category:cs.RO  published:2017-05-04 summary:In this paper, we propose a novel and distributed formation control method for autonomous robots to follow the desired formation while tracking a moving target in dynamic environments. In our approach, the desired formations, which include the virtual nodes arranged into specific shapes, are first generated. Then, autonomous robots are controlled by the proposed artificial force fields in order to converge to these virtual nodes without collisions. The stability analysis based on the Lyapunov approach is given. Moreover, a new combination of rotational force field and repulsive force field in designing an obstacle avoidance controller allows the robot to avoid and escape the convex and nonconvex obstacle shapes. The V-shape and circular shape formations with their advantages are utilized to test the effectiveness of the proposed method. version:1
arxiv-1705-01817 | A Reasoning System for a First-Order Logic of Limited Belief | http://arxiv.org/abs/1705.01817 | id:1705.01817 author:Christoph Schwering category:cs.AI  published:2017-05-04 summary:Logics of limited belief aim at enabling computationally feasible reasoning in highly expressive representation languages. These languages are often dialects of first-order logic with a weaker form of logical entailment that keeps reasoning decidable or even tractable. While a number of such logics have been proposed in the past, they tend to remain for theoretical analysis only and their practical relevance is very limited. In this paper, we aim to go beyond the theory. Building on earlier work by Liu, Lakemeyer, and Levesque, we develop a logic of limited belief that is highly expressive while remaining decidable in the first-order and tractable in the propositional case and exhibits some characteristics that make it attractive for an implementation. We introduce a reasoning system that employs this logic as representation language and present experimental results that showcase the benefit of limited belief. version:1
arxiv-1705-01813 | Fast k-means based on KNN Graph | http://arxiv.org/abs/1705.01813 | id:1705.01813 author:Cheng-Hao Deng, Wan-Lei Zhao category:cs.LG cs.AI cs.CV  published:2017-05-04 summary:In the era of big data, k-means clustering has been widely adopted as a basic processing tool in various contexts. However, its computational cost could be prohibitively high as the data size and the cluster number are large. It is well known that the processing bottleneck of k-means lies in the operation of seeking closest centroid in each iteration. In this paper, a novel solution towards the scalability issue of k-means is presented. In the proposal, k-means is supported by an approximate k-nearest neighbors graph. In the k-means iteration, each data sample is only compared to clusters that its nearest neighbors reside. Since the number of nearest neighbors we consider is much less than k, the processing cost in this step becomes minor and irrelevant to k. The processing bottleneck is therefore overcome. The most interesting thing is that k-nearest neighbor graph is constructed by iteratively calling the fast $k$-means itself. Comparing with existing fast k-means variants, the proposed algorithm achieves hundreds to thousands times speed-up while maintaining high clustering quality. As it is tested on 10 million 512-dimensional data, it takes only 5.2 hours to produce 1 million clusters. In contrast, to fulfill the same scale of clustering, it would take 3 years for traditional k-means. version:1
arxiv-1702-07213 | Synchronizability of Communicating Finite State Machines is not Decidable | http://arxiv.org/abs/1702.07213 | id:1702.07213 author:Alain Finkel, Etienne Lozes category:cs.DC cs.FL  published:2017-02-23 summary:A system of communicating finite state machines is synchronizableif its send trace semantics, i.e.the set of sequences of sendings it can perform, is the same when its communications areFIFO asynchronous and when they are just rendez-vous synchronizations. This property was claimed to be decidable in several conference and journalpapers for either mailboxes or peer-to-peer communications, thanks to a form of small model property. In this paper, we show thatthis small model property does not hold neither for mailbox communications, nor for peer-to-peer communications, therefore the decidabilityof synchronizability becomes an open question. We close this question for peer-to-peer communications, and we show thatsynchronizability is actually undecidable. We show that synchronizability isdecidable if the topology of communications is an oriented ring. We also show that,in this case,synchronizability implies the absence of unspecified receptions and orphan messages, and thechannel-recognizability of the reachability set. version:3
arxiv-1705-01738 | Pixie: A heterogeneous Virtual Coarse-Grained Reconfigurable Array for high performance image processing applications | http://arxiv.org/abs/1705.01738 | id:1705.01738 author:Amit Kulkarni, Dirk Stroobandt, Andre Werner, Florian Fricke, Michael Huebner category:cs.AR  published:2017-05-04 summary:Coarse-Grained Reconfigurable Arrays (CGRAs) enable ease of programmability and result in low development costs. They enable the ease of use specifically in reconfigurable computing applications. The smaller cost of compilation and reduced reconfiguration overhead enables them to become attractive platforms for accelerating high-performance computing applications such as image processing. The CGRAs are ASICs and therefore, expensive to produce. However, Field Programmable Gate Arrays (FPGAs) are relatively cheaper for low volume products but they are not so easily programmable. We combine best of both worlds by implementing a Virtual Coarse-Grained Reconfigurable Array (VCGRA) on FPGA. VCGRAs are a trade off between FPGA with large routing overheads and ASICs. In this perspective we present a novel heterogeneous Virtual Coarse-Grained Reconfigurable Array (VCGRA) called "Pixie" which is suitable for implementing high performance image processing applications. The proposed VCGRA contains generic processing elements and virtual channels that are described using the Hardware Description Language VHDL. Both elements have been optimized by using the parameterized configuration tool flow and result in a resource reduction of 24% for each processing elements and 82% for each virtual channels respectively. version:1
arxiv-1705-01736 | Of the People: Voting Is More Effective with Representative Candidates | http://arxiv.org/abs/1705.01736 | id:1705.01736 author:Yu Cheng, Shaddin Dughmi, David Kempe category:cs.GT cs.AI  published:2017-05-04 summary:In light of the classic impossibility results of Arrow and Gibbard and Satterthwaite regarding voting with ordinal rules, there has been recent interest in characterizing how well common voting rules approximate the social optimum. In order to quantify the quality of approximation, it is natural to consider the candidates and voters as embedded within a common metric space, and to ask how much further the chosen candidate is from the population as compared to the socially optimal one. We use this metric preference model to explore a fundamental and timely question: does the social welfare of a population improve when candidates are representative of the population? If so, then by how much, and how does the answer depend on the complexity of the metric space? We restrict attention to the most fundamental and common social choice setting: a population of voters, two independently drawn candidates, and a majority rule election. When candidates are not representative of the population, it is known that the candidate selected by the majority rule can be thrice as far from the population as the socially optimal one. We examine how this ratio improves when candidates are drawn independently from the population of voters. Our results are two-fold: When the metric is a line, the ratio improves from 3 to 4-2 \sqrt{2}, roughly 1.1716; this bound is tight. When the metric is arbitrary, we show a lower bound of 1.5 and a constant upper bound strictly better than 2 on the approximation ratio of the majority rule. The positive result depends in part on the assumption that candidates are independent and identically distributed. However, we show that independence alone is not enough to achieve the upper bound: even when candidates are drawn independently, if the population of candidates can be different from the voters, then an upper bound of 2 on the approximation is tight. version:1
arxiv-1705-01681 | Tramp Ship Scheduling Problem with Berth Allocation Considerations and Time-dependent Constraints | http://arxiv.org/abs/1705.01681 | id:1705.01681 author:Francisco López-Ramos, Armando Guarnaschelli, José-Fernando Camacho-Vallejo, Laura Hervert-Escobar, Rosa G. González-Ramírez category:cs.AI  published:2017-05-04 summary:This work presents a model for the Tramp Ship Scheduling problem including berth allocation considerations, motivated by a real case of a shipping company. The aim is to determine the travel schedule for each vessel considering multiple docking and multiple time windows at the berths. This work is innovative due to the consideration of both spatial and temporal attributes during the scheduling process. The resulting model is formulated as a mixed-integer linear programming problem, and a heuristic method to deal with multiple vessel schedules is also presented. Numerical experimentation is performed to highlight the benefits of the proposed approach and the applicability of the heuristic. Conclusions and recommendations for further research are provided. version:1
arxiv-1703-03524 | The Ontological Multidimensional Data Model | http://arxiv.org/abs/1703.03524 | id:1703.03524 author:Leopoldo Bertossi, Mostafa Milani category:cs.DB cs.AI  published:2017-03-10 summary:In this extended abstract we describe, mainly by examples, the main elements of the Ontological Multidimensional Data Model, which considerably extends a relational reconstruction of the multidimensional data model proposed by Hurtado and Mendelzon by means of tuple-generating dependencies, equality-generating dependencies, and negative constraints as found in Datalog+-. We briefly mention some good computational properties of the model. version:2
arxiv-1705-01662 | Execution Templates: Caching Control Plane Decisions for Strong Scaling of Data Analytics | http://arxiv.org/abs/1705.01662 | id:1705.01662 author:Omid Mashayekhi, Hang Qu, Chinmayee Shah, Philip Levis category:cs.DC  published:2017-05-04 summary:Control planes of cloud frameworks trade off between scheduling granularity and performance. Centralized systems schedule at task granularity, but only schedule a few thousand tasks per second. Distributed systems schedule hundreds of thousands of tasks per second but changing the schedule is costly. We present execution templates, a control plane abstraction that can schedule hundreds of thousands of tasks per second while supporting fine-grained, per-task scheduling decisions. Execution templates leverage a program's repetitive control flow to cache blocks of frequently-executed tasks. Executing a task in a template requires sending a single message. Large-scale scheduling changes install new templates, while small changes apply edits to existing templates. Evaluations of execution templates in Nimbus, a data analytics framework, find that they provide the fine-grained scheduling flexibility of centralized control planes while matching the strong scaling of distributed ones. Execution templates support complex, real-world applications, such as a fluid simulation with a triply nested loop and data dependent branches. version:1
arxiv-1705-01660 | MapReduce Particle Filtering with Exact Resampling and Deterministic Runtime | http://arxiv.org/abs/1705.01660 | id:1705.01660 author:Jeyarajan Thiyagalingam, Lykourgos Kekempanos, Simon Maskell category:stat.CO cs.DC  published:2017-05-04 summary:Particle filtering is a numerical Bayesian technique that has great potential for solving sequential estimation problems involving non-linear and non-Gaussian models. Since the estimation accuracy achieved by particle filters improves as the number of particles increases, it is natural to consider as many particles as possible. MapReduce is a generic programming model that makes it possible to scale a wide variety of algorithms to Big data. However, despite the application of particle filters across many domains, little attention has been devoted to implementing particle filters using MapReduce. In this paper, we describe an implementation of a particle filter using MapReduce. We focus on a component that what would otherwise be a bottleneck to parallel execution, the resampling component. We devise a new implementation of this component, which requires no approximations, has $O\left(N\right)$ spatial complexity and deterministic $O\left(\left(\log N\right)^2\right)$ time complexity. Results demonstrate the utility of this new component and culminate in consideration of a particle filter with $2^{24}$ particles being distributed across $512$ processor cores. version:1
arxiv-1705-01626 | Compressing DMA Engine: Leveraging Activation Sparsity for Training Deep Neural Networks | http://arxiv.org/abs/1705.01626 | id:1705.01626 author:Minsoo Rhu, Mike O'Connor, Niladrish Chatterjee, Jeff Pool, Stephen W. Keckler category:cs.LG cs.AR  published:2017-05-03 summary:Popular deep learning frameworks require users to fine-tune their memory usage so that the training data of a deep neural network (DNN) fits within the GPU physical memory. Prior work tries to address this restriction by virtualizing the memory usage of DNNs, enabling both CPU and GPU memory to be utilized for memory allocations. Despite its merits, virtualizing memory can incur significant performance overheads when the time needed to copy data back and forth from CPU memory is higher than the latency to perform the computations required for DNN forward and backward propagation. We introduce a high-performance virtualization strategy based on a "compressing DMA engine" (cDMA) that drastically reduces the size of the data structures that are targeted for CPU-side allocations. The cDMA engine offers an average 2.6x (maximum 13.8x) compression ratio by exploiting the sparsity inherent in offloaded data, improving the performance of virtualized DNNs by an average 32% (maximum 61%). version:1
arxiv-1705-00582 | Statistical Multiplexing and Traffic Shaping Games for Network Slicing | http://arxiv.org/abs/1705.00582 | id:1705.00582 author:Jiaxiao Zheng, Pablo Caballero, Gustavo de Veciana, Seung Jun Baek, Albert Banchs category:cs.NI cs.DC  published:2017-05-01 summary:Next generation wireless architectures are expected to enable slices of shared wireless infrastructure which are customized to specific mobile operators/services. Given infrastructure costs and stochastic nature of mobile services' spatial loads, it is highly desirable to achieve efficient statistical multiplexing amongst network slices. We study a simple dynamic resource sharing policy which allocates a 'share' of a pool of (distributed) resources to each slice- Share Constrained Proportionally Fair (SCPF). We give a characterization of the achievable performance gains over static slicing, showing higher gains when a slice's spatial load is more 'imbalanced' than, and/or 'orthogonal' to, the aggregate network load. Under SCPF, traditional network dimensioning translates to a coupled share dimensioning problem, addressing the existence of a feasible share allocation given slices' expected loads and performance requirements. We provide a solution to robust share dimensioning for SCPF-based network slicing. Slices may wish to unilaterally manage their users' performance via admission control which maximizes their carried loads subject to performance requirements. We show this can be modeled as a "traffic shaping" game with an achievable Nash equilibrium. Under high loads, the equilibrium is explicitly characterized, as are the gains in the carried load under SCPF vs. static slicing. Detailed simulations of a wireless infrastructure supporting multiple slices with heterogeneous mobile loads show the fidelity of our models and range of validity of our high load equilibrium analysis. version:2
arxiv-1705-01426 | A Nonlinear Model Predictive Control Scheme for Cooperative Manipulation with Singularity and Collision Avoidance | http://arxiv.org/abs/1705.01426 | id:1705.01426 author:Alexandros Nikou, Christos Verginis, Shahab Heshmati-alamdari, Dimos V. Dimarogonas category:cs.RO cs.SY  published:2017-05-03 summary:This paper addresses the problem of cooperative transportation of an object rigidly grasped by $N$ robotic agents. In particular, we propose a Nonlinear Model Predictive Control (NMPC) scheme that guarantees the navigation of the object to a desired pose in a bounded workspace with obstacles, while complying with certain input saturations of the agents. Moreover, the proposed methodology ensures that the agents do not collide with each other or with the workspace obstacles as well as that they do not pass through singular configurations. The feasibility and convergence analysis of the NMPC are explicitly provided. Finally, simulation results illustrate the validity and efficiency of the proposed method. version:1
arxiv-1705-01399 | Answer Set Programming for Non-Stationary Markov Decision Processes | http://arxiv.org/abs/1705.01399 | id:1705.01399 author:Leonardo A. Ferreira, Reinaldo A. C. Bianchi, Paulo E. Santos, Ramon Lopez de Mantaras category:cs.AI  published:2017-05-03 summary:Non-stationary domains, where unforeseen changes happen, present a challenge for agents to find an optimal policy for a sequential decision making problem. This work investigates a solution to this problem that combines Markov Decision Processes (MDP) and Reinforcement Learning (RL) with Answer Set Programming (ASP) in a method we call ASP(RL). In this method, Answer Set Programming is used to find the possible trajectories of an MDP, from where Reinforcement Learning is applied to learn the optimal policy of the problem. Results show that ASP(RL) is capable of efficiently finding the optimal solution of an MDP representing non-stationary domains. version:1
arxiv-1705-01332 | LiDAR-based Control of Autonomous Rotorcraft for the Inspection of Pier-like Structures: Proofs | http://arxiv.org/abs/1705.01332 | id:1705.01332 author:Bruno J. Guerreiro, Carlos Silvestre, Rita Cunha, David Cabecinhas category:cs.SY cs.RO  published:2017-05-03 summary:This is a complementary document to the paper presented in [1], to provide more detailed proofs for some results. The main paper addresses the problem of trajectory tracking control of autonomous rotorcraft in operation scenarios where only relative position measurements obtained from LiDAR sensors are possible. The proposed approach defines an alternative kinematic model, directly based on LiDAR measurements, and uses a trajectory-dependent error space to express the dynamic model of the vehicle. An LPV representation with piecewise affine dependence on the parameters is adopted to describe the error dynamics over a set of predefined operating regions, and a continuous-time $H_2$ control problem is solved using LMIs and implemented within the scope of gain-scheduling control theory. version:1
arxiv-1701-01587 | An Optimal Randomized Broadcasting Algorithm in Radio Networks with Collision Detection | http://arxiv.org/abs/1701.01587 | id:1701.01587 author:Ny Aina Andriambolamalala, Vlady Ravelomanana category:cs.DC  published:2017-01-06 summary:We present a randomized distributed algorithm that in radio networks with collision detection broadcasts a single message in $O(D+\log^2 n)$ time slots, with high probability. In view of the lower-bound $\Omega(D+\log^2 n)$, our algorithm is optimal in the considered model answering the decades-old question of Alon, Bar-Noy, Linial and Peleg [JCSS 1991]. version:2
arxiv-1704-05908 | An Interpretable Knowledge Transfer Model for Knowledge Base Completion | http://arxiv.org/abs/1704.05908 | id:1704.05908 author:Qizhe Xie, Xuezhe Ma, Zihang Dai, Eduard Hovy category:cs.CL cs.AI cs.LG  published:2017-04-19 summary:Knowledge bases are important resources for a variety of natural language processing tasks but suffer from incompleteness. We propose a novel embedding model, \emph{ITransF}, to perform knowledge base completion. Equipped with a sparse attention mechanism, ITransF discovers hidden concepts of relations and transfer statistical strength through the sharing of concepts. Moreover, the learned associations between relations and concepts, which are represented by sparse attention vectors, can be interpreted easily. We evaluate ITransF on two benchmark datasets---WN18 and FB15k for knowledge base completion and obtains improvements on both the mean rank and Hits@10 metrics, over all baselines that do not use additional information. version:2
arxiv-1705-01229 | Deterministic Distributed Construction of $T$-Dominating Sets in Time $T$ | http://arxiv.org/abs/1705.01229 | id:1705.01229 author:Avery Miller, Andrzej Pelc category:cs.DC  published:2017-05-03 summary:A $k$-dominating set is a set $D$ of nodes of a graph such that, for each node $v$, there exists a node $w \in D$ at distance at most $k$ from $v$. Our aim is the deterministic distributed construction of small $T$-dominating sets in time $T$ in networks modeled as undirected $n$-node graphs and under the $\cal{LOCAL}$ communication model. For any positive integer $T$, if $b$ is the size of a pairwise disjoint collection of balls of radii at least $T$ in a graph, then $b$ is an obvious lower bound on the size of a $T$-dominating set. Our first result shows that, even on rings, it is impossible to construct a $T$-dominating set of size $s$ asymptotically $b$ (i.e., such that $s/b \rightarrow 1$) in time $T$. In the range of time $T \in \Theta (\log^* n)$, the size of a $T$-dominating set turns out to be very sensitive to multiplicative constants in running time. Indeed, it follows from \cite{KP}, that for time $T=\gamma \log^* n$ with large constant $\gamma$, it is possible to construct a $T$-dominating set whose size is a small fraction of $n$. By contrast, we show that, for time $T=\alpha \log^* n $ for small constant $\alpha$, the size of a $T$-dominating set must be a large fraction of $n$. Finally, when $T \in o (\log^* n)$, the above lower bound implies that, for any constant $x<1$, it is impossible to construct a $T$-dominating set of size smaller than $xn$, even on rings. On the positive side, we provide an algorithm that constructs a $T$-dominating set of size $n- \Theta(T)$ on all graphs. version:1
arxiv-1705-01228 | A Versatile, Sound Tool for Simplifying Definitions | http://arxiv.org/abs/1705.01228 | id:1705.01228 author:Alessandro Coglio, Matt Kaufmann, Eric W. Smith category:cs.PL cs.AI  published:2017-05-03 summary:We present a tool, simplify-defun, that transforms the definition of a given function into a simplified definition of a new function, providing a proof checked by ACL2 that the old and new functions are equivalent. When appropriate it also generates termination and guard proofs for the new function. We explain how the tool is engineered so that these proofs will succeed. Examples illustrate its utility, in particular for program transformation in synthesis and verification. version:1
arxiv-1705-00673 | MACA: A Modular Architecture for Conversational Agents | http://arxiv.org/abs/1705.00673 | id:1705.00673 author:Hoai Phuoc Truong, Prasanna Parthasarathi, Joelle Pineau category:cs.AI cs.SE  published:2017-05-01 summary:We propose a software architecture designed to ease the implementation of dialogue systems. The Modular Architecture for Conversational Agents (MACA) uses a plug-n-play style that allows quick prototyping, thereby facilitating the development of new techniques and the reproduction of previous work. The architecture separates the domain of the conversation from the agent's dialogue strategy, and as such can be easily extended to multiple domains. MACA provides tools to host dialogue agents on Amazon Mechanical Turk (mTurk) for data collection and allows processing of other sources of training data. The current version of the framework already incorporates several domains and existing dialogue strategies from the recent literature. version:2
arxiv-1705-01208 | A Rule-Based Computational Model of Cognitive Arithmetic | http://arxiv.org/abs/1705.01208 | id:1705.01208 author:Ashis Pati, Kantwon Rogers, Hanqing Zhu category:cs.AI q-bio.NC  published:2017-05-03 summary:Cognitive arithmetic studies the mental processes used in solving math problems. This area of research explores the retrieval mechanisms and strategies used by people during a common cognitive task. Past research has shown that human performance in arithmetic operations is correlated to the numerical size of the problem. Past research on cognitive arithmetic has pinpointed this trend to either retrieval strength, error checking, or strategy-based approaches when solving equations. This paper describes a rule-based computational model that performs the four major arithmetic operations (addition, subtraction, multiplication and division) on two operands. We then evaluated our model to probe its validity in representing the prevailing concepts observed in psychology experiments from the related works. The experiments specifically explore the problem size effect, an activation-based model for fact retrieval, backup strategies when retrieval fails, and finally optimization strategies when faced with large operands. From our experimental results, we concluded that our model's response times were comparable to results observed when people performed similar tasks during psychology experiments. The fit of our model in reproducing these results and incorporating accuracy into our model are discussed. version:1
arxiv-1705-01197 | Analyzing Knowledge Transfer in Deep Q-Networks for Autonomously Handling Multiple Intersections | http://arxiv.org/abs/1705.01197 | id:1705.01197 author:David Isele, Akansel Cosgun, Kikuo Fujimura category:cs.LG cs.AI  published:2017-05-02 summary:We analyze how the knowledge to autonomously handle one type of intersection, represented as a Deep Q-Network, translates to other types of intersections (tasks). We view intersection handling as a deep reinforcement learning problem, which approximates the state action Q function as a deep neural network. Using a traffic simulator, we show that directly copying a network trained for one type of intersection to another type of intersection decreases the success rate. We also show that when a network that is pre-trained on Task A and then is fine-tuned on a Task B, the resulting network not only performs better on the Task B than an network exclusively trained on Task A, but also retained knowledge on the Task A. Finally, we examine a lifelong learning setting, where we train a single network on five different types of intersections sequentially and show that the resulting network exhibited catastrophic forgetting of knowledge on previous tasks. This result suggests a need for a long-term memory component to preserve knowledge. version:1
arxiv-1705-01196 | Navigating Intersections with Autonomous Vehicles using Deep Reinforcement Learning | http://arxiv.org/abs/1705.01196 | id:1705.01196 author:David Isele, Akansel Cosgun, Kaushik Subramanian, Kikuo Fujimura category:cs.AI cs.RO  published:2017-05-02 summary:Providing an efficient strategy to navigate safely through unsignaled intersections is a difficult task that requires determining the intent of other drivers. We explore the effectiveness of using Deep Reinforcement Learning to handle intersection problems. Combining several recent advances in Deep RL, were we able to learn policies that surpass the performance of a commonly-used heuristic approach in several metrics including task completion time and goal success rate. Our analysis, and the solutions learned by the network point out several short comings of current rule-based methods. The fact that Deep RL policies resulted in collisions, although rarely, combined with the limitations of the policy to generalize well to out-of-sample scenarios suggest a need for further research. version:1
arxiv-1705-01187 | Towards Full Automated Drive in Urban Environments: A Demonstration in GoMentum Station, California | http://arxiv.org/abs/1705.01187 | id:1705.01187 author:Akansel Cosgun, Lichao Ma, Jimmy Chiu, Jiawei Huang, Mahmut Demir, Alexandre Miranda Anon, Thang Lian, Hasan Tafish, Samir Al-Stouhi category:cs.RO cs.AI  published:2017-05-02 summary:Each year, millions of motor vehicle traffic accidents all over the world cause a large number of fatalities, injuries and significant material loss. Automated Driving (AD) has potential to drastically reduce such accidents. In this work, we focus on the technical challenges that arise from AD in urban environments. We present the overall architecture of an AD system and describe in detail the perception and planning modules. The AD system, built on a modified Acura RLX, was demonstrated in a course in GoMentum Station in California. We demonstrated autonomous handling of 4 scenarios: traffic lights, cross-traffic at intersections, construction zones and pedestrians. The AD vehicle displayed safe behavior and performed consistently in repeated demonstrations with slight variations in conditions. Overall, we completed 44 runs, encompassing 110km of automated driving with only 3 cases where the driver intervened the control of the vehicle, mostly due to error in GPS positioning. Our demonstration showed that robust and consistent behavior in urban scenarios is possible, yet more investigation is necessary for full scale roll-out on public roads. version:1
arxiv-1705-01176 | How does Docker affect energy consumption? Evaluating workloads in and out of Docker containers | http://arxiv.org/abs/1705.01176 | id:1705.01176 author:Eddie Antonio Santos, Carson McLean, Christopher Solinas, Abram Hindle category:cs.DC cs.PF H.3.4  published:2017-05-02 summary:Context: Virtual machines provide isolation of services at the cost of hypervisors and more resource usage. This spurred the growth of systems like Docker that enable single hosts to isolate several applications, similar to VMs, within a low-overhead abstraction called containers. Motivation: Although containers tout low overhead performance, do they still have low energy consumption? Methodology: This work statistically compares ($t$-test, Wilcoxon) the energy consumption of three application workloads in Docker and on bare-metal Linux. Results: In all cases, there was a statistically significant ($t$-test and Wilcoxon $p < 0.05$) increase in energy consumption when running tests in Docker, mostly due to the performance of I/O system calls. version:1
arxiv-1705-01172 | Imagining Probabilistic Belief Change as Imaging (Technical Report) | http://arxiv.org/abs/1705.01172 | id:1705.01172 author:Gavin Rens, Thomas Meyer category:cs.AI  published:2017-05-02 summary:Imaging is a form of probabilistic belief change which could be employed for both revision and update. In this paper, we propose a new framework for probabilistic belief change based on imaging, called Expected Distance Imaging (EDI). EDI is sufficiently general to define Bayesian conditioning and other forms of imaging previously defined in the literature. We argue that, and investigate how, EDI can be used for both revision and update. EDI's definition depends crucially on a weight function whose properties are studied and whose effect on belief change operations is analysed. Finally, four EDI instantiations are proposed, two for revision and two for update, and probabilistic rationality postulates are suggested for their analysis. version:1
arxiv-1705-01167 | CDDT: Fast Approximate 2D Ray Casting for Accelerated Localization | http://arxiv.org/abs/1705.01167 | id:1705.01167 author:Corey Walsh, Sertac Karaman category:cs.DS cs.RO  published:2017-05-02 summary:Localization is an essential component for autonomous robots. A well-established localization approach combines ray casting with a particle filter, leading to a computationally expensive algorithm that is difficult to run on resource-constrained mobile robots. We present a novel data structure called the Compressed Directional Distance Transform for accelerating ray casting in two dimensional occupancy grid maps. Our approach has near constant time ray casting performance for a fixed size map, in contrast with other methods which display long tail query time distributions. Our experimental results show that the proposed algorithm approximates the performance characteristics of reading from a three dimensional lookup table of ray cast solutions while requiring two orders of magnitude less memory and precomputation. This results in a particle filter algorithm which can maintain 2500 particles with 61 ray casts per particle at 40Hz, using only a single CPU thread onboard a mobile robot. version:1
arxiv-1705-01152 | Out-of-focus: Learning Depth from Image Bokeh for Robotic Perception | http://arxiv.org/abs/1705.01152 | id:1705.01152 author:Eric Cristofalo, Zijian Wang category:cs.CV cs.RO  published:2017-05-02 summary:In this project, we propose a novel approach for estimating depth from RGB images. Traditionally, most work uses a single RGB image to estimate depth, which is inherently difficult and generally results in poor performance, even with thousands of data examples. In this work, we alternatively use multiple RGB images that were captured while changing the focus of the camera's lens. This method leverages the natural depth information correlated to the different patterns of clarity/blur in the sequence of focal images, which helps distinguish objects at different depths. Since no such data set exists for learning this mapping, we collect our own data set using customized hardware. We then use a convolutional neural network for learning the depth from the stacked focal images. Comparative studies were conducted on both a standard RGBD data set and our own data set (learning from both single and multiple images), and results verified that stacked focal images yield better depth estimation than using just single RGB image. version:1
arxiv-1705-01146 | Population protocols for leader election and exact majority with O(log^2 n) states and O(log^2 n) convergence time | http://arxiv.org/abs/1705.01146 | id:1705.01146 author:Andreas Bilke, Colin Cooper, Robert Elsaesser, Tomasz Radzik category:cs.DC  published:2017-05-02 summary:We consider the model of population protocols, which can be viewed as a sequence of random pairwise interactions of $n$ agents (nodes). We show population protocols for two problems: the leader election and the exact majority voting. The leader election starts with all agents in the same initial state and the goal is to converge to the (global) state when exactly one agent is in a distinct state $L$. The exact majority voting starts with each agent in one of the two distinct states $A$ or $B$ and the goal is to make all nodes know which of these two states was the initial majority state, even if that majority was just by a single vote. Alistarh and Gelashvili [ICALP 2015] showed a leader-election protocol which converges in $O(\log^3 n)$ time w.h.p. and in expectation and needs $\Theta(\log^3 n)$ states per agent. We present a protocol which elects the leader in $O(\log^2 n)$ time w.h.p. and in expectation and uses $\Theta(\log^2 n)$ states per agent. For the exact majority voting, we show a population protocol with the same asymptotic performance: $O(\log^2 n)$ time and $\Theta(\log^2 n)$ states per agent. The exact-majority protocol proposed by Alistarh et al. [PODC 2015] achieves expected $O(\log^2 n)$ time, but requires a relatively high initial imbalance between $A$'s and $B$'s or a large number of states per agent. More recently, Alistarh et al. [SODA 2017] showed $O(\log^2 n)$-state protocols for both problems, with the exact majority protocol converging in time $O(\log^3 n)$, and the leader election protocol converging in time $O(\log^{6.3} n)$ w.h.p. and $O(\log^{5.3} n)$ in expectation. Our leader election and exact majority protocols are based on the idea of agents counting their local interactions and rely on the probabilistic fact that the uniform random selection would limit the divergence of the individual counts. version:1
arxiv-1705-01076 | An improved Ant Colony System for the Sequential Ordering Problem | http://arxiv.org/abs/1705.01076 | id:1705.01076 author:Rafał Skinderowicz category:cs.AI  published:2017-05-02 summary:It is not rare that the performance of one metaheuristic algorithm can be improved by incorporating ideas taken from another. In this article we present how Simulated Annealing (SA) can be used to improve the efficiency of the Ant Colony System (ACS) and Enhanced ACS when solving the Sequential Ordering Problem (SOP). Moreover, we show how the very same ideas can be applied to improve the convergence of a dedicated local search, i.e. the SOP-3-exchange algorithm. A statistical analysis of the proposed algorithms both in terms of finding suitable parameter values and the quality of the generated solutions is presented based on a series of computational experiments conducted on SOP instances from the well-known TSPLIB and SOPLIB2006 repositories. The proposed ACS-SA and EACS-SA algorithms often generate solutions of better quality than the ACS and EACS, respectively. Moreover, the EACS-SA algorithm combined with the proposed SOP-3-exchange-SA local search was able to find 10 new best solutions for the SOP instances from the SOPLIB2006 repository, thus improving the state-of-the-art results as known from the literature. Overall, the best known or improved solutions were found in 41 out of 48 cases. version:1
arxiv-1704-02853 | SemEval 2017 Task 10: ScienceIE - Extracting Keyphrases and Relations from Scientific Publications | http://arxiv.org/abs/1704.02853 | id:1704.02853 author:Isabelle Augenstein, Mrinal Das, Sebastian Riedel, Lakshmi Vikraman, Andrew McCallum category:cs.CL cs.AI stat.ML  published:2017-04-10 summary:We describe the SemEval task of extracting keyphrases and relations between them from scientific documents, which is crucial for understanding which publications describe which processes, tasks and materials. Although this was a new task, we had a total of 26 submissions across 3 evaluation scenarios. We expect the task and the findings reported in this paper to be relevant for researchers working on understanding scientific content, as well as the broader knowledge base population and information extraction communities. version:3
arxiv-1705-00930 | Show, Adapt and Tell: Adversarial Training of Cross-domain Image Captioner | http://arxiv.org/abs/1705.00930 | id:1705.00930 author:Tseng-Hung Chen, Yuan-Hong Liao, Ching-Yao Chuang, Wan-Ting Hsu, Jianlong Fu, Min Sun category:cs.CV cs.AI cs.LG  published:2017-05-02 summary:Impressive image captioning results are achieved in domains with plenty of training image and sentence pairs (e.g., MSCOCO). However, transferring to a target domain with significant domain shifts but no paired training data (referred to as cross-domain image captioning) remains largely unexplored. We propose a novel adversarial training procedure to leverage unpaired data in the target domain. Two critic networks are introduced to guide the captioner, namely domain critic and multi-modal critic. The domain critic assesses whether the generated sentences are indistinguishable from sentences in the target domain. The multi-modal critic assesses whether an image and its generated sentence are a valid pair. During training, the critics and captioner act as adversaries -- captioner aims to generate indistinguishable sentences, whereas critics aim at distinguishing them. The assessment improves the captioner through policy gradient updates. During inference, we further propose a novel critic-based planning method to select high-quality sentences without additional supervision (e.g., tags). To evaluate, we use MSCOCO as the source domain and four other datasets (CUB-200-2011, Oxford-102, TGIF, and Flickr30k) as the target domains. Our method consistently performs well on all datasets. In particular, on CUB-200-2011, we achieve 21.8% CIDEr-D improvement after adaptation. Utilizing critics during inference further gives another 4.5% boost. version:1
arxiv-1412-0041 | FairCache: Introducing Fairness to ICN Caching - Technical Report | http://arxiv.org/abs/1412.0041 | id:1412.0041 author:Liang Wang, Gareth Tyson, Jussi Kangasharju, Jon Crowcroft category:cs.NI cs.DC cs.GT cs.PF  published:2014-11-28 summary:Information-centric networking extensively uses universal in-network caching. However, developing an efficient and fair collaborative caching algorithm for selfish caches is still an open question. In addition, the communication overhead induced by collaboration is especially poorly understood in a general network setting such as realistic ISP and Autonomous System networks. In this paper, we address these two problems by modeling the in-network caching problem as a Nash bargaining game. We show that the game is a convex optimization problem and further derive the corresponding distributed algorithm. We analytically investigate the collaboration overhead on general graph topologies, and theoretically show that collaboration has to be constrained within a small neighborhood due to its cost growing exponentially. Our proposed algorithm achieves at least 16% performance gain over its competitors on different network topologies in the evaluation, and guarantees provable convergence, Pareto efficiency and proportional fairness. version:4
arxiv-1603-06716 | Risk-Averse $ω$-regular Markov Decision Process Control | http://arxiv.org/abs/1603.06716 | id:1603.06716 author:Ruediger Ehlers, Salar Moarref, Ufuk Topcu category:cs.SY cs.LO cs.RO  published:2016-03-22 summary:Many control problems in environments that can be modeled as Markov decision processes (MDPs) concern infinite-time horizon specifications. The classical aim in this context is to compute a control policy that maximizes the probability of satisfying the specification. In many scenarios, there is however a non-zero probability of failure in every step of the system's execution. For infinite-time horizon specifications, this implies that the specification is violated with probability 1 in the long run no matter what policy is chosen, which prevents previous policy computation methods from being useful in these scenarios. In this paper, we introduce a new optimization criterion for MDP policies that captures the task of working towards the satisfaction of some infinite-time horizon $\omega$-regular specification. The new criterion is applicable to MDPs in which the violation of the specification cannot be avoided in the long run. We give an algorithm to compute policies that are optimal in this criterion and show that it captures the ideas of optimism and risk-averseness in MDP control: while the computed policies are optimistic in that a MDP run enters a failure state relatively late, they are risk-averse by always maximizing the probability to reach their respective next goal state. We give results on two robot control scenarios to validate the usability of risk-averse MDP policies. version:2
arxiv-1705-00786 | Social Robot Modelling of Human Affective State | http://arxiv.org/abs/1705.00786 | id:1705.00786 author:D. B. Skillicorn, N. Alsadhan, R. Billingsley, M. -A. - Williams category:cs.RO I.2.9  published:2017-05-02 summary:Social robots need to understand the affective state of the humans with whom they interact. Successful interactions require understanding mood and emotion in the short term, and personality and attitudes over longer periods. Social robots should also be able to infer the desires, wishes, and preferences of humans without being explicitly told. We investigate how effectively affective state can be inferred from corpora in which documents are plausible surrogates for what a robot might hear. For mood, emotions, wishes, desires, and attitudes we show highly ranked documents; for personality dimensions, estimates of ground truth are available and we report performance accuracy. The results are surprisingly strong given the limited information in short documents. version:1
arxiv-1612-04003 | Avoiding communication in primal and dual block coordinate descent methods | http://arxiv.org/abs/1612.04003 | id:1612.04003 author:Aditya Devarakonda, Kimon Fountoulakis, James Demmel, Michael W. Mahoney category:cs.DC 68W10  65F10 G.1.0; G.1.3; G.1.6  published:2016-12-13 summary:Primal and dual block coordinate descent methods are iterative methods for solving regularized and unregularized optimization problems. Distributed-memory parallel implementations of these methods have become popular in analyzing large machine learning datasets. However, existing implementations communicate at every iteration which, on modern data center and supercomputing architectures, often dominates the cost of floating-point computation. Recent results on communication-avoiding Krylov subspace methods suggest that large speedups are possible by re-organizing iterative algorithms to avoid communication. We show how applying similar algorithmic transformations can lead to primal and dual block coordinate descent methods that only communicate every $s$ iterations--where $s$ is a tuning parameter--instead of every iteration for the \textit{regularized least-squares problem}. We show that the communication-avoiding variants reduce the number of synchronizations by a factor of $s$ on distributed-memory parallel machines without altering the convergence rate and attains strong scaling speedups of up to $6.1\times$ on a Cray XC30 supercomputer. version:2
arxiv-1705-00249 | Unimem: Runtime Data Management on Non-Volatile Memory-based Heterogeneous Main Memory | http://arxiv.org/abs/1705.00249 | id:1705.00249 author:Kai Wu, Yingchao Huang, Dong Li category:cs.DC  published:2017-04-29 summary:Non-volatile memory (NVM) provides a scalable and power-efficient solution to replace DRAM as main memory. However, because of relatively high latency and low bandwidth of NVM, NVM is often paired with DRAM to build a heterogeneous memory system (HMS). As a result, data objects of the application must be carefully placed to NVM and DRAM for best performance. In this paper, we introduce a lightweight runtime solution that automatically and transparently manage data placement on HMS without the requirement of hardware modifications and disruptive change to applications. Leveraging online profiling and performance models, the runtime characterizes memory access patterns associated with data objects, and minimizes unnecessary data movement. Our runtime solution effectively bridges the performance gap between NVM and DRAM. We demonstrate that using NVM to replace the majority of DRAM can be a feasible solution for future HPC systems with the assistance of a software-based data management. version:2
arxiv-1705-00047 | Kiwi - A Minimalist CP Solver | http://arxiv.org/abs/1705.00047 | id:1705.00047 author:Renaud Hartert category:cs.AI cs.SE  published:2017-04-28 summary:Kiwi is a minimalist and extendable Constraint Programming (CP) solver specifically designed for education. The particularities of Kiwi stand in its generic trailing state restoration mechanism and its modulable use of variables. By developing Kiwi, the author does not aim to provide an alternative to full featured constraint solvers but rather to provide readers with a basic architecture that will (hopefully) help them to understand the core mechanisms hidden under the hood of constraint solvers, to develop their own extended constraint solver, or to test innovative ideas. version:2
arxiv-1704-08847 | Parseval Networks: Improving Robustness to Adversarial Examples | http://arxiv.org/abs/1704.08847 | id:1704.08847 author:Moustapha Cisse, Piotr Bojanowski, Edouard Grave, Yann Dauphin, Nicolas Usunier category:stat.ML cs.AI cs.LG  published:2017-04-28 summary:We introduce Parseval networks, a form of deep neural networks in which the Lipschitz constant of linear, convolutional and aggregation layers is constrained to be smaller than 1. Parseval networks are empirically and theoretically motivated by an analysis of the robustness of the predictions made by deep neural networks when their input is subject to an adversarial perturbation. The most important feature of Parseval networks is to maintain weight matrices of linear and convolutional layers to be (approximately) Parseval tight frames, which are extensions of orthogonal matrices to non-square matrices. We describe how these constraints can be maintained efficiently during SGD. We show that Parseval networks match the state-of-the-art in terms of accuracy on CIFAR-10/100 and Street View House Numbers (SVHN) while being more robust than their vanilla counterpart against adversarial examples. Incidentally, Parseval networks also tend to train faster and make a better usage of the full capacity of the networks. version:2
arxiv-1705-00264 | High Performance Data Persistence in Non-Volatile Memory for Resilient High Performance Computing | http://arxiv.org/abs/1705.00264 | id:1705.00264 author:Yingchao Huang, Kai Wu, Dong Li category:cs.DC  published:2017-04-30 summary:Resilience is a major design goal for HPC. Checkpoint is the most common method to enable resilient HPC. Checkpoint periodically saves critical data objects to non-volatile storage to enable data persistence. However, using checkpoint, we face dilemmas between resilience, recomputation and checkpoint cost. The reason that accounts for the dilemmas is the cost of data copying inherent in checkpoint. In this paper we explore how to build resilient HPC with non-volatile memory (NVM) as main memory and address the dilemmas. We introduce a variety of optimization techniques that leverage high performance and non-volatility of NVM to enable high performance data persistence for data objects in applications. With NVM we avoid data copying; we optimize cache flushing needed to ensure consistency between caches and NVM. We demonstrate that using NVM is feasible to establish data persistence frequently with small overhead (4.4% on average) to achieve highly resilient HPC and minimize recomputation. version:2
arxiv-1705-00732 | Argumentation-based Security for Social Good | http://arxiv.org/abs/1705.00732 | id:1705.00732 author:Erisa Karafili, Antonis C. Kakas, Nikolaos I. Spanoudakis, Emil C. Lupu category:cs.CR cs.AI  published:2017-05-01 summary:The increase of connectivity and the impact it has in every day life is raising new and existing security problems that are becoming important for social good. We introduce two particular problems: cyber attack attribution and regulatory data sharing. For both problems, decisions about which rules to apply, should be taken under incomplete and context dependent information. The solution we propose is based on argumentation reasoning, that is a well suited technique for implementing decision making mechanisms under conflicting and incomplete information. Our proposal permits us to identify the attacker of a cyber attack and decide the regulation rule that should be used while using and sharing data. We illustrate our solution through concrete examples. version:1
arxiv-1705-00697 | From Imitation to Prediction, Data Compression vs Recurrent Neural Networks for Natural Language Processing | http://arxiv.org/abs/1705.00697 | id:1705.00697 author:Juan Andrés Laura, Gabriel Masi, Luis Argerich category:cs.CL cs.AI cs.IT math.IT  published:2017-05-01 summary:In recent studies [1][13][12] Recurrent Neural Networks were used for generative processes and their surprising performance can be explained by their ability to create good predictions. In addition, data compression is also based on predictions. What the problem comes down to is whether a data compressor could be used to perform as well as recurrent neural networks in natural language processing tasks. If this is possible,then the problem comes down to determining if a compression algorithm is even more intelligent than a neural network in specific tasks related to human language. In our journey we discovered what we think is the fundamental difference between a Data Compression Algorithm and a Recurrent Neural Network. version:1
arxiv-1612-03224 | How to Read Less: On the Benefit of Human-in-the-loop Incremental Learning for Systematic Literature Review | http://arxiv.org/abs/1612.03224 | id:1612.03224 author:Zhe Yu, Nicholas A. Kraft, Tim Menzies category:cs.SE cs.AI 68N01  68T50 D.2.0; I.2.7  published:2016-12-10 summary:Systematic literature reviews (SLRs) are the primary method for aggregating and synthesizing evidence in evidence-based software engineering (SE). Primary study selection is a critical and time-consuming SLR step in which reviewers use titles, abstracts, or even full texts to evaluate thousands of studies to find the dozens of them that are relevant to the research questions. We seek to reduce the effort of primary study selection in SE SLRs by exploring and refactoring the state-of-the-art human-in-the-loop incremental learning techniques from evidence-based medicine and legal electronic discovery. By refactoring those methods, we discovered FASTREAD, which is a new state-of-the-art in human-in-the-loop incremental learning for SE SLRs. Tested on two data sets generated from existing SE SLRs of Hall, Wahono, et al., FASTREAD outperforms the current state-of-the-art methods. Our results suggest that FASTREAD is able to find $90\%$ of the studies found by standard manual methods, by only reading less than $10\%$ of the candidate studies. version:2
arxiv-1705-00677 | A Distributed Method for Optimal Capacity Reservation | http://arxiv.org/abs/1705.00677 | id:1705.00677 author:Nicholas Moehle, Xinyue Shen, Zhi-Quan Luo, Stephen Boyd category:cs.DC cs.DS  published:2017-05-01 summary:We consider the problem of reserving link capacity in a network in such a way that any of a given set of flow scenarios can be supported. In the optimal capacity reservation problem, we choose the reserved link capacities to minimize the reservation cost. This problem reduces to a large linear program, with the number of variables and constraints on the order of the number of links times the number of scenarios. Small and medium size problems are within the capabilities of generic linear program solvers. We develop a more scalable, distributed algorithm for the problem that alternates between solving (in parallel) one flow problem per scenario, and coordination steps, which connect the individual flows and the reservation capacities. version:1
arxiv-1705-00597 | Towards well-specified semi-supervised model-based classifiers via structural adaptation | http://arxiv.org/abs/1705.00597 | id:1705.00597 author:Zhaocai Sun, William K. Cheung, Xiaofeng Zhang, Jun Yang category:cs.LG cs.AI  published:2017-05-01 summary:Semi-supervised learning plays an important role in large-scale machine learning. Properly using additional unlabeled data (largely available nowadays) often can improve the machine learning accuracy. However, if the machine learning model is misspecified for the underlying true data distribution, the model performance could be seriously jeopardized. This issue is known as model misspecification. To address this issue, we focus on generative models and propose a criterion to detect the onset of model misspecification by measuring the performance difference between models obtained using supervised and semi-supervised learning. Then, we propose to automatically modify the generative models during model training to achieve an unbiased generative model. Rigorous experiments were carried out to evaluate the proposed method using two image classification data sets PASCAL VOC'07 and MIR Flickr. Our proposed method has been demonstrated to outperform a number of state-of-the-art semi-supervised learning approaches for the classification task. version:1
arxiv-1705-00594 | A System for Accessible Artificial Intelligence | http://arxiv.org/abs/1705.00594 | id:1705.00594 author:Randal S. Olson, Moshe Sipper, William La Cava, Sharon Tartarone, Steven Vitale, Weixuan Fu, John H. Holmes, Jason H. Moore category:cs.AI cs.HC cs.NE  published:2017-05-01 summary:While artificial intelligence (AI) has become widespread, many commercial AI systems are not yet accessible to individual researchers nor the general public due to the deep knowledge of the systems required to use them. We believe that AI has matured to the point where it should be an accessible technology for everyone. We present an ongoing project whose ultimate goal is to deliver an open source, user-friendly AI system that is specialized for machine learning analysis of complex data in the biomedical and health care domains. We discuss how genetic programming can aid in this endeavor, and highlight specific examples where genetic programming has automated machine learning analyses in previous projects. version:1
arxiv-1705-00561 | WebAPIRec: Recommending Web APIs to Software Projects via Personalized Ranking | http://arxiv.org/abs/1705.00561 | id:1705.00561 author:Ferdian Thung, Richard J. Oentaryo, David Lo, Yuan Tian category:cs.IR cs.AI cs.SE  published:2017-05-01 summary:Application programming interfaces (APIs) offer a plethora of functionalities for developers to reuse without reinventing the wheel. Identifying the appropriate APIs given a project requirement is critical for the success of a project, as many functionalities can be reused to achieve faster development. However, the massive number of APIs would often hinder the developers' ability to quickly find the right APIs. In this light, we propose a new, automated approach called WebAPIRec that takes as input a project profile and outputs a ranked list of {web} APIs that can be used to implement the project. At its heart, WebAPIRec employs a personalized ranking model that ranks web APIs specific (personalized) to a project. Based on the historical data of {web} API usages, WebAPIRec learns a model that minimizes the incorrect ordering of web APIs, i.e., when a used {web} API is ranked lower than an unused (or a not-yet-used) web API. We have evaluated our approach on a dataset comprising 9,883 web APIs and 4,315 web application projects from ProgrammableWeb with promising results. For 84.0% of the projects, WebAPIRec is able to successfully return correct APIs that are used to implement the projects in the top-5 positions. This is substantially better than the recommendations provided by ProgrammableWeb's native search functionality. WebAPIRec also outperforms McMillan et al.'s application search engine and popularity-based recommendation. version:1
arxiv-1705-00387 | Middleware Technologies for Cloud of Things - a survey | http://arxiv.org/abs/1705.00387 | id:1705.00387 author:Amirhossein Farahzadia, Pooyan Shams, Javad Rezazadeh, Reza Farahbakhsh category:cs.DC  published:2017-04-30 summary:The next wave of communication and applications rely on the new services provided by Internet of Things which is becoming an important aspect in human and machines future. The IoT services are a key solution for providing smart environments in homes, buildings and cities. In the era of a massive number of connected things and objects with a high grow rate, several challenges have been raised such as management, aggregation and storage for big produced data. In order to tackle some of these issues, cloud computing emerged to IoT as Cloud of Things (CoT) which provides virtually unlimited cloud services to enhance the large scale IoT platforms. There are several factors to be considered in design and implementation of a CoT platform. One of the most important and challenging problems is the heterogeneity of different objects. This problem can be addressed by deploying suitable "Middleware". Middleware sits between things and applications that make a reliable platform for communication among things with different interfaces, operating systems, and architectures. The main aim of this paper is to study the middleware technologies for CoT. Toward this end, we first present the main features and characteristics of middlewares. Next we study different architecture styles and service domains. Then we presents several middlewares that are suitable for CoT based platforms and lastly a list of current challenges and issues in design of CoT based middlewares is discussed. version:1
arxiv-1704-07468 | GaKCo: a Fast GApped k-mer string Kernel using COunting | http://arxiv.org/abs/1704.07468 | id:1704.07468 author:Ritambhara Singh, Arshdeep Sekhon, Kamran Kowsari, Jack Lanchantin, Beilun Wang, Yanjun Qi category:cs.LG cs.AI cs.CC cs.CL cs.DS  published:2017-04-24 summary:String Kernel (SK) techniques, especially those using gapped $k$-mers as features (gk), have obtained great success in classifying sequences like DNA, protein, and text. However, the state-of-the-art gk-SK runs extremely slow when we increase the dictionary size ($\Sigma$) or allow more mismatches ($M$). This is because current gk-SK uses a trie-based algorithm to calculate co-occurrence of mismatched substrings resulting in a time cost proportional to $O(\Sigma^{M})$. We propose a \textbf{fast} algorithm for calculating \underline{Ga}pped $k$-mer \underline{K}ernel using \underline{Co}unting (GaKCo). GaKCo uses associative arrays to calculate the co-occurrence of substrings using cumulative counting. This algorithm is fast, scalable to larger $\Sigma$ and $M$, and naturally parallelizable. We provide a rigorous asymptotic analysis that compares GaKCo with the state-of-the-art gk-SK. Theoretically, the time cost of GaKCo is independent of the $\Sigma^{M}$ term that slows down the trie-based approach. Experimentally, we observe that GaKCo achieves the same accuracy as the state-of-the-art and outperforms its speed by factors of 2, 100, and 4, on classifying sequences of DNA (5 datasets), protein (12 datasets), and character-based English text (2 datasets), respectively. GaKCo is shared as an open source tool at \url{https://github.com/QData/GaKCo-SVM} version:2
arxiv-1705-00346 | Deep Learning in the Automotive Industry: Applications and Tools | http://arxiv.org/abs/1705.00346 | id:1705.00346 author:Andre Luckow, Matthew Cook, Nathan Ashcraft, Edwin Weill, Emil Djerekarov, Bennie Vorster category:cs.LG cs.CV cs.DC  published:2017-04-30 summary:Deep Learning refers to a set of machine learning techniques that utilize neural networks with many hidden layers for tasks, such as image classification, speech recognition, language understanding. Deep learning has been proven to be very effective in these domains and is pervasively used by many Internet services. In this paper, we describe different automotive uses cases for deep learning in particular in the domain of computer vision. We surveys the current state-of-the-art in libraries, tools and infrastructures (e.\,g.\ GPUs and clouds) for implementing, training and deploying deep neural networks. We particularly focus on convolutional neural networks and computer vision use cases, such as the visual inspection process in manufacturing plants and the analysis of social media data. To train neural networks, curated and labeled datasets are essential. In particular, both the availability and scope of such datasets is typically very limited. A main contribution of this paper is the creation of an automotive dataset, that allows us to learn and automatically recognize different vehicle properties. We describe an end-to-end deep learning application utilizing a mobile app for data collection and process support, and an Amazon-based cloud backend for storage and training. For training we evaluate the use of cloud and on-premises infrastructures (including multiple GPUs) in conjunction with different neural network architectures and frameworks. We assess both the training times as well as the accuracy of the classifier. Finally, we demonstrate the effectiveness of the trained classifier in a real world setting during manufacturing process. version:1
arxiv-1705-00341 | Deriving Quests from Open World Mechanics | http://arxiv.org/abs/1705.00341 | id:1705.00341 author:Ryan Alexander, Chris Martens category:cs.MM cs.AI  published:2017-04-30 summary:Open world games present players with more freedom than games with linear progression structures. However, without clearly-defined objectives, they often leave players without a sense of purpose. Most of the time, quests and objectives are hand-authored and overlaid atop an open world's mechanics. But what if they could be generated organically from the gameplay itself? The goal of our project was to develop a model of the mechanics in Minecraft that could be used to determine the ideal placement of objectives in an open world setting. We formalized the game logic of Minecraft in terms of logical rules that can be manipulated in two ways: they may be executed to generate graphs representative of the player experience when playing an open world game with little developer direction; and they may be statically analyzed to determine dependency orderings, feedback loops, and bottlenecks. These analyses may then be used to place achievements on gameplay actions algorithmically. version:1
arxiv-1705-00335 | Quantifying Mental Health from Social Media with Neural User Embeddings | http://arxiv.org/abs/1705.00335 | id:1705.00335 author:Silvio Amir, Glen Coppersmith, Paula Carvalho, Mário J. Silva, Byron C. Wallace category:cs.CL cs.AI cs.SI  published:2017-04-30 summary:Mental illnesses adversely affect a significant proportion of the population worldwide. However, the methods traditionally used for estimating and characterizing the prevalence of mental health conditions are time-consuming and expensive. Consequently, best-available estimates concerning the prevalence of mental health conditions are often years out of date. Automated approaches to supplement these survey methods with broad, aggregated information derived from social media content provides a potential means for near real-time estimates at scale. These may, in turn, provide grist for supporting, evaluating and iteratively improving upon public health programs and interventions. We propose a novel model for automated mental health status quantification that incorporates user embeddings. This builds upon recent work exploring representation learning methods that induce embeddings by leveraging social media post histories. Such embeddings capture latent characteristics of individuals (e.g., political leanings) and encode a soft notion of homophily. In this paper, we investigate whether user embeddings learned from twitter post histories encode information that correlates with mental health statuses. To this end, we estimated user embeddings for a set of users known to be affected by depression and post-traumatic stress disorder (PTSD), and for a set of demographically matched `control' users. We then evaluated these embeddings with respect to: (i) their ability to capture homophilic relations with respect to mental health status; and (ii) the performance of downstream mental health prediction models based on these features. Our experimental results demonstrate that the user embeddings capture similarities between users with respect to mental conditions, and are predictive of mental health. version:1
arxiv-1704-07498 | Leveraging Patient Similarity and Time Series Data in Healthcare Predictive Models | http://arxiv.org/abs/1704.07498 | id:1704.07498 author:Mohammad Amin Morid, Olivia R. Liu Sheng, Samir Abdelrahman category:cs.AI cs.LG  published:2017-04-25 summary:Patient time series classification faces challenges in high degrees of dimensionality and missingness. In light of patient similarity theory, this study explores effective temporal feature engineering and reduction, missing value imputation, and change point detection methods that can afford similarity-based classification models with desirable accuracy enhancement. We select a piecewise aggregation approximation method to extract fine-grain temporal features and propose a minimalist method to impute missing values in temporal features. For dimensionality reduction, we adopt a gradient descent search method for feature weight assignment. We propose new patient status and directional change definitions based on medical knowledge or clinical guidelines about the value ranges for different patient status levels, and develop a method to detect change points indicating positive or negative patient status changes. We evaluate the effectiveness of the proposed methods in the context of early Intensive Care Unit mortality prediction. The evaluation results show that the k-Nearest Neighbor algorithm that incorporates methods we select and propose significantly outperform the relevant benchmarks for early ICU mortality prediction. This study makes contributions to time series classification and early ICU mortality prediction via identifying and enhancing temporal feature engineering and reduction methods for similarity-based time series classification. version:3
arxiv-1705-00303 | Defense semantics of argumentation: encoding reasons for accepting arguments | http://arxiv.org/abs/1705.00303 | id:1705.00303 author:Beishui Liao, Leendert van der Torre category:cs.AI  published:2017-04-30 summary:In this paper we show how the defense relation among abstract arguments can be used to encode the reasons for accepting arguments. After introducing a novel notion of defenses and defense graphs, we propose a defense semantics together with a new notion of defense equivalence of argument graphs, and compare defense equivalence with standard equivalence and strong equivalence, respectively. Then, based on defense semantics, we define two kinds of reasons for accepting arguments, i.e., direct reasons and root reasons, and a notion of root equivalence of argument graphs. Finally, we show how the notion of root equivalence can be used in argumentation summarization. version:1
arxiv-1705-00267 | Application-Level Resilience Modeling for HPC Fault Tolerance | http://arxiv.org/abs/1705.00267 | id:1705.00267 author:Luanzheng Guo, Hanlin He, Dong Li category:cs.DC  published:2017-04-30 summary:Understanding the application resilience in the presence of faults is critical to address the HPC resilience challenge. Currently, we largely rely on random fault injection (RFI) to quantify the application resilience. However, RFI provides little information on how fault tolerance happens, and RFI results are often not deterministic due to its random nature. In this paper, we introduce a new methodology to quantify the application resilience. Our methodology is based on the observation that at the application level, the application resilience to faults is due to the application-level fault masking. The application-level fault masking happens because of application-inherent semantics and program constructs. Based on this observation, we analyze application execution information and use a data-oriented approach to model the application resilience. We use our model to study how and why HPC applications can (or cannot) tolerate faults. We demonstrate tangible benefits of using the model to direct fault tolerance mechanisms. version:1
arxiv-1601-04037 | Funnel Libraries for Real-Time Robust Feedback Motion Planning | http://arxiv.org/abs/1601.04037 | id:1601.04037 author:Anirudha Majumdar, Russ Tedrake category:cs.RO cs.AI cs.SY math.DS math.OC  published:2016-01-15 summary:We consider the problem of generating motion plans for a robot that are guaranteed to succeed despite uncertainty in the environment, parametric model uncertainty, and disturbances. Furthermore, we consider scenarios where these plans must be generated in real-time, because constraints such as obstacles in the environment may not be known until they are perceived (with a noisy sensor) at runtime. Our approach is to pre-compute a library of "funnels" along different maneuvers of the system that the state is guaranteed to remain within (despite bounded disturbances) when the feedback controller corresponding to the maneuver is executed. We leverage powerful computational machinery from convex optimization (sums-of-squares programming in particular) to compute these funnels. The resulting funnel library is then used to sequentially compose motion plans at runtime while ensuring the safety of the robot. A major advantage of the work presented here is that by explicitly taking into account the effect of uncertainty, the robot can evaluate motion plans based on how vulnerable they are to disturbances. We demonstrate and validate our method using extensive hardware experiments on a small fixed-wing airplane avoiding obstacles at high speed (~12 mph), along with thorough simulation experiments of ground vehicle and quadrotor models navigating through cluttered environments. To our knowledge, these demonstrations constitute one of the first examples of provably safe and robust control for robotic systems with complex nonlinear dynamics that need to plan in real-time in environments with complex geometric constraints. version:3
arxiv-1705-00218 | A floating point division unit based on Taylor-Series expansion algorithm and Iterative Logarithmic Multiplier | http://arxiv.org/abs/1705.00218 | id:1705.00218 author:Riyansh K. Karani, Akash K. Rana, Dhruv H. Reshamwala, Kishore Saldanha category:cs.AR  published:2017-04-29 summary:Floating point division, even though being an infrequent operation in the traditional sense, is indis- pensable when it comes to a range of non-traditional applications such as K-Means Clustering and QR Decomposition just to name a few. In such applications, hardware support for floating point division would boost the performance of the entire system. In this paper, we present a novel architecture for a floating point division unit based on the Taylor-series expansion algorithm. We show that the Iterative Logarithmic Multiplier is very well suited to be used as a part of this architecture. We propose an implementation of the powering unit that can calculate an odd power and an even power of a number simultaneously, meanwhile having little hardware overhead when compared to the Iterative Logarithmic Multiplier. version:1
arxiv-1705-00969 | The Problem of Coincidence in A Theory of Temporal Multiple Recurrence | http://arxiv.org/abs/1705.00969 | id:1705.00969 author:B. O. Akinkunmi category:cs.AI I.2.4  published:2017-04-29 summary:Logical theories have been developed which have allowed temporal reasoning about eventualities (a la Galton) such as states, processes, actions, events, processes and complex eventualities such as sequences and recurrences of other eventualities. This paper presents the problem of coincidence within the framework of a first order logical theory formalising temporal multiple recurrence of two sequences of fixed duration eventualities and presents a solution to it The coincidence problem is described as: if two complex eventualities (or eventuality sequences) consisting respectively of component eventualities x0, x1,....,xr and y0, y1, ..,ys both recur over an interval k and all eventualities are of fixed durations, is there a sub-interval of k over which the incidence xt and yu for t between 0..r and s between 0..s coincide. The solution presented here formalises the intuition that a solution can be found by temporal projection over a cycle of the multiple recurrence of both sequences. version:1
arxiv-1705-00211 | A Partitioning Algorithm for Detecting Eventuality Coincidence in Temporal Double recurrence | http://arxiv.org/abs/1705.00211 | id:1705.00211 author:B. O. Akinkunmi category:cs.AI 90-XX F.2.2; I.2.4  published:2017-04-29 summary:A logical theory of regular double or multiple recurrence of eventualities, which are regular patterns of occurrences that are repeated, in time, has been developed within the context of temporal reasoning that enabled reasoning about the problem of coincidence. i.e. if two complex eventualities, or eventuality sequences consisting respectively of component eventualities x0, x1,....,xr and y0, y1, ..,ys both recur over an interval k and all eventualities are of fixed durations, is there a subinterval of k over which the occurrence xp and yq for p between 1 and r and q between 1 and s coincide. We present the ideas behind a new algorithm for detecting the coincidence of eventualities xp and yq within a cycle of the double recurrence of x and y. The algorithm is based on the novel concept of gcd partitions that requires the partitioning of each of the incidences of both x and y into eventuality sequences each of which components have a duration that is equal to the greatest common divisor of the durations of x and y. The worst case running time of the partitioning algorithm is linear in the maximum of the duration of x and that of y, while the worst case running time of an algorithm exploring a complete cycle is quadratic in the durations of x and y. Hence the partitioning algorithm works faster than the cyclical exploration in the worst case. version:1
arxiv-1705-00154 | Classical Planning in Deep Latent Space: Bridging the Subsymbolic-Symbolic Boundary | http://arxiv.org/abs/1705.00154 | id:1705.00154 author:Masataro Asai, Alex Fukunaga category:cs.AI  published:2017-04-29 summary:Current domain-independent, classical planners require symbolic models of the problem domain and instance as input, resulting in a knowledge acquisition bottleneck. Meanwhile, although recent work in deep learning has achieved impressive results in many fields, the knowledge is encoded in a subsymbolic representation which cannot be directly used by symbolic systems such as planners. We propose LatPlan, an integrated architecture combining deep learning and a classical planner. Given a set of unlabeled training image pairs showing allowed actions in the problem domain, and a pair of images representing the start and goal states, LatPlan uses a Variational Autoencoder to generate a discrete latent vector from the images, based on which a PDDL model can be constructed and then solved by an off-the-shelf planner. We evaluate LatPlan using image-based versions of 3 planning domains: 8-puzzle, LightsOut, and Towers of Hanoi. version:1
arxiv-1705-00106 | Learning to Ask: Neural Question Generation for Reading Comprehension | http://arxiv.org/abs/1705.00106 | id:1705.00106 author:Xinya Du, Junru Shao, Claire Cardie category:cs.CL cs.AI  published:2017-04-29 summary:We study automatic question generation for sentences from text passages in reading comprehension. We introduce an attention-based sequence learning model for the task and investigate the effect of encoding sentence- vs. paragraph-level information. In contrast to all previous work, our model does not rely on hand-crafted rules or a sophisticated NLP pipeline; it is instead trainable end-to-end via sequence-to-sequence learning. Automatic evaluation results show that our system significantly outperforms the state-of-the-art rule-based system. In human evaluations, questions generated by our system are also rated as being more natural (i.e., grammaticality, fluency) and as more difficult to answer (in terms of syntactic and lexical divergence from the original text and reasoning needed to answer). version:1
arxiv-1705-00094 | The Impact of Coevolution and Abstention on the Emergence of Cooperation | http://arxiv.org/abs/1705.00094 | id:1705.00094 author:Marcos Cardinot, Colm O'Riordan, Josephine Griffith category:cs.GT cs.AI cs.MA cs.NE math.DS  published:2017-04-28 summary:This paper explores the Coevolutionary Optional Prisoner's Dilemma (COPD) game, which is a simple model to coevolve game strategy and link weights of agents playing the Optional Prisoner's Dilemma game. We consider a population of agents placed in a lattice grid with boundary conditions. A number of Monte Carlo simulations are performed to investigate the impacts of the COPD game on the emergence of cooperation. Results show that the coevolutionary rules enable cooperators to survive and even dominate, with the presence of abstainers in the population playing a key role in the protection of cooperators against exploitation from defectors. We observe that in adverse conditions such as when the initial population of abstainers is too scarce/abundant, or when the temptation to defect is very high, cooperation has no chance of emerging. However, when the simple coevolutionary rules are applied, cooperators flourish. version:1
arxiv-1705-00091 | Safe Trajectory Synthesis for Autonomous Driving in Unforeseen Environments | http://arxiv.org/abs/1705.00091 | id:1705.00091 author:Shreyas Kousik, Sean Vaskov, Matthew Johnson-Roberson, Ramanarayan Vasudevan category:cs.SY cs.RO  published:2017-04-28 summary:Path planning for autonomous vehicles in arbitrary environments requires a guarantee of safety, but this can be impractical to ensure in real-time when the vehicle is described with a high-fidelity model. To address this problem, this paper develops a method to perform trajectory design by considering a low-fidelity model that accounts for model mismatch. The presented method begins by computing a conservative Forward Reachable Set (FRS) of a high-fidelity model's trajectories produced when tracking trajectories of a low-fidelity model over a finite time horizon. At runtime, the vehicle intersects this FRS with obstacles in the environment to eliminate trajectories that can lead to a collision, then selects an optimal plan from the remaining safe set. By bounding the time for this set intersection and subsequent path selection, this paper proves a lower bound for the FRS time horizon and sensing horizon to guarantee safety. This method is demonstrated in simulation using a kinematic Dubin's car as the low-fidelity model and a dynamic unicycle as the high-fidelity model. version:1
arxiv-1705-00070 | Enabling Interactive Analytics of Secure Data using Cloud Kotta | http://arxiv.org/abs/1705.00070 | id:1705.00070 author:Yadu N. Babuji, Kyle Chard, Eamon Duede category:cs.DC  published:2017-04-28 summary:Research, especially in the social sciences and humanities, is increasingly reliant on the application of data science methods to analyze large amounts of (often private) data. Secure data enclaves provide a solution for managing and analyzing private data. However, such enclaves do not readily support discovery science---a form of exploratory or interactive analysis by which researchers execute a range of (sometimes large) analyses in an iterative and collaborative manner. The batch computing model offered by many data enclaves is well suited to executing large compute tasks; however it is far from ideal for day-to-day discovery science. As researchers must submit jobs to queues and wait for results, the high latencies inherent in queue-based, batch computing systems hinder interactive analysis. In this paper we describe how we have augmented the Cloud Kotta secure data enclave to support collaborative and interactive analysis of sensitive data. Our model uses Jupyter notebooks as a flexible analysis environment and Python language constructs to support the execution of arbitrary functions on private data within this secure framework. version:1
arxiv-1704-08950 | Intelligent Personal Assistant with Knowledge Navigation | http://arxiv.org/abs/1704.08950 | id:1704.08950 author:Amit Kumar, Rahul Dutta, Harbhajan Rai category:cs.AI  published:2017-04-28 summary:An Intelligent Personal Agent (IPA) is an agent that has the purpose of helping the user to gain information through reliable resources with the help of knowledge navigation techniques and saving time to search the best content. The agent is also responsible for responding to the chat-based queries with the help of Conversation Corpus. We will be testing different methods for optimal query generation. To felicitate the ease of usage of the application, the agent will be able to accept the input through Text (Keyboard), Voice (Speech Recognition) and Server (Facebook) and output responses using the same method. Existing chat bots reply by making changes in the input, but we will give responses based on multiple SRT files. The model will learn using the human dialogs dataset and will be able respond human-like. Responses to queries about famous things (places, people, and words) can be provided using web scraping which will enable the bot to have knowledge navigation features. The agent will even learn from its past experiences supporting semi-supervised learning. version:1
arxiv-1612-01392 | An Extended Treatment of Uncertainty Constrained robotic Exploration: An Integrated Exploration Planner | http://arxiv.org/abs/1612.01392 | id:1612.01392 author:Alexander Ivanov, Mark Campbell category:cs.RO  published:2016-12-05 summary:Efficient robotic exploration of unknown, sensor limited, global-information-deficient environments poses unique challenges to path planning algorithms. In these difficult environments, no deterministic guarantees on path completion and mission success can be made in general. Integrated Exploration (IE), which strives to combine localization and exploration, must be solved in order to create an autonomous robotic system capable of long term operation in new and challenging environments. This paper formulates a probabilistic framework which allows the creation of exploration algorithms providing probabilistic guarantees of success. A novel connection is made between the Hamiltonian Path Problem and exploration. The Guaranteed Probabilistic Information Explorer (G-PIE) is developed for the IE problem, providing a probabilistic guarantee on path completion, and asymptotic optimality of exploration. A receding horizon formulation, dubbed RH-PIE, is presented which addresses the exponential complexity present in G-PIE. Finally, RH-PIE planner is verified via autonomous, hardware-in-the-loop experiments. version:2
arxiv-1704-08914 | Past, Present, Future: A Computational Investigation of the Typology of Tense in 1000 Languages | http://arxiv.org/abs/1704.08914 | id:1704.08914 author:Ehsaneddin Asgari, Hinrich Schütze category:cs.CL cs.AI cs.LG  published:2017-04-28 summary:We present SuperPivot, an analysis method for low-resource languages that occur in a superparallel corpus, i.e., in a corpus that contains an order of magnitude more languages than parallel corpora currently in use. We show that SuperPivot performs well for the crosslingual analysis of the linguistic phenomenon of tense. We produce analysis results for more than 1000 languages, conducting - to the best of our knowledge - the largest crosslingual computational study performed to date. We extend existing methodology for leveraging parallel corpora for typological analysis by overcoming a limiting assumption of earlier work: We only require that a linguistic feature is overtly marked in a few of thousands of languages as opposed to requiring that it be marked in all languages under investigation. version:1
arxiv-1704-08880 | Deterministic Gathering with Crash Faults | http://arxiv.org/abs/1704.08880 | id:1704.08880 author:Andrzej Pelc category:cs.DC  published:2017-04-28 summary:A team consisting of an unknown number of mobile agents, starting from different nodes of an unknown network, have to meet at the same node and terminate. This problem is known as {\em gathering}. We study deterministic gathering algorithms under the assumption that agents are subject to {\em crash faults} which can occur at any time. Two fault scenarios are considered. A {\em motion fault} immobilizes the agent at a node or inside an edge but leaves intact its memory at the time when the fault occurred. A more severe {\em total fault} immobilizes the agent as well, but also erases its entire memory. Of course, we cannot require faulty agents to gather. Thus the gathering problem for fault prone agents calls for all fault-free agents to gather at a single node, and terminate. When agents move completely asynchronously, gathering with crash faults of any type is impossible. Hence we consider a restricted version of asynchrony, where each agent is assigned by the adversary a fixed speed, possibly different for each agent. Agents have clocks ticking at the same rate. Each agent can wait for a time of its choice at any node, or decide to traverse an edge but then it moves at constant speed assigned to it. Moreover, agents have different labels. Each agent knows its label and speed but not those of other agents. We construct a gathering algorithm working for any team of at least two agents in the scenario of motion faults, and a gathering algorithm working in the presence of total faults, provided that at least two agents are fault free all the time. If only one agent is fault free, the task of gathering with total faults is sometimes impossible. Both our algorithms work in time polynomial in the size of the graph, in the logarithm of the largest label, in the inverse of the smallest speed, and in the ratio between the largest and the smallest speed. version:1
arxiv-1703-05204 | On Inconsistency Indices and Inconsistency Axioms in Pairwise Comparisons | http://arxiv.org/abs/1703.05204 | id:1703.05204 author:Jiri Mazurek category:cs.AI  published:2017-03-15 summary:Pairwise comparisons are an important tool of modern (multiple criteria) decision making. Since human judgments are often inconsistent, many studies focused on the ways how to express and measure this inconsistency, and several inconsistency indices were proposed as an alternative to Saaty inconsistency index and inconsistency ratio for reciprocal pairwise comparisons matrices. This paper aims to: firstly, introduce a new measure of inconsistency of pairwise comparisons and to prove its basic properties; secondly, to postulate an additional axiom, an upper boundary axiom, to an existing set of axioms; and the last, but not least, the paper provides proofs of satisfaction of this additional axiom by selected inconsistency indices as well as it provides their numerical comparison. version:2
arxiv-1611-02054 | Adopting the FAB-MAP algorithm for indoor localization with WiFi fingerprints | http://arxiv.org/abs/1611.02054 | id:1611.02054 author:Jan Wietrzykowski, Michał Nowicki, Piotr Skrzypczyński category:cs.RO  published:2016-11-07 summary:Personal indoor localization is usually accomplished by fusing information from various sensors. A common choice is to use the WiFi adapter that provides information about Access Points that can be found in the vicinity. Unfortunately, state-of-the-art approaches to WiFi-based localization often employ very dense maps of the WiFi signal distribution, and require a time-consuming process of parameter selection. On the other hand, camera images are commonly used for visual place recognition, detecting whenever the user observes a scene similar to the one already recorded in a database. Visual place recognition algorithms can work with sparse databases of recorded scenes and are in general simple to parametrize. Therefore, we propose a WiFi-based global localization method employing the structure of the well-known FAB-MAP visual place recognition algorithm. Similarly to FAB-MAP our method uses Chow-Liu trees to estimate a joint probability distribution of re-observation of a place given a set of features extracted at places visited so far. However, we are the first who apply this idea to recorded WiFi scans instead of visual words. The new method is evaluated on the UJIIndoorLoc dataset used in the EvAAL competition, allowing fair comparison with other solutions. version:2
arxiv-1701-03322 | From First-Order Logic to Assertional Logic | http://arxiv.org/abs/1701.03322 | id:1701.03322 author:Yi Zhou category:cs.AI  published:2017-01-12 summary:First-Order Logic (FOL) is widely regarded as one of the most important foundations for knowledge representation. Nevertheless, in this paper, we argue that FOL has several critical issues for this purpose. Instead, we propose an alternative called assertional logic, in which all syntactic objects are categorized as set theoretic constructs including individuals, concepts and operators, and all kinds of knowledge are formalized by equality assertions. We first present a primitive form of assertional logic that uses minimal assumed knowledge and constructs. Then, we show how to extend it by definitions, which are special kinds of knowledge, i.e., assertions. We argue that assertional logic, although simpler, is more expressive and extensible than FOL. As a case study, we show how assertional logic can be used to unify logic and probability, and more building blocks in AI. version:2
arxiv-1609-01493 | Axiomatizing Category Theory in Free Logic | http://arxiv.org/abs/1609.01493 | id:1609.01493 author:Christoph Benzmüller, Dana S. Scott category:cs.LO cs.AI math.CT math.LO F.4; I.2.3  published:2016-09-06 summary:Starting from a generalization of the standard axioms for a monoid we present a stepwise development of various, mutually equivalent foundational axiom systems for category theory. Our axiom sets have been formalized in the Isabelle/HOL interactive proof assistant, and this formalization utilizes a semantically correct embedding of free logic in classical higher-order logic. The modeling and formal analysis of our axiom sets has been significantly supported by series of experiments with automated reasoning tools integrated with Isabelle/HOL. We also address the relation of our axiom systems to alternative proposals from the literature, including an axiom set proposed by Freyd and Scedrov for which we reveal a technical issue (when encoded in free logic where free variables range over defined and undefined objects): either all operations, e.g. morphism composition, are total or their axiom system is inconsistent. The repair for this problem is quite straightforward, however. version:4
arxiv-1704-08802 | Proceedings of the 3rd International Workshop on Overlay Architectures for FPGAs (OLAF 2017) | http://arxiv.org/abs/1704.08802 | id:1704.08802 author:Hayden Kwok-Hay So, John Wawrzynek category:cs.AR  published:2017-04-28 summary:The 3rd International Workshop on Overlay Architectures for FPGAs (OLAF 2017) was held on 22 Feb, 2017 as a co-located workshop at the 25th ACM/SIGDA International Symposium on Field-Programmable Gate Arrays (FPGA 2017). This year, the program committee selected 3 papers and 3 extended abstracts to be presented at the workshop, which are subsequently collected in this online volume. version:1
arxiv-1703-08905 | Multileader WAN Paxos: Ruling the Archipelago with Fast Consensus | http://arxiv.org/abs/1703.08905 | id:1703.08905 author:Ailidani Ailijiang, Aleksey Charapko, Murat Demirbas, Tevfik Kosar category:cs.DC  published:2017-03-27 summary:WPaxos is a multileader Paxos protocol that provides low-latency and high-throughput consensus across wide-area network (WAN) deployments. Unlike statically partitioned multiple Paxos deployments, WPaxos perpetually adapts to the changing access locality through object stealing. Multiple concurrent leaders coinciding in different zones steal ownership of objects from each other using phase-1 of Paxos, and then use phase-2 to commit update-requests on these objects locally until they are stolen by other leaders. To achieve zone-local phase-2 commits, WPaxos adopts the flexible quorums idea in a novel manner, and appoints phase-2 acceptors to be at the same zone as their respective leaders. The perpetual dynamic partitioning of the object-space and emphasis on zone-local commits allow WPaxos to significantly outperform leaderless approaches, such as EPaxos, while maintaining the same consistency guarantees. We implemented WPaxos and evaluated it on WAN deployments across 5 AWS regions using the benchmarks introduced in the EPaxos work. Our results show that, for a ~70% access locality workload, WPaxos achieves 2.4 times faster average request latency and 3.9 times faster median latency than EPaxos due to the reduction in WAN communication. For a ~90% access locality workload, WPaxos improves further and achieves 6 times faster average request latency and 59 times faster median latency than EPaxos. version:2
arxiv-1703-01333 | Towards Monetary Incentives in Social Q&A Services | http://arxiv.org/abs/1703.01333 | id:1703.01333 author:Steve T. K. Jan, Chun Wang, Qing Zhang, Gang Wang category:cs.AI cs.HC  published:2017-03-03 summary:Community-based question answering (CQA) services are facing key challenges to motivate domain experts to provide timely answers. Recently, CQA services are exploring new incentive models to engage experts and celebrities by allowing them to set a price on their answers. In this paper, we perform a data-driven analysis on two emerging payment-based CQA systems: Fenda (China) and Whale (US). By analyzing a large dataset of 220K questions (worth 1 million USD collectively), we examine how monetary incentives affect different players in the system. We find that, while monetary incentive enables quick answers from experts, it also drives certain users to aggressively game the system for profits. In addition, in this supplier-driven marketplace, users need to proactively adjust their price to make profits. Famous people are unwilling to lower their price, which in turn hurts their income and engagement over time. Finally, we discuss the key implications to future CQA design. version:2
arxiv-1704-08759 | Obstacle Avoidance through Deep Networks based Intermediate Perception | http://arxiv.org/abs/1704.08759 | id:1704.08759 author:Shichao Yang, Sandeep Konam, Chen Ma, Stephanie Rosenthal, Manuela Veloso, Sebastian Scherer category:cs.RO cs.CV  published:2017-04-27 summary:Obstacle avoidance from monocular images is a challenging problem for robots. Though multi-view structure-from-motion could build 3D maps, it is not robust in textureless environments. Some learning based methods exploit human demonstration to predict a steering command directly from a single image. However, this method is usually biased towards certain tasks or demonstration scenarios and also biased by human understanding. In this paper, we propose a new method to predict a trajectory from images. We train our system on more diverse NYUv2 dataset. The ground truth trajectory is computed from the designed cost functions automatically. The Convolutional Neural Network perception is divided into two stages: first, predict depth map and surface normal from RGB images, which are two important geometric properties related to 3D obstacle representation. Second, predict the trajectory from the depth and normal. Results show that our intermediate perception increases the accuracy by 20% than the direct prediction. Our model generalizes well to other public indoor datasets and is also demonstrated for robot flights in simulation and experiments. version:1
arxiv-1512-09354 | An (MI)LP-based Primal Heuristic for 3-Architecture Connected Facility Location in Urban Access Network Design | http://arxiv.org/abs/1512.09354 | id:1512.09354 author:Fabio D'Andreagiovanni, Fabian Mett, Jonad Pulaj category:math.OC cs.AI cs.NI  published:2015-12-31 summary:We investigate the 3-architecture Connected Facility Location Problem arising in the design of urban telecommunication access networks. We propose an original optimization model for the problem that includes additional variables and constraints to take into account wireless signal coverage. Since the problem can prove challenging even for modern state-of-the art optimization solvers, we propose to solve it by an original primal heuristic which combines a probabilistic fixing procedure, guided by peculiar Linear Programming relaxations, with an exact MIP heuristic, based on a very large neighborhood search. Computational experiments on a set of realistic instances show that our heuristic can find solutions associated with much lower optimality gaps than a state-of-the-art solver. version:3
arxiv-1704-08738 | Portfolio-driven Resource Management for Transient Cloud Servers | http://arxiv.org/abs/1704.08738 | id:1704.08738 author:Prateek Sharma, David Irwin, Prashant Shenoy category:cs.DC  published:2017-04-27 summary:Cloud providers have begun to offer their surplus capacity in the form of low-cost transient servers, which can be revoked unilaterally at any time. While the low cost of transient servers makes them attractive for a wide range of applications, such as data processing and scientific computing, failures due to server revocation can severely degrade application performance. Since different transient server types offer different cost and availability tradeoffs, we present the notion of server portfolios that is based on financial portfolio modeling. Server portfolios enable construction of an "optimal" mix of severs to meet an application's sensitivity to cost and revocation risk. We implement model-driven portfolios in a system called ExoSphere, and show how diverse applications can use portfolios and application-specific policies to gracefully handle transient servers. We show that ExoSphere enables widely-used parallel applications such as Spark, MPI, and BOINC to be made transiency-aware with modest effort. Our experiments show that allowing the applications to use suitable transiency-aware policies, ExoSphere is able to achieve 80\% cost savings when compared to on-demand servers and greatly reduces revocation risk compared to existing approaches. version:1
arxiv-1704-08716 | Artificial Intelligence Based Malware Analysis | http://arxiv.org/abs/1704.08716 | id:1704.08716 author:Avi Pfeffer, Brian Ruttenberg, Lee Kellogg, Michael Howard, Catherine Call, Alison O'Connor, Glenn Takata, Scott Neal Reilly, Terry Patten, Jason Taylor, Robert Hall, Arun Lakhotia, Craig Miles, Dan Scofield, Jared Frank category:cs.CR cs.AI  published:2017-04-27 summary:Artificial intelligence methods have often been applied to perform specific functions or tasks in the cyber-defense realm. However, as adversary methods become more complex and difficult to divine, piecemeal efforts to understand cyber-attacks, and malware-based attacks in particular, are not providing sufficient means for malware analysts to understand the past, present and future characteristics of malware. In this paper, we present the Malware Analysis and Attributed using Genetic Information (MAAGI) system. The underlying idea behind the MAAGI system is that there are strong similarities between malware behavior and biological organism behavior, and applying biologically inspired methods to corpora of malware can help analysts better understand the ecosystem of malware attacks. Due to the sophistication of the malware and the analysis, the MAAGI system relies heavily on artificial intelligence techniques to provide this capability. It has already yielded promising results over its development life, and will hopefully inspire more integration between the artificial intelligence and cyber--defense communities. version:1
arxiv-1704-08713 | Finding the Size of a Radio Network with Short Labels | http://arxiv.org/abs/1704.08713 | id:1704.08713 author:Barun Gorain, Andrzej Pelc category:cs.DC  published:2017-04-27 summary:The number of nodes of a network, called its size, is one of the most important network parameters. A radio network is a collection of stations, called nodes, with wireless transmission and receiving capabilities. It is modeled as a simple connected undirected graph whose nodes communicate in synchronous rounds. In each round, a node can either transmit a message to all its neighbors, or stay silent and listen. At the receiving end, a node $v$ hears a message from a neighbor $w$ in a given round, if $v$ listens in this round, and if $w$ is its only neighbor that transmits in this round. If $v$ listens in a round, and two or more neighbors of $v$ transmit in this round, a collision occurs at $v$. Two scenarios are considered in the literature: if nodes can distinguish collision from silence (the latter occurs when no neighbor transmits), we say that the network has the collision detection capability, otherwise there is no collision detection. We consider the task of size discovery: finding the size of an unknown radio network with collision detection. All nodes have to output the size of the network, using a deterministic algorithm. Nodes have labels which are (not necessarily distinct) binary strings. The length of a labeling scheme is the largest length of a label. Our main result states that the minimum length of a labeling scheme permitting size discovery in the class of networks of maximum degree Delta is Theta(\log\log Delta). version:1
arxiv-1704-08695 | AWEsome: An open-source test platform for airborne wind energy systems | http://arxiv.org/abs/1704.08695 | id:1704.08695 author:Philip Bechtle, Thomas Gehrmann, Christoph Sieg, Udo Zillmann category:cs.SY cs.RO  published:2017-04-27 summary:In this paper we present AWEsome (Airborne Wind Energy Standardized Open-source Model Environment), a test platform for airborne wind energy systems that consists of low-cost hardware and is entirely based on open-source software. It can hence be used without the need of large financial investments, in particular by research groups and startups to acquire first experiences in their flight operations, to test novel control strategies or technical designs, or for usage in public relations. Our system consists of a modified off-the-shelf model aircraft that is controlled by the pixhawk autopilot hardware and the ardupilot software for fixed wing aircraft. The aircraft is attached to the ground by a tether. We have implemented new flight modes for the autonomous tethered flight of the aircraft along periodic patterns. We present the principal functionality of our algorithms. We report on first successful tests of these modes in real flights. version:1
arxiv-1704-08676 | A quantitative assessment of the effect of different algorithmic schemes to the task of learning the structure of Bayesian Networks | http://arxiv.org/abs/1704.08676 | id:1704.08676 author:Stefano Beretta, Mauro Castelli, Ivo Goncalves, Daniele Ramazzotti category:cs.LG cs.AI stat.ML  published:2017-04-27 summary:One of the most challenging tasks when adopting Bayesian Networks (BNs) is the one of learning their structure from data. This task is complicated by the huge search space of possible solutions and turned out to be a well-known NP-hard problem and, hence, approximations are required. However, to the best of our knowledge, a quantitative analysis of the performance and characteristics of the different heuristics to solve this problem has never been done before. For this reason, in this work, we provide a detailed study of the different state-of-the-arts methods for structural learning on simulated data considering both BNs with discrete and continuous variables, and with different rates of noise in the data. In particular, we investigate the characteristics of different widespread scores proposed for the inference and the statistical pitfalls within them. version:1
arxiv-1606-08333 | True Lies | http://arxiv.org/abs/1606.08333 | id:1606.08333 author:Thomas Ågotnes, Hans van Ditmarsch, Yanjing Wang category:cs.AI cs.LO cs.MA  published:2016-06-27 summary:A true lie is a lie that becomes true when announced. In a logic of announcements, where the announcing agent is not modelled, a true lie is a formula (that is false and) that becomes true when announced. We investigate true lies and other types of interaction between announced formulas, their preconditions and their postconditions, in the setting of Gerbrandy's logic of believed announcements, wherein agents may have or obtain incorrect beliefs. Our results are on the satisfiability and validity of instantiations of these semantically defined categories, on iterated announcements, including arbitrarily often iterated announcements, and on syntactic characterization. We close with results for iterated announcements in the logic of knowledge (instead of belief), and for lying as private announcements (instead of public announcements) to different agents. Detailed examples illustrate our lying concepts. version:2
arxiv-1704-08617 | Dissecting Robotics - historical overview and future perspectives | http://arxiv.org/abs/1704.08617 | id:1704.08617 author:Irati Zamalloa, Risto Kojcev, Alejandro Hernández, Iñigo Muguruza, Lander Usategui, Asier Bilbao, Víctor Mayoral category:cs.RO  published:2017-04-27 summary:Robotics is called to be the next technological revolution and estimations indicate that it will trigger the fourth industrial revolution. This article presents a review of some of the most relevant milestones that occurred in robotics over the last few decades and future perspectives. Despite the fact that, nowadays, robotics is an emerging field, the challenges in many technological aspects and more importantly bringing innovative solutions to the market still remain open. The need of reducing the integration time, costs and a common hardware infrastructure are discussed and further analysed in this work. We conclude with a discussion of the future perspectives of robotics as an engineering discipline and with suggestions for future research directions. version:1
arxiv-1704-08526 | An Efficient Reconfigurable FIR Digital Filter Using Modified Distribute Arithmetic Technique | http://arxiv.org/abs/1704.08526 | id:1704.08526 author:Naveen S Naik, Kiran A Gupta category:cs.AR  published:2017-04-27 summary:This paper provides modified Distributed Arithmetic based technique to compute sum of products saving appreciable number of Multiply And accumulation blocks and this consecutively reduces circuit size. In this technique multiplexer based structure is used to reuse the blocks so as to reduce the required memory locations. In this technique a Carry Look Ahead based adder tree is used to have better area-delay product. Designing of FIR filter is done using VHDL and synthesized using Xilinx 12.2 synthesis tool and ISIM simulator. The power analysis is done using Xilinx Xpower analyzer. The proposed structure requires nearly 42% less cells, 40% less LUT flip-flop pairs used, and also 2% less power compared with existing structure. version:1
arxiv-1704-08509 | No More Discrimination: Cross City Adaptation of Road Scene Segmenters | http://arxiv.org/abs/1704.08509 | id:1704.08509 author:Yi-Hsin Chen, Wei-Yu Chen, Yu-Ting Chen, Bo-Cheng Tsai, Yu-Chiang Frank Wang, Min Sun category:cs.CV cs.AI  published:2017-04-27 summary:Despite the recent success of deep-learning based semantic segmentation, deploying a pre-trained road scene segmenter to a city whose images are not presented in the training set would not achieve satisfactory performance due to dataset biases. Instead of collecting a large number of annotated images of each city of interest to train or refine the segmenter, we propose an unsupervised learning approach to adapt road scene segmenters across different cities. By utilizing Google Street View and its time-machine feature, we can collect unannotated images for each road scene at different times, so that the associated static-object priors can be extracted accordingly. By advancing a joint global and class-specific domain adversarial learning framework, adaptation of pre-trained segmenters to that city can be achieved without the need of any user annotation or interaction. We show that our method improves the performance of semantic segmentation in multiple cities across continents, while it performs favorably against state-of-the-art approaches requiring annotated training data. version:1
arxiv-1704-08492 | Extending Message Passing Interface Windows to Storage | http://arxiv.org/abs/1704.08492 | id:1704.08492 author:Sergio Rivas-Gomez, Stefano Markidis, Ivy Bo Peng, Erwin Laure, Gokcen Kestor, Roberto Gioiosa category:cs.DC  published:2017-04-27 summary:This work presents an extension to MPI supporting the one-sided communication model and window allocations in storage. Our design transparently integrates with the current MPI implementations, enabling applications to target MPI windows in storage, memory or both simultaneously, without major modifications. Initial performance results demonstrate that the presented MPI window extension could potentially be helpful for a wide-range of use-cases and with low-overhead. version:1
arxiv-1702-05472 | Threshold Constraints with Guarantees for Parity Objectives in Markov Decision Processes | http://arxiv.org/abs/1702.05472 | id:1702.05472 author:Raphaël Berthon, Mickael Randour, Jean-François Raskin category:cs.LO cs.AI cs.FL cs.GT math.PR  published:2017-02-17 summary:The beyond worst-case synthesis problem was introduced recently by Bruy\`ere et al. [BFRR14]: it aims at building system controllers that provide strict worst-case performance guarantees against an antagonistic environment while ensuring higher expected performance against a stochastic model of the environment. Our work extends the framework of [BFRR14] and follow-up papers, which focused on quantitative objectives, by addressing the case of $\omega$-regular conditions encoded as parity objectives, a natural way to represent functional requirements of systems. We build strategies that satisfy a main parity objective on all plays, while ensuring a secondary one with sufficient probability. This setting raises new challenges in comparison to quantitative objectives, as one cannot easily mix different strategies without endangering the functional properties of the system. We establish that, for all variants of this problem, deciding the existence of a strategy lies in ${\sf NP} \cap {\sf coNP}$, the same complexity class as classical parity games. Hence, our framework provides additional modeling power while staying in the same complexity class. [BFRR14] V\'eronique Bruy\`ere, Emmanuel Filiot, Mickael Randour, and Jean-Fran\c{c}ois Raskin. Meet your expectations with guarantees: Beyond worst-case synthesis in quantitative games. In Ernst W. Mayr and Natacha Portier, editors, 31st International Symposium on Theoretical Aspects of Computer Science, STACS 2014, March 5-8, 2014, Lyon, France, volume 25 of LIPIcs, pages 199-213. Schloss Dagstuhl - Leibniz - Zentrum fuer Informatik, 2014. version:2
arxiv-1704-08464 | Consensus of rankings | http://arxiv.org/abs/1704.08464 | id:1704.08464 author:Zhiwei Lin, Yi Li, Xiaolian Guo category:cs.AI  published:2017-04-27 summary:Rankings are widely used in many information systems. In information retrieval, a ranking is a list of ordered documents, in which a document with lower position has higher ranking score than the documents behind it. This paper studies the consensus measure for a given set of rankings, in order to understand the degree to which the rankings agree and the extent to which the rankings are related. The proposed multi-facet approach, without the need for pairwise comparison between rankings, allows to measure the consensus in a set of rankings, with respect to the length of common patterns, the number of common patterns for a given length, and the number of all common patterns. The experiments show that the proposed approach can be used to compare the search engines in terms of closeness of the returned results when semantically related key words are sent to them. version:1
arxiv-1704-08424 | Multimodal Word Distributions | http://arxiv.org/abs/1704.08424 | id:1704.08424 author:Ben Athiwaratkun, Andrew Gordon Wilson category:stat.ML cs.AI cs.CL cs.LG  published:2017-04-27 summary:Word embeddings provide point representations of words containing useful semantic information. We introduce multimodal word distributions formed from Gaussian mixtures, for multiple word meanings, entailment, and rich uncertainty information. To learn these distributions, we propose an energy-based max-margin objective. We show that the resulting approach captures uniquely expressive semantic information, and outperforms alternatives, such as word2vec skip-grams, and Gaussian embeddings, on benchmark datasets such as word similarity and entailment. version:1
arxiv-1704-08389 | Tweeting AI: Perceptions of AI-Tweeters (AIT) vs Expert AI-Tweeters (EAIT) | http://arxiv.org/abs/1704.08389 | id:1704.08389 author:Lydia Manikonda, Cameron Dudley, Subbarao Kambhampati category:cs.AI cs.CY cs.SI  published:2017-04-27 summary:With the recent advancements in Artificial Intelligence (AI), various organizations and individuals started debating about the progress of AI as a blessing or a curse for the future of the society. This paper conducts an investigation on how the public perceives the progress of AI by utilizing the data shared on Twitter. Specifically, this paper performs a comparative analysis on the understanding of users from two categories -- general AI-Tweeters (AIT) and the expert AI-Tweeters (EAIT) who share posts about AI on Twitter. Our analysis revealed that users from both the categories express distinct emotions and interests towards AI. Users from both the categories regard AI as positive and are optimistic about the progress of AI but the experts are more negative than the general AI-Tweeters. Characterization of users manifested that `London' is the popular location of users from where they tweet about AI. Tweets posted by AIT are highly retweeted than posts made by EAIT that reveals greater diffusion of information from AIT. version:1
arxiv-1704-05588 | Learning to Fly by Crashing | http://arxiv.org/abs/1704.05588 | id:1704.05588 author:Dhiraj Gandhi, Lerrel Pinto, Abhinav Gupta category:cs.RO cs.CV cs.LG  published:2017-04-19 summary:How do you learn to navigate an Unmanned Aerial Vehicle (UAV) and avoid obstacles? One approach is to use a small dataset collected by human experts: however, high capacity learning algorithms tend to overfit when trained with little data. An alternative is to use simulation. But the gap between simulation and real world remains large especially for perception problems. The reason most research avoids using large-scale real data is the fear of crashes! In this paper, we propose to bite the bullet and collect a dataset of crashes itself! We build a drone whose sole purpose is to crash into objects: it samples naive trajectories and crashes into random objects. We crash our drone 11,500 times to create one of the biggest UAV crash dataset. This dataset captures the different ways in which a UAV can crash. We use all this negative flying data in conjunction with positive data sampled from the same trajectories to learn a simple yet powerful policy for UAV navigation. We show that this simple self-supervised model is quite effective in navigating the UAV even in extremely cluttered environments with dynamic obstacles including humans. For supplementary video see: https://youtu.be/u151hJaGKUo version:2
arxiv-1704-08364 | Low-complexity Distributed Tomographic Backprojection for large datasets | http://arxiv.org/abs/1704.08364 | id:1704.08364 author:Gilberto Martinez Jr., Janito V. Ferreira Filho, Eduardo X. Miqueles category:cs.DC  published:2017-04-26 summary:In this manuscript we present a fast GPU implementation for tomographic reconstruction of large datasets using data obtained at the Brazilian synchrotron light source. The algorithm is distributed in a cluster with 4 GPUs through a fast pipeline implemented in C programming language. Our algorithm is theoretically based on a recently discovered low complexity formula, computing the total volume within O(N3logN) floating point operations; much less than traditional algorithms that operates with O(N4) flops over an input data of size O(N3). The results obtained with real data indicate that a reconstruction can be achieved within 1 second provided the data is transferred completely to the memory. version:1
arxiv-1704-08350 | The MacGyver Test - A Framework for Evaluating Machine Resourcefulness and Creative Problem Solving | http://arxiv.org/abs/1704.08350 | id:1704.08350 author:Vasanth Sarathy, Matthias Scheutz category:cs.AI  published:2017-04-26 summary:Current measures of machine intelligence are either difficult to evaluate or lack the ability to test a robot's problem-solving capacity in open worlds. We propose a novel evaluation framework based on the formal notion of MacGyver Test which provides a practical way for assessing the resilience and resourcefulness of artificial agents. version:1
arxiv-1704-08343 | A Distributed Shared Memory Model and C++ Templated Meta-Programming Interface for the Epiphany RISC Array Processor | http://arxiv.org/abs/1704.08343 | id:1704.08343 author:David Richie, James Ross, Jamie Infantolino category:cs.DC  published:2017-04-26 summary:The Adapteva Epiphany many-core architecture comprises a scalable 2D mesh Network-on-Chip (NoC) of low-power RISC cores with minimal uncore functionality. Whereas such a processor offers high computational energy efficiency and parallel scalability, developing effective programming models that address the unique architecture features has presented many challenges. We present here a distributed shared memory (DSM) model supported in software transparently using C++ templated metaprogramming techniques. The approach offers an extremely simple parallel programming model well suited for the architecture. Initial results are presented that demonstrate the approach and provide insight into the efficiency of the programming model and also the ability of the NoC to support a DSM without explicit control over data movement and localization. version:1
arxiv-1704-08273 | Exploring the Performance Benefit of Hybrid Memory System on HPC Environments | http://arxiv.org/abs/1704.08273 | id:1704.08273 author:Ivy Bo Peng, Roberto Gioiosa, Gokcen Kestor, Erwin Laure, Stefano Markidis category:cs.DC  published:2017-04-26 summary:Hardware accelerators have become a de-facto standard to achieve high performance on current supercomputers and there are indications that this trend will increase in the future. Modern accelerators feature high-bandwidth memory next to the computing cores. For example, the Intel Knights Landing (KNL) processor is equipped with 16 GB of high-bandwidth memory (HBM) that works together with conventional DRAM memory. Theoretically, HBM can provide 5x higher bandwidth than conventional DRAM. However, many factors impact the effective performance achieved by applications, including the application memory access pattern, the problem size, the threading level and the actual memory configuration. In this paper, we analyze the Intel KNL system and quantify the impact of the most important factors on the application performance by using a set of applications that are representative of scientific and data-analytics workloads. Our results show that applications with regular memory access benefit from MCDRAM, achieving up to 3x performance when compared to the performance obtained using only DRAM. On the contrary, applications with random memory access pattern are latency-bound and may suffer from performance degradation when using only MCDRAM. For those applications, the use of additional hardware threads may help hide latency and achieve higher aggregated bandwidth when using HBM. version:1
arxiv-1704-08244 | Idle Period Propagation in Message-Passing Applications | http://arxiv.org/abs/1704.08244 | id:1704.08244 author:Ivy Bo Peng, Stefano Markidis, Erwin Laure, Gokcen Kestor, Roberto Gioiosa category:cs.DC  published:2017-04-26 summary:Idle periods on different processes of Message Passing applications are unavoidable. While the origin of idle periods on a single process is well understood as the effect of system and architectural random delays, yet it is unclear how these idle periods propagate from one process to another. It is important to understand idle period propagation in Message Passing applications as it allows application developers to design communication patterns avoiding idle period propagation and the consequent performance degradation in their applications. To understand idle period propagation, we introduce a methodology to trace idle periods when a process is waiting for data from a remote delayed process in MPI applications. We apply this technique in an MPI application that solves the heat equation to study idle period propagation on three different systems. We confirm that idle periods move between processes in the form of waves and that there are different stages in idle period propagation. Our methodology enables us to identify a self-synchronization phenomenon that occurs on two systems where some processes run slower than the other processes. version:1
arxiv-1704-08243 | C-VQA: A Compositional Split of the Visual Question Answering (VQA) v1.0 Dataset | http://arxiv.org/abs/1704.08243 | id:1704.08243 author:Aishwarya Agrawal, Aniruddha Kembhavi, Dhruv Batra, Devi Parikh category:cs.CV cs.AI cs.CL cs.LG  published:2017-04-26 summary:Visual Question Answering (VQA) has received a lot of attention over the past couple of years. A number of deep learning models have been proposed for this task. However, it has been shown that these models are heavily driven by superficial correlations in the training data and lack compositionality -- the ability to answer questions about unseen compositions of seen concepts. This compositionality is desirable and central to intelligence. In this paper, we propose a new setting for Visual Question Answering where the test question-answer pairs are compositionally novel compared to training question-answer pairs. To facilitate developing models under this setting, we present a new compositional split of the VQA v1.0 dataset, which we call Compositional VQA (C-VQA). We analyze the distribution of questions and answers in the C-VQA splits. Finally, we evaluate several existing VQA models under this new setting and show that the performances of these models degrade by a significant amount compared to the original VQA setting. version:1
arxiv-1707-00627 | A Reverse Hex Solver | http://arxiv.org/abs/1707.00627 | id:1707.00627 author:Kenny Young, Ryan B. Hayward category:cs.AI cs.GT  published:2017-04-26 summary:We present Solrex,an automated solver for the game of Reverse Hex.Reverse Hex, also known as Rex, or Misere Hex, is the variant of the game of Hex in which the player who joins her two sides loses the game. Solrex performs a mini-max search of the state space using Scalable Parallel Depth First Proof Number Search, enhanced by the pruning of inferior moves and the early detection of certain winning strategies. Solrex is implemented on the same code base as the Hex program Solver, and can solve arbitrary positions on board sizes up to 6x6, with the hardest position taking less than four hours on four threads. version:1
arxiv-1704-08239 | Exploring Application Performance on Emerging Hybrid-Memory Supercomputers | http://arxiv.org/abs/1704.08239 | id:1704.08239 author:Ivy Bo Peng, Stefano Markidis, Erwin Laure, Gokcen Kestor, Roberto Gioiosa category:cs.DC  published:2017-04-26 summary:Next-generation supercomputers will feature more hierarchical and heterogeneous memory systems with different memory technologies working side-by-side. A critical question is whether at large scale existing HPC applications and emerging data-analytics workloads will have performance improvement or degradation on these systems. We propose a systematic and fair methodology to identify the trend of application performance on emerging hybrid-memory systems. We model the memory system of next-generation supercomputers as a combination of "fast" and "slow" memories. We then analyze performance and dynamic execution characteristics of a variety of workloads, from traditional scientific applications to emerging data analytics to compare traditional and hybrid-memory systems. Our results show that data analytics applications can clearly benefit from the new system design, especially at large scale. Moreover, hybrid-memory systems do not penalize traditional scientific applications, which may also show performance improvement. version:1
arxiv-1704-08224 | Punny Captions: Witty Wordplay in Image Descriptions | http://arxiv.org/abs/1704.08224 | id:1704.08224 author:Arjun Chandrasekaran, Devi Parikh, Mohit Bansal category:cs.CL cs.AI cs.CV  published:2017-04-26 summary:Wit is a quintessential form of rich inter-human interaction, and is often grounded in a specific situation (e.g., a comment in response to an event). In this work, we attempt to build computational models that can produce witty descriptions for a given image. Inspired by a cognitive account of humor appreciation, we employ linguistic wordplay, specifically puns. We compare our approach against meaningful baseline approaches via human studies. In a Turing test style evaluation, people find our model's description for an image to be wittier than a human's witty description 55% of the time! version:1
arxiv-1704-08544 | Network-based coverage of mutational profiles reveals cancer genes | http://arxiv.org/abs/1704.08544 | id:1704.08544 author:Borislav H. Hristov, Mona Singh category:q-bio.GN cs.AI q-bio.MN  published:2017-04-26 summary:A central goal in cancer genomics is to identify the somatic alterations that underpin tumor initiation and progression. This task is challenging as the mutational profiles of cancer genomes exhibit vast heterogeneity, with many alterations observed within each individual, few shared somatically mutated genes across individuals, and important roles in cancer for both frequently and infrequently mutated genes. While commonly mutated cancer genes are readily identifiable, those that are rarely mutated across samples are difficult to distinguish from the large numbers of other infrequently mutated genes. Here, we introduce a method that considers per-individual mutational profiles within the context of protein-protein interaction networks in order to identify small connected subnetworks of genes that, while not individually frequently mutated, comprise pathways that are perturbed across (i.e., "cover") a large fraction of the individuals. We devise a simple yet intuitive objective function that balances identifying a small subset of genes with covering a large fraction of individuals. We show how to solve this problem optimally using integer linear programming and also give a fast heuristic algorithm that works well in practice. We perform a large-scale evaluation of our resulting method, nCOP, on 6,038 TCGA tumor samples across 24 different cancer types. We demonstrate that our approach nCOP is more effective in identifying cancer genes than both methods that do not utilize any network information as well as state-of-the-art network-based methods that aggregate mutational information across individuals. Overall, our work demonstrates the power of combining per-individual mutational information with interaction networks in order to uncover genes functionally relevant in cancers, and in particular those genes that are less frequently mutated. version:1
arxiv-1704-08165 | A Generalization of Convolutional Neural Networks to Graph-Structured Data | http://arxiv.org/abs/1704.08165 | id:1704.08165 author:Yotam Hechtlinger, Purvasha Chakravarti, Jining Qin category:stat.ML cs.AI cs.CV cs.LG  published:2017-04-26 summary:This paper introduces a generalization of Convolutional Neural Networks (CNNs) from low-dimensional grid data, such as images, to graph-structured data. We propose a novel spatial convolution utilizing a random walk to uncover the relations within the input, analogous to the way the standard convolution uses the spatial neighborhood of a pixel on the grid. The convolution has an intuitive interpretation, is efficient and scalable and can also be used on data with varying graph structure. Furthermore, this generalization can be applied to many standard regression or classification problems, by learning the the underlying graph. We empirically demonstrate the performance of the proposed CNN on MNIST, and challenge the state-of-the-art on Merck molecular activity data set. version:1
arxiv-1704-06749 | Proactive Edge Computing in Latency-Constrained Fog Networks | http://arxiv.org/abs/1704.06749 | id:1704.06749 author:Mohammed S. Elbamby, Mehdi Bennis, Walid Saad category:cs.NI cs.DC cs.IT math.IT  published:2017-04-22 summary:In this paper, the fundamental problem of distribution and proactive caching of computing tasks in fog networks is studied under latency and reliability constraints. In the proposed scenario, computing can be executed either locally at the user device or offloaded to an edge cloudlet. Moreover, cloudlets exploit both their computing and storage capabilities by proactively caching popular task computation results to minimize computing latency. To this end, a clustering method to group spatially proximate user devices with mutual task popularity interests and their serving cloudlets is proposed. Then, cloudlets can proactively cache the popular tasks' computations of their cluster members to minimize computing latency. Additionally, the problem of distributing tasks to cloudlets is formulated as a matching game in which a cost function of computing delay is minimized under latency and reliability constraints. Simulation results show that the proposed scheme guarantees reliable computations with bounded latency and achieves up to 91% decrease in computing latency as compared to baseline schemes. version:2
arxiv-1704-08092 | A Recurrent Neural Model with Attention for the Recognition of Chinese Implicit Discourse Relations | http://arxiv.org/abs/1704.08092 | id:1704.08092 author:Samuel Rönnqvist, Niko Schenk, Christian Chiarcos category:cs.CL cs.AI cs.LG cs.NE  published:2017-04-26 summary:We introduce an attention-based Bi-LSTM for Chinese implicit discourse relations and demonstrate that modeling argument pairs as a joint sequence can outperform word order-agnostic approaches. Our model benefits from a partial sampling scheme and is conceptually simple, yet achieves state-of-the-art performance on the Chinese Discourse Treebank. We also visualize its attention activity to illustrate the model's ability to selectively focus on the relevant parts of an input sequence. version:1
arxiv-1704-08588 | Modeling Events as Machines | http://arxiv.org/abs/1704.08588 | id:1704.08588 author:Sabah Al-Fedaghi category:cs.AI cs.SE  published:2017-04-26 summary:The notion of events has occupied a central role in modeling and has an influence in computer science and philosophy. Recent developments in diagrammatic modeling have made it possible to examine conceptual representation of events. This paper explores some aspects of the notion of events that are produced by applying a new diagrammatic methodology with a focus on the interaction of events with such concepts as time and space, objects. The proposed description applies to abstract machines where events form the dynamic phases of a system. The results of this nontechnical research can be utilized in many fields where the notion of an event is typically used in interdisciplinary application. version:1
arxiv-1704-07950 | Structured Production System (extended abstract) | http://arxiv.org/abs/1704.07950 | id:1704.07950 author:Yi Zhou category:cs.AI  published:2017-04-26 summary:In this extended abstract, we propose Structured Production Systems (SPS), which extend traditional production systems with well-formed syntactic structures. Due to the richness of structures, structured production systems significantly enhance the expressive power as well as the flexibility of production systems, for instance, to handle uncertainty. We show that different rule application strategies can be reduced into the basic one by utilizing structures. Also, many fundamental approaches in computer science, including automata, grammar and logic, can be captured by structured production systems. version:1
arxiv-1704-07942 | POMDPs for Robotic Arm Search and Reach to Known Objects | http://arxiv.org/abs/1704.07942 | id:1704.07942 author:Marius Silaghi, Jixing Zheng category:cs.RO  published:2017-04-26 summary:We propose an approach based on probabilistic models, in particular POMDPs, to plan optimized search processes of known objects by intelligent eye in hand robotic arms. Searching and reaching for a known object (a pen, a book, or a hammer) in one's office is an operation that humans perform frequently in their daily activities. There is no reason why intelligent robotic arms would not encounter this problem frequently in the various applications in which they are expected to serve. The problem suffers from uncertainties coming both from the lack of information about the position of the object, from noisy sensors, imperfect models of the target object, of imperfect models of the environment, and from approximations in computations. The use of probabilistic models helps us to mitigate at least a few of these challenges, approaching optimality for this important task. version:1
arxiv-1704-07926 | From Language to Programs: Bridging Reinforcement Learning and Maximum Marginal Likelihood | http://arxiv.org/abs/1704.07926 | id:1704.07926 author:Kelvin Guu, Panupong Pasupat, Evan Zheran Liu, Percy Liang category:cs.AI cs.LG stat.ML  published:2017-04-25 summary:Our goal is to learn a semantic parser that maps natural language utterances into executable programs when only indirect supervision is available: examples are labeled with the correct execution result, but not the program itself. Consequently, we must search the space of programs for those that output the correct result, while not being misled by spurious programs: incorrect programs that coincidentally output the correct result. We connect two common learning paradigms, reinforcement learning (RL) and maximum marginal likelihood (MML), and then present a new learning algorithm that combines the strengths of both. The new algorithm guards against spurious programs by combining the systematic search traditionally employed in MML with the randomized exploration of RL, and by updating parameters such that probability is spread more evenly across consistent programs. We apply our learning algorithm to a new neural semantic parser and show significant gains over existing state-of-the-art results on a recent context-dependent semantic parsing task. version:1
arxiv-1704-07911 | Explaining How a Deep Neural Network Trained with End-to-End Learning Steers a Car | http://arxiv.org/abs/1704.07911 | id:1704.07911 author:Mariusz Bojarski, Philip Yeres, Anna Choromanska, Krzysztof Choromanski, Bernhard Firner, Lawrence Jackel, Urs Muller category:cs.CV cs.LG cs.NE cs.RO  published:2017-04-25 summary:As part of a complete software stack for autonomous driving, NVIDIA has created a neural-network-based system, known as PilotNet, which outputs steering angles given images of the road ahead. PilotNet is trained using road images paired with the steering angles generated by a human driving a data-collection car. It derives the necessary domain knowledge by observing human drivers. This eliminates the need for human engineers to anticipate what is important in an image and foresee all the necessary rules for safe driving. Road tests demonstrated that PilotNet can successfully perform lane keeping in a wide variety of driving conditions, regardless of whether lane markings are present or not. The goal of the work described here is to explain what PilotNet learns and how it makes its decisions. To this end we developed a method for determining which elements in the road image most influence PilotNet's steering decision. Results show that PilotNet indeed learns to recognize relevant objects on the road. In addition to learning the obvious features such as lane markings, edges of roads, and other cars, PilotNet learns more subtle features that would be hard to anticipate and program by engineers, for example, bushes lining the edge of the road and atypical vehicle classes. version:1
arxiv-1704-07910 | Adaptive Cost Function for Pointcloud Registration | http://arxiv.org/abs/1704.07910 | id:1704.07910 author:Johan Ekekrantz, John Folkesson, Patric Jensfelt category:cs.RO cs.CV  published:2017-04-25 summary:In this paper we introduce an adaptive cost function for pointcloud registration. The algorithm automatically estimates the sensor noise, which is important for generalization across different sensors and environments. Through experiments on real and synthetic data, we show significant improvements in accuracy and robustness over state-of-the-art solutions. version:1
arxiv-1704-07899 | Reinforcement Learning-based Thermal Comfort Control for Vehicle Cabins | http://arxiv.org/abs/1704.07899 | id:1704.07899 author:James Brusey, Diana Hintea, Elena Gaura, Neil Beloe category:cs.AI  published:2017-04-25 summary:Vehicle climate control systems aim to keep passengers thermally comfortable. However, current systems control temperature rather than thermal comfort and tend to be energy hungry, which is of particular concern when considering electric vehicles. This paper poses energy-efficient vehicle comfort control as a Markov Decision Process, which is then solved numerically using Sarsa({\lambda}) and an empirically validated, single-zone, 1D thermal model of the cabin. The resulting controller was tested in simulation using 200 randomly selected scenarios and found to exceed the performance of bang-bang, proportional, simple fuzzy logic, and commercial controllers with 23%, 43%, 40%, 56% increase, respectively. Compared to the next best performing controller, energy consumption is reduced by 13% while the proportion of time spent thermally comfortable is increased by 23%. These results indicate that this is a viable approach that promises to translate into substantial comfort and energy improvements in the car. version:1
arxiv-1704-07883 | Models of fault-tolerant distributed computation via dynamic epistemic logic | http://arxiv.org/abs/1704.07883 | id:1704.07883 author:Eric Goubault, Sergio Rajsbaum category:cs.DC cs.LO cs.MA math.AT  published:2017-04-25 summary:The computability power of a distributed computing model is determined by the communication media available to the processes, the timing assumptions about processes and communication, and the nature of failures that processes can suffer. In a companion paper we showed how dynamic epistemic logic can be used to give a formal semantics to a given distributed computing model, to capture precisely the knowledge needed to solve a distributed task, such as consensus. Furthermore, by moving to a dual model of epistemic logic defined by simplicial complexes, topological invariants are exposed, which determine task solvability. In this paper we show how to extend the setting above to include in the knowledge of the processes, knowledge about the model of computation itself. The extension describes the knowledge processes gain about the current execution, in problems where processes have no input values at all. version:1
arxiv-1704-07807 | A decentralized proximal-gradient method with network independent step-sizes and separated convergence rates | http://arxiv.org/abs/1704.07807 | id:1704.07807 author:Zhi Li, Wei Shi, Ming Yan category:math.OC cs.DC cs.LG math.NA stat.ML  published:2017-04-25 summary:This paper considers the problem of decentralized optimization with a composite objective containing smooth and non-smooth terms. To solve the problem, a proximal-gradient scheme is studied. Specifically, the smooth and nonsmooth terms are dealt with by gradient update and proximal update, respectively. The studied algorithm is closely related to a previous decentralized optimization algorithm, PG-EXTRA [37], but has a few advantages. First of all, in our new scheme, agents use uncoordinated step-sizes and the stable upper bounds on step-sizes are independent from network topology. The step-sizes depend on local objective functions, and they can be as large as that of the gradient descent. Secondly, for the special case without non-smooth terms, linear convergence can be achieved under the strong convexity assumption. The dependence of the convergence rate on the objective functions and the network are separated, and the convergence rate of our new scheme is as good as one of the two convergence rates that match the typical rates for the general gradient descent and the consensus averaging. We also provide some numerical experiments to demonstrate the efficacy of the introduced algorithms and validate our theoretical discoveries. version:1
arxiv-1704-07751 | Fine-Grained Entity Typing with High-Multiplicity Assignments | http://arxiv.org/abs/1704.07751 | id:1704.07751 author:Maxim Rabinovich, Dan Klein category:cs.CL cs.AI cs.IR cs.LG stat.ML  published:2017-04-25 summary:As entity type systems become richer and more fine-grained, we expect the number of types assigned to a given entity to increase. However, most fine-grained typing work has focused on datasets that exhibit a low degree of type multiplicity. In this paper, we consider the high-multiplicity regime inherent in data sources such as Wikipedia that have semi-open type systems. We introduce a set-prediction approach to this problem and show that our model outperforms unstructured baselines on a new Wikipedia-based fine-grained typing corpus. version:1
arxiv-1704-08101 | Event Stream-Based Process Discovery using Abstract Representations | http://arxiv.org/abs/1704.08101 | id:1704.08101 author:Sebastiaan J. van Zelst, Boudewijn F. van Dongen, Wil M. P. van der Aalst category:cs.DB cs.AI cs.DS stat.ML  published:2017-04-25 summary:The aim of process discovery, originating from the area of process mining, is to discover a process model based on business process execution data. A majority of process discovery techniques relies on an event log as an input. An event log is a static source of historical data capturing the execution of a business process. In this paper we focus on process discovery relying on online streams of business process execution events. Learning process models from event streams poses both challenges and opportunities, i.e. we need to handle unlimited amounts of data using finite memory and, preferably, constant time. We propose a generic architecture that allows for adopting several classes of existing process discovery techniques in context of event streams. Moreover, we provide several instantiations of the architecture, accompanied by implementations in the process mining tool-kit ProM (http://promtools.org). Using these instantiations, we evaluate several dimensions of stream-based process discovery. The evaluation shows that the proposed architecture allows us to lift process discovery to the streaming domain. version:1
arxiv-1610-08469 | Kissing Cuisines: Exploring Worldwide Culinary Habits on the Web | http://arxiv.org/abs/1610.08469 | id:1610.08469 author:Sina Sajadmanesh, Sina Jafarzadeh, Seyed Ali Osia, Hamid R. Rabiee, Hamed Haddadi, Yelena Mejova, Mirco Musolesi, Emiliano De Cristofaro, Gianluca Stringhini category:cs.CY cs.AI cs.SI  published:2016-10-26 summary:Food and nutrition occupy an increasingly prevalent space on the web, and dishes and recipes shared online provide an invaluable mirror into culinary cultures and attitudes around the world. More specifically, ingredients, flavors, and nutrition information become strong signals of the taste preferences of individuals and civilizations. However, there is little understanding of these palate varieties. In this paper, we present a large-scale study of recipes published on the web and their content, aiming to understand cuisines and culinary habits around the world. Using a database of more than 157K recipes from over 200 different cuisines, we analyze ingredients, flavors, and nutritional values which distinguish dishes from different regions, and use this knowledge to assess the predictability of recipes from different cuisines. We then use country health statistics to understand the relation between these factors and health indicators of different nations, such as obesity, diabetes, migration, and health expenditure. Our results confirm the strong effects of geographical and cultural similarities on recipes, health indicators, and culinary preferences across the globe. version:4
arxiv-1704-07624 | 280 Birds with One Stone: Inducing Multilingual Taxonomies from Wikipedia using Character-level Classification | http://arxiv.org/abs/1704.07624 | id:1704.07624 author:Amit Gupta, Rémi Lebret, Hamza Harkous, Karl Aberer category:cs.CL cs.AI cs.IR  published:2017-04-25 summary:We propose a simple, yet effective, approach towards inducing multilingual taxonomies from Wikipedia. Given an English taxonomy, our approach leverages the interlanguage links of Wikipedia followed by character-level classifiers to induce high-precision, high-coverage taxonomies in other languages. Through experiments, we demonstrate that our approach significantly outperforms the state-of-the-art, heuristics-heavy approaches for six languages. As a consequence of our work, we release presumably the largest and the most accurate multilingual taxonomic resource spanning over 280 languages. version:1
arxiv-1704-07619 | Asynchronous Early Output Dual-Bit Full Adders Based on Homogeneous and Heterogeneous Delay-Insensitive Data Encoding | http://arxiv.org/abs/1704.07619 | id:1704.07619 author:P Balasubramanian, K Prasad category:cs.AR  published:2017-04-25 summary:This paper presents the designs of asynchronous early output dual-bit full adders without and with redundant logic (implicit) corresponding to homogeneous and heterogeneous delay-insensitive data encoding. For homogeneous delay-insensitive data encoding only dual-rail i.e. 1-of-2 code is used, and for heterogeneous delay-insensitive data encoding 1-of-2 and 1-of-4 codes are used. The 4-phase return-to-zero protocol is used for handshaking. To demonstrate the merits of the proposed dual-bit full adder designs, 32-bit ripple carry adders (RCAs) are constructed comprising dual-bit full adders. The proposed dual-bit full adders based 32-bit RCAs incorporating redundant logic feature reduced latency and area compared to their non-redundant counterparts with no accompanying power penalty. In comparison with the weakly indicating 32-bit RCA constructed using homogeneously encoded dual-bit full adders containing redundant logic, the early output 32-bit RCA comprising the proposed homogeneously encoded dual-bit full adders with redundant logic reports corresponding reductions in latency and area by 22.2% and 15.1% with no associated power penalty. On the other hand, the early output 32-bit RCA constructed using the proposed heterogeneously encoded dual-bit full adder which incorporates redundant logic reports respective decreases in latency and area than the weakly indicating 32-bit RCA that consists of heterogeneously encoded dual-bit full adders with redundant logic by 21.5% and 21.3% with nil power overhead. The simulation results obtained are based on a 32/28nm CMOS process technology. version:1
arxiv-1704-07555 | Molecular De Novo Design through Deep Reinforcement Learning | http://arxiv.org/abs/1704.07555 | id:1704.07555 author:Marcus Olivecrona, Thomas Blaschke, Ola Engkvist, Hongming Chen category:cs.AI  published:2017-04-25 summary:This work introduces a method to tune a sequence-based generative model for molecular de novo design that through augmented episodic likelihood can learn to generate structures with certain specified desirable properties. We demonstrate how this model can execute a range of tasks such as generating analogues to a query structure and generating compounds predicted to be active against a biological target. As a proof of principle, the model is first trained to generate molecules that do not contain sulphur. As a second example, the model is trained to generate analogues to the drug Celecoxib, a technique that could be used for scaffold hopping or library expansion starting from a single molecule. Finally, when tuning the model towards generating compounds predicted to be active against the dopamine receptor D2, the model generates structures of which more than 95% are predicted to be active, including experimentally confirmed actives that have not been included in either the generative model nor the activity prediction model. version:1
arxiv-1704-07548 | Semi-supervised Bayesian Deep Multi-modal Emotion Recognition | http://arxiv.org/abs/1704.07548 | id:1704.07548 author:Changde Du, Changying Du, Jinpeng Li, Wei-long Zheng, Bao-liang Lu, Huiguang He category:cs.AI cs.LG stat.ML  published:2017-04-25 summary:In emotion recognition, it is difficult to recognize human's emotional states using just a single modality. Besides, the annotation of physiological emotional data is particularly expensive. These two aspects make the building of effective emotion recognition model challenging. In this paper, we first build a multi-view deep generative model to simulate the generative process of multi-modality emotional data. By imposing a mixture of Gaussians assumption on the posterior approximation of the latent variables, our model can learn the shared deep representation from multiple modalities. To solve the labeled-data-scarcity problem, we further extend our multi-view model to semi-supervised learning scenario by casting the semi-supervised classification problem as a specialized missing data imputation task. Our semi-supervised multi-view deep generative framework can leverage both labeled and unlabeled data from multiple modalities, where the weight factor for each modality can be learned automatically. Compared with previous emotion recognition methods, our method is more robust and flexible. The experiments conducted on two real multi-modal emotion datasets have demonstrated the superiority of our framework over a number of competitors. version:1
arxiv-1704-07538 | Path Planning with Kinematic Constraints for Robot Groups | http://arxiv.org/abs/1704.07538 | id:1704.07538 author:Wolfgang Hönig, T. K. Satish Kumar, Liron Cohen, Hang Ma, Sven Koenig, Nora Ayanian category:cs.AI cs.RO  published:2017-04-25 summary:Path planning for multiple robots is well studied in the AI and robotics communities. For a given discretized environment, robots need to find collision-free paths to a set of specified goal locations. Robots can be fully anonymous, non-anonymous, or organized in groups. Although powerful solvers for this abstract problem exist, they make simplifying assumptions by ignoring kinematic constraints, making it difficult to use the resulting plans on actual robots. In this paper, we present a solution which takes kinematic constraints, such as maximum velocities, into account, while guaranteeing a user-specified minimum safety distance between robots. We demonstrate our approach in simulation and on real robots in 2D and 3D environments. version:1
arxiv-1704-07535 | Abstract Syntax Networks for Code Generation and Semantic Parsing | http://arxiv.org/abs/1704.07535 | id:1704.07535 author:Maxim Rabinovich, Mitchell Stern, Dan Klein category:cs.CL cs.AI cs.LG stat.ML  published:2017-04-25 summary:Tasks like code generation and semantic parsing require mapping unstructured (or partially structured) inputs to well-formed, executable outputs. We introduce abstract syntax networks, a modeling framework for these problems. The outputs are represented as abstract syntax trees (ASTs) and constructed by a decoder with a dynamically-determined modular structure paralleling the structure of the output tree. On the benchmark Hearthstone dataset for code generation, our model obtains 79.2 BLEU and 22.7% exact match accuracy, compared to previous state-of-the-art values of 67.1 and 6.1%. Furthermore, we perform competitively on the Atis, Jobs, and Geo semantic parsing datasets with no task-specific engineering. version:1
arxiv-1704-07503 | Learning of Human-like Algebraic Reasoning Using Deep Feedforward Neural Networks | http://arxiv.org/abs/1704.07503 | id:1704.07503 author:Cheng-Hao Cai, Dengfeng Ke, Yanyan Xu, Kaile Su category:cs.AI cs.LG cs.LO  published:2017-04-25 summary:There is a wide gap between symbolic reasoning and deep learning. In this research, we explore the possibility of using deep learning to improve symbolic reasoning. Briefly, in a reasoning system, a deep feedforward neural network is used to guide rewriting processes after learning from algebraic reasoning examples produced by humans. To enable the neural network to recognise patterns of algebraic expressions with non-deterministic sizes, reduced partial trees are used to represent the expressions. Also, to represent both top-down and bottom-up information of the expressions, a centralisation technique is used to improve the reduced partial trees. Besides, symbolic association vectors and rule application records are used to improve the rewriting processes. Experimental results reveal that the algebraic reasoning examples can be accurately learnt only if the feedforward neural network has enough hidden layers. Also, the centralisation technique, the symbolic association vectors and the rule application records can reduce error rates of reasoning. In particular, the above approaches have led to 4.6% error rate of reasoning on a dataset of linear equations, differentials and integrals. version:1
arxiv-1704-07499 | PPMF: A Patient-based Predictive Modeling Framework for Early ICU Mortality Prediction | http://arxiv.org/abs/1704.07499 | id:1704.07499 author:Mohammad Amin Morid, Olivia R. Liu Sheng, Samir Abdelrahman category:cs.LG cs.AI  published:2017-04-25 summary:To date, developing a good model for early intensive care unit (ICU) mortality prediction is still challenging. This paper presents a patient based predictive modeling framework (PPMF) to improve the performance of ICU mortality prediction using data collected during the first 48 hours of ICU admission. PPMF consists of three main components verifying three related research hypotheses. The first component captures dynamic changes of patients status in the ICU using their time series data (e.g., vital signs and laboratory tests). The second component is a local approximation algorithm that classifies patients based on their similarities. The third component is a Gradient Decent wrapper that updates feature weights according to the classification feedback. Experiments using data from MIMICIII show that PPMF significantly outperforms: (1) the severity score systems, namely SASP III, APACHE IV, and MPM0III, (2) the aggregation based classifiers that utilize summarized time series, and (3) baseline feature selection methods. version:1
arxiv-1704-07489 | Multi-Task Video Captioning with Video and Entailment Generation | http://arxiv.org/abs/1704.07489 | id:1704.07489 author:Ramakanth Pasunuru, Mohit Bansal category:cs.CL cs.AI cs.CV  published:2017-04-24 summary:Video captioning, the task of describing the content of a video, has seen some promising improvements in recent years with sequence-to-sequence models, but accurately learning the temporal and logical dynamics involved in the task still remains a challenge, especially given the lack of sufficient annotated data. We improve video captioning by sharing knowledge with two related directed-generation tasks: a temporally-directed unsupervised video prediction task to learn richer context-aware video encoder representations, and a logically-directed language entailment generation task to learn better video-entailing caption decoder representations. For this, we present a many-to-many multi-task learning model that shares parameters across the encoders and decoders of the three tasks. We achieve significant improvements and the new state-of-the-art on several standard video captioning datasets using diverse automatic and human evaluations. We also show mutual multi-task improvements on the entailment generation task. version:1
arxiv-1704-07475 | Active Target Tracking with Self-Triggered Communications in Multi-Robot Teams | http://arxiv.org/abs/1704.07475 | id:1704.07475 author:Lifeng Zhou, Pratap Tokekar category:cs.RO  published:2017-04-24 summary:We study the problem of reducing the amount of communication in decentralized target tracking. We focus on the scenario where a team of robots are allowed to move on the boundary of the environment. Their goal is to seek a formation so as to best track a target moving in the interior of the environment. The robots are capable of measuring distances to the target. Decentralized control strategies have been proposed in the past that guarantee that the robots asymptotically converge to the optimal formation. However, existing methods require that the robots exchange information with their neighbors at all time steps. Instead, we focus on decentralized strategies to reduce the amount of communication among robots. We propose a self-triggered communication strategy that decides when a particular robot should seek up-to-date information from its neighbors and when it is safe to operate with possibly outdated information. We prove that this strategy converges asymptotically to a desired formation when the target is stationary. For the case of a mobile target, we propose an extension whereby each robot decides its optimal partner to share its measurements with using observability as a criterion. We evaluate all the approaches (constant communication and self-triggered communication with centralized and decentralized sensor fusion) through simulations. version:1
arxiv-1704-07466 | Learning from Ontology Streams with Semantic Concept Drift | http://arxiv.org/abs/1704.07466 | id:1704.07466 author:Freddy Lecue, Jiaoyan Chen, Jeff Pan, Huajun Chen category:cs.AI  published:2017-04-24 summary:Data stream learning has been largely studied for extracting knowledge structures from continuous and rapid data records. In the semantic Web, data is interpreted in ontologies and its ordered sequence is represented as an ontology stream. Our work exploits the semantics of such streams to tackle the problem of concept drift i.e., unexpected changes in data distribution, causing most of models to be less accurate as time passes. To this end we revisited (i) semantic inference in the context of supervised stream learning, and (ii) models with semantic embeddings. The experiments show accurate prediction with data from Dublin and Beijing. version:1
arxiv-1704-07436 | Real-time Teaching Cues for Automated Surgical Coaching | http://arxiv.org/abs/1704.07436 | id:1704.07436 author:Anand Malpani, S. Swaroop Vedula, Henry C. Lin, Gregory D. Hager, Russell H. Taylor category:cs.RO cs.HC  published:2017-04-24 summary:With introduction of new technologies in the operating room like the da Vinci Surgical System, training surgeons to use them effectively and efficiently is crucial in the delivery of better patient care. Coaching by an expert surgeon is effective in teaching relevant technical skills, but current methods to deliver effective coaching are limited and not scalable. We present a virtual reality simulation-based framework for automated virtual coaching in surgical education. We implement our framework within the da Vinci Skills Simulator. We provide three coaching modes ranging from a hands-on teacher (continuous guidance) to a handsoff guide (assistance upon request). We present six teaching cues targeted at critical learning elements of a needle passing task, which are shown to the user based on the coaching mode. These cues are graphical overlays which guide the user, inform them about sub-par performance, and show relevant video demonstrations. We evaluated our framework in a pilot randomized controlled trial with 16 subjects in each arm. In a post-study questionnaire, participants reported high comprehension of feedback, and perceived improvement in performance. After three practice repetitions of the task, the control arm (independent learning) showed better motion efficiency whereas the experimental arm (received real-time coaching) had better performance of learning elements (as per the ACS Resident Skills Curriculum). We observed statistically higher improvement in the experimental group based on one of the metrics (related to needle grasp orientation). In conclusion, we developed an automated coach that provides real-time cues for surgical training and demonstrated its feasibility. version:1
arxiv-1612-08060 | TAPSpMV: Topology-Aware Parallel Sparse Matrix Vector Multiplication | http://arxiv.org/abs/1612.08060 | id:1612.08060 author:Amanda Bienz, William D. Gropp, Luke N. Olson category:cs.DC cs.MS  published:2016-12-23 summary:This paper introduces a method to reduce communication that is injected into the network during a sparse matrix-vector multiply by reorganizing messages on each node. This results in a reduction of the inter-node communication, replaced by less-costly intra-node communication, which reduces both the number and size of messages that are injected into the network. version:2
arxiv-1609-04741 | Joint Attention in Autonomous Driving (JAAD) | http://arxiv.org/abs/1609.04741 | id:1609.04741 author:Iuliia Kotseruba, Amir Rasouli, John K. Tsotsos category:cs.RO  published:2016-09-15 summary:In this paper we present a novel dataset for a critical aspect of autonomous driving, the joint attention that must occur between drivers and of pedestrians, cyclists or other drivers. This dataset is produced with the intention of demonstrating the behavioral variability of traffic participants. We also show how visual complexity of the behaviors and scene understanding is affected by various factors such as different weather conditions, geographical locations, traffic and demographics of the people involved. The ground truth data conveys information regarding the location of participants (bounding boxes), the physical conditions (e.g. lighting and speed) and the behavior of the parties involved. version:5
arxiv-1704-07402 | Prominent Object Detection and Recognition: A Saliency-based Pipeline | http://arxiv.org/abs/1704.07402 | id:1704.07402 author:Hamed R. Tavakoli, Jorma Laaksonen category:cs.CV cs.AI  published:2017-04-24 summary:This manuscript introduces the problem of prominent object detection and recognition. The problem deals with finding the most important region of interest, segmenting the relevant item/object in that area, and assigning it an object class label. In other words, we are solving the three problems of saliency modeling, saliency detection, and object recognition under one umbrella. The motivation behind such a problem formulation is 1) the benefits to the knowledge representation-based vision pipelines, and 2) the potential improvements in emulating bio-inspired vision systems by solving these three problems together. We propose a method as a baseline for further research. The proposed model predicts the most important area in the image, segments the associated objects, and labels them. The proposed problem and method are evaluated against human fixations, annotated segmentation masks, and object class categories. We define a chance level for each of the evaluation criterion to compare the proposed algorithm with. Despite the good performance of the proposed baseline, the overall evaluations indicate that the problem of prominent object detection and recognition is a challenging task that is still worth investigating further. version:1
arxiv-1704-07400 | Development of An Autonomous Bridge Deck Inspection Robotic System | http://arxiv.org/abs/1704.07400 | id:1704.07400 author:Hung M. La, Nenad Gucunski, Kristin Dana, Seong-Hoon Kee category:cs.RO  published:2017-04-24 summary:The threat to safety of aging bridges has been recognized as a critical concern to the general public due to the poor condition of many bridges in the U.S. Currently, the bridge inspection is conducted manually, and it is not efficient to identify bridge condition deterioration in order to facilitate implementation of appropriate maintenance or rehabilitation procedures. In this paper, we report a new development of the autonomous mobile robotic system for bridge deck inspection and evaluation. The robot is integrated with several nondestructive evaluation (NDE) sensors and a navigation control algorithm to allow it to accurately and autonomously maneuver on the bridge deck to collect visual images and conduct NDE measurements. The developed robotic system can reduce the cost and time of the bridge deck data collection and inspection. For efficient bridge deck monitoring, the crack detection algorithm to build the deck crack map is presented in detail. The impact-echo (IE), ultrasonic surface waves (USW) and electrical resistivity (ER) data collected by the robot are analyzed to generate the delamination, concrete elastic modulus, corrosion maps of the bridge deck, respectively. The presented robotic system has been successfully deployed to inspect numerous bridges in more than ten different states in the U.S. version:1
arxiv-1704-07221 | Turing at SemEval-2017 Task 8: Sequential Approach to Rumour Stance Classification with Branch-LSTM | http://arxiv.org/abs/1704.07221 | id:1704.07221 author:Elena Kochkina, Maria Liakata, Isabelle Augenstein category:cs.CL cs.AI  published:2017-04-24 summary:This paper describes team Turing's submission to SemEval 2017 RumourEval: Determining rumour veracity and support for rumours (SemEval 2017 Task 8, Subtask A). Subtask A addresses the challenge of rumour stance classification, which involves identifying the attitude of Twitter users towards the truthfulness of the rumour they are discussing. Stance classification is considered to be an important step towards rumour verification, therefore performing well in this task is expected to be useful in debunking false rumours. In this work we classify a set of Twitter posts discussing rumours into either supporting, denying, questioning or commenting on the underlying rumours. We propose a LSTM-based sequential model that, through modelling the conversational structure of tweets, which achieves an accuracy of 0.784 on the RumourEval test set outperforming all other systems in Subtask A. version:1
arxiv-1704-07183 | Stochastic Constraint Programming as Reinforcement Learning | http://arxiv.org/abs/1704.07183 | id:1704.07183 author:Steven Prestwich, Roberto Rossi, Armagan Tarim category:cs.AI  published:2017-04-24 summary:Stochastic Constraint Programming (SCP) is an extension of Constraint Programming (CP) used for modelling and solving problems involving constraints and uncertainty. SCP inherits excellent modelling abilities and filtering algorithms from CP, but so far it has not been applied to large problems. Reinforcement Learning (RL) extends Dynamic Programming to large stochastic problems, but is problem-specific and has no generic solvers. We propose a hybrid combining the scalability of RL with the modelling and constraint filtering methods of CP. We implement a prototype in a CP system and demonstrate its usefulness on SCP problems. version:1
arxiv-1702-02302 | Autonomous Braking System via Deep Reinforcement Learning | http://arxiv.org/abs/1702.02302 | id:1702.02302 author:Hyunmin Chae, Chang Mook Kang, ByeoungDo Kim, Jaekyum Kim, Chung Choo Chung, Jun Won Choi category:cs.AI  published:2017-02-08 summary:In this paper, we propose a new autonomous braking system based on deep reinforcement learning. The proposed autonomous braking system automatically decides whether to apply the brake at each time step when confronting the risk of collision using the information on the obstacle obtained by the sensors. The problem of designing brake control is formulated as searching for the optimal policy in Markov decision process (MDP) model where the state is given by the relative position of the obstacle and the vehicle's speed, and the action space is defined as whether brake is stepped or not. The policy used for brake control is learned through computer simulations using the deep reinforcement learning method called deep Q-network (DQN). In order to derive desirable braking policy, we propose the reward function which balances the damage imposed to the obstacle in case of accident and the reward achieved when the vehicle runs out of risk as soon as possible. DQN is trained for the scenario where a vehicle is encountered with a pedestrian crossing the urban road. Experiments show that the control agent exhibits desirable control behavior and avoids collision without any mistake in various uncertain environments. version:2
arxiv-1704-08119 | Using a new parsimonious AHP methodology combined with the Choquet integral: An application for evaluating social housing initiatives | http://arxiv.org/abs/1704.08119 | id:1704.08119 author:Francesca Abastante, Salvatore Corrente, Salvatore Greco, Alessio Ishizaka, Isabella Lami category:cs.AI math.OC  published:2017-04-24 summary:We propose a development of the Analytic Hierarchy Process (AHP) permitting to use the methodology also in cases of decision problems with a very large number of alternatives evaluated with respect to several criteria. While the application of the original AHP method involves many pairwise comparisons between alternatives and criteria, our proposal is composed of three steps: (i) direct evaluation of the alternatives at hand on the considered criteria, (ii) selection of some reference evaluations; (iii) application of the original AHP method to reference evaluations; (iv) revision of the direct evaluation on the basis of the prioritization supplied by AHP on reference evaluations. The new proposal has been tested and validated in an experiment conducted on a sample of university students. The new methodology has been therefore applied to a real world problem involving the evaluation of 21 Social Housing initiatives sited in the Piedmont region (Italy). To take into account interaction between criteria, the Choquet integral preference model has been considered within a Non Additive Robust Ordinal Regression approach. version:1
arxiv-1612-01395 | The communication-hiding pipelined BiCGStab method for the parallel solution of large unsymmetric linear systems | http://arxiv.org/abs/1612.01395 | id:1612.01395 author:Siegfried Cools, Wim Vanroose category:cs.DC 65F10  published:2016-12-05 summary:A High Performance Computing alternative to traditional Krylov subspace methods, pipelined Krylov subspace solvers offer better scalability in the strong scaling limit compared to standard Krylov subspace methods for large and sparse linear systems. The typical synchronization bottleneck is mitigated by overlapping time-consuming global communication phases with local computations in the algorithm. This paper describes a general framework for deriving the pipelined variant of any Krylov subspace algorithm. The proposed framework was implicitly used to derive the pipelined Conjugate Gradient (p-CG) method in "Hiding global synchronization latency in the preconditioned Conjugate Gradient algorithm" by P. Ghysels and W. Vanroose, Parallel Computing, 40(7):224--238, 2014. The pipelining framework is subsequently illustrated by formulating a pipelined version of the BiCGStab method for the solution of large unsymmetric linear systems on parallel hardware. A residual replacement strategy is proposed to account for the possible loss of attainable accuracy and robustness by the pipelined BiCGStab method. It is shown that the pipelined algorithm improves scalability on distributed memory machines, leading to significant speedups compared to standard preconditioned BiCGStab. version:3
arxiv-1704-07158 | An Integrated Decision and Control Theoretic Solution to Multi-Agent Co-Operative Search Problems | http://arxiv.org/abs/1704.07158 | id:1704.07158 author:Titas Bera, Rajarshi Bardhan, Sundaram Suresh category:cs.RO  published:2017-04-24 summary:This paper considers the problem of autonomous multi-agent cooperative target search in an unknown environment using a decentralized framework under a no-communication scenario. The targets are considered as static targets and the agents are considered to be homogeneous. The no-communication scenario translates as the agents do not exchange either the information about the environment or their actions among themselves. We propose an integrated decision and control theoretic solution for a search problem which generates feasible agent trajectories. In particular, a perception based algorithm is proposed which allows an agent to estimate the probable strategies of other agents' and to choose a decision based on such estimation. The algorithm shows robustness with respect to the estimation accuracy to a certain degree. The performance of the algorithm is compared with random strategies and numerical simulation shows considerable advantages. version:1
arxiv-1704-07133 | Beeping a Maximal Independent Set Fast | http://arxiv.org/abs/1704.07133 | id:1704.07133 author:Stephan Holzer, Nancy Lynch category:cs.DC  published:2017-04-24 summary:We adapt a recent algorithm by Ghaffari [SODA'16] for computing a Maximal Independent Set in the LOCAL model, so that it works in the significantly weaker BEEP model. For networks with maximum degree $\Delta$, our algorithm terminates locally within time $O((\log \Delta + \log (1/\epsilon)) \cdot \log(1/\epsilon))$, with probability at least $1 - \epsilon$. The key idea of the modification is to replace explicit messages about transmission probabilities with estimates based on the number of received messages. After the successful introduction (and implicit use) of local analysis, e.g., by Barenboim et al. [JACM'16], Chung et al. [PODC'14], Ghaffari [SODA'16], and Halldorsson et al. [PODC'15], we study this concept in the BEEP model for the first time. By doing so, we improve over local bounds that are implicitly derived from previous work (that uses traditional global analysis) on computing a Maximal Independent Set in the \beep model for a large range of values of the parameter $\Delta$. At the same time, we show that our algorithm in the \beep model only needs to pay a $\log(1/\epsilon)$ factor in the runtime compared to the best known MIS algorithm in the much more powerful \local model. We demonstrate that this overhead is negligible, as communication via beeps can be implemented using significantly less resources than communication in the LOCAL model. In particular, when looking at implementing these models, one round of the \local model needs at least $O(\Delta)$ time units, while one round in the BEEP model needs $O(\log\Delta)$ time units, an improvement that diminishes the loss of a $\log(1/\epsilon)$ factor in most settings. version:1
arxiv-1704-07121 | Being Negative but Constructively: Lessons Learnt from Creating Better Visual Question Answering Datasets | http://arxiv.org/abs/1704.07121 | id:1704.07121 author:Wei-Lun Chao, Hexiang Hu, Fei Sha category:cs.CL cs.AI cs.CV cs.LG  published:2017-04-24 summary:Visual question answering (QA) has attracted a lot of attention lately, seen essentially as a form of (visual) Turing test that artificial intelligence should strive to achieve. In this paper, we study a crucial component of this task: how can we design good datasets for the task? We focus on the design of multiple-choice based datasets where the learner has to select the right answer from a set of candidate ones including the target (i.e. the correct one) and the decoys (i.e. the incorrect ones). Through careful analysis of the results attained by state-of-the-art learning models and human annotators on existing datasets, we show the design of the decoy answers has a significant impact on how and what the learning models learn from the datasets. In particular, the resulting learner can ignore the visual information, the question, or the both while still doing well on the task. Inspired by this, we propose automatic procedures to remedy such design deficiencies. We apply the procedures to re-construct decoy answers for two popular visual QA datasets as well as to create a new visual QA dataset from the Visual Genome project, resulting in the largest dataset for this task. Extensive empirical studies show that the design deficiencies have been alleviated in the remedied datasets and the performance on them is likely a more faithful indicator of the difference among learning models. The datasets are released and publicly available via http://www.teds.usc.edu/website_vqa/. version:1
arxiv-1704-07075 | Analysis of Vanilla Rolling Horizon Evolution Parameters in General Video Game Playing | http://arxiv.org/abs/1704.07075 | id:1704.07075 author:Raluca D. Gaina, Jialin Liu, Simon M. Lucas, Diego Perez-Liebana category:cs.AI  published:2017-04-24 summary:Monte Carlo Tree Search techniques have generally dominated General Video Game Playing, but recent research has started looking at Evolutionary Algorithms and their potential at matching Tree Search level of play or even outperforming these methods. Online or Rolling Horizon Evolution is one of the options available to evolve sequences of actions for planning in General Video Game Playing, but no research has been done up to date that explores the capabilities of the vanilla version of this algorithm in multiple games. This study aims to critically analyse the different configurations regarding population size and individual length in a set of 20 games from the General Video Game AI corpus. Distinctions are made between deterministic and stochastic games, and the implications of using superior time budgets are studied. Results show that there is scope for the use of these techniques, which in some configurations outperform Monte Carlo Tree Search, and also suggest that further research in these methods could boost their performance. version:1
arxiv-1704-07069 | Evaluating and Modelling Hanabi-Playing Agents | http://arxiv.org/abs/1704.07069 | id:1704.07069 author:Joseph Walton-Rivers, Piers R. Williams, Richard Bartle, Diego Perez-Liebana, Simon M. Lucas category:cs.AI  published:2017-04-24 summary:Agent modelling involves considering how other agents will behave, in order to influence your own actions. In this paper, we explore the use of agent modelling in the hidden-information, collaborative card game Hanabi. We implement a number of rule-based agents, both from the literature and of our own devising, in addition to an Information Set Monte Carlo Tree Search (IS-MCTS) agent. We observe poor results from IS-MCTS, so construct a new, predictor version that uses a model of the agents with which it is paired. We observe a significant improvement in game-playing strength from this agent in comparison to IS-MCTS, resulting from its consideration of what the other agents in a game would do. In addition, we create a flawed rule-based agent to highlight the predictor's capabilities with such an agent. version:1
arxiv-1704-07004 | Dependent Session Types | http://arxiv.org/abs/1704.07004 | id:1704.07004 author:Hanwen Wu, Hongwei Xi category:cs.PL cs.DC F.1.2; F.4.1  published:2017-04-24 summary:Session types offer a type-based discipline for enforcing communication protocols in distributed programming. We have previously formalized simple session types in the setting of multi-threaded $\lambda$-calculus with linear types. In this work, we build upon our earlier work by presenting a form of dependent session types (of DML-style). The type system we formulate provides linearity and duality guarantees with no need for any runtime checks or special encodings. Our formulation of dependent session types is the first of its kind, and it is particularly suitable for practical implementation. As an example, we describe one implementation written in ATS that compiles to an Erlang/Elixir back-end. version:1
arxiv-1704-08111 | A Popperian Falsification of AI - Lighthill's Argument Defended | http://arxiv.org/abs/1704.08111 | id:1704.08111 author:Steven Meyer category:cs.AI I.1; I.1.2  published:2017-04-23 summary:The area of computation called artificial intelligence (AI) is falsified by describing a previous 1972 falsification of AI by British applied mathematician James Lighthill. It is explained how Lighthill's arguments continue to apply to current AI. It is argued that AI should use the Popperian scientific method in which it is the duty of every scientist to attempt to falsify theories and if theories are falsified to replace or modify them. The paper describes the Popperian method in detail and discusses Paul Nurse's application of the method to cell biology that also involves questions of mechanism and behavior. Arguments used by Lighthill in his original 1972 report that falsifed AI are discussed. The Lighthill arguments are then shown to apply to current AI. The argument uses recent scholarship to explain Lighthill's assumptions and to show how the arguments based on those assumptions continue to falsify modern AI. An iimportant focus of the argument involves Hilbert's philosophical programme that defined knowledge and truth as provable formal sentences. Current AI takes the Hilbert programme as dogma beyond criticism while Lighthill as a mid 20th century applied mathematician had abandoned it. The paper uses recent scholarship to explain John von Neumann's criticism of AI that I claim was assumed by Lighthill. The paper discusses computer chess programs to show Lighthill's combinatorial explosion still applies to AI but not humans. An argument showing that Turing Machines (TM) are not the correct description of computation is given. The paper concludes by advocating studying computation as Peter Naur's Dataology. version:1
arxiv-1704-06976 | Exploring compression techniques for ROOT IO | http://arxiv.org/abs/1704.06976 | id:1704.06976 author:Zhe Zhang, Brian Bockelman category:cs.DC  published:2017-04-23 summary:ROOT provides an flexible format used throughout the HEP community. The number of use cases - from an archival data format to end-stage analysis - has required a number of tradeoffs to be exposed to the user. For example, a high "compression level" in the traditional DEFLATE algorithm will result in a smaller file (saving disk space) at the cost of slower decompression (costing CPU time when read). At the scale of the LHC experiment, poor design choices can result in terabytes of wasted space or wasted CPU time. We explore and attempt to quantify some of these tradeoffs. Specifically, we explore: the use of alternate compressing algorithms to optimize for read performance; an alternate method of compressing individual events to allow efficient random access; and a new approach to whole-file compression. Quantitative results are given, as well as guidance on how to make compression decisions for different use cases. version:1
arxiv-1704-06956 | Naturalizing a Programming Language via Interactive Learning | http://arxiv.org/abs/1704.06956 | id:1704.06956 author:Sida I. Wang, Samuel Ginn, Percy Liang, Christoper D. Manning category:cs.CL cs.AI cs.HC cs.LG I.2.7; I.2.6; I.2.1  published:2017-04-23 summary:Our goal is to create a convenient natural language interface for performing well-specified but complex actions such as analyzing data, manipulating text, and querying databases. However, existing natural language interfaces for such tasks are quite primitive compared to the power one wields with a programming language. To bridge this gap, we start with a core programming language and allow users to "naturalize" the core language incrementally by defining alternative, more natural syntax and increasingly complex concepts in terms of compositions of simpler ones. In a voxel world, we show that a community of users can simultaneously teach a common system a diverse language and use it to build hundreds of complex voxel structures. Over the course of three days, these users went from using only the core language to using the naturalized language in 85.9\% of the last 10K utterances. version:1
arxiv-1704-06945 | General Video Game AI: Learning from Screen Capture | http://arxiv.org/abs/1704.06945 | id:1704.06945 author:Kamolwan Kunanusont, Simon M. Lucas, Diego Perez-Liebana category:cs.AI  published:2017-04-23 summary:General Video Game Artificial Intelligence is a general game playing framework for Artificial General Intelligence research in the video-games domain. In this paper, we propose for the first time a screen capture learning agent for General Video Game AI framework. A Deep Q-Network algorithm was applied and improved to develop an agent capable of learning to play different games in the framework. After testing this algorithm using various games of different categories and difficulty levels, the results suggest that our proposed screen capture learning agent has the potential to learn many different games using only a single learning algorithm. version:1
arxiv-1704-06942 | Population Seeding Techniques for Rolling Horizon Evolution in General Video Game Playing | http://arxiv.org/abs/1704.06942 | id:1704.06942 author:Rauca D. Gaina, Simon M. Lucas, Diego Perez-Liebana category:cs.AI cs.NE  published:2017-04-23 summary:While Monte Carlo Tree Search and closely related methods have dominated General Video Game Playing, recent research has demonstrated the promise of Rolling Horizon Evolutionary Algorithms as an interesting alternative. However, there is little attention paid to population initialization techniques in the setting of general real-time video games. Therefore, this paper proposes the use of population seeding to improve the performance of Rolling Horizon Evolution and presents the results of two methods, One Step Look Ahead and Monte Carlo Tree Search, tested on 20 games of the General Video Game AI corpus with multiple evolution parameter values (population size and individual length). An in-depth analysis is carried out between the results of the seeding methods and the vanilla Rolling Horizon Evolution. In addition, the paper presents a comparison to a Monte Carlo Tree Search algorithm. The results are promising, with seeding able to boost performance significantly over baseline evolution and even match the high level of play obtained by the Monte Carlo Tree Search. version:1
arxiv-1701-07696 | Identifying Consistent Statements about Numerical Data with Dispersion-Corrected Subgroup Discovery | http://arxiv.org/abs/1701.07696 | id:1701.07696 author:Mario Boley, Bryan R. Goldsmith, Luca M. Ghiringhelli, Jilles Vreeken category:cs.AI cs.DB  published:2017-01-26 summary:Existing algorithms for subgroup discovery with numerical targets do not optimize the error or target variable dispersion of the groups they find. This often leads to unreliable or inconsistent statements about the data, rendering practical applications, especially in scientific domains, futile. Therefore, we here extend the optimistic estimator framework for optimal subgroup discovery to a new class of objective functions: we show how tight estimators can be computed efficiently for all functions that are determined by subgroup size (non-decreasing dependence), the subgroup median value, and a dispersion measure around the median (non-increasing dependence). In the important special case when dispersion is measured using the average absolute deviation from the median, this novel approach yields a linear time algorithm. Empirical evaluation on a wide range of datasets shows that, when used within branch-and-bound search, this approach is highly efficient and indeed discovers subgroups with much smaller errors. version:2
arxiv-1704-06888 | Time-Contrastive Networks: Self-Supervised Learning from Multi-View Observation | http://arxiv.org/abs/1704.06888 | id:1704.06888 author:Pierre Sermanet, Corey Lynch, Jasmine Hsu, Sergey Levine category:cs.CV cs.RO  published:2017-04-23 summary:We propose a self-supervised approach for learning representations entirely from unlabeled videos recorded from multiple viewpoints. This is particularly relevant to robotic imitation learning, which requires a viewpoint-invariant understanding of the relationships between humans and their environment, including object interactions, attributes and body pose. We train our representations using a triplet loss, where multiple simultaneous viewpoints of the same observation are attracted in the embedding space, while being repelled from temporal neighbors which are often visually similar but functionally different. This signal encourages our model to discover attributes that do not change across viewpoint, but do change across time, while ignoring nuisance variables such as occlusions, motion blur, lighting and background. Our experiments demonstrate that such a representation even acquires some degree of invariance to object instance. We demonstrate that our model can correctly identify corresponding steps in complex object interactions, such as pouring, across different videos with different instances. We also show what is, to the best of our knowledge, the first self-supervised results for end-to-end imitation learning of human motions by a real robot. version:1
arxiv-1704-06885 | A General Theory for Training Learning Machine | http://arxiv.org/abs/1704.06885 | id:1704.06885 author:Hong Zhao category:stat.ML cs.AI cs.CV cs.LG  published:2017-04-23 summary:Though the deep learning is pushing the machine learning to a new stage, basic theories of machine learning are still limited. The principle of learning, the role of the a prior knowledge, the role of neuron bias, and the basis for choosing neural transfer function and cost function, etc., are still far from clear. In this paper, we present a general theoretical framework for machine learning. We classify the prior knowledge into common and problem-dependent parts, and consider that the aim of learning is to maximally incorporate them. The principle we suggested for maximizing the former is the design risk minimization principle, while the neural transfer function, the cost function, as well as pretreatment of samples, are endowed with the role for maximizing the latter. The role of the neuron bias is explained from a different angle. We develop a Monte Carlo algorithm to establish the input-output responses, and we control the input-output sensitivity of a learning machine by controlling that of individual neurons. Applications of function approaching and smoothing, pattern recognition and classification, are provided to illustrate how to train general learning machines based on our theory and algorithm. Our method may in addition induce new applications, such as the transductive inference. version:1
arxiv-1704-06857 | A Review on Deep Learning Techniques Applied to Semantic Segmentation | http://arxiv.org/abs/1704.06857 | id:1704.06857 author:Alberto Garcia-Garcia, Sergio Orts-Escolano, Sergiu Oprea, Victor Villena-Martinez, Jose Garcia-Rodriguez category:cs.CV cs.AI  published:2017-04-22 summary:Image semantic segmentation is more and more being of interest for computer vision and machine learning researchers. Many applications on the rise need accurate and efficient segmentation mechanisms: autonomous driving, indoor navigation, and even virtual or augmented reality systems to name a few. This demand coincides with the rise of deep learning approaches in almost every field or application target related to computer vision, including semantic segmentation or scene understanding. This paper provides a review on deep learning methods for semantic segmentation applied to various application areas. Firstly, we describe the terminology of this field as well as mandatory background concepts. Next, the main datasets and challenges are exposed to help researchers decide which are the ones that best suit their needs and their targets. Then, existing methods are reviewed, highlighting their contributions and their significance in the field. Finally, quantitative results are given for the described methods and the datasets in which they were evaluated, following up with a discussion of the results. At last, we point out a set of promising future works and draw our own conclusions about the state of the art of semantic segmentation using deep learning techniques. version:1
arxiv-1704-06829 | Extreme-Scale Block-Structured Adaptive Mesh Refinement | http://arxiv.org/abs/1704.06829 | id:1704.06829 author:Florian Schornbaum, Ulrich Rüde category:cs.DC  published:2017-04-22 summary:In this article, we present a novel approach for block-structured adaptive mesh refinement (AMR) that is suitable for extreme-scale parallelism. All data structures are designed such that the size of the meta data in each distributed processor memory remains bounded independent of the processor number. In all stages of the AMR process, we use only distributed algorithms. No central resources such as a master process or replicated data are employed, so that an unlimited scalability can be achieved. For the dynamic load balancing in particular, we propose to exploit the hierarchical nature of the block-structured domain partitioning by creating a lightweight, temporary copy of the core data structure. This copy acts as a local and fully distributed proxy data structure. It does not contain simulation data, but only provides topological information about the domain partitioning into blocks. Ultimately, this approach enables an inexpensive, local, diffusion-based dynamic load balancing scheme. We demonstrate the excellent performance and the full scalability of our new AMR implementation for two architecturally different petascale supercomputers. Benchmarks on an IBM Blue Gene/Q system with a mesh containing 3.7 trillion unknowns distributed to 458,752 processes confirm the applicability for future extreme-scale parallel machines. The algorithms proposed in this article operate on blocks that result from the domain partitioning. This concept and its realization support the storage of arbitrary data. In consequence, the software framework can be used for different simulation methods, including mesh based and meshless methods. In this article, we demonstrate fluid simulations based on the lattice Boltzmann method. version:1
arxiv-1704-06817 | COCrIP: Compliant OmniCrawler In-pipeline Robot | http://arxiv.org/abs/1704.06817 | id:1704.06817 author:Akash Singh, Enna Sachdeva, Abhishek Sarkar, K. Madhava Krishna category:cs.RO  published:2017-04-22 summary:This paper presents a modular in-pipeline climbing robot with a novel compliant foldable OmniCrawler mechanism. The circular cross-section of the OmniCrawler module enables a holonomic motion to facilitate the alignment of the robot in the direction of bends. Additionally, the crawler mechanism provides a fair amount of traction, even on slippery surfaces. These advantages of crawler modules have been further supplemented by incorporating active compliance in the module itself which helps to negotiate sharp bends in small diameter pipes. The robot has a series of 3 such compliant foldable modules interconnected by the links via passive joints. For the desirable pipe diameter and curvature of the bends, the spring stiffness value for each passive joint is determined by formulating a constrained optimization problem using the quasi-static model of the robot. Moreover, a minimum friction coefficient value between the module-pipe surface which can be vertically climbed by the robot without slipping is estimated. The numerical simulation results have further been validated by experiments on real robot prototype. version:1
arxiv-1607-00307 | Optimal Tree Hash Modes: the Case of Trees Having their Leaves at All the Levels | http://arxiv.org/abs/1607.00307 | id:1607.00307 author:Kevin Atighehchi category:cs.DC cs.CR  published:2016-07-01 summary:A recent work shows how we can optimize a tree based mode of operation for a hash function where the sizes of input message blocks and digest are the same, subject to the constraint that the involved tree structure has all its leaves at the same depth. In this work, we show that we can further optimize the running time of such a mode by using a tree having leaves at all its levels. We make the assumption that the input message block has a size a multiple of that of the digest and denote by $d$ the ratio block size over digest size. The running time is evaluated in terms of number of operations performed by the hash function, i.e. the number of calls to its underlying function. It turns out that a digest can be computed in $\lceil \log_{d+1} (l/2) \rceil+2$ evaluations of the underlying function using $\lceil l/2 \rceil$ processors, where $l$ is the number of blocks of the message. Other results of interest are discussed, such as the optimization of the parallel running time for a tree of restricted height. version:10
arxiv-1704-06738 | Towards Distributed Machine Learning in Shared Clusters: A Dynamically-Partitioned Approach | http://arxiv.org/abs/1704.06738 | id:1704.06738 author:Peng Sun, Yonggang Wen, Ta Nguyen Binh Duong, Shengen Yan category:cs.DC  published:2017-04-22 summary:Many cluster management systems (CMSs) have been proposed to share a single cluster with multiple distributed computing systems. However, none of the existing approaches can handle distributed machine learning (ML) workloads given the following criteria: high resource utilization, fair resource allocation and low sharing overhead. To solve this problem, we propose a new CMS named Dorm, incorporating a dynamically-partitioned cluster management mechanism and an utilization-fairness optimizer. Specifically, Dorm uses the container-based virtualization technique to partition a cluster, runs one application per partition, and can dynamically resize each partition at application runtime for resource efficiency and fairness. Each application directly launches its tasks on the assigned partition without petitioning for resources frequently, so Dorm imposes flat sharing overhead. Extensive performance evaluations showed that Dorm could simultaneously increase the resource utilization by a factor of up to 2.32, reduce the fairness loss by a factor of up to 1.52, and speed up popular distributed ML applications by a factor of up to 2.72, compared to existing approaches. Dorm's sharing overhead is less than 5% in most cases. version:1
arxiv-1704-06724 | Complexity Analysis of the Parallel Guided Ejection Search for the Pickup and Delivery Problem with Time Windows | http://arxiv.org/abs/1704.06724 | id:1704.06724 author:Miroslaw Blocho, Jakub Nalepa category:cs.DS cs.DC  published:2017-04-21 summary:This paper presents the pessimistic time complexity analysis of the parallel algorithm for minimizing the fleet size in the pickup and delivery problem with time windows. We show how to estimate the pessimistic complexity step by step. This approach can be easily adopted to other parallel algorithms for solving complex transportation problems. version:1
arxiv-1704-06718 | Hierarchical Bayesian Data Fusion for Robotic Platform Navigation | http://arxiv.org/abs/1704.06718 | id:1704.06718 author:Andres F. Echeverri, Henry Medeiros, Ryan Walsh, Yevgeniy Reznichenko, Richard Povinelli category:cs.RO  published:2017-04-21 summary:Data fusion has become an active research topic in recent years. Growing computational performance has allowed the use of redundant sensors to measure a single phenomenon. While Bayesian fusion approaches are common in general applications, the computer vision field has largely relegated this approach. Most object following algorithms have gone towards pure machine learning fusion techniques that tend to lack flexibility. Consequently, a more general data fusion scheme is needed. Within this work, a hierarchical Bayesian fusion approach is proposed, which outperforms individual trackers by using redundant measurements. The adaptive framework is achieved by relying on each measurement's local statistics and a global softened majority voting. The proposed approach was validated in a simulated application and two robotic platforms. version:1
arxiv-1611-09240 | Linear vs Nonlinear MPC for Trajectory Tracking Applied to Rotary Wing Micro Aerial Vehicles | http://arxiv.org/abs/1611.09240 | id:1611.09240 author:Mina Kamel, Michael Burri, Roland Siegwart category:cs.RO  published:2016-11-28 summary:Precise trajectory tracking is a crucial property for \acp{MAV} to operate in cluttered environment or under disturbances. In this paper we present a detailed comparison between two state-of-the-art model-based control techniques for \ac{MAV} trajectory tracking. A classical \ac{LMPC} is presented and compared against a more advanced \ac{NMPC} that considers the full system model. In a careful analysis we show the advantages and disadvantages of the two implementations in terms of speed and tracking performance. This is achieved by evaluating hovering performance, step response, and aggressive trajectory tracking under nominal conditions and under external wind disturbances. version:2
arxiv-1704-06215 | On Singleton Arc Consistency for Natural CSPs Defined by Forbidden Patterns | http://arxiv.org/abs/1704.06215 | id:1704.06215 author:Clement Carbonnel, David A. Cohen, Martin C. Cooper, Stanislav Zivny category:cs.CC cs.AI cs.DM  published:2017-04-20 summary:Singleton arc consistency is an important type of local consistency which has been recently shown to solve all constraint satisfaction problems (CSPs) over constraint languages of bounded width. We aim to characterise all classes of CSPs defined by a forbidden pattern that are solved by singleton arc consistency and closed under removing constraints. We identify five new patterns whose absence ensures solvability by singleton arc consistency, four of which are provably maximal and three of which generalise 2-SAT. Combined with simple counter-examples for other patterns, we make significant progress towards a complete classification. version:2
arxiv-1704-06676 | Multi-Objective Deep Q-Learning with Subsumption Architecture | http://arxiv.org/abs/1704.06676 | id:1704.06676 author:Tomasz Tajmajer category:cs.AI cs.RO  published:2017-04-21 summary:In this work we present a method for using Deep Q-Networks (DQNs) in multi-objective tasks. Deep Q-Networks provide remarkable performance in single objective tasks learning from high-level visual perception. However, in many scenarios (e.g in robotics), the agent needs to pursue multiple objectives simultaneously. We propose an architecture in which separate DQNs are used to control the agent's behaviour with respect to particular objectives. In this architecture we use signal suppression, known from the (Brooks) subsumption architecture, to combine outputs of several DQNs into a single action. Our architecture enables the decomposition of the agent's behaviour into controllable and replaceable sub-behaviours learned by distinct modules. To evaluate our solution we used a game-like simulator in which an agent - provided with high-level visual input - pursues multiple objectives in a 2D world. Our solution provides benefits of modularity, while its performance is comparable to the monolithic approach. version:1
arxiv-1704-06623 | Symmetry in Software Synthesis | http://arxiv.org/abs/1704.06623 | id:1704.06623 author:Andrés Goens, Sergio Siccha, Jeronimo Castrillon category:cs.DC  published:2017-04-21 summary:With the surge of multi- and manycores, much research has focused on algorithms for mapping and scheduling on these complex platforms. Large classes of these algorithms face scalability problems. This is why diverse methods are commonly used for reducing the search space. While most such approaches leverage the inherent symmetry of architectures and applications, they do it in a problem-specific and intuitive way. However, intuitive approaches become impractical with growing hardware complexity, like Network-on-Chip interconnect or heterogeneous cores. In this paper, we present a formal framework that can determine the inherent symmetry of architectures and applications algorithmically and leverage these for problems in software synthesis. Our approach is based on the mathematical theory of groups and a generalization called inverse semigroups. We evaluate our approach in two state-of-the-art mapping frameworks. Even for the platforms with a handful of cores of today and moderate-size benchmarks, our approach consistently yields reductions of the overall execution time of algorithms, accelerating them by a factor up to 10 in our experiments, or improving the quality of the results. version:1
arxiv-1704-06621 | A hybrid spatial data mining approach based on fuzzy topological relations and MOSES evolutionary algorithm | http://arxiv.org/abs/1704.06621 | id:1704.06621 author:Amir Hossein Goudarzi, Nasser Ghadiri category:cs.AI H.2.8; H.4.2  published:2017-04-21 summary:Making high-quality decisions in strategic spatial planning is heavily dependent on extracting knowledge from vast amounts of data. Although many decision-making problems like developing urban areas require such perception and reasoning, existing methods in this field usually neglect the deep knowledge mined from geographic databases and are based on pure statistical methods. Due to the large volume of data gathered in spatial databases, and the uncertainty of spatial objects, mining association rules for high-level knowledge representation is a challenging task. Few algorithms manage geographical and non-geographical data using topological relations. In this paper, a novel approach for spatial data mining based on the MOSES evolutionary framework is presented which improves the classic genetic programming approach. A hybrid architecture called GGeo is proposed to apply the MOSES mining rules considering fuzzy topological relations from spatial data. The uncertainty and fuzziness aspects are addressed using an enriched model of topological relations by fuzzy region connection calculus. Moreover, to overcome the problem of time-consuming fuzzy topological relationships calculations, this a novel data pre-processing method is offered. GGeo analyses and learns from geographical and non-geographical data and uses topological and distance parameters, and returns a series of arithmetic-spatial formulas as classification rules. The proposed approach is resistant to noisy data, and all its stages run in parallel to increase speed. This approach may be used in different spatial data classification problems as well as representing an appropriate method of data analysis and economic policy making. version:1
arxiv-1704-06616 | Accurately and Efficiently Interpreting Human-Robot Instructions of Varying Granularities | http://arxiv.org/abs/1704.06616 | id:1704.06616 author:Dilip Arumugam, Siddharth Karamcheti, Nakul Gopalan, Lawson L. S. Wong, Stefanie Tellex category:cs.AI  published:2017-04-21 summary:Humans can ground natural language commands to tasks at both abstract and fine-grained levels of specificity. For instance, a human forklift operator can be instructed to perform a high-level action, like "grab a pallet" or a lowlevel action like "tilt back a little bit." While robots are also capable of grounding language commands to tasks, previous methods implicitly assume that all commands and tasks reside at a single, fixed level of abstraction. Additionally, those approaches that do not use abstraction experience inefficient planning and execution times due to the large, intractable state-action spaces, which closely resemble real world complexity. In this work, by grounding commands to all the tasks or subtasks available in a hierarchical planning framework, we arrive at a model capable of interpreting language at multiple levels of specificity ranging from coarse to more granular. We show that the accuracy of the grounding procedure is improved when simultaneously inferring the degree of abstraction in language used to communicate the task. Leveraging hierarchy also improves efficiency: our proposed approach enables a robot to respond to a command within one second on 90% of our tasks, while baselines take over twenty seconds on half the tasks. Finally, we demonstrate that a real, physical robot can ground commands at multiple levels of abstraction allowing it to efficiently plan different subtasks within the same planning hierarchy. version:1
arxiv-1704-06259 | A Semantic QA-Based Approach for Text Summarization Evaluation | http://arxiv.org/abs/1704.06259 | id:1704.06259 author:Ping Chen, Fei Wu, Tong Wang category:cs.CL cs.AI  published:2017-04-21 summary:Many Natural Language Processing and Computational Linguistics applications involves the generation of new texts based on some existing texts, such as summarization, text simplification and machine translation. However, there has been a serious problem haunting these applications for decades, that is, how to automatically and accurately assess quality of these applications. In this paper, we will present some preliminary results on one especially useful and challenging problem in NLP system evaluation: how to pinpoint content differences of two text passages (especially for large pas-sages such as articles and books). Our idea is intuitive and very different from existing approaches. We treat one text passage as a small knowledge base, and ask it a large number of questions to exhaustively identify all content points in it. By comparing the correctly answered questions from two text passages, we will be able to compare their content precisely. The experiment using 2007 DUC summarization corpus clearly shows promising results. version:1
arxiv-1704-06654 | Governing Governance: A Formal Framework for Analysing Institutional Design and Enactment Governance | http://arxiv.org/abs/1704.06654 | id:1704.06654 author:Thomas C. King category:cs.AI cs.MA  published:2017-04-21 summary:This dissertation is motivated by the need, in today's globalist world, for a precise way to enable governments, organisations and other regulatory bodies to evaluate the constraints they place on themselves and others. An organisation's modus operandi is enacting and fulfilling contracts between itself and its participants. Yet, organisational contracts should respect external laws, such as those setting out data privacy rights and liberties. Contracts can only be enacted by following contract law processes, which often require bilateral agreement and consideration. Governments need to legislate whilst understanding today's context of national and international governance hierarchy where law makers shun isolationism and seek to influence one another. Governments should avoid punishment by respecting constraints from international treaties and human rights charters. Governments can only enact legislation by following their own, pre-existing, law making procedures. In other words, institutions, such as laws and contracts are designed and enacted under constraints. version:1
arxiv-1608-05866 | AllConcur: Leaderless Concurrent Atomic Broadcast (Extended Version) | http://arxiv.org/abs/1608.05866 | id:1608.05866 author:Marius Poke, Torsten Hoefler, Colin W. Glass category:cs.DC  published:2016-08-20 summary:Many distributed systems require coordination between the components involved. With the steady growth of such systems, the probability of failures increases, which necessitates scalable fault-tolerant agreement protocols. The most common practical agreement protocol, for such scenarios, is leader-based atomic broadcast. In this work, we propose AllConcur, a distributed system that provides agreement through a leaderless concurrent atomic broadcast algorithm, thus, not suffering from the bottleneck of a central coordinator. In AllConcur, all components exchange messages concurrently through a logical overlay network that employs early termination to minimize the agreement latency. Our implementation of AllConcur supports standard sockets-based TCP as well as high-performance InfiniBand Verbs communications. AllConcur can handle up to 135 million requests per second and achieves 17x higher throughput than today's standard leader-based protocols, such as Libpaxos. Thus, AllConcur is highly competitive with regard to existing solutions and, due to its decentralized approach, enables hitherto unattainable system designs in a variety of fields. version:2
arxiv-1611-03631 | Voxblox: Incremental 3D Euclidean Signed Distance Fields for On-Board MAV Planning | http://arxiv.org/abs/1611.03631 | id:1611.03631 author:Helen Oleynikova, Zachary Taylor, Marius Fehr, Juan Nieto, Roland Siegwart category:cs.RO  published:2016-11-11 summary:Micro Aerial Vehicles (MAVs) that operate in unstructured, unexplored environments require fast and flexible local planning, which can replan when new parts of the map are explored. Trajectory optimization methods fulfill these needs, but require obstacle distance information, which can be given by Euclidean Signed Distance Fields (ESDFs). We propose a method to incrementally build ESDFs from Truncated Signed Distance Fields (TSDFs), a common implicit surface representation used in computer graphics and vision. TSDFs are fast to build and smooth out sensor noise over many observations, and are designed to produce surface meshes. Meshes allow human operators to get a better assessment of the robot's environment, and set high-level mission goals. We show that we can build TSDFs faster than Octomaps, and that it is more accurate to build ESDFs out of TSDFs than occupancy maps. Our complete system, called voxblox, will be available as open source and runs in real-time on a single CPU core. We validate our approach on-board an MAV, by using our system with a trajectory optimization local planner, entirely on-board and in real-time. version:2
arxiv-1509-04627 | A tetrahedral space-filling curve for non-conforming adaptive meshes | http://arxiv.org/abs/1509.04627 | id:1509.04627 author:Carsten Burstedde, Johannes Holke category:cs.DC cs.MS  published:2015-09-15 summary:We introduce a space-filling curve for triangular and tetrahedral red-refinement that can be computed using bitwise interleaving operations similar to the well-known Z-order or Morton curve for cubical meshes. To store sufficient information for random access, we define a low-memory encoding using 10 bytes per triangle and 14 bytes per tetrahedron. We present algorithms that compute the parent, children, and face-neighbors of a mesh element in constant time, as well as the next and previous element in the space-filling curve and whether a given element is on the boundary of the root simplex or not. Our presentation concludes with a scalability demonstration that creates and adapts selected meshes on a large distributed-memory system. version:2
arxiv-1704-05579 | A Large Self-Annotated Corpus for Sarcasm | http://arxiv.org/abs/1704.05579 | id:1704.05579 author:Mikhail Khodak, Nikunj Saunshi, Kiran Vodrahalli category:cs.CL cs.AI cs.LG  published:2017-04-19 summary:We introduce the Self-Annotated Reddit Corpus (SARC), a large corpus for sarcasm research and for training and evaluating systems for sarcasm detection. The corpus has 1.3 million sarcastic statements -- 10 times more than any previous dataset -- and many times more instances of non-sarcastic statements, allowing for learning in regimes of both balanced and unbalanced labels. Each statement is furthermore self-annotated -- sarcasm is labeled by the author and not an independent annotator -- and provided with user, topic, and conversation context. We evaluate the corpus for accuracy, compare it to previous related corpora, and provide baselines for the task of sarcasm detection. version:2
arxiv-1604-00478 | State Space Model based Trust Evaluation over Wireless Sensor Networks: An Iterative Particle Filter Approach | http://arxiv.org/abs/1604.00478 | id:1604.00478 author:Bin Liu, Shi Cheng category:cs.DC cs.SY  published:2016-04-02 summary:In this paper we propose a state space modeling approach for trust evaluation in wireless sensor networks. In our state space trust model (SSTM), each sensor node is associated with a trust metric, which measures to what extent the data transmitted from this node would better be trusted by the server node. Given the SSTM, we translate the trust evaluation problem to be a nonlinear state filtering problem. To estimate the state based on the SSTM, a component-wise iterative state inference procedure is proposed to work in tandem with the particle filter, and thus the resulting algorithm is termed as iterative particle filter (IPF). The computational complexity of the IPF algorithm is theoretically linearly related with the dimension of the state. This property is desirable especially for high dimensional trust evaluation and state filtering problems. The performance of the proposed algorithm is evaluated by both simulations and real data analysis. version:2
arxiv-1704-02658 | Distributed Statistical Estimation and Rates of Convergence in Normal Approximation | http://arxiv.org/abs/1704.02658 | id:1704.02658 author:Stanislav Minsker, Nate Strawn category:math.ST cs.DC stat.ML stat.TH 68W15  62G35  published:2017-04-09 summary:This paper presents new algorithms for distributed statistical estimation that can take advantage of the divide-and-conquer approach. We show that one of the key benefits attained by an appropriate divide-and-conquer strategy is robustness, an important characteristic of large distributed systems. We introduce a class of algorithms that are based on the properties of the geometric median, establish connections between performance of these distributed algorithms and rates of convergence in normal approximation, and provide tight deviations guarantees for resulting estimators in the form of exponential concentration inequalities. Our techniques are illustrated through several examples; in particular, we obtain new results for the median-of-means estimator, as well as provide performance guarantees for robust distributed maximum likelihood estimation. version:2
arxiv-1704-06302 | Quality of Service of an Asynchronous Crash-Recovery Leader Election Algorithm | http://arxiv.org/abs/1704.06302 | id:1704.06302 author:Vinícius A. Reis, Gustavo M. D. Vieira category:cs.DC  published:2017-04-20 summary:In asynchronous distributed systems it is very hard to assess if one of the processes taking part in a computation is operating correctly or has failed. To overcome this problem, distributed algorithms are created using unreliable failure detectors that capture in an abstract way timing assumptions necessary to assess the operating status of a process. One particular type of failure detector is a leader election, that indicates a single process that has not failed. The unreliability of these failure detectors means that they can make mistakes, however if they are to be used in practice there must be limits to the eventual behavior of these detectors. These limits are defined as the quality of service (QoS) provided by the detector. Many works have tackled the problem of creating failure detectors with predictable QoS, but only for crash-stop processes and synchronous systems. This paper presents and analyzes the behavior of a new leader election algorithm named NFD-L for the asynchronous crash-recovery failure model that is efficient in terms of its use of stable memory and message exchanges. version:1
arxiv-1704-06300 | A Reinforcement Learning Approach to Weaning of Mechanical Ventilation in Intensive Care Units | http://arxiv.org/abs/1704.06300 | id:1704.06300 author:Niranjani Prasad, Li-Fang Cheng, Corey Chivers, Michael Draugelis, Barbara E Engelhardt category:cs.AI  published:2017-04-20 summary:The management of invasive mechanical ventilation, and the regulation of sedation and analgesia during ventilation, constitutes a major part of the care of patients admitted to intensive care units. Both prolonged dependence on mechanical ventilation and premature extubation are associated with increased risk of complications and higher hospital costs, but clinical opinion on the best protocol for weaning patients off of a ventilator varies. This work aims to develop a decision support tool that uses available patient information to predict time-to-extubation readiness and to recommend a personalized regime of sedation dosage and ventilator support. To this end, we use off-policy reinforcement learning algorithms to determine the best action at a given patient state from sub-optimal historical ICU data. We compare treatment policies from fitted Q-iteration with extremely randomized trees and with feedforward neural networks, and demonstrate that the policies learnt show promise in recommending weaning protocols with improved outcomes, in terms of minimizing rates of reintubation and regulating physiological stability. version:1
arxiv-1704-06297 | A Time Hierarchy Theorem for the LOCAL Model | http://arxiv.org/abs/1704.06297 | id:1704.06297 author:Yi-Jun Chang, Seth Pettie category:cs.DC cs.CC cs.DS  published:2017-04-20 summary:The celebrated Time Hierarchy Theorem for Turing machines states, informally, that more problems can be solved given more time. The extent to which a time hierarchy-type theorem holds in the distributed LOCAL model has been open for many years. It is consistent with previous results that all natural problems in the LOCAL model can be classified according to a small constant number of complexities, such as $O(1),O(\log^* n), O(\log n), 2^{O(\sqrt{\log n})}$, etc. In this paper we establish the first time hierarchy theorem for the LOCAL model and prove that several gaps exist in the LOCAL time hierarchy. 1. We define an infinite set of simple coloring problems called Hierarchical $2\frac{1}{2}$-Coloring}. A correctly colored graph can be confirmed by simply checking the neighborhood of each vertex, so this problem fits into the class of locally checkable labeling (LCL) problems. However, the complexity of the $k$-level Hierarchical $2\frac{1}{2}$-Coloring problem is $\Theta(n^{1/k})$, for $k\in\mathbb{Z}^+$. The upper and lower bounds hold for both general graphs and trees, and for both randomized and deterministic algorithms. 2. Consider any LCL problem on bounded degree trees. We prove an automatic-speedup theorem that states that any randomized $n^{o(1)}$-time algorithm solving the LCL can be transformed into a deterministic $O(\log n)$-time algorithm. Together with a previous result, this establishes that on trees, there are no natural deterministic complexities in the ranges $\omega(\log^* n)$---$o(\log n)$ or $\omega(\log n)$---$n^{o(1)}$. 3. We expose a gap in the randomized time hierarchy on general graphs. Any randomized algorithm that solves an LCL problem in sublogarithmic time can be sped up to run in $O(T_{LLL})$ time, which is the complexity of the distributed Lovasz local lemma problem, currently known to be $\Omega(\log\log n)$ and $O(\log n)$. version:1
arxiv-1704-06221 | Discrete configuration spaces of squares and hexagons | http://arxiv.org/abs/1704.06221 | id:1704.06221 author:Hannah Alpert category:math.MG cs.RO math.CO 05C85  55R80  68W10  published:2017-04-20 summary:We consider generalizations of the familiar fifteen-piece sliding puzzle on the 4 by 4 square grid. On larger grids with more pieces and more holes, asymptotically how fast can we move the puzzle into the solved state? We also give a variation with sliding hexagons. The square puzzles and the hexagon puzzles are both discrete versions of configuration spaces of disks, which are of interest in statistical mechanics and topological robotics. The combinatorial theorems and proofs in this paper suggest followup questions in both combinatorics and topology, and may turn out to be useful for proving topological statements about configuration spaces. version:1
arxiv-1704-06193 | Intrusion Prevention and Detection in Grid Computing - The ALICE Case | http://arxiv.org/abs/1704.06193 | id:1704.06193 author:Andres Gomez, Camilo Lara, Udo Kebschull category:cs.DC cs.AI cs.CR hep-ex  published:2017-04-20 summary:Grids allow users flexible on-demand usage of computing resources through remote communication networks. A remarkable example of a Grid in High Energy Physics (HEP) research is used in the ALICE experiment at European Organization for Nuclear Research CERN. Physicists can submit jobs used to process the huge amount of particle collision data produced by the Large Hadron Collider (LHC). Grids face complex security challenges. They are interesting targets for attackers seeking for huge computational resources. Since users can execute arbitrary code in the worker nodes on the Grid sites, special care should be put in this environment. Automatic tools to harden and monitor this scenario are required. Currently, there is no integrated solution for such requirement. This paper describes a new security framework to allow execution of job payloads in a sandboxed context. It also allows process behavior monitoring to detect intrusions, even when new attack methods or zero day vulnerabilities are exploited, by a Machine Learning approach. We plan to implement the proposed framework as a software prototype that will be tested as a component of the ALICE Grid middleware. version:1
arxiv-1704-06096 | The Dependent Doors Problem: An Investigation into Sequential Decisions without Feedback | http://arxiv.org/abs/1704.06096 | id:1704.06096 author:Amos Korman, Yoav Rodeh category:cs.AI  published:2017-04-20 summary:We introduce the dependent doors problem as an abstraction for situations in which one must perform a sequence of possibly dependent decisions, without receiving feedback information on the effectiveness of previously made actions. Informally, the problem considers a set of $d$ doors that are initially closed, and the aim is to open all of them as fast as possible. To open a door, the algorithm knocks on it and it might open or not according to some probability distribution. This distribution may depend on which other doors are currently open, as well as on which other doors were open during each of the previous knocks on that door. The algorithm aims to minimize the expected time until all doors open. Crucially, it must act at any time without knowing whether or which other doors have already opened. In this work, we focus on scenarios where dependencies between doors are both positively correlated and acyclic.The fundamental distribution of a door describes the probability it opens in the best of conditions (with respect to other doors being open or closed). We show that if in two configurations of $d$ doors corresponding doors share the same fundamental distribution, then these configurations have the same optimal running time up to a universal constant, no matter what are the dependencies between doors and what are the distributions. We also identify algorithms that are optimal up to a universal constant factor. For the case in which all doors share the same fundamental distribution we additionally provide a simpler algorithm, and a formula to calculate its running time. We furthermore analyse the price of lacking feedback for several configurations governed by standard fundamental distributions. In particular, we show that the price is logarithmic in $d$ for memoryless doors, but can potentially grow to be linear in $d$ for other distributions.We then turn our attention to investigate precise bounds. Even for the case of two doors, identifying the optimal sequence is an intriguing combinatorial question. Here, we study the case of two cascading memoryless doors. That is, the first door opens on each knock independently with probability $p\_1$. The second door can only open if the first door is open, in which case it will open on each knock independently with probability $p\_2$. We solve this problem almost completely by identifying algorithms that are optimal up to an additive term of 1. version:1
arxiv-1704-06092 | How Bandwidth Affects the $CONGEST$ Model | http://arxiv.org/abs/1704.06092 | id:1704.06092 author:Dennis Olivetti category:cs.DC  published:2017-04-20 summary:The $CONGEST$ model for distributed network computing is well suited for analyzing the impact of limiting the throughput of a network on its capacity to solve tasks efficiently. For many "global" problems there exists a lower bound of $\Omega(D + \sqrt{n/B})$, where $B$ is the amount of bits that can be exchanged between two nodes in one round of communication, $n$ is the number of nodes and $D$ is the diameter of the graph. Typically, upper bounds are given only for the case $B=O(\log n)$, or for the case $B = +\infty$. For $B=O(\log n)$, the Minimum Spanning Tree (MST) construction problem can be solved in $O(D + \sqrt{n}\log^* n)$ rounds, and the Single Source Shortest Path (SSSP) problem can be $(1+\epsilon)$-approximated in $\widetilde{O}(\epsilon^{-O(1)} (D+\sqrt{n}) )$ rounds. We extend these results by providing algorithms with a complexity parametric on $B$. We show that, for any $B=\Omega(\log n)$, there exists an algorithm that constructs a MST in $\widetilde{O}(D + \sqrt{n/B})$ rounds, and an algorithm that $(1+\epsilon)$-approximate the SSSP problem in $\widetilde{O}(\epsilon^{-O(1)} (D+\sqrt{n/B}) )$ rounds. We also show that there exist problems that are bandwidth insensitive. version:1
arxiv-1704-06084 | Knowledge Fusion via Embeddings from Text, Knowledge Graphs, and Images | http://arxiv.org/abs/1704.06084 | id:1704.06084 author:Steffen Thoma, Achim Rettinger, Fabian Both category:cs.AI cs.LG stat.ML I.2.6; I.2.4  published:2017-04-20 summary:We present a baseline approach for cross-modal knowledge fusion. Different basic fusion methods are evaluated on existing embedding approaches to show the potential of joining knowledge about certain concepts across modalities in a fused concept representation. version:1
arxiv-1704-06070 | Certification of Compact Low-Stretch Routing Schemes | http://arxiv.org/abs/1704.06070 | id:1704.06070 author:Alkida Balliu, Pierre Fraigniaud category:cs.DC  published:2017-04-20 summary:On the one hand, the correctness of routing protocols in networks is an issue of utmost importance for guaranteeing the delivery of messages from any source to any target. On the other hand, a large collection of routing schemes have been proposed during the last two decades, with the objective of transmitting messages along short routes, while keeping the routing tables small. Regrettably, all these schemes share the property that an adversary may modify the content of the routing tables with the objective of, e.g., blocking the delivery of messages between some pairs of nodes, without being detected by any node. In this paper, we present a simple certification mechanism which enables the nodes to locally detect any alteration of their routing tables. In particular, we show how to locally verify the stretch-3 routing scheme by Thorup and Zwick [SPAA 2001] by adding certificates of $\widetilde{O}(\sqrt{n})$ bits at each node in $n$-node networks, that is, by keeping the memory size of the same order of magnitude as the original routing tables. We also propose a new name-independent routing scheme using routing tables of size $\widetilde{O}(\sqrt{n})$ bits. This new routing scheme can be locally verified using certificates on $\widetilde{O}(\sqrt{n})$ bits. Its stretch is3 if using handshaking, and 5 otherwise. version:1
arxiv-1704-06053 | Using Inertial Sensors for Position and Orientation Estimation | http://arxiv.org/abs/1704.06053 | id:1704.06053 author:Manon Kok, Jeroen D. Hol, Thomas B. Schön category:cs.RO cs.SY  published:2017-04-20 summary:In recent years, MEMS inertial sensors (3D accelerometers and 3D gyroscopes) have become widely available due to their small size and low cost. Inertial sensor measurements are obtained at high sampling rates and can be integrated to obtain position and orientation information. These estimates are accurate on a short time scale, but suffer from integration drift over longer time scales. To overcome this issue, inertial sensors are typically combined with additional sensors and models. In this tutorial we focus on the signal processing aspects of position and orientation estimation using inertial sensors. We discuss different modeling choices and a selected number of important algorithms. The algorithms include optimization-based smoothing and filtering as well as computationally cheaper extended Kalman filter and complementary filter implementations. The quality of their estimates is illustrated using both experimental and simulated data. version:1
arxiv-1704-06033 | Predicting Cognitive Decline with Deep Learning of Brain Metabolism and Amyloid Imaging | http://arxiv.org/abs/1704.06033 | id:1704.06033 author:Hongyoon Choi, Kyong Hwan Jin category:cs.CV cs.AI stat.ML  published:2017-04-20 summary:For effective treatment of Alzheimer disease (AD), it is important to identify subjects who are most likely to exhibit rapid cognitive decline. Herein, we developed a novel framework based on a deep convolutional neural network which can predict future cognitive decline in mild cognitive impairment (MCI) patients using flurodeoxyglucose and florbetapir positron emission tomography (PET). The architecture of the network only relies on baseline PET studies of AD and normal subjects as the training dataset. Feature extraction and complicated image preprocessing including nonlinear warping are unnecessary for our approach. Accuracy of prediction (84.2%) for conversion to AD in MCI patients outperformed conventional feature-based quantification approaches. ROC analyses revealed that performance of CNN-based approach was significantly higher than that of the conventional quantification methods (p < 0.05). Output scores of the network were strongly correlated with the longitudinal change in cognitive measurements. These results show the feasibility of deep learning as a tool for predicting disease outcome using brain images. version:1
arxiv-1704-02259 | Vectorization of Hybrid Breadth First Search on the Intel Xeon Phi | http://arxiv.org/abs/1704.02259 | id:1704.02259 author:Mireya Paredes, Graham Riley, Mikel Lujan category:cs.DC  published:2017-04-07 summary:The Breadth-First Search (BFS) algorithm is an important building block for graph analysis of large datasets. The BFS parallelisation has been shown to be challenging because of its inherent characteristics, including irregular memory access patterns, data dependencies and workload imbalance, that limit its scalability. We investigate the optimisation and vectorisation of the hybrid BFS (a combination of top-down and bottom-up approaches for BFS) on the Xeon Phi, which has advanced vector processing capabilities. The results show that our new implementation improves by 33\%, for a one million vertices graph, compared to the state-of-the-art. version:2
arxiv-1704-05972 | SemEval-2017 Task 8: RumourEval: Determining rumour veracity and support for rumours | http://arxiv.org/abs/1704.05972 | id:1704.05972 author:Leon Derczynski, Kalina Bontcheva, Maria Liakata, Rob Procter, Geraldine Wong Sak Hoi, Arkaitz Zubiaga category:cs.CL cs.AI  published:2017-04-20 summary:Media is full of false claims. Even Oxford Dictionaries named "post-truth" as the word of 2016. This makes it more important than ever to build systems that can identify the veracity of a story, and the kind of discourse there is around it. RumourEval is a SemEval shared task that aims to identify and handle rumours and reactions to them, in text. We present an annotation scheme, a large dataset covering multiple topics - each having their own families of claims and replies - and use these to pose two concrete challenges as well as the results achieved by participants on these challenges. version:1
arxiv-1701-01539 | Algorithms for Optimal Replica Placement Under Correlated Failure in Hierarchical Failure Domains | http://arxiv.org/abs/1701.01539 | id:1701.01539 author:K. Alex Mills, R. Chandrasekaran, Neeraj Mittal category:cs.DS cs.DC cs.DM  published:2017-01-06 summary:In data centers, data replication is the primary method used to ensure availability of customer data. To avoid correlated failure, cloud storage infrastructure providers model hierarchical failure domains using a tree, and avoid placing a large number of data replicas within the same failure domain (i.e. on the same branch of the tree). Typical best practices ensure that replicas are distributed across failure domains, but relatively little is known concerning optimization algorithms for distributing data replicas. Using a hierarchical model, we answer how to distribute replicas across failure domains optimally. We formulate a novel optimization problem for replica placement in data centers. As part of our problem, we formalize and explain a new criterion for optimizing a replica placement. Our overall goal is to choose placements in which correlated failures disable as few replicas as possible. We provide two optimization algorithms for dependency models represented by trees. We first present an $O(n + \rho \log \rho)$ time dynamic programming algorithm for placing $\rho$ replicas of a single file on the leaves (representing servers) of a tree with $n$ vertices. We next consider the problem of placing replicas of $m$ blocks of data, where each block may have different replication factors. For this problem, we give an exact algorithm which runs in polynomial time when the skew, the difference in the number of replicas between the largest and smallest blocks of data, is constant. version:4
arxiv-1704-05963 | Monte Carlo Tree Search with Sampled Information Relaxation Dual Bounds | http://arxiv.org/abs/1704.05963 | id:1704.05963 author:Daniel R. Jiang, Lina Al-Kanj, Warren B. Powell category:math.OC cs.AI cs.LG  published:2017-04-20 summary:Monte Carlo Tree Search (MCTS), most famously used in game-play artificial intelligence (e.g., the game of Go), is a well-known strategy for constructing approximate solutions to sequential decision problems. Its primary innovation is the use of a heuristic, known as a default policy, to obtain Monte Carlo estimates of downstream values for states in a decision tree. This information is used to iteratively expand the tree towards regions of states and actions that an optimal policy might visit. However, to guarantee convergence to the optimal action, MCTS requires the entire tree to be expanded asymptotically. In this paper, we propose a new technique called Primal-Dual MCTS that utilizes sampled information relaxation upper bounds on potential actions, creating the possibility of "ignoring" parts of the tree that stem from highly suboptimal choices. This allows us to prove that despite converging to a partial decision tree in the limit, the recommended action from Primal-Dual MCTS is optimal. The new approach shows significant promise when used to optimize the behavior of a single driver navigating a graph while operating on a ride-sharing platform. Numerical experiments on a real dataset of 7,000 trips in New Jersey suggest that Primal-Dual MCTS improves upon standard MCTS by producing deeper decision trees and exhibits a reduced sensitivity to the size of the action space. version:1
arxiv-1704-05959 | SLAM with Objects using a Nonparametric Pose Graph | http://arxiv.org/abs/1704.05959 | id:1704.05959 author:Beipeng Mu, Shih-Yuan Liu, Liam Paull, John Leonard, Jonathan How category:cs.CV cs.RO  published:2017-04-19 summary:Mapping and self-localization in unknown environments are fundamental capabilities in many robotic applications. These tasks typically involve the identification of objects as unique features or landmarks, which requires the objects both to be detected and then assigned a unique identifier that can be maintained when viewed from different perspectives and in different images. The \textit{data association} and \textit{simultaneous localization and mapping} (SLAM) problems are, individually, well-studied in the literature. But these two problems are inherently tightly coupled, and that has not been well-addressed. Without accurate SLAM, possible data associations are combinatorial and become intractable easily. Without accurate data association, the error of SLAM algorithms diverge easily. This paper proposes a novel nonparametric pose graph that models data association and SLAM in a single framework. An algorithm is further introduced to alternate between inferring data association and performing SLAM. Experimental results show that our approach has the new capability of associating object detections and localizing objects at the same time, leading to significantly better performance on both the data association and SLAM problems than achieved by considering only one and ignoring imperfections in the other. version:1
arxiv-1508-03891 | A Refinement-Based Architecture for Knowledge Representation and Reasoning in Robotics | http://arxiv.org/abs/1508.03891 | id:1508.03891 author:Mohan Sridharan, Michael Gelfond, Shiqi Zhang, Jeremy Wyatt category:cs.RO cs.AI cs.LO  published:2015-08-17 summary:This paper describes an architecture that combines the complementary strengths of probabilistic graphical models and declarative programming to enable robots to represent and reason with logic-based and probabilistic descriptions of uncertainty and domain knowledge. An action language is extended to support non-boolean fluents and non-deterministic causal laws. This action language is used to describe tightly-coupled transition diagrams at two levels of granularity, refining a coarse-resolution transition diagram of the domain to obtain a fine-resolution transition diagram. The coarse-resolution system description, and a history that includes (prioritized) defaults, are translated into an Answer Set Prolog (ASP) program. For any given goal, inference in the ASP program provides a plan of abstract actions. To implement each such abstract action probabilistically, the part of the fine-resolution transition diagram relevant to this action is identified, and a probabilistic representation of the uncertainty in sensing and actuation is included and used to construct a partially observable Markov decision process (POMDP). The policy obtained by solving the POMDP is invoked repeatedly to implement the abstract action as a sequence of concrete actions, with the corresponding observations being recorded in the coarse-resolution history and used for subsequent reasoning. The architecture is evaluated in simulation and on a mobile robot moving objects in an indoor domain, to show that it supports reasoning with violation of defaults, noisy observations and unreliable actions, in complex domains. version:3
arxiv-1704-05905 | A Coalition Formation Algorithm for Multi-Robot Task Allocation in Large-Scale Natural Disasters | http://arxiv.org/abs/1704.05905 | id:1704.05905 author:Carla Mouradian, Jagruti Sahoo, Roch H. Glitho, Monique J. Morrow, Paul A. Polakos category:cs.MA cs.RO  published:2017-04-19 summary:In large-scale natural disasters, humans are likely to fail when they attempt to reach high-risk sites or act in search and rescue operations. Robots, however, outdo their counterparts in surviving the hazards and handling the search and rescue missions due to their multiple and diverse sensing and actuation capabilities. The dynamic formation of optimal coalition of these heterogeneous robots for cost efficiency is very challenging and research in the area is gaining more and more attention. In this paper, we propose a novel heuristic. Since the population of robots in large-scale disaster settings is very large, we rely on Quantum Multi-Objective Particle Swarm Optimization (QMOPSO). The problem is modeled as a multi-objective optimization problem. Simulations with different test cases and metrics, and comparison with other algorithms such as NSGA-II and SPEA-II are carried out. The experimental results show that the proposed algorithm outperforms the existing algorithms not only in terms of convergence but also in terms of diversity and processing time. version:1
arxiv-1611-02646 | On interestingness measures of formal concepts | http://arxiv.org/abs/1611.02646 | id:1611.02646 author:Sergei O. Kuznetsov, Tatiana Makhalova category:cs.AI  published:2016-11-08 summary:Formal concepts and closed itemsets proved to be of big importance for knowledge discovery, both as a tool for concise representation of association rules and a tool for clustering and constructing domain taxonomies and ontologies. Exponential explosion makes it difficult to consider the whole concept lattice arising from data, one needs to select most useful and interesting concepts. In this paper interestingness measures of concepts are considered and compared with respect to various aspects, such as efficiency of computation and applicability to noisy data and performing ranking correlation. version:2
arxiv-1704-05832 | SkiMap: An Efficient Mapping Framework for Robot Navigation | http://arxiv.org/abs/1704.05832 | id:1704.05832 author:Daniele De Gregorio, Luigi Di Stefano category:cs.CV cs.RO  published:2017-04-19 summary:We present a novel mapping framework for robot navigation which features a multi-level querying system capable to obtain rapidly representations as diverse as a 3D voxel grid, a 2.5D height map and a 2D occupancy grid. These are inherently embedded into a memory and time efficient core data structure organized as a Tree of SkipLists. Compared to the well-known Octree representation, our approach exhibits a better time efficiency, thanks to its simple and highly parallelizable computational structure, and a similar memory footprint when mapping large workspaces. Peculiarly within the realm of mapping for robot navigation, our framework supports realtime erosion and re-integration of measurements upon reception of optimized poses from the sensor tracker, so as to improve continuously the accuracy of the map. version:1
arxiv-1704-05796 | Network Dissection: Quantifying Interpretability of Deep Visual Representations | http://arxiv.org/abs/1704.05796 | id:1704.05796 author:David Bau, Bolei Zhou, Aditya Khosla, Aude Oliva, Antonio Torralba category:cs.CV cs.AI I.2.10  published:2017-04-19 summary:We propose a general framework called Network Dissection for quantifying the interpretability of latent representations of CNNs by evaluating the alignment between individual hidden units and a set of semantic concepts. Given any CNN model, the proposed method draws on a broad data set of visual concepts to score the semantics of hidden units at each intermediate convolutional layer. The units with semantics are given labels across a range of objects, parts, scenes, textures, materials, and colors. We use the proposed method to test the hypothesis that interpretability of units is equivalent to random linear combinations of units, then we apply our method to compare the latent representations of various networks when trained to solve different supervised and self-supervised training tasks. We further analyze the effect of training iterations, compare networks trained with different initializations, examine the impact of network depth and width, and measure the effect of dropout and batch normalization on the interpretability of deep visual representations. We demonstrate that the proposed method can shed light on characteristics of CNN models and training methods that go beyond measurements of their discriminative power. version:1
arxiv-1704-01631 | Multitask Learning with Low-Level Auxiliary Tasks for Encoder-Decoder Based Speech Recognition | http://arxiv.org/abs/1704.01631 | id:1704.01631 author:Shubham Toshniwal, Hao Tang, Liang Lu, Karen Livescu category:cs.CL cs.AI  published:2017-04-05 summary:End-to-end training of deep learning-based models allows for implicit learning of intermediate representations based on the final task loss. However, the end-to-end approach ignores the useful domain knowledge encoded in explicit intermediate-level supervision. We hypothesize that using intermediate representations as auxiliary supervision at lower levels of deep networks may be a good way of combining the advantages of end-to-end training and more traditional pipeline approaches. We present experiments on conversational speech recognition where we use lower-level tasks, such as phoneme recognition, in a multitask training approach with an encoder-decoder model for direct character transcription. We compare multiple types of lower-level tasks and analyze the effects of the auxiliary tasks. Our results on the Switchboard corpus show that this approach improves recognition accuracy over a standard encoder-decoder model on the Eval2000 test set. version:2
arxiv-1601-07613 | Edge coloring in unstructured CFD codes | http://arxiv.org/abs/1601.07613 | id:1601.07613 author:Andrew Giuliani, Lilia Krivodonova category:cs.DC  published:2016-01-28 summary:We propose a way of preventing race conditions in the evaluation of the surface integral contribution in discontinuous Galerkin and finite volume flow solvers by coloring the edges (or faces) of the computational mesh. In this work we use a partitioning algorithm that separates the edges of triangular elements into three groups and the faces of quadrangular and tetrahedral elements into four groups; we then extend this partitioning to adaptively refined, nonconforming meshes. We use the ascribed coloring to reduce code memory requirements and optimize accessing the elemental data in memory. This process reduces memory access latencies and speeds up computations on graphics processing units. version:2
arxiv-1704-02254 | Recurrent Environment Simulators | http://arxiv.org/abs/1704.02254 | id:1704.02254 author:Silvia Chiappa, Sébastien Racaniere, Daan Wierstra, Shakir Mohamed category:cs.AI cs.LG stat.ML  published:2017-04-07 summary:Models that can simulate how environments change in response to actions can be used by agents to plan and act efficiently. We improve on previous environment simulators from high-dimensional pixel observations by introducing recurrent neural networks that are able to make temporally and spatially coherent predictions for hundreds of time-steps into the future. We present an in-depth analysis of the factors affecting performance, providing the most extensive attempt to advance the understanding of the properties of these models. We address the issue of computationally inefficiency with a model that does not need to generate a high-dimensional image at each time-step. We show that our approach can be used to improve exploration and is adaptable to many diverse environments, namely 10 Atari games, a 3D car racing environment, and complex 3D mazes. version:2
arxiv-1704-05739 | How Long It Takes for an Ordinary Node with an Ordinary ID to Output? | http://arxiv.org/abs/1704.05739 | id:1704.05739 author:Laurent Feuilloley category:cs.DC  published:2017-04-19 summary:In the context of distributed synchronous computing, processors perform in rounds, and the time-complexity of a distributed algorithm is classically defined as the number of rounds before all computing nodes have output. Hence, this complexity measure captures the running time of the slowest node(s). In this paper, we are interested in the running time of the ordinary nodes, to be compared with the running time of the slowest nodes. The node-averaged time-complexity of a distributed algorithm on a given instance is defined as the average, taken over every node of the instance, of the number of rounds before that node output. We compare the node-averaged time-complexity with the classical one in the standard LOCAL model for distributed network computing. We show that there can be an exponential gap between the node-averaged time-complexity and the classical time-complexity, as witnessed by, e.g., leader election. Our first main result is a positive one, stating that, in fact, the two time-complexities behave the same for a large class of problems on very sparse graphs. In particular, we show that, for LCL problems on cycles, the node-averaged time complexity is of the same order of magnitude as the slowest node time-complexity. In addition, in the LOCAL model, the time-complexity is computed as a worst case over all possible identity assignments to the nodes of the network. In this paper, we also investigate the ID-averaged time-complexity, when the number of rounds is averaged over all possible identity assignments. Our second main result is that the ID-averaged time-complexity is essentially the same as the expected time-complexity of randomized algorithms (where the expectation is taken over all possible random bits used by the nodes, and the number of rounds is measured for the worst-case identity assignment). Finally, we study the node-averaged ID-averaged time-complexity. version:1
arxiv-1704-02603 | Estimating Tactile Data for Adaptive Grasping of Novel Objects | http://arxiv.org/abs/1704.02603 | id:1704.02603 author:Emil Hyttinen, Danica Kragic, Renaud Detry category:cs.RO  published:2017-04-09 summary:We present an adaptive grasping method that finds stable grasps on novel objects. The main contributions of this paper is in the computation of the probability of success of grasps in the vicinity of an already applied grasp. Our method performs grasp adaptions by simulating tactile data for grasps in the vicinity of the current grasp. The simulated data is used to evaluate hypothetical grasps and thereby guide us toward better grasps. We demonstrate the applicability of our method by constructing a system that can plan, apply and adapt grasps on novel objects. Experiments are conducted on objects from the YCB object set and the success rate of our method is 88%. Our experiments show that the application of our grasp adaption method improves grasp stability significantly. version:2
arxiv-1704-06140 | Hazard Analysis and Risk Assessment for an Automated Unmanned Protective Vehicle | http://arxiv.org/abs/1704.06140 | id:1704.06140 author:Torben Stolte, Gerrit Bagschik, Andreas Reschka, and Markus Maurer category:cs.RO  published:2017-04-19 summary:For future application of automated vehicles in public traffic, ensuring functional safety is essential. In this context, a hazard analysis and risk assessment is an important input for designing functionally vehicle automation systems. In this contribution, we present a detailed hazard analysis and risk assessment (HARA) according to the ISO 26262 standard for a specific Level 4 application, namely an unmanned protective vehicle operated without human supervision for motorway hard shoulder roadworks. version:1
arxiv-1704-05692 | A multi-method simulation of a high-frequency bus line using AnyLogic | http://arxiv.org/abs/1704.05692 | id:1704.05692 author:Thierry van der Spek category:cs.AI cs.MA  published:2017-04-19 summary:In this work a mixed agent-based and discrete event simulation model is developed for a high frequency bus route in the Netherlands. With this model, different passenger growth scenarios can be easily evaluated. This simulation model helps policy makers to predict changes that have to be made to bus routes and planned travel times before problems occur. The model is validated using several performance indicators, showing that under some model assumptions, it can realistically simulate real-life situations. The simulation's workings are illustrated by two use cases. version:1
arxiv-1702-07543 | Embedding Knowledge Graphs Based on Transitivity and Antisymmetry of Rules | http://arxiv.org/abs/1702.07543 | id:1702.07543 author:Mengya Wang, Hankui Zhuo, Huiling Zhu category:cs.AI  published:2017-02-24 summary:Representation learning of knowledge graphs encodes entities and relation types into a continuous low-dimensional vector space, learns embeddings of entities and relation types. Most existing methods only concentrate on knowledge triples, ignoring logic rules which contain rich background knowledge. Although there has been some work aiming at leveraging both knowledge triples and logic rules, they ignore the transitivity and antisymmetry of logic rules. In this paper, we propose a novel approach to learn knowledge representations with entities and ordered relations in knowledges and logic rules. The key idea is to integrate knowledge triples and logic rules, and approximately order the relation types in logic rules to utilize the transitivity and antisymmetry of logic rules. All entries of the embeddings of relation types are constrained to be non-negative. We translate the general constrained optimization problem into an unconstrained optimization problem to solve the non-negative matrix factorization. Experimental results show that our model significantly outperforms other baselines on knowledge graph completion task. It indicates that our model is capable of capturing the transitivity and antisymmetry information, which is significant when learning embeddings of knowledge graphs. version:2
arxiv-1704-05592 | Testing Docker Performance for HPC Applications | http://arxiv.org/abs/1704.05592 | id:1704.05592 author:Alexey Ermakov, Alexey Vasyukov category:cs.PF cs.DC  published:2017-04-19 summary:The main goal for this article is to compare performance penalties when using KVM virtualization and Docker containers for creating isolated environments for HPC applications. The article provides both data obtained using commonly accepted synthetic tests (High Performance Linpack) and real life applications (OpenFOAM). The article highlights the influence on resulting application performance of major infrastructure configuration options: CPU type presented to VM, networking connection type used. version:1
arxiv-1704-05591 | OCRAPOSE II: An OCR-based indoor positioning system using mobile phone images | http://arxiv.org/abs/1704.05591 | id:1704.05591 author:Hamed Sadeghi, Shahrokh Valaee, Shahram Shirani category:cs.CV cs.AI  published:2017-04-19 summary:In this paper, we propose an OCR (optical character recognition)-based localization system called OCRAPOSE II, which is applicable in a number of indoor scenarios including office buildings, parkings, airports, grocery stores, etc. In these scenarios, characters (i.e. texts or numbers) can be used as suitable distinctive landmarks for localization. The proposed system takes advantage of OCR to read these characters in the query still images and provides a rough location estimate using a floor plan. Then, it finds depth and angle-of-view of the query using the information provided by the OCR engine in order to refine the location estimate. We derive novel formulas for the query angle-of-view and depth estimation using image line segments and the OCR box information. We demonstrate the applicability and effectiveness of the proposed system through experiments in indoor scenarios. It is shown that our system demonstrates better performance compared to the state-of-the-art benchmarks in terms of location recognition rate and average localization error specially under sparse database condition. version:1
arxiv-1704-05573 | Proposal of Vital Data Analysis Platform using Wearable Sensor | http://arxiv.org/abs/1704.05573 | id:1704.05573 author:Yoji Yamato category:cs.DC cs.CY  published:2017-04-19 summary:In this paper, we propose a vital data analysis platform which resolves existing problems to utilize vital data for real-time actions. Recently, IoT technologies have been progressed but in the healthcare area, real-time actions based on analyzed vital data are not considered sufficiently yet. The causes are proper use of analyzing methods of stream / micro batch processing and network cost. To resolve existing problems, we propose our vital data analysis platform. Our platform collects vital data of Electrocardiograph and acceleration using an example of wearable vital sensor and analyzes them to extract posture, fatigue and relaxation in smart phones or cloud. Our platform can show analyzed dangerous posture or fatigue level change. We implemented the platform. And we are now preparing a field test. version:1
arxiv-1704-05572 | Answering Complex Questions Using Open Information Extraction | http://arxiv.org/abs/1704.05572 | id:1704.05572 author:Tushar Khot, Ashish Sabharwal, Peter Clark category:cs.AI cs.CL  published:2017-04-19 summary:While there has been substantial progress in factoid question-answering (QA), answering complex questions remains challenging, typically requiring both a large body of knowledge and inference techniques. Open Information Extraction (Open IE) provides a way to generate semi-structured knowledge for QA, but to date such knowledge has only been used to answer simple questions with retrieval-based methods. We overcome this limitation by presenting a method for reasoning with Open IE knowledge, allowing more complex questions to be handled. Using a recently proposed support graph optimization framework for QA, we develop a new inference model for Open IE, in particular one that can work effectively with multiple short facts, noise, and the relational structure of tuples. Our model significantly outperforms a state-of-the-art structured solver on complex questions of varying difficulty, while also removing the reliance on manually curated knowledge. version:1
arxiv-1704-05569 | Using Contexts and Constraints for Improved Geotagging of Human Trafficking Webpages | http://arxiv.org/abs/1704.05569 | id:1704.05569 author:Rahul Kapoor, Mayank Kejriwal, Pedro Szekely category:cs.AI  published:2017-04-19 summary:Extracting geographical tags from webpages is a well-motivated application in many domains. In illicit domains with unusual language models, like human trafficking, extracting geotags with both high precision and recall is a challenging problem. In this paper, we describe a geotag extraction framework in which context, constraints and the openly available Geonames knowledge base work in tandem in an Integer Linear Programming (ILP) model to achieve good performance. In preliminary empirical investigations, the framework improves precision by 28.57% and F-measure by 36.9% on a difficult human trafficking geotagging task compared to a machine learning-based baseline. The method is already being integrated into an existing knowledge base construction system widely used by US law enforcement agencies to combat human trafficking. version:1
arxiv-1703-07994 | Containment for Rule-Based Ontology-Mediated Queries | http://arxiv.org/abs/1703.07994 | id:1703.07994 author:Pablo Barcelo, Gerald Berger, Andreas Pieris category:cs.DB cs.AI cs.LO  published:2017-03-23 summary:Many efforts have been dedicated to identifying restrictions on ontologies expressed as tuple-generating dependencies (tgds), a.k.a. existential rules, that lead to the decidability for the problem of answering ontology-mediated queries (OMQs). This has given rise to three families of formalisms: guarded, non-recursive, and sticky sets of tgds. In this work, we study the containment problem for OMQs expressed in such formalisms, which is a key ingredient for solving static analysis tasks associated with them. Our main contribution is the development of specially tailored techniques for OMQ containment under the classes of tgds stated above. This enables us to obtain sharp complexity bounds for the problems at hand, which in turn allow us to delimitate its practical applicability. We also apply our techniques to pinpoint the complexity of problems associated with two emerging applications of OMQ containment: distribution over components and UCQ rewritability of OMQs. version:3
arxiv-1704-05566 | Simultaneous Policy Learning and Latent State Inference for Imitating Driver Behavior | http://arxiv.org/abs/1704.05566 | id:1704.05566 author:Jeremy Morton, Mykel J. Kochenderfer category:cs.LG cs.AI stat.ML  published:2017-04-19 summary:In this work, we propose a method for learning driver models that account for variables that cannot be observed directly. When trained on a synthetic dataset, our models are able to learn encodings for vehicle trajectories that distinguish between four distinct classes of driver behavior. Such encodings are learned without any knowledge of the number of driver classes or any objective that directly requires the models to learn encodings for each class. We show that driving policies trained with knowledge of latent variables are more effective than baseline methods at imitating the driver behavior that they are trained to replicate. Furthermore, we demonstrate that the actions chosen by our policy are heavily influenced by the latent variable settings that are provided to them. version:1
