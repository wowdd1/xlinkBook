arxiv-1606-05340 | Exponential expressivity in deep neural networks through transient chaos | http://arxiv.org/abs/1606.05340 | id:1606.05340 author:Ben Poole, Subhaneil Lahiri, Maithra Raghu, Jascha Sohl-Dickstein, Surya Ganguli category:stat.ML cs.LG  published:2016-06-16 summary:We combine Riemannian geometry with the mean field theory of high dimensional chaos to study the nature of signal propagation in generic, deep neural networks with random weights. Our results reveal an order-to-chaos expressivity phase transition, with networks in the chaotic phase computing nonlinear functions whose global curvature grows exponentially with depth but not width. We prove this generic class of deep random functions cannot be efficiently computed by any shallow network, going beyond prior work restricted to the analysis of single functions. Moreover, we formalize and quantitatively demonstrate the long conjectured idea that deep networks can disentangle highly curved manifolds in input space into flat manifolds in hidden space. Our theoretical analysis of the expressive power of deep networks broadly applies to arbitrary nonlinearities, and provides a quantitative underpinning for previously abstract notions about the geometry of deep functions. version:1
arxiv-1606-05336 | On the expressive power of deep neural networks | http://arxiv.org/abs/1606.05336 | id:1606.05336 author:Maithra Raghu, Ben Poole, Jon Kleinberg, Surya Ganguli, Jascha Sohl-Dickstein category:stat.ML cs.AI cs.LG  published:2016-06-16 summary:We study the expressivity of deep neural networks with random weights. We provide several results, both theoretical and experimental, precisely characterizing their functional properties in terms of the depth and width of the network. In doing so, we illustrate inherent connections between the length of a latent trajectory, local neuron transitions, and network activation patterns. The latter, a notion defined in this paper, is further studied using properties of hyperplane arrangements, which also help precisely characterize the effect of the neural network on the input space. We further show dualities between changes to the latent state and changes to the network weights, and between the number of achievable activation patterns and the number of achievable labellings over input data. We see that the depth of the network affects all of these quantities exponentially, while the width appears at most as a base. These results also suggest that the remaining depth of a neural network is an important determinant of expressivity, supported by experiments on MNIST and CIFAR-10. version:1
arxiv-1606-05328 | Conditional Image Generation with PixelCNN Decoders | http://arxiv.org/abs/1606.05328 | id:1606.05328 author:Aaron van den Oord, Nal Kalchbrenner, Oriol Vinyals, Lasse Espeholt, Alex Graves, Koray Kavukcuoglu category:cs.CV cs.LG  published:2016-06-16 summary:This work explores conditional image generation with a new image density model based on the PixelCNN architecture. The model can be conditioned on any vector, including descriptive labels or tags, or latent embeddings created by other networks. When conditioned on class labels from the ImageNet database, the model is able to generate diverse, realistic scenes representing distinct animals, objects, landscapes and structures. When conditioned on an embedding produced by a convolutional network given a single image of an unseen face, it generates a variety of new portraits of the same person with different facial expressions, poses and lighting conditions. We also show that conditional PixelCNN can serve as a powerful decoder in an image autoencoder, creating. Additionally, the gated convolutional layers in the proposed model improve the log-likelihood of PixelCNN to match the state-of-the-art performance of PixelRNN on ImageNet, with greatly reduced computational cost. version:1
arxiv-1606-05325 | ACDC: $α$-Carving Decision Chain for Risk Stratification | http://arxiv.org/abs/1606.05325 | id:1606.05325 author:Yubin Park, Joyce Ho, Joydeep Ghosh category:stat.ML cs.LG  published:2016-06-16 summary:In many healthcare settings, intuitive decision rules for risk stratification can help effective hospital resource allocation. This paper introduces a novel variant of decision tree algorithms that produces a chain of decisions, not a general tree. Our algorithm, $\alpha$-Carving Decision Chain (ACDC), sequentially carves out "pure" subsets of the majority class examples. The resulting chain of decision rules yields a pure subset of the minority class examples. Our approach is particularly effective in exploring large and class-imbalanced health datasets. Moreover, ACDC provides an interactive interpretation in conjunction with visual performance metrics such as Receiver Operating Characteristics curve and Lift chart. version:1
arxiv-1606-05320 | Increasing the Interpretability of Recurrent Neural Networks Using Hidden Markov Models | http://arxiv.org/abs/1606.05320 | id:1606.05320 author:Viktoriya Krakovna, Finale Doshi-Velez category:stat.ML cs.CL cs.LG  published:2016-06-16 summary:As deep neural networks continue to revolutionize various application domains, there is increasing interest in making these powerful models more understandable and interpretable, and narrowing down the causes of good and bad predictions. We focus on recurrent neural networks (RNNs), state of the art models in speech recognition and translation. Our approach to increasing interpretability is by combining an RNN with a hidden Markov model (HMM), a simpler and more transparent model. We explore various combinations of RNNs and HMMs: an HMM trained on LSTM states; a hybrid model where an HMM is trained first, then a small LSTM is given HMM state distributions and trained to fill in gaps in the HMM's performance; and a jointly trained hybrid model. We find that the LSTM and HMM learn complementary information about the features in the text. version:1
arxiv-1606-05316 | Learning Infinite-Layer Networks: Beyond the Kernel Trick | http://arxiv.org/abs/1606.05316 | id:1606.05316 author:Amir Globerson, Roi Livni category:cs.LG  published:2016-06-16 summary:Infinite--Layer Networks (ILN) have recently been proposed as an architecture that mimics neural networks while enjoying some of the advantages of kernel methods. ILN are networks that integrate over infinitely many nodes within a single hidden layer. It has been demonstrated by several authors that the problem of learning ILN can be reduced to the kernel trick, implying that whenever a certain integral can be computed analytically they are efficiently learnable. In this work we give an online algorithm for ILN, which avoids the kernel trick assumption. More generally and of independent interest, we show that kernel methods in general can be exploited even when the kernel cannot be efficiently computed but can only be estimated via sampling. We provide a regret analysis for our algorithm, showing that it matches the sample complexity of methods which have access to kernel values. Thus, our method is the first to demonstrate that the kernel trick is not necessary as such, and random features suffice to obtain comparable performance. version:1
arxiv-1606-05313 | Unsupervised Risk Estimation Using Only Conditional Independence Structure | http://arxiv.org/abs/1606.05313 | id:1606.05313 author:Jacob Steinhardt, Percy Liang category:cs.LG cs.AI stat.ML  published:2016-06-16 summary:We show how to estimate a model's test error from unlabeled data, on distributions very different from the training distribution, while assuming only that certain conditional independencies are preserved between train and test. We do not need to assume that the optimal predictor is the same between train and test, or that the true distribution lies in any parametric family. We can also efficiently differentiate the error estimate to perform unsupervised discriminative learning. Our technical tool is the method of moments, which allows us to exploit conditional independencies in the absence of a fully-specified model. Our framework encompasses a large family of losses including the log and exponential loss, and extends to structured output settings such as hidden Markov models. version:1
arxiv-1606-05310 | Holistic Features For Real-Time Crowd Behaviour Anomaly Detection | http://arxiv.org/abs/1606.05310 | id:1606.05310 author:M. Marsden, K. McGuinness, S. Little, N. E. O'Connor category:cs.CV  published:2016-06-16 summary:This paper presents a new approach to crowd behaviour anomaly detection that uses a set of efficiently computed, easily interpretable, scene-level holistic features. This low-dimensional descriptor combines two features from the literature: crowd collectiveness [1] and crowd conflict [2], with two newly developed crowd features: mean motion speed and a new formulation of crowd density. Two different anomaly detection approaches are investigated using these features. When only normal training data is available we use a Gaussian Mixture Model (GMM) for outlier detection. When both normal and abnormal training data is available we use a Support Vector Machine (SVM) for binary classification. We evaluate on two crowd behaviour anomaly detection datasets, achieving both state-of-the-art classification performance on the violent-flows dataset [3] as well as better than real-time processing performance (40 frames per second). version:1
arxiv-1606-05302 | Generalized Direct Change Estimation in Ising Model Structure | http://arxiv.org/abs/1606.05302 | id:1606.05302 author:Farideh Fazayeli, Arindam Banerjee category:math.ST cs.LG stat.TH  published:2016-06-16 summary:We consider the problem of estimating change in the dependency structure between two $p$-dimensional Ising models, based on respectively $n_1$ and $n_2$ samples drawn from the models. The change is assumed to be structured, e.g., sparse, block sparse, node-perturbed sparse, etc., such that it can be characterized by a suitable (atomic) norm. We present and analyze a norm-regularized estimator for directly estimating the change in structure, without having to estimate the structures of the individual Ising models. The estimator can work with any norm, and can be generalized to other graphical models under mild assumptions. We show that only one set of samples, say $n_2$, needs to satisfy the sample complexity requirement for the estimator to work, and the estimation error decreases as $\frac{c}{\sqrt{\min(n_1,n_2)}}$, where $c$ depends on the Gaussian width of the unit norm ball. For example, for $\ell_1$ norm applied to $s$-sparse change, the change can be accurately estimated with $\min(n_1,n_2)=O(s \log p)$ which is sharper than an existing result $n_1= O(s^2 \log p)$ and $n_2 = O(n_1^2)$. Experimental results illustrating the effectiveness of the proposed estimator are presented. version:1
arxiv-1602-06294 | Stacking for machine learning redshifts applied to SDSS galaxies | http://arxiv.org/abs/1602.06294 | id:1602.06294 author:Roman Zitlau, Ben Hoyle, Kerstin Paech, Jochen Weller, Markus Michael Rau, Stella Seitz category:astro-ph.IM astro-ph.CO cs.LG  published:2016-02-19 summary:We present an analysis of a general machine learning technique called 'stacking' for the estimation of photometric redshifts. Stacking techniques can feed the photometric redshift estimate, as output by a base algorithm, back into the same algorithm as an additional input feature in a subsequent learning round. We shown how all tested base algorithms benefit from at least one additional stacking round (or layer). To demonstrate the benefit of stacking, we apply the method to both unsupervised machine learning techniques based on self-organising maps (SOMs), and supervised machine learning methods based on decision trees. We explore a range of stacking architectures, such as the number of layers and the number of base learners per layer. Finally we explore the effectiveness of stacking even when using a successful algorithm such as AdaBoost. We observe a significant improvement of between 1.9% and 21% on all computed metrics when stacking is applied to weak learners (such as SOMs and decision trees). When applied to strong learning algorithms (such as AdaBoost) the ratio of improvement shrinks, but still remains positive and is between 0.4% and 2.5% for the explored metrics and comes at almost no additional computational cost. version:2
arxiv-1606-05286 | Spectral decomposition method of dialog state tracking via collective matrix factorization | http://arxiv.org/abs/1606.05286 | id:1606.05286 author:Julien Perez category:cs.CL stat.ML  published:2016-06-16 summary:The task of dialog management is commonly decomposed into two sequential subtasks: dialog state tracking and dialog policy learning. In an end-to-end dialog system, the aim of dialog state tracking is to accurately estimate the true dialog state from noisy observations produced by the speech recognition and the natural language understanding modules. The state tracking task is primarily meant to support a dialog policy. From a probabilistic perspective, this is achieved by maintaining a posterior distribution over hidden dialog states composed of a set of context dependent variables. Once a dialog policy is learned, it strives to select an optimal dialog act given the estimated dialog state and a defined reward function. This paper introduces a novel method of dialog state tracking based on a bilinear algebric decomposition model that provides an efficient inference schema through collective matrix factorization. We evaluate the proposed approach on the second Dialog State Tracking Challenge (DSTC-2) dataset and we show that the proposed tracker gives encouraging results compared to the state-of-the-art trackers that participated in this standard benchmark. Finally, we show that the prediction schema is computationally efficient in comparison to the previous approaches. version:1
arxiv-1606-05275 | Designing Intelligent Automation based Solutions for Complex Social Problems | http://arxiv.org/abs/1606.05275 | id:1606.05275 author:Sanjay Podder, Janardan Misra, Senthil Kumaresan, Neville Dubash, Indrani Bhattacharya category:stat.ML cs.CY  published:2016-06-16 summary:Deciding effective and timely preventive measures against complex social problems affecting relatively low income geographies is a difficult challenge. There is a strong need to adopt intelligent automation based solutions with low cost imprints to tackle these problems at larger scales. Starting with the hypothesis that analytical modelling and analysis of social phenomena with high accuracy is in general inherently hard, in this paper we propose design framework to enable data-driven machine learning based adaptive solution approach towards enabling more effective preventive measures. We use survey data collected from a socio-economically backward region of India about adolescent girls to illustrate the design approach. version:1
arxiv-1606-05273 | The Effect of Heteroscedasticity on Regression Trees | http://arxiv.org/abs/1606.05273 | id:1606.05273 author:Will Ruth, Thomas Loughin category:stat.ML  published:2016-06-16 summary:Regression trees are becoming increasingly popular as omnibus predicting tools and as the basis of numerous modern statistical learning ensembles. Part of their popularity is their ability to create a regression prediction without ever specifying a structure for the mean model. However, the method implicitly assumes homogeneous variance across the entire explanatory-variable space. It is unknown how the algorithm behaves when faced with heteroscedastic data. In this study, we assess the performance of the most popular regression-tree algorithm in a single-variable setting under a very simple step-function model for heteroscedasticity. We use simulation to show that the locations of splits, and hence the ability to accurately predict means, are both adversely influenced by the change in variance. We identify the pruning algorithm as the main concern, although the effects on the splitting algorithm may be meaningful in some applications. version:1
arxiv-1409-8230 | RENOIR - A Dataset for Real Low-Light Noise Image Reduction | http://arxiv.org/abs/1409.8230 | id:1409.8230 author:Josue Anaya, Adrian Barbu category:cs.CV  published:2014-09-29 summary:The application of noise reduction or image denoising is a very important topic in the field of computer vision and image processing. Many modern and popular state of the art image denoising algorithms are trained and evaluated using images with added artificial noise. These trained algorithms and their evaluations on synthetic data may lead to incorrect conclusions about their performances on real noise. In this paper we introduce a benchmark dataset of uncompressed color images corrupted by natural noise due to low-light conditions, together with spatially and intensity-aligned low noise images of the same scenes. The dataset contains over 100 scenes and more than 400 images, including both 16-bit RAW formatted images and 8-bit BMP pixel and intensity-aligned images from 2 digital cameras (Canon S90 and Canon T3i) and a mobile phone (Xiaomi Mi3). We also introduce a method for estimating the true noise level in each of our images, since even the low noise images contain a small amount of noise. Finally, we exemplify the use of our dataset by evaluating four denoising algorithms: Active Random Field, BM3D, Bilevel MRF optimization, and Multi-Layer Perceptron. We show that while the Multi-Layer Perceptron algorithm works as well as or even better than BM3D on synthetic noise, it does not do the same on our dataset. version:3
arxiv-1606-05262 | Convolutional Residual Memory Networks | http://arxiv.org/abs/1606.05262 | id:1606.05262 author:Joel Moniz, Christopher Pal category:cs.CV  published:2016-06-16 summary:Very deep convolutional neural networks (CNNs) yield state of the art results on a wide variety of visual recognition problems. A number of state of the the art methods for image recognition are based on networks with well over 100 layers and the performance vs. depth trend is moving towards networks in excess of 1000 layers. In such extremely deep architectures the vanishing or exploding gradient problem becomes a key issue. Recent evidence also indicates that convolutional networks could benefit from an interface to explicitly constructed memory mechanisms interacting with a CNN feature processing hierarchy. Correspondingly, we propose and evaluate a memory mechanism enhanced convolutional neural network architecture based on augmenting convolutional residual networks with a long short term memory mechanism. We refer to this as a convolutional residual memory network and we find that this approach can yield state of the art performance on the CIFAR-100 and SVHN benchmarks. This is achieved using a network with more breadth, much less depth and much less overall computation relative to comparable models without the memory mechanism. Our experiments and analysis explore the importance of the memory mechanism, network depth, breadth, and predictive performance. version:1
arxiv-1410-7876 | Collaborative Multi-sensor Classification via Sparsity-based Representation | http://arxiv.org/abs/1410.7876 | id:1410.7876 author:Minh Dao, Nam H. Nguyen, Nasser M. Nasrabadi, Trac D. Tran category:cs.CV cs.LG stat.ML  published:2014-10-29 summary:In this paper, we propose a general collaborative sparse representation framework for multi-sensor classification, which takes into account the correlations as well as complementary information between heterogeneous sensors simultaneously while considering joint sparsity within each sensor's observations. We also robustify our models to deal with the presence of sparse noise and low-rank interference signals. Specifically, we demonstrate that incorporating the noise or interference signal as a low-rank component in our models is essential in a multi-sensor classification problem when multiple co-located sources/sensors simultaneously record the same physical event. We further extend our frameworks to kernelized models which rely on sparsely representing a test sample in terms of all the training samples in a feature space induced by a kernel function. A fast and efficient algorithm based on alternative direction method is proposed where its convergence to an optimal solution is guaranteed. Extensive experiments are conducted on several real multi-sensor data sets and results are compared with the conventional classifiers to verify the effectiveness of the proposed methods. version:2
arxiv-1606-05255 | 3D zigzag for multislicing, multiband and video processing | http://arxiv.org/abs/1606.05255 | id:1606.05255 author:Mario Mastriani category:cs.CV  published:2016-06-16 summary:We present a 3D zigzag rafter (first in literature) which allows us to obtain the exact sequence of spectral components after application of Discrete Cosine Transform 3D (DCT-2D) over a cube. Such cube represents part of a video or eventually a group of images such as multislicing (e.g., Magnetic Resonance or Computed Tomography imaging) and multi or hyperspectral imagery (optical satellites). Besides, we present a new version of the traditional 2D zigzag, including the case of rectangular blocks. Finally, all the attached code is done in MATLAB, and that code serves both blocks of pixels or blocks of blocks. version:1
arxiv-1602-01783 | Asynchronous Methods for Deep Reinforcement Learning | http://arxiv.org/abs/1602.01783 | id:1602.01783 author:Volodymyr Mnih, Adrià Puigdomènech Badia, Mehdi Mirza, Alex Graves, Timothy P. Lillicrap, Tim Harley, David Silver, Koray Kavukcuoglu category:cs.LG  published:2016-02-04 summary:We propose a conceptually simple and lightweight framework for deep reinforcement learning that uses asynchronous gradient descent for optimization of deep neural network controllers. We present asynchronous variants of four standard reinforcement learning algorithms and show that parallel actor-learners have a stabilizing effect on training allowing all four methods to successfully train neural network controllers. The best performing method, an asynchronous variant of actor-critic, surpasses the current state-of-the-art on the Atari domain while training for half the time on a single multi-core CPU instead of a GPU. Furthermore, we show that asynchronous actor-critic succeeds on a wide variety of continuous motor control problems as well as on a new task of navigating random 3D mazes using a visual input. version:2
arxiv-1606-05250 | SQuAD: 100,000+ Questions for Machine Comprehension of Text | http://arxiv.org/abs/1606.05250 | id:1606.05250 author:Pranav Rajpurkar, Jian Zhang, Konstantin Lopyrev, Percy Liang category:cs.CL  published:2016-06-16 summary:We present a new reading comprehension dataset, SQuAD, consisting of 100,000+ questions posed by crowdworkers on a set of Wikipedia articles, where the answer to each question is a segment of text from the corresponding reading passage. We analyze the dataset in both manual and automatic ways to understand the types of reasoning required to answer the questions, leaning heavily on dependency and constituency trees. We built a strong logistic regression model, which achieves an F1 score of 51.0%, a significant improvement over a simple baseline (20%). However, human performance (86.8%) is much higher, indicating that the dataset presents a good challenge problem for future research. version:1
arxiv-1606-04289 | Automatic Text Scoring Using Neural Networks | http://arxiv.org/abs/1606.04289 | id:1606.04289 author:Dimitrios Alikaniotis, Helen Yannakoudakis, Marek Rei category:cs.CL cs.LG cs.NE I.5.1; I.2.6; I.2.7  published:2016-06-14 summary:Automated Text Scoring (ATS) provides a cost-effective and consistent alternative to human marking. However, in order to achieve good performance, the predictive features of the system need to be manually engineered by human experts. We introduce a model that forms word representations by learning the extent to which specific words contribute to the text's score. Using Long-Short Term Memory networks to represent the meaning of texts, we demonstrate that a fully automated framework is able to achieve excellent results over similar approaches. In an attempt to make our results more interpretable, and inspired by recent advances in visualizing neural networks, we introduce a novel method for identifying the regions of the text that the model has found more discriminative. version:2
arxiv-1606-05241 | The Mondrian Kernel | http://arxiv.org/abs/1606.05241 | id:1606.05241 author:Matej Balog, Balaji Lakshminarayanan, Zoubin Ghahramani, Daniel M. Roy, Yee Whye Teh category:stat.ML  published:2016-06-16 summary:We introduce the Mondrian kernel, a fast random feature approximation to the Laplace kernel. It is suitable for both batch and online learning, and admits a fast kernel-width-selection procedure as the random features can be re-used efficiently for all kernel widths. The features are constructed by sampling trees via a Mondrian process [Roy and Teh, 2009], and we highlight the connection to Mondrian forests [Lakshminarayanan et al., 2014], where trees are also sampled via a Mondrian process, but fit independently. This link provides a new insight into the relationship between kernel methods and random forests. version:1
arxiv-1606-05233 | Learning feed-forward one-shot learners | http://arxiv.org/abs/1606.05233 | id:1606.05233 author:Luca Bertinetto, João F. Henriques, Jack Valmadre, Philip H. S. Torr, Andrea Vedaldi category:cs.CV cs.LG  published:2016-06-16 summary:One-shot learning is usually tackled by using generative models or discriminative embeddings. Discriminative methods based on deep learning, which are very effective in other learning scenarios, are ill-suited for one-shot learning as they need large amounts of training data. In this paper, we propose a method to learn the parameters of a deep model in one shot. We construct the learner as a second deep network, called a learnet, which predicts the parameters of a pupil network from a single exemplar. In this manner we obtain an efficient feed-forward one-shot learner, trained end-to-end by minimizing a one-shot classification objective in a learning to learn formulation. In order to make the construction feasible, we propose a number of factorizations of the parameters of the pupil network. We demonstrate encouraging results by learning characters from single exemplars in Omniglot, and by tracking visual objects from a single initial exemplar in the Visual Object Tracking benchmark. version:1
arxiv-1606-05229 | Estimating mutual information in high dimensions via classification error | http://arxiv.org/abs/1606.05229 | id:1606.05229 author:Charles Y. Zheng, Yuval Benjamini category:stat.ML cs.IT math.IT  published:2016-06-16 summary:Estimating the mutual information $I(X; Y)$ based on observations becomes statistically infeasible in high dimensions without some kind of assumption or prior. One approach is to assume a parametric joint distribution on $(X, Y)$, but in many applications, such a strong modeling assumption cannot be justified. Alternatively, one can estimate the mutual information based the performance of a classifier trained on the data. In this paper, we construct a novel classification-based estimator of mutual information based on high-dimensional asymptotics. We show that in a particular limiting regime, the mutual information is an invertible function of the expected $k$-class Bayes error. While the theory is based on a large-sample, high-dimensional limit, we demonstrate through simulations that our proposed estimator has superior performance to the alternatives in problems of moderate dimensionality. version:1
arxiv-1606-05228 | How many faces can be recognized? Performance extrapolation for multi-class classification | http://arxiv.org/abs/1606.05228 | id:1606.05228 author:Charles Y. Zheng, Rakesh Achanta, Yuval Benjamini category:stat.ML cs.CV cs.IT cs.LG math.IT  published:2016-06-16 summary:The difficulty of multi-class classification generally increases with the number of classes. Using data from a subset of the classes, can we predict how well a classifier will scale with an increased number of classes? Under the assumption that the classes are sampled exchangeably, and under the assumption that the classifier is generative (e.g. QDA or Naive Bayes), we show that the expected accuracy when the classifier is trained on $k$ classes is the $k-1$st moment of a \emph{conditional accuracy distribution}, which can be estimated from data. This provides the theoretical foundation for performance extrapolation based on pseudolikelihood, unbiased estimation, and high-dimensional asymptotics. We investigate the robustness of our methods to non-generative classifiers in simulations and one optical character recognition example. version:1
arxiv-1605-05860 | False Discovery Rate Control and Statistical Quality Assessment of Annotators in Crowdsourced Ranking | http://arxiv.org/abs/1605.05860 | id:1605.05860 author:Qianqian Xu, Jiechao Xiong, Xiaochun Cao, Yuan Yao category:stat.ML  published:2016-05-19 summary:With the rapid growth of crowdsourcing platforms it has become easy and relatively inexpensive to collect a dataset labeled by multiple annotators in a short time. However due to the lack of control over the quality of the annotators, some abnormal annotators may be affected by position bias which can potentially degrade the quality of the final consensus labels. In this paper we introduce a statistical framework to model and detect annotator's position bias in order to control the false discovery rate (FDR) without a prior knowledge on the amount of biased annotators - the expected fraction of false discoveries among all discoveries being not too high, in order to assure that most of the discoveries are indeed true and replicable. The key technical development relies on some new knockoff filters adapted to our problem and new algorithms based on the Inverse Scale Space dynamics whose discretization is potentially suitable for large scale crowdsourcing data analysis. Our studies are supported by experiments with both simulated examples and real-world data. The proposed framework provides us a useful tool for quantitatively studying annotator's abnormal behavior in crowdsourcing data arising from machine learning, sociology, computer vision, multimedia, etc. version:3
arxiv-1606-05201 | Assessing and tuning brain decoders: cross-validation, caveats, and guidelines | http://arxiv.org/abs/1606.05201 | id:1606.05201 author:Gaël Varoquaux, Pradeep Raamana, Denis Engemann, Andrés Hoyos-Idrobo, Yannick Schwartz, Bertrand Thirion category:stat.ML  published:2016-06-16 summary:Decoding, ie prediction from brain images or signals, calls for empirical evaluation of its predictive power. Such evaluation is achieved via cross-validation, a method also used to tune decoders' hyper-parameters. This paper is a review on cross-validation procedures for decoding in neuroimaging. It includes a didactic overview of the relevant theoretical considerations. Practical aspects are highlighted with an extensive empirical study of the common decoders in within-and across-subject predictions, on multiple datasets --anatomical and functional MRI and MEG-- and simulations. Theory and experiments outline that the popular "leave-one-out" strategy leads to unstable and biased estimates, and a repeated random splits method should be preferred. Experiments outline the large error bars of cross-validation in neuroimaging settings: typical confidence intervals of 10%. Nested cross-validation can tune decoders' parameters while avoiding circularity bias. However we find that it can be more favorable to use sane defaults, in particular for non-sparse decoders. version:1
arxiv-1601-02403 | Argumentation Mining in User-Generated Web Discourse | http://arxiv.org/abs/1601.02403 | id:1601.02403 author:Ivan Habernal, Iryna Gurevych category:cs.CL  published:2016-01-11 summary:The goal of argumentation mining, an evolving research field in computational linguistics, is to design methods capable of analyzing people's argumentation. In this article, we go beyond the state of the art in several ways. (i) We deal with actual Web data and take up the challenges given by the variety of registers, multiple domains, and unrestricted noisy user-generated Web discourse. (ii) We bridge the gap between normative argumentation theories and argumentation phenomena encountered in actual data by adapting an argumentation model tested in an extensive annotation study. (iii) We create a new gold standard corpus (90k tokens in 340 documents) and experiment with several machine learning methods to identify argument components. We offer the data, source codes, and annotation guidelines to the community under free licenses. Our findings show that argumentation mining in user-generated Web discourse is a feasible but challenging task. version:4
arxiv-1602-01132 | Interactive algorithms: from pool to stream | http://arxiv.org/abs/1602.01132 | id:1602.01132 author:Sivan Sabato, Tom Hess category:stat.ML cs.LG math.ST stat.TH  published:2016-02-02 summary:We consider interactive algorithms in the pool-based setting, and in the stream-based setting. Interactive algorithms observe suggested elements (representing actions or queries), and interactively select some of them and receive responses. Pool-based algorithms can select elements at any order, while stream-based algorithms observe elements in sequence, and can only select elements immediately after observing them. We assume that the suggested elements are generated independently from some source distribution, and ask what is the stream size required for emulating a pool algorithm with a given pool size. We provide algorithms and matching lower bounds for general pool algorithms, and for utility-based pool algorithms. We further show that a maximal gap between the two settings exists also in the special case of active learning for binary classification. version:3
arxiv-1606-05169 | Learning from Non-Stationary Stream Data in Multiobjective Evolutionary Algorithm | http://arxiv.org/abs/1606.05169 | id:1606.05169 author:Jianyong Sun, Hu Zhang, Aimin Zhou, Qingfu Zhang category:cs.NE  published:2016-06-16 summary:Evolutionary algorithms (EAs) have been well acknowledged as a promising paradigm for solving optimisation problems with multiple conflicting objectives in the sense that they are able to locate a set of diverse approximations of Pareto optimal solutions in a single run. EAs drive the search for approximated solutions through maintaining a diverse population of solutions and by recombining promising solutions selected from the population. Combining machine learning techniques has shown great potentials since the intrinsic structure of the Pareto optimal solutions of an multiobjective optimisation problem can be learned and used to guide for effective recombination. However, existing multiobjective EAs (MOEAs) based on structure learning spend too much computational resources on learning. To address this problem, we propose to use an online learning scheme. Based on the fact that offsprings along evolution are streamy, dependent and non-stationary (which implies that the intrinsic structure, if any, is temporal and scale-variant), an online agglomerative clustering algorithm is applied to adaptively discover the intrinsic structure of the Pareto optimal solution set; and to guide effective offspring recombination. Experimental results have shown significant improvement over five state-of-the-art MOEAs on a set of well-known benchmark problems with complicated Pareto sets and complex Pareto fronts. version:1
arxiv-1603-02238 | On higher order computations and synaptic meta-plasticity in the human brain: IT point of view (June, 2016) | http://arxiv.org/abs/1603.02238 | id:1603.02238 author:Stanislaw Ambroszkiewicz category:cs.NE q-bio.NC 92B20 F.1.1  published:2016-03-07 summary:Glia modify neuronal connectivity by creating structural changes in the neuronal connectome. Glia also influence the functional connectome by modifying the flow of information through neural networks (Fields et al. 2015). There are strong experimental evidences that glia are responsible for synaptic meta-plasticity. Synaptic plasticity is the modification of the strength of connections between neurons. Meta-plasticity, i.e. plasticity of synaptic plasticity, may be viewed as mechanisms for dynamic reconfiguration of neuron circuits. First order computations in the brain are done by static neuron circuits, whereas higher order computations are done by dynamic reconfigurations of the links (synapses) between the neuron circuits. Static neuron circuits correspond to first order computable functions. Synapse creation correspond to the mathematical notion of function composition. Functionals are higher order functions that take functions as their arguments. The construction of functionals is based on dynamic reconfigurations of the function composition. Perhaps the functionals correspond to the meta-plasticity in the human brain. version:3
arxiv-1606-05158 | CLEAR: Covariant LEAst-square Re-fitting with applications to image restoration | http://arxiv.org/abs/1606.05158 | id:1606.05158 author:C-A. Deledalle, N. Papadakis, J. Salmon, S. Vaiter category:math.ST cs.CV stat.ML stat.TH  published:2016-06-16 summary:In this paper, we propose a new framework to remove parts of the systematic errors affecting popular restoration algorithms, with a special focus for image processing tasks. Extending ideas that emerged for $\ell_1$ regularization, we develop an approach that can help re-fitting the results of standard methods towards the input data. Total variation regularizations and non-local means are special cases of interest. We identify important covariant information that should be preserved by the re-fitting method, and emphasize the importance of preserving the Jacobian (w.r.t to the observed signal) of the original estimator. Then, we provide an approach that has a "twicing" flavor and allows re-fitting the restored signal by adding back a local affine transformation of the residual term. We illustrate the benefits of our method on numerical simulations for image restoration tasks. version:1
arxiv-1605-05157 | Monocular Urban Localization using Street View | http://arxiv.org/abs/1605.05157 | id:1605.05157 author:Li Yu, Cyril Joly, Guillaume Bresson, Fabien Moutarde category:cs.RO cs.CV  published:2016-05-17 summary:This paper presents a metric global localization in the urban environment only with a monocular camera and the Google Street View database. We fully leverage the abundant sources from the Street View and benefits from its topo-metric structure to build a coarse-to-fine positioning, namely a topological place recognition process and then a metric pose estimation by local bundle adjustment. Our method is tested on a 3 km urban environment and demonstrates both sub-meter accuracy and robustness to viewpoint changes, illumination and occlusion. To our knowledge, this is the first work that studies the global urban localization simply with a single camera and Street View. version:2
arxiv-1512-00177 | LSTM Neural Reordering Feature for Statistical Machine Translation | http://arxiv.org/abs/1512.00177 | id:1512.00177 author:Yiming Cui, Shijin Wang, Jianfeng Li category:cs.CL cs.AI cs.NE  published:2015-12-01 summary:Artificial neural networks are powerful models, which have been widely applied into many aspects of machine translation, such as language modeling and translation modeling. Though notable improvements have been made in these areas, the reordering problem still remains a challenge in statistical machine translations. In this paper, we present a novel neural reordering model that directly models word pairs and alignment. By utilizing LSTM recurrent neural networks, much longer context could be learned for reordering prediction. Experimental results on NIST OpenMT12 Arabic-English and Chinese-English 1000-best rescoring task show that our LSTM neural reordering feature is robust and achieves significant improvements over various baseline systems. version:3
arxiv-1512-01655 | Approximated and User Steerable tSNE for Progressive Visual Analytics | http://arxiv.org/abs/1512.01655 | id:1512.01655 author:Nicola Pezzotti, Boudewijn P. F. Lelieveldt, Laurens van der Maaten, Thomas Höllt, Elmar Eisemann, Anna Vilanova category:cs.CV cs.LG  published:2015-12-05 summary:Progressive Visual Analytics aims at improving the interactivity in existing analytics techniques by means of visualization as well as interaction with intermediate results. One key method for data analysis is dimensionality reduction, for example, to produce 2D embeddings that can be visualized and analyzed efficiently. t-Distributed Stochastic Neighbor Embedding (tSNE) is a well-suited technique for the visualization of several high-dimensional data. tSNE can create meaningful intermediate results but suffers from a slow initialization that constrains its application in Progressive Visual Analytics. We introduce a controllable tSNE approximation (A-tSNE), which trades off speed and accuracy, to enable interactive data exploration. We offer real-time visualization techniques, including a density-based solution and a Magic Lens to inspect the degree of approximation. With this feedback, the user can decide on local refinements and steer the approximation level during the analysis. We demonstrate our technique with several datasets, in a real-world research scenario and for the real-time analysis of high-dimensional streams to illustrate its effectiveness for interactive data analysis. version:3
arxiv-1606-05110 | Machine Learning meets Data-Driven Journalism: Boosting International Understanding and Transparency in News Coverage | http://arxiv.org/abs/1606.05110 | id:1606.05110 author:Elena Erdmann, Karin Boczek, Lars Koppers, Gerret von Nordheim, Christian Pölitz, Alejandro Molina, Katharina Morik, Henrik Müller, Jörg Rahnenführer, Kristian Kersting category:stat.ML cs.CY  published:2016-06-16 summary:Migration crisis, climate change or tax havens: Global challenges need global solutions. But agreeing on a joint approach is difficult without a common ground for discussion. Public spheres are highly segmented because news are mainly produced and received on a national level. Gain- ing a global view on international debates about important issues is hindered by the enormous quantity of news and by language barriers. Media analysis usually focuses only on qualitative re- search. In this position statement, we argue that it is imperative to pool methods from machine learning, journalism studies and statistics to help bridging the segmented data of the international public sphere, using the Transatlantic Trade and Investment Partnership (TTIP) as a case study. version:1
arxiv-1606-05105 | Machine Learning Across Cultures: Modeling the Adoption of Financial Services for the Poor | http://arxiv.org/abs/1606.05105 | id:1606.05105 author:Muhammad Raza Khan, Joshua E. Blumenstock category:stat.ML cs.CY  published:2016-06-16 summary:Recently, mobile operators in many developing economies have launched "Mobile Money" platforms that deliver basic financial services over the mobile phone network. While many believe that these services can improve the lives of the poor, a consistent difficulty has been identifying individuals most likely to benefit from access to the new technology. Here, we combine terabyte-scale data from three different mobile phone operators from Ghana, Pakistan, and Zambia, to better understand the behavioral determinants of mobile money adoption. Our supervised learning models provide insight into the best predictors of adoption in three very distinct cultures. We find that models fit on one population fail to generalize to another, and in general are highly context-dependent. These findings highlight the need for a nuanced approach to understanding the role and potential of financial services for the poor. version:1
arxiv-1604-08098 | Local Uncertainty Sampling for Large-Scale Multi-Class Logistic Regression | http://arxiv.org/abs/1604.08098 | id:1604.08098 author:Lei Han, Ting Yang, Tong Zhang category:stat.CO cs.LG stat.ML  published:2016-04-27 summary:A major challenge for building statistical models in the big data era is that the available data volume may exceed the computational capability. A common approach to solve this problem is to employ a subsampled dataset that can be handled by the available computational resources. In this paper, we propose a general subsampling scheme for large-scale multi-class logistic regression, and examine the variance of the resulting estimator. We show that asymptotically, the proposed method always achieves a smaller variance than that of the uniform random sampling. Moreover, when the classes are conditional imbalanced, significant improvement over uniform sampling can be achieved. Empirical performance of the proposed method is compared to other methods on both simulated and real-world datasets, and these results match and confirm our theoretical analysis. version:2
arxiv-1606-04435 | Adversarial Perturbations Against Deep Neural Networks for Malware Classification | http://arxiv.org/abs/1606.04435 | id:1606.04435 author:Kathrin Grosse, Nicolas Papernot, Praveen Manoharan, Michael Backes, Patrick McDaniel category:cs.CR cs.LG cs.NE  published:2016-06-14 summary:Deep neural networks, like many other machine learning models, have recently been shown to lack robustness against adversarially crafted inputs. These inputs are derived from regular inputs by minor yet carefully selected perturbations that deceive machine learning models into desired misclassifications. Existing work in this emerging field was largely specific to the domain of image classification, since the high-entropy of images can be conveniently manipulated without changing the images' overall visual appearance. Yet, it remains unclear how such attacks translate to more security-sensitive applications such as malware detection - which may pose significant challenges in sample generation and arguably grave consequences for failure. In this paper, we show how to construct highly-effective adversarial sample crafting attacks for neural networks used as malware classifiers. The application domain of malware classification introduces additional constraints in the adversarial sample crafting problem when compared to the computer vision domain: (i) continuous, differentiable input domains are replaced by discrete, often binary inputs; and (ii) the loose condition of leaving visual appearance unchanged is replaced by requiring equivalent functional behavior. We demonstrate the feasibility of these attacks on many different instances of malware classifiers that we trained using the DREBIN Android malware data set. We furthermore evaluate to which extent potential defensive mechanisms against adversarial crafting can be leveraged to the setting of malware classification. While feature reduction did not prove to have a positive impact, distillation and re-training on adversarially crafted samples show promising results. version:2
arxiv-1606-02556 | DISCO Nets: DISsimilarity COefficient Networks | http://arxiv.org/abs/1606.02556 | id:1606.02556 author:Diane Bouchacourt, M. Pawan Kumar, Sebastian Nowozin category:cs.CV cs.AI  published:2016-06-08 summary:We present a new type of probabilistic model which we call DISsimilarity COefficient Networks (DISCO Nets). DISCO Nets allow us to efficiently sample from a posterior distribution parametrised by a neural network. During training, DISCO Nets are learned by minimising the dissimilarity coefficient between the true distribution and the estimated distribution. This allows us to tailor the training to the loss related to the task at hand. We empirically show that (i) by modeling uncertainty on the output value, DISCO Nets outperform equivalent non-probabilistic predictive networks and (ii) DISCO Nets accurately model the uncertainty of the output, outperforming existing probabilistic models based on deep neural networks. version:3
arxiv-1506-02222 | No penalty no tears: Least squares in high-dimensional linear models | http://arxiv.org/abs/1506.02222 | id:1506.02222 author:Xiangyu Wang, David Dunson, Chenlei Leng category:stat.ME cs.LG math.ST stat.ML stat.TH  published:2015-06-07 summary:Ordinary least squares (OLS) is the default method for fitting linear models, but is not applicable for problems with dimensionality larger than the sample size. For these problems, we advocate the use of a generalized version of OLS motivated by ridge regression, and propose two novel three-step algorithms involving least squares fitting and hard thresholding. The algorithms are methodologically simple to understand intuitively, computationally easy to implement efficiently, and theoretically appealing for choosing models consistently. Numerical exercises comparing our methods with penalization-based approaches in simulations and data analyses illustrate the great potential of the proposed algorithms. version:5
arxiv-1606-04801 | A Powerful Generative Model Using Random Weights for the Deep Image Representation | http://arxiv.org/abs/1606.04801 | id:1606.04801 author:Kun He, Yan Wang, John Hopcroft category:cs.CV cs.LG cs.NE  published:2016-06-15 summary:To what extent is the success of deep visualization due to the training? Could we do deep visualization using untrained, random weight networks? To address this issue, we explore new and powerful generative models for three popular deep visualization tasks using untrained, random weight convolutional neural networks. First we invert representations in feature spaces and reconstruct images from white noise inputs. The reconstruction quality is statistically higher than that of the same method applied on well trained networks with the same architecture. Next we synthesize textures using scaled correlations of representations in multiple layers and our results are almost indistinguishable with the original natural texture and the synthesized textures based on the trained network. Third, by recasting the content of an image in the style of various artworks, we create artistic images with high perceptual quality, highly competitive to the prior work of Gatys et al. on pretrained networks. To our knowledge this is the first demonstration of image representations using untrained deep neural networks. Our work provides a new and fascinating tool to study the representation of deep network architecture and sheds light on new understandings on deep visualization. version:2
arxiv-1602-05473 | Auxiliary Deep Generative Models | http://arxiv.org/abs/1602.05473 | id:1602.05473 author:Lars Maaløe, Casper Kaae Sønderby, Søren Kaae Sønderby, Ole Winther category:stat.ML cs.AI cs.LG  published:2016-02-17 summary:Deep generative models parameterized by neural networks have recently achieved state-of-the-art performance in unsupervised and semi-supervised learning. We extend deep generative models with auxiliary variables which improves the variational approximation. The auxiliary variables leave the generative model unchanged but make the variational distribution more expressive. Inspired by the structure of the auxiliary variable we also propose a model with two stochastic layers and skip connections. Our findings suggest that more expressive and properly specified deep generative models converge faster with better results. We show state-of-the-art performance within semi-supervised learning on MNIST, SVHN and NORB datasets. version:4
arxiv-1511-08308 | Named Entity Recognition with Bidirectional LSTM-CNNs | http://arxiv.org/abs/1511.08308 | id:1511.08308 author:Jason P. C. Chiu, Eric Nichols category:cs.CL cs.LG cs.NE 68T50 I.2.7  published:2015-11-26 summary:Named entity recognition is a challenging task that has traditionally required large amounts of knowledge in the form of feature engineering and lexicons to achieve high performance. In this paper, we present a novel neural network architecture that automatically detects word- and character-level features using a hybrid bidirectional LSTM and CNN architecture, eliminating the need for most feature engineering. We also propose a novel method of encoding partial lexicon matches in neural networks and compare it to existing approaches. Extensive evaluation shows that, given only tokenized text and publicly available word embeddings, our system is competitive on the CoNLL-2003 dataset and surpasses the previously reported state of the art on the OntoNotes 5.0 dataset by 2.13 F1 points. By using two lexicons from public sources, we establish new states of the art with an F1 score of 91.62 on CoNLL-2003 and 86.28 on OntoNotes, surpassing systems that employ heavy feature engineering, proprietary lexicons, and rich entity linking information. version:4
arxiv-1606-05060 | Pruning Random Forests for Prediction on a Budget | http://arxiv.org/abs/1606.05060 | id:1606.05060 author:Feng Nan, Joseph Wang, Venkatesh Saligrama category:stat.ML cs.LG  published:2016-06-16 summary:We propose to prune a random forest (RF) for resource-constrained prediction. We first construct a RF and then prune it to optimize expected feature cost & accuracy. We pose pruning RFs as a novel 0-1 integer program with linear constraints that encourages feature re-use. We establish total unimodularity of the constraint set to prove that the corresponding LP relaxation solves the original integer program. We then exploit connections to combinatorial optimization and develop an efficient primal-dual algorithm, scalable to large datasets. In contrast to our bottom-up approach, which benefits from good RF initialization, conventional methods are top-down acquiring features based on their utility value and is generally intractable, requiring heuristics. Empirically, our pruning algorithm outperforms existing state-of-the-art resource-constrained algorithms. version:1
arxiv-1511-03641 | A Size-Free CLT for Poisson Multinomials and its Applications | http://arxiv.org/abs/1511.03641 | id:1511.03641 author:Constantinos Daskalakis, Anindya De, Gautam Kamath, Christos Tzamos category:cs.DS cs.GT cs.LG math.PR math.ST stat.TH  published:2015-11-11 summary:An $(n,k)$-Poisson Multinomial Distribution (PMD) is the distribution of the sum of $n$ independent random vectors supported on the set ${\cal B}_k=\{e_1,\ldots,e_k\}$ of standard basis vectors in $\mathbb{R}^k$. We show that any $(n,k)$-PMD is ${\rm poly}\left({k\over \sigma}\right)$-close in total variation distance to the (appropriately discretized) multi-dimensional Gaussian with the same first two moments, removing the dependence on $n$ from the Central Limit Theorem of Valiant and Valiant. Interestingly, our CLT is obtained by bootstrapping the Valiant-Valiant CLT itself through the structural characterization of PMDs shown in recent work by Daskalakis, Kamath, and Tzamos. In turn, our stronger CLT can be leveraged to obtain an efficient PTAS for approximate Nash equilibria in anonymous games, significantly improving the state of the art, and matching qualitatively the running time dependence on $n$ and $1/\varepsilon$ of the best known algorithm for two-strategy anonymous games. Our new CLT also enables the construction of covers for the set of $(n,k)$-PMDs, which are proper and whose size is shown to be essentially optimal. Our cover construction combines our CLT with the Shapley-Folkman theorem and recent sparsification results for Laplacian matrices by Batson, Spielman, and Srivastava. Our cover size lower bound is based on an algebraic geometric construction. Finally, leveraging the structural properties of the Fourier spectrum of PMDs we show that these distributions can be learned from $O_k(1/\varepsilon^2)$ samples in ${\rm poly}_k(1/\varepsilon)$-time, removing the quasi-polynomial dependence of the running time on $1/\varepsilon$ from the algorithm of Daskalakis, Kamath, and Tzamos. version:2
arxiv-1603-06147 | A Character-Level Decoder without Explicit Segmentation for Neural Machine Translation | http://arxiv.org/abs/1603.06147 | id:1603.06147 author:Junyoung Chung, Kyunghyun Cho, Yoshua Bengio category:cs.CL cs.LG  published:2016-03-19 summary:The existing machine translation systems, whether phrase-based or neural, have relied almost exclusively on word-level modelling with explicit segmentation. In this paper, we ask a fundamental question: can neural machine translation generate a character sequence without any explicit segmentation? To answer this question, we evaluate an attention-based encoder-decoder with a subword-level encoder and a character-level decoder on four language pairs--En-Cs, En-De, En-Ru and En-Fi-- using the parallel corpora from WMT'15. Our experiments show that the models with a character-level decoder outperform the ones with a subword-level decoder on all of the four language pairs. Furthermore, the ensembles of neural models with a character-level decoder outperform the state-of-the-art non-neural machine translation systems on En-Cs, En-De and En-Fi and perform comparably on En-Ru. version:3
arxiv-1605-01115 | MARLow: A Joint Multiplanar Autoregressive and Low-Rank Approach for Image Completion | http://arxiv.org/abs/1605.01115 | id:1605.01115 author:Mading Li, Jiaying Liu, Zhiwei Xiong, Xiaoyan Sun, Zongming Guo category:cs.CV cs.MM  published:2016-05-03 summary:In this paper, we propose a novel multiplanar autoregressive (AR) model to exploit the correlation in cross-dimensional planes of a similar patch group collected in an image, which has long been neglected by previous AR models. On that basis, we then present a joint multiplanar AR and low-rank based approach (MARLow) for image completion from random sampling, which exploits the nonlocal self-similarity within natural images more effectively. Specifically, the multiplanar AR model constraints the local stationarity in different cross-sections of the patch group, while the low-rank minimization captures the intrinsic coherence of nonlocal patches. The proposed approach can be readily extended to multichannel images (e.g. color images), by simultaneously considering the correlation in different channels. Experimental results demonstrate that the proposed approach significantly outperforms state-of-the-art methods, even if the pixel missing rate is as high as 90%. version:2
arxiv-1606-05032 | Zero-Shot Hashing via Transferring Supervised Knowledge | http://arxiv.org/abs/1606.05032 | id:1606.05032 author:Yang Yang, Weilun Chen, Yadan Luo, Fumin Shen, Jie Shao, Heng Tao Shen category:cs.CV  published:2016-06-16 summary:Hashing has shown its efficiency and effectiveness in facilitating large-scale multimedia applications. Supervised knowledge e.g. semantic labels or pair-wise relationship) associated to data is capable of significantly improving the quality of hash codes and hash functions. However, confronted with the rapid growth of newly-emerging concepts and multimedia data on the Web, existing supervised hashing approaches may easily suffer from the scarcity and validity of supervised information due to the expensive cost of manual labelling. In this paper, we propose a novel hashing scheme, termed \emph{zero-shot hashing} (ZSH), which compresses images of "unseen" categories to binary codes with hash functions learned from limited training data of "seen" categories. Specifically, we project independent data labels i.e. 0/1-form label vectors) into semantic embedding space, where semantic relationships among all the labels can be precisely characterized and thus seen supervised knowledge can be transferred to unseen classes. Moreover, in order to cope with the semantic shift problem, we rotate the embedded space to more suitably align the embedded semantics with the low-level visual feature space, thereby alleviating the influence of semantic gap. In the meantime, to exert positive effects on learning high-quality hash functions, we further propose to preserve local structural property and discrete nature in binary codes. Besides, we develop an efficient alternating algorithm to solve the ZSH model. Extensive experiments conducted on various real-life datasets show the superior zero-shot image retrieval performance of ZSH as compared to several state-of-the-art hashing methods. version:1
arxiv-1605-07717 | Deep Structured Energy Based Models for Anomaly Detection | http://arxiv.org/abs/1605.07717 | id:1605.07717 author:Shuangfei Zhai, Yu Cheng, Weining Lu, Zhongfei Zhang category:cs.LG stat.ML  published:2016-05-25 summary:In this paper, we attack the anomaly detection problem by directly modeling the data distribution with deep architectures. We propose deep structured energy based models (DSEBMs), where the energy function is the output of a deterministic deep neural network with structure. We develop novel model architectures to integrate EBMs with different types of data such as static data, sequential data, and spatial data, and apply appropriate model architectures to adapt to the data structure. Our training algorithm is built upon the recent development of score matching \cite{sm}, which connects an EBM with a regularized autoencoder, eliminating the need for complicated sampling method. Statistically sound decision criterion can be derived for anomaly detection purpose from the perspective of the energy landscape of the data distribution. We investigate two decision criteria for performing anomaly detection: the energy score and the reconstruction error. Extensive empirical studies on benchmark tasks demonstrate that our proposed model consistently matches or outperforms all the competing methods. version:2
arxiv-1606-05029 | Simple and Effective Question Answering with Recurrent Neural Networks | http://arxiv.org/abs/1606.05029 | id:1606.05029 author:Ferhan Ture, Oliver Jojic category:cs.CL  published:2016-06-16 summary:First-order factoid question answering assumes that the question can be answered by a single fact in a knowledge base (KB). While this does not seem like a challenging task, many recent attempts that apply either complex linguistic reasoning or deep neural networks achieve 35%-65% on benchmark sets. Our approach formulates the task as two machine learning problems: detecting the entities in the question, and classifying the question as one of the relation types in the KB. Based on this assumption of the structure, our simple yet effective approach trains two recurrent neural networks to outperform state of the art by significant margins --- relative improvement reaches 16% for WebQuestions, and surpasses 38% for SimpleQuestions. version:1
arxiv-1512-00932 | The Indian Spontaneous Expression Database for Emotion Recognition | http://arxiv.org/abs/1512.00932 | id:1512.00932 author:S L Happy, Priyadarshi Patnaik, Aurobinda Routray, Rajlakshmi Guha category:cs.CV  published:2015-12-03 summary:Automatic recognition of spontaneous facial expressions is a major challenge in the field of affective computing. Head rotation, face pose, illumination variation, occlusion etc. are the attributes that increase the complexity of recognition of spontaneous expressions in practical applications. Effective recognition of expressions depends significantly on the quality of the database used. Most well-known facial expression databases consist of posed expressions. However, currently there is a huge demand for spontaneous expression databases for the pragmatic implementation of the facial expression recognition algorithms. In this paper, we propose and establish a new facial expression database containing spontaneous expressions of both male and female participants of Indian origin. The database consists of 428 segmented video clips of the spontaneous facial expressions of 50 participants. In our experiment, emotions were induced among the participants by using emotional videos and simultaneously their self-ratings were collected for each experienced emotion. Facial expression clips were annotated carefully by four trained decoders, which were further validated by the nature of stimuli used and self-report of emotions. An extensive analysis was carried out on the database using several machine learning algorithms and the results are provided for future reference. Such a spontaneous database will help in the development and validation of algorithms for recognition of spontaneous expressions. version:2
arxiv-1606-05027 | Learning Optimal Interventions | http://arxiv.org/abs/1606.05027 | id:1606.05027 author:Jonas Mueller, David Reshef, George Du, Tommi Jaakkola category:stat.ML cs.LG  published:2016-06-16 summary:Our goal is to identify beneficial interventions from observational data. We consider interventions that are narrowly focused (impacting few features) and may be tailored to each individual or globally enacted over a population. If the underlying relationship obeys an invariance condition, our approach can identify beneficial interventions directly from observational data, side-stepping causal inference. We provide theoretical guarantees for predicted gains when the relationship is governed by a Gaussian Process, even in settings involving unintentional downstream effects. Empirically, our approach outperforms causal inference techniques (even when our model is misspecified) and is able to discover good interventions in two practical applications: gene perturbation and writing improvement. version:1
arxiv-1606-05018 | Improving Power Generation Efficiency using Deep Neural Networks | http://arxiv.org/abs/1606.05018 | id:1606.05018 author:Stefan Hosein, Patrick Hosein category:stat.ML cs.LG cs.NE  published:2016-06-16 summary:Recently there has been significant research on power generation, distribution and transmission efficiency especially in the case of renewable resources. The main objective is reduction of energy losses and this requires improvements on data acquisition and analysis. In this paper we address these concerns by using consumers' electrical smart meter readings to estimate network loading and this information can then be used for better capacity planning. We compare Deep Neural Network (DNN) methods with traditional methods for load forecasting. Our results indicate that DNN methods outperform most traditional methods. This comes at the cost of additional computational complexity but this can be addressed with the use of cloud resources. We also illustrate how these results can be used to better support dynamic pricing. version:1
arxiv-1508-01922 | The Discrete Dantzig Selector: Estimating Sparse Linear Models via Mixed Integer Linear Optimization | http://arxiv.org/abs/1508.01922 | id:1508.01922 author:Rahul Mazumder, Peter Radchenko category:stat.ME math.OC math.ST stat.CO stat.ML stat.TH  published:2015-08-08 summary:We propose a novel high-dimensional linear regression estimator: the Discrete Dantzig Selector, which minimizes the number of nonzero regression coefficients, subject to a budget on the maximal absolute correlation between the features and residuals. We show that the estimator can be expressed as a solution to a Mixed Integer Linear Optimization (MILO) problem, a computationally tractable framework that delivers provably optimal global solutions. The current state of algorithmics in integer optimization makes our proposal substantially more scalable than the least squares subset selection framework based on integer quadratic optimization, recently proposed in [7] and the continuous nonconvex quadratic optimization framework of [33]. We propose new discrete first-order methods, which, when paired with state-of-the-art MILO solvers, lead to superior upper bounds for the Discrete Dantzig Selector problem for a given computational budget. We demonstrate that the integrated approach, proposed herein, also provides globally optimal solutions in significantly shorter computation times, when compared to off-the-shelf MILO solvers. We demonstrate, both theoretically and empirically, that, in a wide range of regimes, the statistical properties of the Discrete Dantzig Selector are superior to those of popular $\ell_{1}$-based approaches. Our approach gracefully scales to problem instances up to p = 10,000 features with provable optimality, making it, to the best of our knowledge, one of the most scalable exact variable selection approaches in sparse linear modeling at the moment. version:2
arxiv-1606-05007 | Automatic Pronunciation Generation by Utilizing a Semi-supervised Deep Neural Networks | http://arxiv.org/abs/1606.05007 | id:1606.05007 author:Naoya Takahashi, Tofigh Naghibi, Beat Pfister category:cs.CL cs.LG cs.SD  published:2016-06-15 summary:Phonemic or phonetic sub-word units are the most commonly used atomic elements to represent speech signals in modern ASRs. However they are not the optimal choice due to several reasons such as: large amount of effort required to handcraft a pronunciation dictionary, pronunciation variations, human mistakes and under-resourced dialects and languages. Here, we propose a data-driven pronunciation estimation and acoustic modeling method which only takes the orthographic transcription to jointly estimate a set of sub-word units and a reliable dictionary. Experimental results show that the proposed method which is based on semi-supervised training of a deep neural network largely outperforms phoneme based continuous speech recognition on the TIMIT dataset. version:1
arxiv-1606-05002 | 3DFS: Deformable Dense Depth Fusion and Segmentation for Object Reconstruction from a Handheld Camera | http://arxiv.org/abs/1606.05002 | id:1606.05002 author:Tanmay Gupta, Daeyun Shin, Naren Sivagnanadasan, Derek Hoiem category:cs.CV  published:2016-06-15 summary:We propose an approach for 3D reconstruction and segmentation of a single object placed on a flat surface from an input video. Our approach is to perform dense depth map estimation for multiple views using a proposed objective function that preserves detail. The resulting depth maps are then fused using a proposed implicit surface function that is robust to estimation error, producing a smooth surface reconstruction of the entire scene. Finally, the object is segmented from the remaining scene using a proposed 2D-3D segmentation that incorporates image and depth cues with priors and regularization over the 3D volume and 2D segmentations. We evaluate 3D reconstructions qualitatively on our Object-Videos dataset, comparing to fusion, multiview stereo, and segmentation baselines. We also quantitatively evaluate the dense depth estimation using the RGBD Scenes V2 dataset [Henry et al. 2013] and the segmentation using keyframe annotations of the Object-Videos dataset. version:1
arxiv-1606-04995 | Joint Data Compression and MAC Protocol Design for Smartgrids with Renewable Energy | http://arxiv.org/abs/1606.04995 | id:1606.04995 author:Le Thanh Tan, Long Bao Le category:cs.NI cs.IT math.IT math.OC math.ST stat.ML stat.TH  published:2016-06-15 summary:In this paper, we consider the joint design of data compression and 802.15.4-based medium access control (MAC) protocol for smartgrids with renewable energy. We study the setting where a number of nodes, each of which comprises electricity load and/or renewable sources, report periodically their injected powers to a data concentrator. Our design exploits the correlation of the reported data in both time and space to efficiently design the data compression using the compressed sensing (CS) technique and theMAC protocol so that the reported data can be recovered reliably within minimum reporting time. Specifically, we perform the following design tasks: i) we employ the two-dimensional (2D) CS technique to compress the reported data in the distributed manner; ii) we propose to adapt the 802.15.4 MAC protocol frame structure to enable efficient data transmission and reliable data reconstruction; and iii) we develop an analytical model based on which we can obtain efficient MAC parameter configuration to minimize the reporting delay. Finally, numerical results are presented to demonstrate the effectiveness of our proposed framework compared to existing solutions. version:1
arxiv-1506-04130 | CloudCV: Large Scale Distributed Computer Vision as a Cloud Service | http://arxiv.org/abs/1506.04130 | id:1506.04130 author:Harsh Agrawal, Clint Solomon Mathialagan, Yash Goyal, Neelima Chavali, Prakriti Banik, Akrit Mohapatra, Ahmed Osman, Dhruv Batra category:cs.CV cs.DC  published:2015-06-12 summary:We are witnessing a proliferation of massive visual data. Unfortunately scaling existing computer vision algorithms to large datasets leaves researchers repeatedly solving the same algorithmic, logistical, and infrastructural problems. Our goal is to democratize computer vision; one should not have to be a computer vision, big data and distributed computing expert to have access to state-of-the-art distributed computer vision algorithms. We present CloudCV, a comprehensive system to provide access to state-of-the-art distributed computer vision algorithms as a cloud service through a Web Interface and APIs. version:2
arxiv-1606-04992 | A Hierarchical Pose-Based Approach to Complex Action Understanding Using Dictionaries of Actionlets and Motion Poselets | http://arxiv.org/abs/1606.04992 | id:1606.04992 author:Ivan Lillo, Juan Carlos Niebles, Alvaro Soto category:cs.CV  published:2016-06-15 summary:In this paper, we introduce a new hierarchical model for human action recognition using body joint locations. Our model can categorize complex actions in videos, and perform spatio-temporal annotations of the atomic actions that compose the complex action being performed.That is, for each atomic action, the model generates temporal action annotations by estimating its starting and ending times, as well as, spatial annotations by inferring the human body parts that are involved in executing the action. our model includes three key novel properties: (i) it can be trained with no spatial supervision, as it can automatically discover active body parts from temporal action annotations only; (ii) it jointly learns flexible representations for motion poselets and actionlets that encode the visual variability of body parts and atomic actions; (iii) a mechanism to discard idle or non-informative body parts which increases its robustness to common pose estimation errors. We evaluate the performance of our method using multiple action recognition benchmarks. Our model consistently outperforms baselines and state-of-the-art action recognition methods. version:1
arxiv-1606-04991 | A Class of Parallel Doubly Stochastic Algorithms for Large-Scale Learning | http://arxiv.org/abs/1606.04991 | id:1606.04991 author:Aryan Mokhtari, Alec Koppel, Alejandro Ribeiro category:cs.LG math.OC stat.ML  published:2016-06-15 summary:We consider learning problems over training sets in which both, the number of training examples and the dimension of the feature vectors, are large. To solve these problems we propose the random parallel stochastic algorithm (RAPSA). We call the algorithm random parallel because it utilizes multiple parallel processors to operate on a randomly chosen subset of blocks of the feature vector. We call the algorithm stochastic because processors choose training subsets uniformly at random. Algorithms that are parallel in either of these dimensions exist, but RAPSA is the first attempt at a methodology that is parallel in both the selection of blocks and the selection of elements of the training set. In RAPSA, processors utilize the randomly chosen functions to compute the stochastic gradient component associated with a randomly chosen block. The technical contribution of this paper is to show that this minimally coordinated algorithm converges to the optimal classifier when the training objective is convex. Moreover, we present an accelerated version of RAPSA (ARAPSA) that incorporates the objective function curvature information by premultiplying the descent direction by a Hessian approximation matrix. We further extend the results for asynchronous settings and show that if the processors perform their updates without any coordination the algorithms are still convergent to the optimal argument. RAPSA and its extensions are then numerically evaluated on a linear estimation problem and a binary image classification task using the MNIST handwritten digit dataset. version:1
arxiv-1606-04988 | Logarithmic Time One-Against-Some | http://arxiv.org/abs/1606.04988 | id:1606.04988 author:Hal Daume III, Nikos Karampatziakis, John Langford, Paul Mineiro category:stat.ML cs.LG  published:2016-06-15 summary:We create a new online reduction of multiclass classification to binary classification for which training and prediction time scale logarithmically with the number of classes. Compared to previous approaches, we obtain substantially better statistical performance for two reasons: First, we prove a tighter and more complete boosting theorem, and second we translate the results more directly into an algorithm. We show that several simple techniques give rise to an algorithm that can compete with one-against-all in both space and predictive power while offering exponential improvements in speed when the number of classes is large. version:1
arxiv-1606-04985 | Combining multiscale features for classification of hyperspectral images: a sequence based kernel approach | http://arxiv.org/abs/1606.04985 | id:1606.04985 author:Yanwei Cui, Laetitia Chapel, Sébastien Lefèvre category:cs.CV cs.LG stat.ML  published:2016-06-15 summary:Nowadays, hyperspectral image classification widely copes with spatial information to improve accuracy. One of the most popular way to integrate such information is to extract hierarchical features from a multiscale segmentation. In the classification context, the extracted features are commonly concatenated into a long vector (also called stacked vector), on which is applied a conventional vector-based machine learning technique (e.g. SVM with Gaussian kernel). In this paper, we rather propose to use a sequence structured kernel: the spectrum kernel. We show that the conventional stacked vector-based kernel is actually a special case of this kernel. Experiments conducted on various publicly available hyperspectral datasets illustrate the improvement of the proposed kernel w.r.t. conventional ones using the same hierarchical spatial features. version:1
arxiv-1606-04963 | The Edit Distance Transducer in Action: The University of Cambridge English-German System at WMT16 | http://arxiv.org/abs/1606.04963 | id:1606.04963 author:Felix Stahlberg, Eva Hasler, Bill Byrne category:cs.CL  published:2016-06-15 summary:This paper presents the University of Cambridge submission to WMT16. Motivated by the complementary nature of syntactical machine translation and neural machine translation (NMT), we exploit the synergies of Hiero and NMT in different combination schemes. Starting out with a simple neural lattice rescoring approach, we show that the Hiero lattices are often too narrow for NMT ensembles. Therefore, instead of a hard restriction of the NMT search space to the lattice, we propose to loosely couple NMT and Hiero by composition with a modified version of the edit distance transducer. The loose combination outperforms lattice rescoring, especially when using multiple NMT systems in an ensemble. version:1
arxiv-1606-04934 | Improving Variational Inference with Inverse Autoregressive Flow | http://arxiv.org/abs/1606.04934 | id:1606.04934 author:Diederik P Kingma, Tim Salimans, Max Welling category:cs.LG stat.ML  published:2016-06-15 summary:We propose a simple and scalable method for improving the flexibility of variational inference through a transformation with autoregressive networks. Autoregressive networks, such as RNNs and MADE, are very powerful models; however, ancestral sampling in such networks is a sequential operation, therefore unappealing for direct use as approximate posteriors in variational inference on parallel hardware such as GPUs. We find that by inverting autoregressive networks we can obtain equally powerful data transformations that can often be computed in parallel. We show that such data transformations, inverse autoregressive flows (IAF), can be used to transform a simple distribution over the latent variables into a much more flexible distribution, while still allowing us to compute the resulting variables' probability density function. The method is simple to implement, can be made arbitrarily flexible, and (in contrast with previous work) is naturally applicable to latent variables that are organized in multidimensional tensors, such as 2D grids or time series. The method is applied to a novel deep architecture of variational auto-encoders. In experiments we demonstrate that autoregressive flow leads to significant performance gains when applied to variational autoencoders for natural images. version:1
arxiv-1606-04930 | Deep Learning for Music | http://arxiv.org/abs/1606.04930 | id:1606.04930 author:Allen Huang, Raymond Wu category:cs.LG cs.SD  published:2016-06-15 summary:Our goal is to be able to build a generative model from a deep neural network architecture to try to create music that has both harmony and melody and is passable as music composed by humans. Previous work in music generation has mainly been focused on creating a single melody. More recent work on polyphonic music modeling, centered around time series probability density estimation, has met some partial success. In particular, there has been a lot of work based off of Recurrent Neural Networks combined with Restricted Boltzmann Machines (RNN-RBM) and other similar recurrent energy based models. Our approach, however, is to perform end-to-end learning and generation with deep neural nets alone. version:1
arxiv-1602-07387 | Discrete Distribution Estimation under Local Privacy | http://arxiv.org/abs/1602.07387 | id:1602.07387 author:Peter Kairouz, Keith Bonawitz, Daniel Ramage category:stat.ML cs.LG  published:2016-02-24 summary:The collection and analysis of user data drives improvements in the app and web ecosystems, but comes with risks to privacy. This paper examines discrete distribution estimation under local privacy, a setting wherein service providers can learn the distribution of a categorical statistic of interest without collecting the underlying data. We present new mechanisms, including hashed K-ary Randomized Response (KRR), that empirically meet or exceed the utility of existing mechanisms at all privacy levels. New theoretical results demonstrate the order-optimality of KRR and the existing RAPPOR mechanism at different privacy regimes. version:3
arxiv-1606-04884 | cltorch: a Hardware-Agnostic Backend for the Torch Deep Neural Network Library, Based on OpenCL | http://arxiv.org/abs/1606.04884 | id:1606.04884 author:Hugh Perkins category:cs.NE cs.CV I.2.6; I.5.1  published:2016-06-15 summary:This paper presents cltorch, a hardware-agnostic backend for the Torch neural network framework. cltorch enables training of deep neural networks on GPUs from diverse hardware vendors, including AMD, NVIDIA, and Intel. cltorch contains sufficient implementation to run models such as AlexNet, VGG, Overfeat, and GoogleNet. It is written using the OpenCL language, a portable compute language, governed by the Khronos Group. cltorch is the top-ranked hardware-agnostic machine learning framework on Chintala's convnet-benchmarks page. This paper presents the technical challenges encountered whilst creating the cltorch backend for Torch, and looks in detail at the challenges related to obtaining a fast hardware-agnostic implementation. The convolutional layers are identified as the key area of focus for accelerating hardware-agnostic frameworks. Possible approaches to accelerating the convolutional implementation are identified including: implementation of the convolutions using the implicitgemm or winograd algorithm, using a GEMM implementation adapted to the geometries associated with the convolutional algorithm, or using a pluggable hardware-specific convolutional implementation. version:1
arxiv-1606-04870 | Smart Reply: Automated Response Suggestion for Email | http://arxiv.org/abs/1606.04870 | id:1606.04870 author:Anjuli Kannan, Karol Kurach, Sujith Ravi, Tobias Kaufmann, Andrew Tomkins, Balint Miklos, Greg Corrado, Laszlo Lukacs, Marina Ganea, Peter Young, Vivek Ramavajjala category:cs.CL  published:2016-06-15 summary:In this paper we propose and investigate a novel end-to-end method for automatically generating short email responses, called Smart Reply. It generates semantically diverse suggestions that can be used as complete email responses with just one tap on mobile. The system is currently used in Inbox by Gmail and is responsible for assisting with 10% of all mobile responses. It is designed to work at very high throughput and process hundreds of millions of messages daily. The system exploits state-of-the-art, large-scale deep learning. We describe the architecture of the system as well as the challenges that we faced while building it, like response diversity and scalability. We also introduce a new method for semantic clustering of user-generated content that requires only a modest amount of explicitly labeled data. version:1
arxiv-1606-04853 | The ND-IRIS-0405 Iris Image Dataset | http://arxiv.org/abs/1606.04853 | id:1606.04853 author:Kevin W. Bowyer, Patrick J. Flynn category:cs.CV  published:2016-06-15 summary:The Computer Vision Research Lab at the University of Notre Dame began collecting iris images in the spring semester of 2004. The initial data collections used an LG 2200 iris imaging system for image acquisition. Image datasets acquired in 2004-2005 at Notre Dame with this LG 2200 have been used in the ICE 2005 and ICE 2006 iris biometric evaluations. The ICE 2005 iris image dataset has been distributed to over 100 research groups around the world. The purpose of this document is to describe the content of the ND-IRIS-0405 iris image dataset. This dataset is a superset of the iris image datasets used in ICE 2005 and ICE 2006. The ND 2004-2005 iris image dataset contains 64,980 images corresponding to 356 unique subjects, and 712 unique irises. The age range of the subjects is 18 to 75 years old. 158 of the subjects are female, and 198 are male. 250 of the subjects are Caucasian, 82 are Asian, and 24 are other ethnicities. version:1
arxiv-1606-04838 | Optimization Methods for Large-Scale Machine Learning | http://arxiv.org/abs/1606.04838 | id:1606.04838 author:Léon Bottou, Frank E. Curtis, Jorge Nocedal category:stat.ML cs.LG math.OC  published:2016-06-15 summary:This paper provides a review and commentary on the past, present, and future of numerical optimization algorithms in the context of machine learning applications. Through case studies on text classification and the training of deep neural networks, we discuss how optimization problems arise in machine learning and what makes them challenging. A major theme of our study is that large-scale machine learning represents a distinctive setting in which the stochastic gradient (SG) method has traditionally played a central role while conventional gradient-based nonlinear optimization techniques typically falter. Based on this viewpoint, we present a comprehensive theory of a straightforward, yet versatile SG algorithm, discuss its practical behavior, and highlight opportunities for designing algorithms with improved performance. This leads to a discussion about the next generation of optimization methods for large-scale machine learning, including an investigation of two main streams of research on techniques that diminish noise in the stochastic directions and methods that make use of second-order derivative approximations. version:1
arxiv-1606-04835 | Multi-phase Word Sense Embedding Retrofitting with Lexical Ontology | http://arxiv.org/abs/1606.04835 | id:1606.04835 author:Qi Li, Tianshi Li, Baobao Chang category:cs.CL  published:2016-06-15 summary:Word embeddings play a significant role in many modern NLP systems. However, most used word embedding learning methods learn one representation per word which is problematic for polysemous words and homonymous words. To address this problem, we propose a multi-phase word sense embedding retrofitting method which utilizes a lexical ontology to learn one embedding per word sense. We use word sense definitions and relations between word senses defined in a lexical ontology in a different way from existing systems. Experimental results on word similarity task show that our approach remarkablely improves the quality of embeddings. version:1
arxiv-1606-04820 | Understanding Probabilistic Sparse Gaussian Process Approximations | http://arxiv.org/abs/1606.04820 | id:1606.04820 author:Matthias Stephan Bauer, Mark van der Wilk, Carl Edward Rasmussen category:stat.ML  published:2016-06-15 summary:Good sparse approximations are essential for practical inference in Gaussian Processes as the computational cost of exact methods is prohibitive for large datasets. The Fully Independent Training Conditional (FITC) and the Variational Free Energy (VFE) approximations are two recent popular methods. Despite superficial similarities, these approximations have surprisingly different theoretical properties and behave differently in practice. We thoroughly investigate the two methods for regression both analytically and through illustrative examples, and draw conclusions to guide practical application. version:1
arxiv-1606-04809 | Asaga: Asynchronous Parallel Saga | http://arxiv.org/abs/1606.04809 | id:1606.04809 author:Rémi Leblond, Fabian Pedregosa, Simon Lacoste-Julien category:math.OC cs.LG stat.ML  published:2016-06-15 summary:We describe Asaga, an asynchronous parallel version of the incremental gradient algorithm Saga that enjoys fast linear convergence rates. We highlight a subtle but important technical issue present in a large fraction of the recent convergence rate proofs for asynchronous parallel optimization algorithms, and propose a simplification of the recently proposed "perturbed iterate" framework that resolves it. We thereby prove that Asaga can obtain a theoretical linear speedup on multi-core systems even without sparsity assumptions. We present results of an implementation on a 40-core architecture illustrating the practical speedup as well as the hardware overhead. version:1
arxiv-1606-04797 | V-Net: Fully Convolutional Neural Networks for Volumetric Medical Image Segmentation | http://arxiv.org/abs/1606.04797 | id:1606.04797 author:Fausto Milletari, Nassir Navab, Seyed-Ahmad Ahmadi category:cs.CV  published:2016-06-15 summary:Convolutional Neural Networks (CNNs) have been recently employed to solve problems from both the computer vision and medical image analysis fields. Despite their popularity, most approaches are only able to process 2D images while most medical data used in clinical practice consists of 3D volumes. In this work we propose an approach to 3D image segmentation based on a volumetric, fully convolutional, neural network. Our CNN is trained end-to-end on MRI volumes depicting prostate, and learns to predict segmentation for the whole volume at once. We introduce a novel objective function, that we optimise during training, based on Dice coefficient. In this way we can deal with situations where there is a strong imbalance between the number of foreground and background voxels. To cope with the limited number of annotated volumes available for training, we augment the data applying random non-linear transformations and histogram matching. We show in our experimental evaluation that our approach achieves good performances on challenging test data while requiring only a fraction of the processing time needed by other previous methods. version:1
arxiv-1606-04789 | Network Maximal Correlation | http://arxiv.org/abs/1606.04789 | id:1606.04789 author:Soheil Feizi, Ali Makhdoumi, Ken Duffy, Muriel Medard, Manolis Kellis category:stat.ML  published:2016-06-15 summary:We introduce Network Maximal Correlation (NMC) as a multivariate measure of nonlinear association among random variables. NMC is defined via an optimization that infers (non-trivial) transformations of variables by maximizing aggregate inner products between transformed variables. We characterize a solution of the NMC optimization using geometric properties of Hilbert spaces for finite discrete and jointly Gaussian random variables. For finite discrete variables, we propose an algorithm based on alternating conditional expectation to determine NMC. We also show that empirically computed NMC converges to NMC exponentially fast in sample size. For jointly Gaussian variables, we show that under some conditions the NMC optimization is an instance of the Max-Cut problem. We then illustrate an application of NMC and multiple MC in inference of graphical model for bijective, possibly non-monotone, functions of jointly Gaussian variables generalizing the copula setup developed by Liu et al. Finally, we illustrate NMC's utility in a real data application of learning nonlinear dependencies among genes in a cancer dataset. version:1
arxiv-1606-04778 | The Learning and Prediction of Application-level Traffic Data in Cellular Networks | http://arxiv.org/abs/1606.04778 | id:1606.04778 author:Rongpeng Li, Zhifeng Zhao, Jianchao Zheng, Yan Chen, Chengli Mei, Yueming Cai, Honggang Zhang category:cs.NI cs.LG  published:2016-06-15 summary:Traffic learning and prediction is at the heart of the evaluation of the performance of telecommunications networks and attracts a lot of attention in wired broadband networks. Now, benefiting from the big data in cellular networks, it becomes possible to make the analyses one step further into the application level. In this paper, we firstly collect a significant amount of application-level traffic data from cellular network operators. Afterwards, with the aid of the traffic "big data", we make a comprehensive study over the modeling and prediction framework of cellular network traffic. Our results solidly demonstrate that there universally exist some traffic statistical modeling characteristics, including ALPHA-stable modeled property in the temporal domain and the sparsity in the spatial domain. Meanwhile, the results also demonstrate the distinctions originated from the uniqueness of different service types of applications. Furthermore, we propose a new traffic prediction framework to encompass and explore these aforementioned characteristics and then develop a dictionary learning-based alternating direction method to solve it. Besides, we validate the prediction accuracy improvement and the robustness of the proposed framework through extensive simulation results. version:1
arxiv-1606-04774 | Free Form based active contours for image segmentation and free space perception | http://arxiv.org/abs/1606.04774 | id:1606.04774 author:Ouiddad Labbani I., Pauline Merveilleux O, Olivier Ruatta category:cs.RO cs.CV  published:2016-06-15 summary:In this paper we present a novel approach for representing and evolving deformable active contours. The method combines piecewise regular B{\'e}zier models and curve evolution defined by local Free Form Deformation. The contour deformation is locally constrained which allows contour convergence with almost linear complexity while adapting to various shape settings and handling topology changes of the active contour. We demonstrate the effectiveness of the new active contour scheme for visual free space perception and segmentation using omnidirectional images acquired by a robot exploring unknown indoor and outdoor environments. Several experiments validate the approach with comparison to state-of-the art parametric and geometric active contours and provide fast and real-time robot free space segmentation and navigation. version:1
arxiv-1606-04766 | Probe-based Rapid Hybrid Hyperspectral and Tissue Surface Imaging Aided by Fully Convolutional Networks | http://arxiv.org/abs/1606.04766 | id:1606.04766 author:Jianyu Lin, Neil T. Clancy, Xueqing Sun, Ji Qi, Mirek Janatka, Danail Stoyanov, Daniel S. Elson category:cs.CV  published:2016-06-15 summary:Tissue surface shape and reflectance spectra provide rich intra-operative information useful in surgical guidance. We propose a hybrid system which displays an endoscopic image with a fast joint inspection of tissue surface shape using structured light (SL) and hyperspectral imaging (HSI). For SL a miniature fibre probe is used to project a coloured spot pattern onto the tissue surface. In HSI mode standard endoscopic illumination is used, with the fibre probe collecting reflected light and encoding the spatial information into a linear format that can be imaged onto the slit of a spectrograph. Correspondence between the arrangement of fibres at the distal and proximal ends of the bundle was found using spectral encoding. Then during pattern decoding, a fully convolutional network (FCN) was used for spot detection, followed by a matching propagation algorithm for spot identification. This method enabled fast reconstruction (12 frames per second) using a GPU. The hyperspectral image was combined with the white light image and the reconstructed surface, showing the spectral information of different areas. Validation of this system using phantom and ex vivo experiments has been demonstrated. version:1
arxiv-1606-04754 | A Correlational Encoder Decoder Architecture for Pivot Based Sequence Generation | http://arxiv.org/abs/1606.04754 | id:1606.04754 author:Amrita Saha, Mitesh M. Khapra, Sarath Chandar, Janarthanan Rajendran, Kyunghyun Cho category:cs.CL  published:2016-06-15 summary:Interlingua based Machine Translation (MT) aims to encode multiple languages into a common linguistic representation and then decode sentences in multiple target languages from this representation. In this work we explore this idea in the context of neural encoder decoder architectures, albeit on a smaller scale and without MT as the end goal. Specifically, we consider the case of three languages or modalities X, Z and Y wherein we are interested in generating sequences in Y starting from information available in X. However, there is no parallel training data available between X and Y but, training data is available between X & Z and Z & Y (as is often the case in many real world applications). Z thus acts as a pivot/bridge. An obvious solution, which is perhaps less elegant but works very well in practice is to train a two stage model which first converts from X to Z and then from Z to Y. Instead we explore an interlingua inspired solution which jointly learns to do the following (i) encode X and Z to a common representation and (ii) decode Y from this common representation. We evaluate our model on two tasks: (i) bridge transliteration and (ii) bridge captioning. We report promising results in both these applications and believe that this is a right step towards truly interlingua inspired encoder decoder architectures. version:1
arxiv-1606-04753 | Safe Exploration in Finite Markov Decision Processes with Gaussian Processes | http://arxiv.org/abs/1606.04753 | id:1606.04753 author:Matteo Turchetta, Felix Berkenkamp, Andreas Krause category:cs.LG cs.AI cs.RO stat.ML  published:2016-06-15 summary:In classical reinforcement learning, when exploring an environment, agents accept arbitrary short term loss for long term gain. This is infeasible for safety critical applications, such as robotics, where even a single unsafe action may cause system failure. In this paper, we address the problem of safely exploring finite Markov decision processes (MDP). We define safety in terms of an, a priori unknown, safety constraint that depends on states and actions. We aim to explore the MDP under this constraint, assuming that the unknown function satisfies regularity conditions expressed via a Gaussian process prior. We develop a novel algorithm for this task and prove that it is able to completely explore the safely reachable part of the MDP without violating the safety constraint. To achieve this, it cautiously explores safe states and actions in order to gain statistical confidence about the safety of unvisited state-action pairs from noisy observations collected while navigating the environment. Moreover, the algorithm explicitly considers reachability when exploring the MDP, ensuring that it does not get stuck in any state with no safe way out. We demonstrate our method on digital terrain models for the task of exploring an unknown map with a rover. version:1
arxiv-1606-03238 | IDNet: Smartphone-based Gait Recognition with Convolutional Neural Networks | http://arxiv.org/abs/1606.03238 | id:1606.03238 author:Matteo Gadaleta, Michele Rossi category:cs.CV cs.LG  published:2016-06-10 summary:Here, we present IDNet, an original user authentication framework from smartphone-acquired motion signals. Its goal is to recognize a target user from her/his way of walking, using the accelerometer and gyroscope (inertial) signals provided by a commercial smartphone worn in the front pocket of the user's trousers. Our design features several innovations including: a robust and smartphone-orientation-independent walking cycle extraction block, a novel feature extractor based on convolutional neural networks, a one-class support vector machine to classify walking cycles, and the coherent integration of these into a multi-stage authentication system. To the best of our knowledge, our system is the first exploiting convolutional neural networks as universal feature extractors for gait recognition, and using classification results from subsequent walking cycles into a multi-stage decision making framework. Experimental results show the superiority of our approach against state-of-the-art techniques, leading to misclassification rates (either false negatives or positives) smaller than 0.15% in fewer than five walking cycles. Design choices are discussed and motivated throughout, assessing their impact on the authentication performance. version:2
arxiv-1606-04750 | Multi-Modal Hybrid Deep Neural Network for Speech Enhancement | http://arxiv.org/abs/1606.04750 | id:1606.04750 author:Zhenzhou Wu, Sunil Sivadas, Yong Kiam Tan, Ma Bin, Rick Siow Mong Goh category:cs.LG cs.NE cs.SD  published:2016-06-15 summary:Deep Neural Networks (DNN) have been successful in en- hancing noisy speech signals. Enhancement is achieved by learning a nonlinear mapping function from the features of the corrupted speech signal to that of the reference clean speech signal. The quality of predicted features can be improved by providing additional side channel information that is robust to noise, such as visual cues. In this paper we propose a novel deep learning model inspired by insights from human audio visual perception. In the proposed unified hybrid architecture, features from a Convolution Neural Network (CNN) that processes the visual cues and features from a fully connected DNN that processes the audio signal are integrated using a Bidirectional Long Short-Term Memory (BiLSTM) network. The parameters of the hybrid model are jointly learned using backpropagation. We compare the quality of enhanced speech from the hybrid models with those from traditional DNN and BiLSTM models. version:1
arxiv-1602-02990 | Self-organized control for musculoskeletal robots | http://arxiv.org/abs/1602.02990 | id:1602.02990 author:Ralf Der, Georg Martius category:cs.RO cs.LG cs.SY I.2.9; I.2.6  published:2016-02-09 summary:With the accelerated development of robot technologies, optimal control becomes one of the central themes of research. In traditional approaches, the controller, by its internal functionality, finds appropriate actions on the basis of the history of sensor values, guided by the goals, intentions, objectives, learning schemes, and so on planted into it. The idea is that the controller controls the world---the body plus its environment---as reliably as possible. However, in elastically actuated robots this approach faces severe difficulties. This paper advocates for a new paradigm of self-organized control. The paper presents a solution with a controller that is devoid of any functionalities of its own, given by a fixed, explicit and context-free function of the recent history of the sensor values. When applying this controller to a muscle-tendon driven arm-shoulder system from the Myorobotics toolkit, we observe a vast variety of self-organized behavior patterns: when left alone, the arm realizes pseudo-random sequences of different poses but one can also manipulate the system into definite motion patterns. But most interestingly, after attaching an object, the controller gets in a functional resonance with the object's internal dynamics: when given a half-filled bottle, the system spontaneously starts shaking the bottle so that maximum response from the dynamics of the water is being generated. After attaching a pendulum to the arm, the controller drives the pendulum into a circular mode. In this way, the robot discovers dynamical affordances of objects its body is interacting with. We also discuss perspectives for using this controller paradigm for intention driven behavior generation. version:2
arxiv-1606-04722 | Differentially Private Stochastic Gradient Descent for in-RDBMS Analytics | http://arxiv.org/abs/1606.04722 | id:1606.04722 author:Xi Wu, Arun Kumar, Kamalika Chaudhuri, Somesh Jha, Jeffrey F. Naughton category:cs.LG cs.CR cs.DB stat.ML  published:2016-06-15 summary:In-RDBMS data analysis has received considerable attention in the past decade and has been widely used in sensitive domains to extract patterns in data using machine learning. For these domains, there has also been growing concern about privacy, and differential privacy has emerged as the gold standard for private data analysis. However, while differentially private machine learning and in-RDBMS data analytics have been studied separately, little previous work has explored private learning in an in-RDBMS system. This work considers a specific algorithm --- stochastic gradient descent (SGD) for differentially private machine learning --- and explores how to integrate it into an RDBMS system. We find that previous solutions on differentially private SGD have characteristics that render them unattractive for an RDBMS implementation. To address this, we propose an algorithm that runs SGD for a constant number of passes and then adds noise to the resulting output. We provide a novel analysis of the privacy properties of this algorithm. We then integrate it, along with two existing versions of differentially private SGD, in the Postgres RDBMS. Experimental results demonstrate that our proposed approach can be easily integrated into an RDBMS, incurs virtually no overhead, and yields substantially better test accuracy than the other private SGD algorithm implementations. version:1
arxiv-1606-04721 | Personality Traits and Echo Chambers on Facebook | http://arxiv.org/abs/1606.04721 | id:1606.04721 author:Alessandro Bessi category:cs.SI cs.CL cs.CY cs.HC  published:2016-06-15 summary:In online social networks, users tend to select information that adhere to their system of beliefs and to form polarized groups of like minded people. Polarization as well as its effects on online social interactions have been extensively investigated. Still, the relation between group formation and personality traits remains unclear. A better understanding of the cognitive and psychological determinants of online social dynamics might help to design more efficient communication strategies and to challenge the digital misinformation threat. In this work, we focus on users commenting posts published by US Facebook pages supporting scientific and conspiracy-like narratives, and we classify the personality traits of those users according to their online behavior. We show that different and conflicting communities are populated by users showing similar psychological profiles, and that the dominant personality model is the same in both scientific and conspiracy echo chambers. Moreover, we observe that the permanence within echo chambers slightly shapes users' psychological profiles. Our results suggest that the presence of specific personality traits in individuals lead to their considerable involvement in supporting narratives inside virtual echo chambers. version:1
arxiv-1511-06676 | Personalizing Human Video Pose Estimation | http://arxiv.org/abs/1511.06676 | id:1511.06676 author:James Charles, Tomas Pfister, Derek Magee, David Hogg, Andrew Zisserman category:cs.CV  published:2015-11-20 summary:We propose a personalized ConvNet pose estimator that automatically adapts itself to the uniqueness of a person's appearance to improve pose estimation in long videos. We make the following contributions: (i) we show that given a few high-precision pose annotations, e.g. from a generic ConvNet pose estimator, additional annotations can be generated throughout the video using a combination of image-based matching for temporally distant frames, and dense optical flow for temporally local frames; (ii) we develop an occlusion aware self-evaluation model that is able to automatically select the high-quality and reject the erroneous additional annotations; and (iii) we demonstrate that these high-quality annotations can be used to fine-tune a ConvNet pose estimator and thereby personalize it to lock on to key discriminative features of the person's appearance. The outcome is a substantial improvement in the pose estimates for the target video using the personalized ConvNet compared to the original generic ConvNet. Our method outperforms the state of the art (including top ConvNet methods) by a large margin on two standard benchmarks, as well as on a new challenging YouTube video dataset. Furthermore, we show that training from the automatically generated annotations can be used to improve the performance of a generic ConvNet on other benchmarks. version:2
arxiv-1606-04333 | Neither Quick Nor Proper -- Evaluation of QuickProp for Learning Deep Neural Networks | http://arxiv.org/abs/1606.04333 | id:1606.04333 author:Clemens-Alexander Brust, Sven Sickert, Marcel Simon, Erik Rodner, Joachim Denzler category:cs.CV  published:2016-06-14 summary:Neural networks and especially convolutional neural networks are of great interest in current computer vision research. However, many techniques, extensions, and modifications have been published in the past, which are not yet used by current approaches. In this paper, we study the application of a method called QuickProp for training of deep neural networks. In particular, we apply QuickProp during learning and testing of fully convolutional networks for the task of semantic segmentation. We compare QuickProp empirically with gradient descent, which is the current standard method. Experiments suggest that QuickProp can not compete with standard gradient descent techniques for complex computer vision tasks like semantic segmentation. version:2
arxiv-1606-04702 | DeepProposals: Hunting Objects and Actions by Cascading Deep Convolutional Layers | http://arxiv.org/abs/1606.04702 | id:1606.04702 author:Amir Ghodrati, Ali Diba, Marco Pedersoli, Tinne Tuytelaars, Luc Van Gool category:cs.CV  published:2016-06-15 summary:In this paper, a new method for generating object and action proposals in images and videos is proposed. It builds on activations of different convolutional layers of a pretrained CNN, combining the localization accuracy of the early layers with the high informative-ness (and hence recall) of the later layers. To this end, we build an inverse cascade that, going backward from the later to the earlier convolutional layers of the CNN, selects the most promising locations and refines them in a coarse-to-fine manner. The method is efficient, because i) it re-uses the same features extracted for detection, ii) it aggregates features using integral images, and iii) it avoids a dense evaluation of the proposals thanks to the use of the inverse coarse-to-fine cascade. The method is also accurate. We show that our DeepProposals outperform most of the previously proposed object proposal and action proposal approaches and, when plugged into a CNN-based object detector, produce state-of-the-art detection performance. version:1
arxiv-1606-04940 | A practical local tomography reconstruction algorithm based on known subregion | http://arxiv.org/abs/1606.04940 | id:1606.04940 author:Pierre Paleo, Michel Desvignes, Alessandro Mirone category:physics.med-ph cs.CV  published:2016-06-15 summary:We propose a new method to reconstruct data acquired in a local tomography setup. This method uses an initial reconstruction and refines it by correcting the low frequency artifacts known as the cupping effect. A basis of Gaussian functions is used to correct the initial reconstruction. The coefficients of this basis are iteratively optimized under the constraint of a known subregion. Using a coarse basis reduces the degrees of freedom of the problem while actually correcting the cupping effect. Simulations show that the known region constraint yields an unbiased reconstruction, in accordance to uniqueness theorems stated in local tomography. version:1
arxiv-1606-04695 | Strategic Attentive Writer for Learning Macro-Actions | http://arxiv.org/abs/1606.04695 | id:1606.04695 author:Alexander, Vezhnevets, Volodymyr Mnih, John Agapiou, Simon Osindero, Alex Graves, Oriol Vinyals, Koray Kavukcuoglu category:cs.AI cs.LG  published:2016-06-15 summary:We present a novel deep recurrent neural network architecture that learns to build implicit plans in an end-to-end manner by purely interacting with an environment in reinforcement learning setting. The network builds an internal plan, which is continuously updated upon observation of the next input from the environment. It can also partition this internal representation into contiguous sub- sequences by learning for how long the plan can be committed to - i.e. followed without re-planing. Combining these properties, the proposed model, dubbed STRategic Attentive Writer (STRAW) can learn high-level, temporally abstracted macro- actions of varying lengths that are solely learnt from data without any prior information. These macro-actions enable both structured exploration and economic computation. We experimentally demonstrate that STRAW delivers strong improvements on several ATARI games by employing temporally extended planning strategies (e.g. Ms. Pacman and Frostbite). It is at the same time a general algorithm that can be applied on any sequence data. To that end, we also show that when trained on text prediction task, STRAW naturally predicts frequent n-grams (instead of macro-actions), demonstrating the generality of the approach. version:1
arxiv-1606-04686 | Natural Language Generation as Planning under Uncertainty Using Reinforcement Learning | http://arxiv.org/abs/1606.04686 | id:1606.04686 author:Verena Rieser, Oliver Lemon category:cs.CL cs.AI  published:2016-06-15 summary:We present and evaluate a new model for Natural Language Generation (NLG) in Spoken Dialogue Systems, based on statistical planning, given noisy feedback from the current generation context (e.g. a user and a surface realiser). We study its use in a standard NLG problem: how to present information (in this case a set of search results) to users, given the complex trade- offs between utterance length, amount of information conveyed, and cognitive load. We set these trade-offs by analysing existing MATCH data. We then train a NLG pol- icy using Reinforcement Learning (RL), which adapts its behaviour to noisy feed- back from the current generation context. This policy is compared to several base- lines derived from previous work in this area. The learned policy significantly out- performs all the prior approaches. version:1
arxiv-1606-04672 | Constitutional Precedent of Amicus Briefs | http://arxiv.org/abs/1606.04672 | id:1606.04672 author:Allen Huang, Lars Roemheld category:cs.CL cs.CY  published:2016-06-15 summary:We investigate shared language between U.S. Supreme Court majority opinions and interest groups' corresponding amicus briefs. Specifically, we evaluate whether language that originated in an amicus brief acquired legal precedent status by being cited in the Court's opinion. Using plagiarism detection software, automated querying of a large legal database, and manual analysis, we establish seven instances where interest group amici were able to formulate constitutional case law, setting binding legal precedent. We discuss several such instances for their implications in the Supreme Court's creation of case law. Our results indicate that around 100 more instances can be found in our data. version:1
arxiv-1606-04671 | Progressive Neural Networks | http://arxiv.org/abs/1606.04671 | id:1606.04671 author:Andrei A. Rusu, Neil C. Rabinowitz, Guillaume Desjardins, Hubert Soyer, James Kirkpatrick, Koray Kavukcuoglu, Razvan Pascanu, Raia Hadsell category:cs.LG  published:2016-06-15 summary:Learning to solve complex sequences of tasks--while both leveraging transfer and avoiding catastrophic forgetting--remains a key obstacle to achieving human-level intelligence. The progressive networks approach represents a step forward in this direction: they are immune to forgetting and can leverage prior knowledge via lateral connections to previously learned features. We evaluate this architecture extensively on a wide variety of reinforcement learning tasks (Atari and 3D maze games), and show that it outperforms common baselines based on pretraining and finetuning. Using a novel sensitivity measure, we demonstrate that transfer occurs at both low-level sensory and high-level control layers of the learned policy. version:1
arxiv-1601-01356 | From Word Embeddings to Item Recommendation | http://arxiv.org/abs/1601.01356 | id:1601.01356 author:Makbule Gulcin Ozsoy category:cs.LG cs.CL cs.IR cs.SI  published:2016-01-07 summary:Social network platforms can use the data produced by their users to serve them better. One of the services these platforms provide is recommendation service. Recommendation systems can predict the future preferences of users using their past preferences. In the recommendation systems literature there are various techniques, such as neighborhood based methods, machine-learning based methods and matrix-factorization based methods. In this work, a set of well known methods from natural language processing domain, namely Word2Vec, is applied to recommendation systems domain. Unlike previous works that use Word2Vec for recommendation, this work uses non-textual features, the check-ins, and it recommends venues to visit/check-in to the target users. For the experiments, a Foursquare check-in dataset is used. The results show that use of continuous vector space representations of items modeled by techniques of Word2Vec is promising for making recommendations. version:3
arxiv-1605-00090 | Topic Augmented Neural Network for Short Text Conversation | http://arxiv.org/abs/1605.00090 | id:1605.00090 author:Yu Wu, Wei Wu, Zhoujun Li, Ming Zhou category:cs.CL  published:2016-04-30 summary:Message response matching is an important task within retrieval-based chatbots. We present a topic augmented neural network(TANN), comprising a sentence embedding layer, a topic embedding layer, and a matching layer, to match messages and response candidates. TANN inherits the benefits of neutral networks on matching sentence pairs, and leverages extra topic information and their corresponding weights as prior knowledge into a matching process. In TANN, the sentence embedding layer embeds an input message and a response into a vector space, while the topic embedding layer forms a topic vector by a linear combination of the embedding of topic words whose weights are determined by both themselves and the message vector. The message vector, the response vector, and the topic vector are then fed to the matching layer to calculate a matching score. The extensive evaluation of TANN, using large human annotated data sets, shows that TANN outperforms simple neutral network methods, while beating other typical matching models with a large margin. version:2
arxiv-1606-04646 | Unsupervised Learning of Predictors from Unpaired Input-Output Samples | http://arxiv.org/abs/1606.04646 | id:1606.04646 author:Jianshu Chen, Po-Sen Huang, Xiaodong He, Jianfeng Gao, Li Deng category:cs.LG  published:2016-06-15 summary:Unsupervised learning is the most challenging problem in machine learning and especially in deep learning. Among many scenarios, we study an unsupervised learning problem of high economic value --- learning to predict without costly pairing of input data and corresponding labels. Part of the difficulty in this problem is a lack of solid evaluation measures. In this paper, we take a practical approach to grounding unsupervised learning by using the same success criterion as for supervised learning in prediction tasks but we do not require the presence of paired input-output training data. In particular, we propose an objective function that aims to make the predicted outputs fit well the structure of the output while preserving the correlation between the input and the predicted output. We experiment with a synthetic structural prediction problem and show that even with simple linear classifiers, the objective function is already highly non-convex. We further demonstrate the nature of this non-convex optimization problem as well as potential solutions. In particular, we show that with regularization via a generative model, learning with the proposed unsupervised objective function converges to an optimal solution. version:1
arxiv-1606-04640 | Siamese CBOW: Optimizing Word Embeddings for Sentence Representations | http://arxiv.org/abs/1606.04640 | id:1606.04640 author:Tom Kenter, Alexey Borisov, Maarten de Rijke category:cs.CL  published:2016-06-15 summary:We present the Siamese Continuous Bag of Words (Siamese CBOW) model, a neural network for efficient estimation of high-quality sentence embeddings. Averaging the embeddings of words in a sentence has proven to be a surprisingly successful and efficient way of obtaining sentence embeddings. However, word embeddings trained with the methods currently available are not optimized for the task of sentence representation, and, thus, likely to be suboptimal. Siamese CBOW handles this problem by training word embeddings directly for the purpose of being averaged. The underlying neural network learns word embeddings by predicting, from a sentence representation, its surrounding sentences. We show the robustness of the Siamese CBOW model by evaluating it on 20 datasets stemming from a wide variety of sources. version:1
arxiv-1606-04637 | Ego-Surfing First-Person Videos | http://arxiv.org/abs/1606.04637 | id:1606.04637 author:Ryo Yonetani, Kris M. Kitani, Yoichi Sato category:cs.CV  published:2016-06-15 summary:We envision a future time when wearable cameras are worn by the masses, recording first-person point-of-view (POV) videos of everyday life. While these cameras can enable new assistive technologies and novel research challenges, they also raise serious privacy concerns. For example, first-person videos passively recorded by wearable cameras will necessarily include anyone who comes into the view of a camera -- with or without consent. Motivated by these benefits and risks, we developed a self-search technique tailored to first-person videos. The key observation of our work is that the egocentric head motion of a target person (i.e., the self) is observed both in the POV video of the target and observer. The motion correlation between the target person's video and the observer's video can then be used to identify instances of the self uniquely. We incorporate this feature into the proposed approach that computes the motion correlation over densely-sampled trajectories to search for a target in observer videos. Our approach significantly improves self-search performance over several well-known face detectors and recognizers. Furthermore, we show how our approach can enable several practical applications such as privacy filtering, target video retrieval, and social group clustering. version:1
arxiv-1606-04199 | Deep Recurrent Models with Fast-Forward Connections for Neural Machine Translation | http://arxiv.org/abs/1606.04199 | id:1606.04199 author:Jie Zhou, Ying Cao, Xuguang Wang, Peng Li, Wei Xu category:cs.CL cs.LG  published:2016-06-14 summary:Neural machine translation (NMT) aims at solving machine translation (MT) problems with purely neural networks and exhibits promising results in recent years. However, most of the existing NMT models are of shallow topology and there is still a performance gap between the single NMT model and the best conventional MT system. In this work, we introduce a new type of linear connections, named fast-forward connections, based on deep Long Short-Term Memory (LSTM) network, together with the interleaved bi-directional way for stacking them. Fast-forward connections play an essential role to propagate the gradients in building the deep topology of depth 16. On WMT'14 English- to-French task, we achieved BLEU=37.7 with single attention model, which outperforms the corresponding single shallow model by 6.2 BLEU points. It is the first time that a single NMT model achieves state-of-the-art performance and outperforms the best conventional model by 0.7 BLEU points. Even without considering attention mechanism, we can still achieve BLEU=36.3. After the special handling for unknown words and the model ensemble, we obtained the best score on this task with BLEU=40.4. Our models are also verified on the more difficult WMT'14 English-to-German task. version:2
arxiv-1606-04631 | Bidirectional Long-Short Term Memory for Video Description | http://arxiv.org/abs/1606.04631 | id:1606.04631 author:Yi Bin, Yang Yang, Zi Huang, Fumin Shen, Xing Xu, Heng Tao Shen category:cs.MM cs.CL  published:2016-06-15 summary:Video captioning has been attracting broad research attention in multimedia community. However, most existing approaches either ignore temporal information among video frames or just employ local contextual temporal knowledge. In this work, we propose a novel video captioning framework, termed as \emph{Bidirectional Long-Short Term Memory} (BiLSTM), which deeply captures bidirectional global temporal structure in video. Specifically, we first devise a joint visual modelling approach to encode video data by combining a forward LSTM pass, a backward LSTM pass, together with visual features from Convolutional Neural Networks (CNNs). Then, we inject the derived video representation into the subsequent language model for initialization. The benefits are in two folds: 1) comprehensively preserving sequential and visual information; and 2) adaptively learning dense visual features and sparse semantic representations for videos and sentences, respectively. We verify the effectiveness of our proposed video captioning framework on a commonly-used benchmark, i.e., Microsoft Video Description (MSVD) corpus, and the experimental results demonstrate that the superiority of the proposed approach as compared to several state-of-the-art methods. version:1
arxiv-1602-08357 | Cortical Computation via Iterative Constructions | http://arxiv.org/abs/1602.08357 | id:1602.08357 author:Christos Papadimitrou, Samantha Petti, Santosh Vempala category:cs.NE cs.DS  published:2016-02-26 summary:We study Boolean functions of an arbitrary number of input variables that can be realized by simple iterative constructions based on constant-size primitives. This restricted type of construction needs little global coordination or control and thus is a candidate for neurally feasible computation. Valiant's construction of a majority function can be realized in this manner and, as we show, can be generalized to any uniform threshold function. We study the rate of convergence, finding that while linear convergence to the correct function can be achieved for any threshold using a fixed set of primitives, for quadratic convergence, the size of the primitives must grow as the threshold approaches 0 or 1. We also study finite realizations of this process and the learnability of the functions realized. We show that the constructions realized are accurate outside a small interval near the target threshold, where the size of the construction grows as the inverse square of the interval width. This phenomenon, that errors are higher closer to thresholds (and thresholds closer to the boundary are harder to represent), is a well-known cognitive finding. version:2
arxiv-1606-04624 | Finite-time Analysis for the Knowledge-Gradient Policy | http://arxiv.org/abs/1606.04624 | id:1606.04624 author:Yingfei Wang, Warren Powell category:cs.LG  published:2016-06-15 summary:We consider sequential decision problems in which we adaptively choose one of finitely many alternatives and observe a stochastic reward. We offer a new perspective of interpreting Bayesian ranking and selection problems as adaptive stochastic multi-set maximization problems and derive the first finite-time bound of the knowledge-gradient policy for adaptive submodular objective functions. In addition, we introduce the concept of prior-optimality and provide another insight into the performance of the knowledge gradient policy based on the submodular assumption on the value of information. We demonstrate submodularity for the two-alternative case and provide other conditions for more general problems, bringing out the issue and importance of submodularity in learning problems. Empirical experiments are conducted to further illustrate the finite time behavior of the knowledge gradient policy. version:1
arxiv-1606-04621 | Image Caption Generation with Text-Conditional Semantic Attention | http://arxiv.org/abs/1606.04621 | id:1606.04621 author:Luowei Zhou, Chenliang Xu, Parker Koch, Jason J. Corso category:cs.CV  published:2016-06-15 summary:We propose a semantic attention mechanism for image caption generation, called text-conditional semantic attention, which allows the caption generator to automatically learn which parts of the image feature to focus on given previously generated text. To acquire text-related image features for our attention model, we also improve the guiding Long Short-Term Memory (gLSTM) structure by back-propagating the training loss though semantic guidance to fine-tune the CNN weights. In contrast to existing gLSTM methods, such as emb-gLSTM, our fine-tuned model enables guidance information to be more text-related. This also allows jointly learning of the image embedding, text embedding, semantic attention and language model with one simple network architecture in an end-to-end manner. We implement our model based on NeuralTalk2, an open-source image caption generator, and test it on MSCOCO dataset. We evaluate the proposed method with three metrics: BLEU, METEOR and CIDEr. The proposed methods outperform state-of-the-art methods. version:1
arxiv-1606-05200 | High-speed real-time single-pixel microscopy based on Fourier sampling | http://arxiv.org/abs/1606.05200 | id:1606.05200 author:Qiang Guo, Hongwei Chen, Yuxi Wang, Yong Guo, Peng Liu, Xiurui Zhu, Zheng Cheng, Zhenming Yu, Minghua Chen, Sigang Yang, Shizhong Xie category:cs.CV physics.optics  published:2016-06-15 summary:Single-pixel cameras based on the concepts of compressed sensing (CS) leverage the inherent structure of images to retrieve them with far fewer measurements and operate efficiently over a significantly broader spectral range than conventional silicon-based cameras. Recently, photonic time-stretch (PTS) technique facilitates the emergence of high-speed single-pixel cameras. A significant breakthrough in imaging speed of single-pixel cameras enables observation of fast dynamic phenomena. However, according to CS theory, image reconstruction is an iterative process that consumes enormous amounts of computational time and cannot be performed in real time. To address this challenge, we propose a novel single-pixel imaging technique that can produce high-quality images through rapid acquisition of their effective spatial Fourier spectrum. We employ phase-shifting sinusoidal structured illumination instead of random illumination for spectrum acquisition and apply inverse Fourier transform to the obtained spectrum for image restoration. We evaluate the performance of our prototype system by recognizing quick response (QR) codes and flow cytometric screening of cells. A frame rate of 625 kHz and a compression ratio of 10% are experimentally demonstrated in accordance with the recognition rate of the QR code. An imaging flow cytometer enabling high-content screening with an unprecedented throughput of 100,000 cells/s is also demonstrated. For real-time imaging applications, the proposed single-pixel microscope can significantly reduce the time required for image reconstruction by two orders of magnitude, which can be widely applied in industrial quality control and label-free biomedical imaging. version:1
arxiv-1606-04618 | Masking Strategies for Image Manifolds | http://arxiv.org/abs/1606.04618 | id:1606.04618 author:Hamid Dadkhahi, Marco F. Duarte category:stat.ML cs.LG  published:2016-06-15 summary:We consider the problem of selecting an optimal mask for an image manifold, i.e., choosing a subset of the pixels of the image that preserves the manifold's geometric structure present in the original data. Such masking implements a form of compressive sensing through emerging imaging sensor platforms for which the power expense grows with the number of pixels acquired. Our goal is for the manifold learned from masked images to resemble its full image counterpart as closely as possible. More precisely, we show that one can indeed accurately learn an image manifold without having to consider a large majority of the image pixels. In doing so, we consider two masking methods that preserve the local and global geometric structure of the manifold, respectively. In each case, the process of finding the optimal masking pattern can be cast as a binary integer program, which is computationally expensive but can be approximated by a fast greedy algorithm. Numerical experiments show that the relevant manifold structure is preserved through the data-dependent masking process, even for modest mask sizes. version:1
arxiv-1606-04616 | Natural Scene Character Recognition Using Robust PCA and Sparse Representation | http://arxiv.org/abs/1606.04616 | id:1606.04616 author:Zheng Zhang, Yong Xu, Cheng-Lin Liu category:cs.CV  published:2016-06-15 summary:Natural scene character recognition is challenging due to the cluttered background, which is hard to separate from text. In this paper, we propose a novel method for robust scene character recognition. Specifically, we first use robust principal component analysis (PCA) to denoise character image by recovering the missing low-rank component and filtering out the sparse noise term, and then use a simple Histogram of oriented Gradient (HOG) to perform image feature extraction, and finally, use a sparse representation based classifier for recognition. In experiments on four public datasets, namely the Char74K dataset, ICADAR 2003 robust reading dataset, Street View Text (SVT) dataset and IIIT5K-word dataset, our method was demonstrated to be competitive with the state-of-the-art methods. version:1
arxiv-1606-04615 | Deep Reinforcement Learning With Macro-Actions | http://arxiv.org/abs/1606.04615 | id:1606.04615 author:Ishan P. Durugkar, Clemens Rosenbaum, Stefan Dernbach, Sridhar Mahadevan category:cs.LG cs.AI cs.NE  published:2016-06-15 summary:Deep reinforcement learning has been shown to be a powerful framework for learning policies from complex high-dimensional sensory inputs to actions in complex tasks, such as the Atari domain. In this paper, we explore output representation modeling in the form of temporal abstraction to improve convergence and reliability of deep reinforcement learning approaches. We concentrate on macro-actions, and evaluate these on different Atari 2600 games, where we show that they yield significant improvements in learning speed. Additionally, we show that they can even achieve better scores than DQN. We offer analysis and explanation for both convergence and final results, revealing a problem deep RL approaches have with sparse reward signals. version:1
arxiv-1603-07400 | A Reconfigurable Low Power High Throughput Architecture for Deep Network Training | http://arxiv.org/abs/1603.07400 | id:1603.07400 author:Raqibul Hasan, Tarek Taha category:cs.LG cs.AR cs.DC  published:2016-03-24 summary:General purpose computing systems are used for a large variety of applications. Extensive supports for flexibility in these systems limit their energy efficiencies. Neural networks, including deep networks, are widely used for signal processing and pattern recognition applications. In this paper we propose a multicore architecture for deep neural network based processing. Memristor crossbars are utilized to provide low power high throughput execution of neural networks. The system has both training and recognition (evaluation of new input) capabilities. The proposed system could be used for classification, dimensionality reduction, feature extraction, and anomaly detection applications. The system level area and power benefits of the specialized architecture is compared with the NVIDIA Telsa K20 GPGPU. Our experimental evaluations show that the proposed architecture can provide up to five orders of magnitude more energy efficiency over GPGPUs for deep neural network processing. version:2
arxiv-1606-04597 | Agreement-based Learning of Parallel Lexicons and Phrases from Non-Parallel Corpora | http://arxiv.org/abs/1606.04597 | id:1606.04597 author:Chunyang Liu, Yang Liu, Huanbo Luan, Maosong Sun, Heng Yu category:cs.CL  published:2016-06-15 summary:We introduce an agreement-based approach to learning parallel lexicons and phrases from non-parallel corpora. The basic idea is to encourage two asymmetric latent-variable translation models (i.e., source-to-target and target-to-source) to agree on identifying latent phrase and word alignments. The agreement is defined at both word and phrase levels. We develop a Viterbi EM algorithm for jointly training the two unidirectional models efficiently. Experiments on the Chinese-English dataset show that agreement-based learning significantly improves both alignment and translation performance. version:1
arxiv-1502-07738 | Achieving Exact Cluster Recovery Threshold via Semidefinite Programming: Extensions | http://arxiv.org/abs/1502.07738 | id:1502.07738 author:Bruce Hajek, Yihong Wu, Jiaming Xu category:stat.ML cs.SI math.PR  published:2015-02-26 summary:Resolving a conjecture of Abbe, Bandeira and Hall, the authors have recently shown that the semidefinite programming (SDP) relaxation of the maximum likelihood estimator achieves the sharp threshold for exactly recovering the community structure under the binary stochastic block model of two equal-sized clusters. The same was shown for the case of a single cluster and outliers. Extending the proof techniques, in this paper it is shown that SDP relaxations also achieve the sharp recovery threshold in the following cases: (1) Binary stochastic block model with two clusters of sizes proportional to network size but not necessarily equal; (2) Stochastic block model with a fixed number of equal-sized clusters; (3) Binary censored block model with the background graph being Erd\H{o}s-R\'enyi. Furthermore, a sufficient condition is given for an SDP procedure to achieve exact recovery for the general case of a fixed number of clusters plus outliers. These results demonstrate the versatility of SDP relaxation as a simple, general purpose, computationally feasible methodology for community detection. version:3
arxiv-1606-04596 | Semi-Supervised Learning for Neural Machine Translation | http://arxiv.org/abs/1606.04596 | id:1606.04596 author:Yong Cheng, Wei Xu, Zhongjun He, Wei He, Hua Wu, Maosong Sun, Yang Liu category:cs.CL  published:2016-06-15 summary:While end-to-end neural machine translation (NMT) has made remarkable progress recently, NMT systems only rely on parallel corpora for parameter estimation. Since parallel corpora are usually limited in quantity, quality, and coverage, especially for low-resource languages, it is appealing to exploit monolingual corpora to improve NMT. We propose a semi-supervised approach for training NMT models on the concatenation of labeled (parallel corpora) and unlabeled (monolingual corpora) data. The central idea is to reconstruct the monolingual corpora using an autoencoder, in which the source-to-target and target-to-source translation models serve as the encoder and decoder, respectively. Our approach can not only exploit the monolingual corpora of the target language, but also of the source language. Experiments on the Chinese-English dataset show that our approach achieves significant improvements over state-of-the-art SMT and NMT systems. version:1
arxiv-1512-02433 | Minimum Risk Training for Neural Machine Translation | http://arxiv.org/abs/1512.02433 | id:1512.02433 author:Shiqi Shen, Yong Cheng, Zhongjun He, Wei He, Hua Wu, Maosong Sun, Yang Liu category:cs.CL  published:2015-12-08 summary:We propose minimum risk training for end-to-end neural machine translation. Unlike conventional maximum likelihood estimation, minimum risk training is capable of optimizing model parameters directly with respect to arbitrary evaluation metrics, which are not necessarily differentiable. Experiments show that our approach achieves significant improvements over maximum likelihood estimation on a state-of-the-art neural machine translation system across various languages pairs. Transparent to architectures, our approach can be applied to more neural networks and potentially benefit more NLP tasks. version:3
arxiv-1606-03558 | Universal Correspondence Network | http://arxiv.org/abs/1606.03558 | id:1606.03558 author:Christopher B. Choy, JunYoung Gwak, Silvio Savarese, Manmohan Chandraker category:cs.CV  published:2016-06-11 summary:We present a deep learning framework for accurate visual correspondences and demonstrate its effectiveness for both geometric and semantic matching, spanning across rigid motions to intra-class shape or appearance variations. In contrast to previous CNN-based approaches that optimize a surrogate patch similarity objective, we use deep metric learning to directly learn a feature space that preserves either geometric or semantic similarity. Our fully convolutional architecture, along with a novel correspondence contrastive loss allows faster training by effective reuse of computations, accurate gradient computation through the use of thousands of examples per image pair and faster testing with O(n) feedforward passes for n keypoints, instead of O(n^2) for typical patch similarity methods. We propose a convolutional spatial transformer to mimic patch normalization in traditional features like SIFT, which is shown to dramatically boost accuracy for semantic correspondences across intra-class shape variations. Extensive experiments on KITTI, PASCAL, and CUB-2011 datasets demonstrate the significant advantages of our features over prior works that use either hand-constructed or learned features. version:2
arxiv-1606-04590 | In the Shadows, Shape Priors Shine: Using Occlusion to Improve Multi-Region Segmentation | http://arxiv.org/abs/1606.04590 | id:1606.04590 author:Yuka Kihara, Matvey Soloviev, Tsuhan Chen category:cs.CV 65D19 I.4.6  published:2016-06-14 summary:We present a new algorithm for multi-region segmentation of 2D images with objects that may partially occlude each other. Our algorithm is based on the observation hat human performance on this task is based both on prior knowledge about plausible shapes and taking into account the presence of occluding objects whose shape is already known - once an occluded region is identified, the shape prior can be used to guess the shape of the missing part. We capture the former aspect using a deep learning model of shape; for the latter, we simultaneously minimize the energy of all regions and consider only unoccluded pixels for data agreement. Existing algorithms incorporating object shape priors consider every object separately in turn and can't distinguish genuine deviation from the expected shape from parts missing due to occlusion. We show that our method significantly improves on the performance of a representative algorithm, as evaluated on both preprocessed natural and synthetic images. Furthermore, on the synthetic images, we recover the ground truth segmentation with good accuracy. version:1
arxiv-1606-04586 | Regularization With Stochastic Transformations and Perturbations for Deep Semi-Supervised Learning | http://arxiv.org/abs/1606.04586 | id:1606.04586 author:Mehdi Sajjadi, Mehran Javanmardi, Tolga Tasdizen category:cs.CV  published:2016-06-14 summary:Effective convolutional neural networks are trained on large sets of labeled data. However, creating large labeled datasets is a very costly and time-consuming task. Semi-supervised learning uses unlabeled data to train a model with higher accuracy when there is a limited set of labeled data available. In this paper, we consider the problem of semi-supervised learning with convolutional neural networks. Techniques such as randomized data augmentation, dropout and random max-pooling provide better generalization and stability for classifiers that are trained using gradient descent. Multiple passes of an individual sample through the network might lead to different predictions due to the non-deterministic behavior of these techniques. We propose an unsupervised loss function that takes advantage of the stochastic nature of these methods and minimizes the difference between the predictions of multiple passes of a training sample through the network. We evaluate the proposed method on several benchmark datasets. version:1
arxiv-1606-04582 | Query-Regression Networks for Machine Comprehension | http://arxiv.org/abs/1606.04582 | id:1606.04582 author:Minjoon Seo, Hannaneh Hajishirzi, Ali Farhadi category:cs.CL  published:2016-06-14 summary:We present Query-Regression Network (QRN), a variant of Recurrent Neural Network (RNN) that is suitable for end-to-end machine comprehension. While previous work largely relied on external memory and attention mechanism, QRN is a single recurrent unit with internal memory. Unlike most RNN-based models, QRN is able to effectively handle long-term dependencies and is highly parallelizable. In our experiments we show that QRN outperforms the state of the art in end-to-end bAbI QA tasks. version:1
arxiv-1511-08861 | Loss Functions for Neural Networks for Image Processing | http://arxiv.org/abs/1511.08861 | id:1511.08861 author:Hang Zhao, Orazio Gallo, Iuri Frosio, Jan Kautz category:cs.CV  published:2015-11-28 summary:Neural networks are becoming central in several areas of computer vision and image processing and different architectures have been proposed to solve specific problems. The impact of the loss layer of neural networks, however, has not received much attention in the context of image processing: the default and virtually only choice is L2. In this paper we bring attention to alternative choices. We study the performance of several losses, including perceptually-motivated losses, and propose a novel, differentiable error function. We show that the quality of the results improves significantly with better loss functions, even when the network architecture is left unchanged. version:2
arxiv-1606-04561 | A two-stage learning method for protein-protein interaction prediction | http://arxiv.org/abs/1606.04561 | id:1606.04561 author:A. Ahooye Atashin, P. Bagherzadeh, K. Ghiasi-Shirazi category:cs.LG cs.CE  published:2016-06-14 summary:In this paper, a new method for PPI (proteinprotein interaction) prediction is proposed. In PPI prediction, a reliable and sufficient number of training samples is not available, but a large number of unlabeled samples is in hand. In the proposed method, the denoising auto encoders are employed for learning robust features. The obtained robust features are used in order to train a classifier with a better performance. The experimental results demonstrate the capabilities of the proposed method. Protein-protein interaction; Denoising auto encoder;Robust features; Unlabelled data; version:1
arxiv-1606-04552 | A New Approach to Dimensionality Reduction for Anomaly Detection in Data Traffic | http://arxiv.org/abs/1606.04552 | id:1606.04552 author:Tingshan Huang, Harish Sethu, Nagarajan Kandasamy category:cs.LG cs.CR cs.NI  published:2016-06-14 summary:The monitoring and management of high-volume feature-rich traffic in large networks offers significant challenges in storage, transmission and computational costs. The predominant approach to reducing these costs is based on performing a linear mapping of the data to a low-dimensional subspace such that a certain large percentage of the variance in the data is preserved in the low-dimensional representation. This variance-based subspace approach to dimensionality reduction forces a fixed choice of the number of dimensions, is not responsive to real-time shifts in observed traffic patterns, and is vulnerable to normal traffic spoofing. Based on theoretical insights proved in this paper, we propose a new distance-based approach to dimensionality reduction motivated by the fact that the real-time structural differences between the covariance matrices of the observed and the normal traffic is more relevant to anomaly detection than the structure of the training data alone. Our approach, called the distance-based subspace method, allows a different number of reduced dimensions in different time windows and arrives at only the number of dimensions necessary for effective anomaly detection. We present centralized and distributed versions of our algorithm and, using simulation on real traffic traces, demonstrate the qualitative and quantitative advantages of the distance-based subspace approach. version:1
arxiv-1606-04521 | Training variance and performance evaluation of neural networks in speech | http://arxiv.org/abs/1606.04521 | id:1606.04521 author:Ewout van den Berg, Bhuvana Ramabhadran, Michael Picheny category:cs.LG  published:2016-06-14 summary:In this work we study variance in the results of neural network training on a wide variety of configurations in automatic speech recognition. Although this variance itself is well known, this is, to the best of our knowledge, the first paper that performs an extensive empirical study on its effects in speech recognition. We view training as sampling from a distribution and show that these distributions can have a substantial variance. These results show the urgent need to rethink the way in which results in the literature are reported and interpreted. version:1
arxiv-1606-04518 | Sparsely Connected and Disjointly Trained Deep Neural Networks for Low Resource Behavioral Annotation: Acoustic Classification in Couples' Therapy | http://arxiv.org/abs/1606.04518 | id:1606.04518 author:Haoqi Li, Brian Baucom, Panayiotis Georgiou category:cs.LG cs.NE  published:2016-06-14 summary:Observational studies are based on accurate assessment of human state. A behavior recognition system that models interlocutors' state in real-time can significantly aid the mental health domain. However, behavior recognition from speech remains a challenging task since it is difficult to find generalizable and representative features because of noisy and high-dimensional data, especially when data is limited and annotated coarsely and subjectively. Deep Neural Networks (DNN) have shown promise in a wide range of machine learning tasks, but for Behavioral Signal Processing (BSP) tasks their application has been constrained due to limited quantity of data. We propose a Sparsely-Connected and Disjointly-Trained DNN (SD-DNN) framework to deal with limited data. First, we break the acoustic feature set into subsets and train multiple distinct classifiers. Then, the hidden layers of these classifiers become parts of a deeper network that integrates all feature streams. The overall system allows for full connectivity while limiting the number of parameters trained at any time and allows convergence possible with even limited data. We present results on multiple behavior codes in the couples' therapy domain and demonstrate the benefits in behavior classification accuracy. We also show the viability of this system towards live behavior annotations. version:1
arxiv-1509-04491 | Sparse Multinomial Logistic Regression via Approximate Message Passing | http://arxiv.org/abs/1509.04491 | id:1509.04491 author:Evan Byrne, Philip Schniter category:cs.IT math.IT stat.ML  published:2015-09-15 summary:For the problem of multi-class linear classification and feature selection, we propose approximate message passing approaches to sparse multinomial logistic regression (MLR). First, we propose two algorithms based on the Hybrid Generalized Approximate Message Passing (HyGAMP) framework: one finds the maximum a posteriori (MAP) linear classifier and the other finds an approximation of the test-error-rate minimizing linear classifier. Then we design computationally simplified variants of these two algorithms. Next, we detail methods to tune the hyperparameters of their assumed statistical models using Stein's unbiased risk estimate (SURE) and expectation-maximization (EM), respectively. Finally, using both synthetic and real-world datasets, we demonstrate improved error-rate and runtime performance relative to existing state-of-the-art approaches to sparse MLR. version:2
arxiv-1606-04506 | Max-Margin Feature Selection | http://arxiv.org/abs/1606.04506 | id:1606.04506 author:Yamuna Prasad, Dinesh Khandelwal, K. K. Biswas category:cs.LG cs.CV  published:2016-06-14 summary:Many machine learning applications such as in vision, biology and social networking deal with data in high dimensions. Feature selection is typically employed to select a subset of features which im- proves generalization accuracy as well as reduces the computational cost of learning the model. One of the criteria used for feature selection is to jointly minimize the redundancy and maximize the rele- vance of the selected features. In this paper, we formulate the task of feature selection as a one class SVM problem in a space where features correspond to the data points and instances correspond to the dimensions. The goal is to look for a representative subset of the features (support vectors) which describes the boundary for the region where the set of the features (data points) exists. This leads to a joint optimization of relevance and redundancy in a principled max-margin framework. Additionally, our formulation enables us to leverage existing techniques for optimizing the SVM objective resulting in highly computationally efficient solutions for the task of feature selection. Specifically, we employ the dual coordinate descent algorithm (Hsieh et al., 2008), originally proposed for SVMs, for our formulation. We use a sparse representation to deal with data in very high dimensions. Experiments on seven publicly available benchmark datasets from a variety of domains show that our approach results in orders of magnitude faster solutions even while retaining the same level of accuracy compared to the state of the art feature selection techniques. version:1
arxiv-1606-04503 | Shallow Discourse Parsing Using Distributed Argument Representations and Bayesian Optimization | http://arxiv.org/abs/1606.04503 | id:1606.04503 author:Akanksha, Jacob Eisenstein category:cs.CL  published:2016-06-14 summary:This paper describes the Georgia Tech team's approach to the CoNLL-2016 supplementary evaluation on discourse relation sense classification. We use long short-term memories (LSTM) to induce distributed representations of each argument, and then combine these representations with surface features in a neural network. The architecture of the neural network is determined by Bayesian hyperparameter search. version:1
arxiv-1505-04211 | Discontinuous Piecewise Polynomial Neural Networks | http://arxiv.org/abs/1505.04211 | id:1505.04211 author:John Loverich category:cs.NE  published:2015-05-15 summary:An artificial neural network is presented based on the idea of connections between units that are only active for a specific range of input values and zero outside that range (and so are not evaluated outside the active range). The connection function is represented by a polynomial with compact support. The finite range of activation allows for great activation sparsity in the network and means that theoretically you are able to add computational power to the network without increasing the computational time required to evaluate the network for a given input. The polynomial order ranges from first to fifth order. Unit dropout is used for regularization and a parameter free weight update is used. Better performance is obtained by moving from piecewise linear connections to piecewise quadratic, even better performance can be obtained by moving to higher order polynomials. The algorithm is tested on the MAGIC Gamma ray data set as well as the MNIST data set. version:2
arxiv-1606-04487 | Omnivore: An Optimizer for Multi-device Deep Learning on CPUs and GPUs | http://arxiv.org/abs/1606.04487 | id:1606.04487 author:Stefan Hadjis, Ce Zhang, Ioannis Mitliagkas, Christopher Ré category:cs.DC cs.LG I.2.6  published:2016-06-14 summary:We perform a study of the factors affecting training time in multi-device deep learning systems. Given a specification of a convolutional neural network, we study how to minimize the time to train this model on a cluster of commodity CPUs and GPUs. Our first contribution focuses on the single-node setting, in which we show that by using standard batching and data-parallel techniques throughput can be improved by at least 5.5x over state-of-the-art systems when training on CPUs. This ensures an end-to-end training time directly proportional to the throughput of a device regardless of its underlying hardware, allowing each node in the cluster to be treated as a black box. Our second contribution is a theoretical and empirical study of the tradeoffs affecting end-to-end training time in a multiple-device setting. We identify the degree of asynchronous parallelization as a key feature affecting both hardware and statistical efficiency. We show that asynchrony can be viewed as introducing a momentum parameter, which we use to limit our search space; in turn, this leads to a simpler optimizer, which is our third contribution. Our optimizer involves a predictive model for the total time to convergence and selects an allocation of resources to minimize that time. We demonstrate that the most popular distributed deep learning systems fall within our tradeoff space but do not optimize within the space. By doing such optimization, our prototype runs 1.9x to 12x faster than the fastest state-of-the-art systems. version:1
arxiv-1606-04478 | Bayesian Inference on Matrix Manifolds for Linear Dimensionality Reduction | http://arxiv.org/abs/1606.04478 | id:1606.04478 author:Andrew Holbrook, Alexander Vandenberg-Rodes, Babak Shahbaba category:stat.CO stat.ML  published:2016-06-14 summary:We reframe linear dimensionality reduction as a problem of Bayesian inference on matrix manifolds. This natural paradigm extends the Bayesian framework to dimensionality reduction tasks in higher dimensions with simpler models at greater speeds. Here an orthogonal basis is treated as a single point on a manifold and is associated with a linear subspace on which observations vary maximally. Throughout this paper, we employ the Grassmann and Stiefel manifolds for various dimensionality reduction problems, explore the connection between the two manifolds, and use Hybrid Monte Carlo for posterior sampling on the Grassmannian for the first time. We delineate in which situations either manifold should be considered. Further, matrix manifold models are used to yield scientific insight in the context of cognitive neuroscience, and we conclude that our methods are suitable for basic inference as well as accurate prediction. version:1
arxiv-1606-04474 | Learning to learn by gradient descent by gradient descent | http://arxiv.org/abs/1606.04474 | id:1606.04474 author:Marcin Andrychowicz, Misha Denil, Sergio Gomez, Matthew W. Hoffman, David Pfau, Tom Schaul, Nando de Freitas category:cs.NE cs.LG  published:2016-06-14 summary:The move from hand-designed features to learned features in machine learning has been wildly successful. In spite of this, optimization algorithms are still designed by hand. In this paper we show how the design of an optimization algorithm can be cast as a learning problem, allowing the algorithm to learn to exploit structure in the problems of interest in an automatic way. Our learned algorithms, implemented by LSTMs, outperform generic, hand-designed competitors on the tasks for which they are trained, and also generalize well to new tasks with similar structure. We demonstrate this on a number of tasks, including simple convex problems, training neural networks, and styling images with neural art. version:1
arxiv-1606-04535 | Efficient adaptation of complex-valued noiselet sensing matrices for compressed single-pixel imaging | http://arxiv.org/abs/1606.04535 | id:1606.04535 author:Anna Pastuszczak, Bartłomiej Szczygieł, Michał Mikołajczyk, Rafał Kotyński category:cs.CV cs.IT math.IT physics.optics  published:2016-06-14 summary:Minimal mutual coherence of discrete noiselets and Haar wavelets makes this pair of bases an essential choice for the measurement and compression matrices in compressed-sensing-based single-pixel detectors. In this paper we propose an efficient way of using complex-valued and non-binary noiselet functions for object sampling in single-pixel cameras with binary spatial light modulators and incoherent illumination. The proposed method allows to determine m complex noiselet coefficients from m+1 binary sampling measurements. Further, we introduce a modification to the complex fast noiselet transform, which enables computationally-efficient real-time generation of the binary noiselet-based patterns using efficient integer calculations on bundled patterns. The proposed method is verified experimentally with a single-pixel camera system using a binary spatial light modulator. version:1
arxiv-1606-04466 | Neural Networks and Continuous Time | http://arxiv.org/abs/1606.04466 | id:1606.04466 author:Frieder Stolzenburg, Florian Ruh category:cs.NE  published:2016-06-14 summary:The fields of neural computation and artificial neural networks have developed much in the last decades. Most of the works in these fields focus on implementing and/or learning discrete functions or behavior. However, technical, physical, and also cognitive processes evolve continuously in time. This cannot be described directly with standard architectures of artificial neural networks such as multi-layer feed-forward perceptrons. Therefore, in this paper, we will argue that neural networks modeling continuous time are needed explicitly for this purpose, because with them the synthesis and analysis of continuous and possibly periodic processes in time are possible (e.g. for robot behavior) besides computing discrete classification functions (e.g. for logical reasoning). We will relate possible neural network architectures with (hybrid) automata models that allow to express continuous processes. version:1
arxiv-1606-04460 | Model-Free Episodic Control | http://arxiv.org/abs/1606.04460 | id:1606.04460 author:Charles Blundell, Benigno Uria, Alexander Pritzel, Yazhe Li, Avraham Ruderman, Joel Z Leibo, Jack Rae, Daan Wierstra, Demis Hassabis category:stat.ML cs.LG q-bio.NC  published:2016-06-14 summary:State of the art deep reinforcement learning algorithms take many millions of interactions to attain human-level performance. Humans, on the other hand, can very quickly exploit highly rewarding nuances of an environment upon first discovery. In the brain, such rapid learning is thought to depend on the hippocampus and its capacity for episodic memory. Here we investigate whether a simple model of hippocampal episodic control can learn to solve difficult sequential decision-making tasks. We demonstrate that it not only attains a highly rewarding strategy significantly faster than state-of-the-art deep reinforcement learning algorithms, but also achieves a higher overall reward on some of the more challenging domains. version:1
arxiv-1606-04450 | Multiple Human Tracking in RGB-D Data: A Survey | http://arxiv.org/abs/1606.04450 | id:1606.04450 author:Massimo Camplani, Adeline Paiement, Majid Mirmehdi, Dima Damen, Sion Hannuna, Tilo Burghardt, Lili Tao category:cs.CV  published:2016-06-14 summary:Multiple human tracking (MHT) is a fundamental task in many computer vision applications. Appearance-based approaches, primarily formulated on RGB data, are constrained and affected by problems arising from occlusions and/or illumination variations. In recent years, the arrival of cheap RGB-Depth (RGB-D) devices has {led} to many new approaches to MHT, and many of these integrate color and depth cues to improve each and every stage of the process. In this survey, we present the common processing pipeline of these methods and review their methodology based (a) on how they implement this pipeline and (b) on what role depth plays within each stage of it. We identify and introduce existing, publicly available, benchmark datasets and software resources that fuse color and depth data for MHT. Finally, we present a brief comparative evaluation of the performance of those works that have applied their methods to these datasets. version:1
arxiv-1606-04449 | Recurrent neural network training with preconditioned stochastic gradient descent | http://arxiv.org/abs/1606.04449 | id:1606.04449 author:Xi-Lin Li category:stat.ML cs.LG  published:2016-06-14 summary:Recurrent neural networks (RNN), especially the ones requiring extremely long term memories, are difficult to training. Hence, they provide an ideal testbed for benchmarking the performance of optimization algorithms. This paper reports test results of a recently proposed preconditioned stochastic gradient descent (PSGD) algorithm on RNN training. We find that PSGD may outperform Hessian-free optimization which achieves the state-of-the-art performance on the target problems, although it is only slightly more complicated than stochastic gradient descent (SGD) and is user friendly, virtually a tuning free algorithm. version:1
arxiv-1606-04446 | Attend Refine Repeat: Active Box Proposal Generation via In-Out Localization | http://arxiv.org/abs/1606.04446 | id:1606.04446 author:Spyros Gidaris, Nikos Komodakis category:cs.CV  published:2016-06-14 summary:The problem of computing category agnostic bounding box proposals is utilized as a core component in many computer vision tasks and thus has lately attracted a lot of attention. In this work we propose a new approach to tackle this problem that is based on an active strategy for generating box proposals that starts from a set of seed boxes, which are uniformly distributed on the image, and then progressively moves its attention on the promising image areas where it is more likely to discover well localized bounding box proposals. We call our approach AttractioNet and a core component of it is a CNN-based category agnostic object location refinement module that is capable of yielding accurate and robust bounding box predictions regardless of the object category. We extensively evaluate our AttractioNet approach on several image datasets (i.e. COCO, PASCAL, ImageNet detection and NYU-Depth V2 datasets) reporting on all of them state-of-the-art results that surpass the previous work in the field by a significant margin and also providing strong empirical evidence that our approach is capable to generalize to unseen categories. Furthermore, we evaluate our AttractioNet proposals in the context of the object detection task using a VGG16-Net based detector and the achieved detection performance on COCO manages to significantly surpass all other VGG16-Net based detectors while even being competitive with a heavily tuned ResNet-101 based detector. Code as well as box proposals computed for several datasets are available at:: https://github.com/gidariss/AttractioNet. version:1
arxiv-1606-04443 | A scalable end-to-end Gaussian process adapter for irregularly sampled time series classification | http://arxiv.org/abs/1606.04443 | id:1606.04443 author:Steven Cheng-Xian Li, Benjamin Marlin category:stat.ML cs.LG  published:2016-06-14 summary:We present a general framework for classification of sparse and irregularly-sampled time series. The properties of such time series can result in substantial uncertainty about the values of the underlying temporal processes, while making the data difficult to deal with using standard classification methods that assume fixed-dimensional feature spaces. To address these challenges, we propose an uncertainty-aware classification framework based on a special computational layer we refer to as the Gaussian process adapter that can connect irregularly sampled time series data to to any black-box classifier learnable using gradient descent. We show how to scale up the required computations based on combining the structured kernel interpolation framework and the Lanczos approximation method, and how to discriminatively train the Gaussian process adapter in combination with a number of classifiers end-to-end using backpropagation. version:1
arxiv-1606-04442 | DeepMath - Deep Sequence Models for Premise Selection | http://arxiv.org/abs/1606.04442 | id:1606.04442 author:Alex A. Alemi, Francois Chollet, Geoffrey Irving, Christian Szegedy, Josef Urban category:cs.AI cs.LG cs.LO  published:2016-06-14 summary:We study the effectiveness of neural sequence models for premise selection in automated theorem proving, one of the main bottlenecks in the formalization of mathematics. We propose a two stage approach for this task that yields good results for the premise selection task on the Mizar corpus while avoiding the hand-engineered features of existing state-of-the-art models. To our knowledge, this is the first time deep learning has been applied to theorem proving. version:1
arxiv-1604-02313 | Norm-preserving Orthogonal Permutation Linear Unit Activation Functions (OPLU) | http://arxiv.org/abs/1604.02313 | id:1604.02313 author:Artem Chernodub, Dimitri Nowicki category:cs.NE  published:2016-04-08 summary:We propose a novel activation function that implements piece-wise orthogonal non-linear mappings based on permutations. It is straightforward to implement, and very computationally efficient, also it has little memory requirements. We tested it on two toy problems for feedforward and recurrent networks, it shows similar performance to tanh and ReLU. OPLU activation function ensures norm preservance of the backpropagated gradients, therefore it is potentially good for the training of deep, extra deep, and recurrent neural networks. version:2
arxiv-1603-01006 | Automatic learning of gait signatures for people identification | http://arxiv.org/abs/1603.01006 | id:1603.01006 author:F. M. Castro, M. J. Marin-Jimenez, N. Guil, N. Perez de la Blanca category:cs.CV cs.AI  published:2016-03-03 summary:This work targets people identification in video based on the way they walk (i.e. gait). While classical methods typically derive gait signatures from sequences of binary silhouettes, in this work we explore the use of convolutional neural networks (CNN) for learning high-level descriptors from low-level motion features (i.e. optical flow components). We carry out a thorough experimental evaluation of the proposed CNN architecture on the challenging TUM-GAID dataset. The experimental results indicate that using spatio-temporal cuboids of optical flow as input data for CNN allows to obtain state-of-the-art results on the gait task with an image resolution eight times lower than the previously reported results (i.e. 80x60 pixels). version:2
arxiv-1508-04422 | Scalable Out-of-Sample Extension of Graph Embeddings Using Deep Neural Networks | http://arxiv.org/abs/1508.04422 | id:1508.04422 author:Aren Jansen, Gregory Sell, Vince Lyzinski category:stat.ML cs.LG cs.NE stat.ME  published:2015-08-18 summary:Several popular graph embedding techniques for representation learning and dimensionality reduction rely on performing computationally expensive eigendecompositions to derive a nonlinear transformation of the input data space. The resulting eigenvectors encode the embedding coordinates for the training samples only, and so the embedding of novel data samples requires further costly computation. In this paper, we present a method for the out-of-sample extension of graph embeddings using deep neural networks (DNN) to parametrically approximate these nonlinear maps. Compared with traditional nonparametric out-of-sample extension methods, we demonstrate that the DNNs can generalize with equal or better fidelity and require orders of magnitude less computation at test time. Moreover, we find that unsupervised pretraining of the DNNs improves optimization for larger network sizes, thus removing sensitivity to model selection. version:3
arxiv-1606-04429 | Using Fuzzy Logic to Leverage HTML Markup for Web Page Representation | http://arxiv.org/abs/1606.04429 | id:1606.04429 author:Alberto P. García-Plaza, Víctor Fresno, Raquel Martínez, Arkaitz Zubiaga category:cs.IR cs.CL  published:2016-06-14 summary:The selection of a suitable document representation approach plays a crucial role in the performance of a document clustering task. Being able to pick out representative words within a document can lead to substantial improvements in document clustering. In the case of web documents, the HTML markup that defines the layout of the content provides additional structural information that can be further exploited to identify representative words. In this paper we introduce a fuzzy term weighing approach that makes the most of the HTML structure for document clustering. We set forth and build on the hypothesis that a good representation can take advantage of how humans skim through documents to extract the most representative words. The authors of web pages make use of HTML tags to convey the most important message of a web page through page elements that attract the readers' attention, such as page titles or emphasized elements. We define a set of criteria to exploit the information provided by these page elements, and introduce a fuzzy combination of these criteria that we evaluate within the context of a web page clustering task. Our proposed approach, called Abstract Fuzzy Combination of Criteria (AFCC), can adapt to datasets whose features are distributed differently, achieving good results compared to other similar fuzzy logic based approaches and TF-IDF across different datasets. version:1
arxiv-1606-04422 | Logic Tensor Networks: Deep Learning and Logical Reasoning from Data and Knowledge | http://arxiv.org/abs/1606.04422 | id:1606.04422 author:Luciano Serafini, Artur d'Avila Garcez category:cs.AI cs.LG cs.LO cs.NE  published:2016-06-14 summary:We propose real logic: a uniform framework for integrating automatic learning and reasoning. Real logic is defined on a full first-order language where formulas have truth-value in the interval [0,1] and semantics defined concretely on the domain of real numbers. Logical constants are interpreted as (feature) vectors of real numbers. Real logic promotes a well-founded integration of deductive reasoning on knowledge-bases with efficient, data-driven relational machine learning. We show how Real Logic can be implemented in deep Tensor Neural Networks with the use of Google's TensorFlow primitives. The paper concludes with experiments on a simple but representative example of knowledge completion. version:1
arxiv-1512-09080 | Detection in the stochastic block model with multiple clusters: proof of the achievability conjectures, acyclic BP, and the information-computation gap | http://arxiv.org/abs/1512.09080 | id:1512.09080 author:Emmanuel Abbe, Colin Sandon category:math.PR cs.CC cs.IT cs.LG cs.SI math.IT  published:2015-12-30 summary:In a paper that initiated the modern study of the stochastic block model, Decelle et al., backed by Mossel et al., made a fascinating conjecture: Denote by $k$ the number of balanced communities, $a/n$ the probability of connecting inside communities and $b/n$ across, and set $\mathrm{SNR}=(a-b)^2/(k(a+(k-1)b)$; for any $k \geq 2$, it is possible to detect communities efficiently whenever $\mathrm{SNR}>1$ (the KS threshold), whereas for $k\geq 4$, it is possible to detect communities information-theoretically for some $\mathrm{SNR}<1$. Massouli\'e, Mossel et al.\ and Bordenave et al.\ succeeded in proving that the KS threshold is efficiently achievable for $k=2$, while Mossel et al.\ proved that it cannot be crossed information-theoretically for $k=2$. The above conjecture remained open for $k \geq 3$. This paper proves this conjecture, and further extends the efficient detection to non-symmetrical SBMs with a generalized notion of detection and KS threshold. For the efficient part, a linearized acyclic belief propagation (ABP) algorithm is developed and proved to detect communities for any $k$ down to the KS threshold in time $O(n \log n)$. Achieving this requires showing optimality of ABP in the presence of cycles, a challenge in the realm of graphical models. The paper further connects ABP to a power iteration method with a nonbacktracking operator of generalized order, formalizing the interplay between message passing and spectral methods. For the information-theoretic (IT) part, a non-efficient algorithm sampling a typical clustering is shown to break down the KS threshold at $k=4$. The emerging gap is shown to be large in some cases; if $a=0$, the KS threshold reads $b \gtrsim k^2$ whereas the IT bound reads $b \gtrsim k \ln(k)$. version:3
arxiv-1606-04414 | The Parallel Knowledge Gradient Method for Batch Bayesian Optimization | http://arxiv.org/abs/1606.04414 | id:1606.04414 author:Jian Wu, Peter I. Frazier category:stat.ML cs.AI cs.LG  published:2016-06-14 summary:In many applications of black-box optimization, one can evaluate multiple points simultaneously, e.g. when evaluating the performances of several different neural network architectures in a parallel computing environment. In this paper, we develop a novel batch Bayesian optimization algorithm --- the parallel knowledge gradient method. By construction, this method provides the one-step Bayes optimal batch of points to sample. We provide an efficient strategy for computing this Bayes-optimal batch of points, and we demonstrate that the parallel knowledge gradient method finds global optima significantly faster than previous batch Bayesian optimization algorithms on both synthetic test functions and when tuning hyperparameters of practical machine learning algorithms, especially when function evaluations are noisy. version:1
arxiv-1606-04404 | End-to-End Comparative Attention Networks for Person Re-identification | http://arxiv.org/abs/1606.04404 | id:1606.04404 author:Hao Liu, Jiashi Feng, Meibin Qi, Jianguo Jiang, Shuicheng Yan category:cs.CV  published:2016-06-14 summary:Person re-identification across disjoint camera views has been widely applied in video surveillance yet it is still a challenging problem. One of the major challenges lies in the lack of spatial and temporal cues, which makes it difficult to deal with large variations of lighting conditions, viewing angles, body poses and occlusions. Recently, several deep learning based person re-identification approaches have been proposed and achieved remarkable performance. However, most of those approaches extract discriminative features from the whole frame at one glimpse without differentiating various parts of the persons to identify. It is essentially important to examine multiple highly discriminative local regions of the person images in details through multiple glimpses for dealing with the large appearance variance. In this paper, we propose a new soft attention based model, i.e., the end to-end Comparative Attention Network (CAN), specifically tailored for the task of person re-identification. The end-to-end CAN learns to selectively focus on parts of pairs of person images after taking a few glimpses of them and adaptively comparing their appearance. The CAN model is able to learn which parts of images are relevant for discerning persons and automatically integrates information from different parts to determine whether a pair of images belongs to the same person. In other words, our proposed CAN model simulates the human perception process to verify whether two images are from the same person. Extensive experiments on three benchmark person re-identification datasets, including CUHK01, CHUHK03 and Market-1501, clearly demonstrate that our proposed end-to-end CAN for person re-identification outperforms well established baselines significantly and offer new state-of-the-art performance. version:1
arxiv-1606-04393 | EvoNet: Evolutionary Synthesis of Deep Neural Networks | http://arxiv.org/abs/1606.04393 | id:1606.04393 author:Mohammad Javad Shafiee, Akshaya Mishra, Alexander Wong category:cs.CV cs.LG cs.NE stat.ML  published:2016-06-14 summary:In this study, we introduce the idea of synthesizing new highly efficient, yet powerful deep neural networks via a novel evolutionary process from ancestor deep neural networks. The architectural genetics of ancestor deep neural networks is encapsulated using the concept of synaptic probability density models, which can be viewed as the 'DNA' of these ancestor networks. These synaptic probability density models from the ancestor networks are then leveraged, along with computational environmental factor models to synthesize new descendant deep neural networks with different network architectures in a random manner to mimic natural selection and random mutations. These 'evolved' deep neural networks (which we will term EvoNets) are then trained into fully functional networks, like one would train a newborn, and have more efficient, more varied synapse architectures than their ancestor networks, while achieving powerful modeling capabilities. Experimental results using the MSRA-B dataset for the purpose of image segmentation was performed, and it was demonstrated that the synthesized EvoNets can achieve state-of-the-art F_beta score (0.872 at second generation, 0.859 at third generation, and 0.839 at fourth generation) while having synapse architectures that are significantly more efficient (~19X fewer synapses by the fourth generation) compared to the original ancestor deep neural network. version:1
arxiv-1605-08104 | Deep Predictive Coding Networks for Video Prediction and Unsupervised Learning | http://arxiv.org/abs/1605.08104 | id:1605.08104 author:William Lotter, Gabriel Kreiman, David Cox category:cs.LG cs.AI cs.CV cs.NE q-bio.NC  published:2016-05-25 summary:While great strides have been made in using deep learning algorithms to solve supervised learning tasks, the problem of unsupervised learning - leveraging unlabeled examples to learn about the structure of a domain - remains a difficult unsolved challenge. Here, we explore prediction of future frames in a video sequence as an unsupervised learning rule for learning about the structure of the visual world. We describe a predictive neural network ("PredNet") architecture that is inspired by the concept of "predictive coding" from the neuroscience literature. These networks learn to predict future frames in a video sequence, with each layer in the network making local predictions and only forwarding deviations from those predictions to subsequent network layers. We show that these networks are able to robustly learn to predict the movement of synthetic (rendered) objects, and that in doing so, the networks learn internal representations that are useful for decoding latent object parameters (e.g. pose) that support object recognition with fewer training views. We also show that these networks can scale to complex natural image streams (car-mounted camera videos), capturing key aspects of both egocentric movement and the movement of objects in the visual scene, and generalizing across video datasets. These results suggest that prediction represents a powerful framework for unsupervised learning, allowing for implicit learning of object and scene structure. version:2
arxiv-1606-04366 | Recursive nonlinear-system identification using latent variables | http://arxiv.org/abs/1606.04366 | id:1606.04366 author:Per Mattsson, Dave Zachariah, Petre Stoica category:stat.ML  published:2016-06-14 summary:In this paper we develop a method for learning nonlinear systems with multiple outputs and inputs. We begin by modelling the errors of a nominal predictor of the system using a latent variable framework. Then using the maximum likelihood principle we derive a criterion for learning the model. The resulting optimization problem is tackled using a majorization-minimization approach. Finally, we develop a convex majorization technique and show that it enables a recursive identification method. The method learns parsimonious predictive models and is tested on both synthetic and real nonlinear systems. version:1
arxiv-1505-04342 | Sifting Robotic from Organic Text: A Natural Language Approach for Detecting Automation on Twitter | http://arxiv.org/abs/1505.04342 | id:1505.04342 author:Eric M. Clark, Jake Ryland Williams, Chris A. Jones, Richard A. Galbraith, Christopher M. Danforth, Peter Sheridan Dodds category:cs.CL  published:2015-05-17 summary:Twitter, a popular social media outlet, has evolved into a vast source of linguistic data, rich with opinion, sentiment, and discussion. Due to the increasing popularity of Twitter, its perceived potential for exerting social influence has led to the rise of a diverse community of automatons, commonly referred to as bots. These inorganic and semi-organic Twitter entities can range from the benevolent (e.g., weather-update bots, help-wanted-alert bots) to the malevolent (e.g., spamming messages, advertisements, or radical opinions). Existing detection algorithms typically leverage meta-data (time between tweets, number of followers, etc.) to identify robotic accounts. Here, we present a powerful classification scheme that exclusively uses the natural language text from organic users to provide a criterion for identifying accounts posting automated messages. Since the classifier operates on text alone, it is flexible and may be applied to any textual data beyond the Twitter-sphere. version:6
arxiv-1606-04351 | TwiSE at SemEval-2016 Task 4: Twitter Sentiment Classification | http://arxiv.org/abs/1606.04351 | id:1606.04351 author:Georgios Balikas, Massih-Reza Amini category:cs.CL cs.IR cs.LG  published:2016-06-14 summary:This paper describes the participation of the team "TwiSE" in the SemEval 2016 challenge. Specifically, we participated in Task 4, namely "Sentiment Analysis in Twitter" for which we implemented sentiment classification systems for subtasks A, B, C and D. Our approach consists of two steps. In the first step, we generate and validate diverse feature sets for twitter sentiment evaluation, inspired by the work of participants of previous editions of such challenges. In the second step, we focus on the optimization of the evaluation measures of the different subtasks. To this end, we examine different learning strategies by validating them on the data provided by the task organisers. For our final submissions we used an ensemble learning approach (stacked generalization) for Subtask A and single linear models for the rest of the subtasks. In the official leaderboard we were ranked 9/35, 8/19, 1/11 and 2/14 for subtasks A, B, C and D respectively.\footnote{We make the code available for research purposes at \url{https://github.com/balikasg/SemEval2016-Twitter\_Sentiment\_Evaluation}.} version:1
arxiv-1606-02342 | Optimizing Spectral Learning for Parsing | http://arxiv.org/abs/1606.02342 | id:1606.02342 author:Shashi Narayan, Shay B. Cohen category:cs.CL  published:2016-06-07 summary:We describe a search algorithm for optimizing the number of latent states when estimating latent-variable PCFGs with spectral methods. Our results show that contrary to the common belief that the number of latent states for each nonterminal in an L-PCFG can be decided in isolation with spectral methods, parsing results significantly improve if the number of latent states for each nonterminal is globally optimized, while taking into account interactions between the different nonterminals. In addition, we contribute an empirical analysis of spectral algorithms on eight morphologically rich languages: Basque, French, German, Hebrew, Hungarian, Korean, Polish and Swedish. Our results show that our estimation consistently performs better or close to coarse-to-fine expectation-maximization techniques for these languages. version:3
arxiv-1606-04335 | LLFR: A Lanczos-Based Latent Factor Recommender for Big Data Scenarios | http://arxiv.org/abs/1606.04335 | id:1606.04335 author:Maria Kalantzi category:stat.ML cs.IR cs.SI  published:2016-06-14 summary:The purpose if this master's thesis is to study and develop a new algorithmic framework for Collaborative Filtering to produce recommendations in the top-N recommendation problem. Thus, we propose Lanczos Latent Factor Recommender (LLFR); a novel "big data friendly" collaborative filtering algorithm for top-N recommendation. Using a computationally efficient Lanczos-based procedure, LLFR builds a low dimensional item similarity model, that can be readily exploited to produce personalized ranking vectors over the item space. A number of experiments on real datasets indicate that LLFR outperforms other state-of-the-art top-N recommendation methods from a computational as well as a qualitative perspective. Our experimental results also show that its relative performance gains, compared to competing methods, increase as the data get sparser, as in the Cold Start Problem. More specifically, this is true both when the sparsity is generalized - as in the New Community Problem, a very common problem faced by real recommender systems in their beginning stages, when there is not sufficient number of ratings for the collaborative filtering algorithms to uncover similarities between items or users - and in the very interesting case where the sparsity is localized in a small fraction of the dataset - as in the New Users Problem, where new users are introduced to the system, they have not rated many items and thus, the CF algorithm can not make reliable personalized recommendations yet. version:1
arxiv-1606-04317 | Calibration of Phone Likelihoods in Automatic Speech Recognition | http://arxiv.org/abs/1606.04317 | id:1606.04317 author:David A. van Leeuwen, Joost van Doremalen category:stat.ML cs.LG cs.SD  published:2016-06-14 summary:In this paper we study the probabilistic properties of the posteriors in a speech recognition system that uses a deep neural network (DNN) for acoustic modeling. We do this by reducing Kaldi's DNN shared pdf-id posteriors to phone likelihoods, and using test set forced alignments to evaluate these using a calibration sensitive metric. Individual frame posteriors are in principle well-calibrated, because the DNN is trained using cross entropy as the objective function, which is a proper scoring rule. When entire phones are assessed, we observe that it is best to average the log likelihoods over the duration of the phone. Further scaling of the average log likelihoods by the logarithm of the duration slightly improves the calibration, and this improvement is retained when tested on independent test data. version:1
arxiv-1606-04316 | Time for a change: a tutorial for comparing multiple classifiers through Bayesian analysis | http://arxiv.org/abs/1606.04316 | id:1606.04316 author:Alessio Benavoli, Giorgio Corani, Janez Demsar, Marco Zaffalon category:stat.ML cs.LG  published:2016-06-14 summary:The machine learning community adopted the use of null hypothesis significance testing (NHST) in order to ensure the statistical validity of results. Many scientific fields however realized the shortcomings of frequentist reasoning and in the most radical cases even banned its use in publications. We should do the same: just as we have embraced the Bayesian paradigm in the development of new machine learning methods, so we should also use it in the analysis of our own results. We argue for abandonment of NHST by exposing its fallacies and, more importantly, offer better - more sound and useful - alternatives for it. version:1
arxiv-1606-03865 | Prediction Performance After Learning in Gaussian Process Regression | http://arxiv.org/abs/1606.03865 | id:1606.03865 author:Johan Wågberg, Dave Zachariah, Thomas B. Schön, Petre Stoica category:stat.ML  published:2016-06-13 summary:This paper considers the quantification of the prediction performance in Gaussian process regression. The standard approach is to base the prediction error bars on the theoretical predictive variance, which is a lower bound on the mean square-error. This approach, however, does not take into account that the statistical model is learned from the data. We show that this omission leads to a systematic underestimation of the prediction errors. Starting from a generalization of the Cram\'er-Rao bound, we derive a more accurate measure of uncertainty for prediction of Gaussian processes and illustrate it using synthetic and real data examples. version:2
arxiv-1606-04308 | Motion Deblurring for Light Fields | http://arxiv.org/abs/1606.04308 | id:1606.04308 author:Donald G. Dansereau, Anders Eriksson, Jürgen Leitner category:cs.CV  published:2016-06-14 summary:We generalize Richardson-Lucy deblurring to 4-D light fields by replacing the convolution steps with light field rendering of motion blur. The method deals correctly with blur caused by 6-degree-of-freedom camera motion in complex 3-D scenes, without performing depth estimation. We include a novel regularization term that maintains parallax information in the light field, and employ 4-D anisotropic total variation to reduce noise and ringing. We demonstrate the method operating effectively on rendered scenes and scenes captured using an off-the-shelf light field camera mounted on an industrial robot arm. Examples include complex 3-D geometry and cover all major classes of camera motion. Both qualitative and quantitative results confirm the effectiveness of the method over a range of conditions, including commonly occurring cases for which previously published methods fail. We include mathematical proof that the algorithm converges to the maximum-likelihood estimate of the unblurred scene under Poisson noise. version:1
arxiv-1606-04306 | Viral Search algorithm | http://arxiv.org/abs/1606.04306 | id:1606.04306 author:Matteo Gardini category:cs.NE  published:2016-06-14 summary:The article, after a brief introduction on genetic algorithms and their functioning, presents a kind of genetic algorithm called Viral Search. We present the key concepts, we formally derive the algorithm and we perform numerical tests designed to illustrate the potential and limits. version:1
arxiv-1606-04300 | Neural Word Segmentation Learning for Chinese | http://arxiv.org/abs/1606.04300 | id:1606.04300 author:Deng Cai, Hai Zhao category:cs.CL  published:2016-06-14 summary:Most previous approaches to Chinese word segmentation formalize this problem as a character-based sequence labeling task so that only contextual information within fixed sized local windows and simple interactions between adjacent tags can be captured. In this paper, we propose a novel neural framework which thoroughly eliminates context windows and can utilize complete segmentation history. Our model employs a gated combination neural network over characters to produce distributed representations of word candidates, which are then given to a long short-term memory (LSTM) language scoring model. Experiments on the benchmark datasets show that without the help of feature engineering as most existing approaches, our models achieve competitive or better performances with previous state-of-the-art methods. version:1
arxiv-1602-07109 | Variational Inference for On-line Anomaly Detection in High-Dimensional Time Series | http://arxiv.org/abs/1602.07109 | id:1602.07109 author:Maximilian Soelch, Justin Bayer, Marvin Ludersdorfer, Patrick van der Smagt category:stat.ML cs.LG  published:2016-02-23 summary:Approximate variational inference has shown to be a powerful tool for modeling unknown complex probability distributions. Recent advances in the field allow us to learn probabilistic models of sequences that actively exploit spatial and temporal structure. We apply a Stochastic Recurrent Network (STORN) to learn robot time series data. Our evaluation demonstrates that we can robustly detect anomalies both off- and on-line. version:5
arxiv-1606-04279 | Cross-Lingual Morphological Tagging for Low-Resource Languages | http://arxiv.org/abs/1606.04279 | id:1606.04279 author:Jan Buys, Jan A. Botha category:cs.CL  published:2016-06-14 summary:Morphologically rich languages often lack the annotated linguistic resources required to develop accurate natural language processing tools. We propose models suitable for training morphological taggers with rich tagsets for low-resource languages without using direct supervision. Our approach extends existing approaches of projecting part-of-speech tags across languages, using bitext to infer constraints on the possible tags for a given word type or token. We propose a tagging model using Wsabie, a discriminative embedding-based model with rank-based learning. In our evaluation on 11 languages, on average this model performs on par with a baseline weakly-supervised HMM, while being more scalable. Multilingual experiments show that the method performs best when projecting between related language pairs. Despite the inherently lossy projection, we show that the morphological tags predicted by our models improve the downstream performance of a parser by +0.6 LAS on average. version:1
arxiv-1606-04278 | Exact and efficient top-K inference for multi-target prediction by querying separable linear relational models | http://arxiv.org/abs/1606.04278 | id:1606.04278 author:Michiel Stock, Krzysztof Dembczynski, Bernard De Baets, Willem Waegeman category:cs.IR cs.LG  published:2016-06-14 summary:Many complex multi-target prediction problems that concern large target spaces are characterised by a need for efficient prediction strategies that avoid the computation of predictions for all targets explicitly. Examples of such problems emerge in several subfields of machine learning, such as collaborative filtering, multi-label classification, dyadic prediction and biological network inference. In this article we analyse efficient and exact algorithms for computing the top-$K$ predictions in the above problem settings, using a general class of models that we refer to as separable linear relational models. We show how to use those inference algorithms, which are modifications of well-known information retrieval methods, in a variety of machine learning settings. Furthermore, we study the possibility of scoring items incompletely, while still retaining an exact top-K retrieval. Experimental results in several application domains reveal that the so-called threshold algorithm is very scalable, performing often many orders of magnitude more efficiently than the naive approach. version:1
arxiv-1606-04275 | Efficient Pairwise Learning Using Kernel Ridge Regression: an Exact Two-Step Method | http://arxiv.org/abs/1606.04275 | id:1606.04275 author:Michiel Stock, Tapio Pahikkala, Antti Airola, Bernard De Baets, Willem Waegeman category:cs.LG  published:2016-06-14 summary:Pairwise learning or dyadic prediction concerns the prediction of properties for pairs of objects. It can be seen as an umbrella covering various machine learning problems such as matrix completion, collaborative filtering, multi-task learning, transfer learning, network prediction and zero-shot learning. In this work we analyze kernel-based methods for pairwise learning, with a particular focus on a recently-suggested two-step method. We show that this method offers an appealing alternative for commonly-applied Kronecker-based methods that model dyads by means of pairwise feature representations and pairwise kernels. In a series of theoretical results, we establish correspondences between the two types of methods in terms of linear algebra and spectral filtering, and we analyze their statistical consistency. In addition, the two-step method allows us to establish novel algorithmic shortcuts for efficient training and validation on very large datasets. Putting those properties together, we believe that this simple, yet powerful method can become a standard tool for many problems. Extensive experimental results for a range of practical settings are reported. version:1
arxiv-1606-04269 | Context Trees: Augmenting Geospatial Trajectories with Context | http://arxiv.org/abs/1606.04269 | id:1606.04269 author:Alasdair Thomason, Nathan Griffiths, Victor Sanchez category:cs.DS cs.LG  published:2016-06-14 summary:Exposing latent knowledge in geospatial trajectories has the potential to provide a better understanding of the movements of individuals and groups. Motivated by such a desire, this work presents the context tree, a new hierarchical data structure that summarises the context behind user actions in a single model. We propose a method for context tree construction that augments geospatial trajectories with land usage data to identify such contexts. Through evaluation of the construction method and analysis of the properties of generated context trees, we demonstrate the foundation for understanding and modelling behaviour afforded. Summarising user contexts into a single data structure gives easy access to information that would otherwise remain latent, providing the basis for better understanding and predicting the actions and behaviours of individuals and groups. Finally, we also present a method for pruning context trees, for use in applications where it is desirable to reduce the size of the tree while retaining useful information. version:1
arxiv-1606-04268 | Local Canonical Correlation Analysis for Nonlinear Common Variables Discovery | http://arxiv.org/abs/1606.04268 | id:1606.04268 author:Or Yair, Ronen Talmon category:cs.LG stat.ML  published:2016-06-14 summary:In this paper, we address the problem of hidden common variables discovery from multimodal data sets of nonlinear high-dimensional observations. We present a metric based on local applications of canonical correlation analysis (CCA) and incorporate it in a kernel-based manifold learning technique.We show that this metric discovers the hidden common variables underlying the multimodal observations by estimating the Euclidean distance between them. Our approach can be viewed both as an extension of CCA to a nonlinear setting as well as an extension of manifold learning to multiple data sets. Experimental results show that our method indeed discovers the common variables underlying high-dimensional nonlinear observations without assuming prior rigid model assumptions. version:1
arxiv-1508-03040 | Syntax Evolution: Problems and Recursion | http://arxiv.org/abs/1508.03040 | id:1508.03040 author:Ramón Casares category:cs.CL I.2.7; I.2.8  published:2015-08-12 summary:Why only we evolved Turing completeness? Turing completeness is the maximum computing capacity, and we are Turing complete because we can calculate whatever any Turing machine can compute. Thus we can learn any natural or artificial language, and it seems that no other species can, so we are the only Turing complete species. The evolutionary advantage of Turing completeness is full problem solving, and not syntactic proficiency, but the expression of problems requires a syntax because separate words are not enough, and only our ancestors evolved a protolanguage, and then a syntax, and finally Turing completeness. Besides these results, the introduction of Turing completeness and problem solving to explain the evolution of syntax should help us to fit the evolution of language in the evolution of cognition, giving us some new clues to understand the elusive relation between language and thinking. version:5
arxiv-1505-05770 | Variational Inference with Normalizing Flows | http://arxiv.org/abs/1505.05770 | id:1505.05770 author:Danilo Jimenez Rezende, Shakir Mohamed category:stat.ML cs.AI cs.LG stat.CO stat.ME  published:2015-05-21 summary:The choice of approximate posterior distribution is one of the core problems in variational inference. Most applications of variational inference employ simple families of posterior approximations in order to allow for efficient inference, focusing on mean-field or other simple structured approximations. This restriction has a significant impact on the quality of inferences made using variational methods. We introduce a new approach for specifying flexible, arbitrarily complex and scalable approximate posterior distributions. Our approximations are distributions constructed through a normalizing flow, whereby a simple initial density is transformed into a more complex one by applying a sequence of invertible transformations until a desired level of complexity is attained. We use this view of normalizing flows to develop categories of finite and infinitesimal flows and provide a unified view of approaches for constructing rich posterior approximations. We demonstrate that the theoretical advantages of having posteriors that better match the true posterior, combined with the scalability of amortized variational approaches, provides a clear improvement in performance and applicability of variational inference. version:6
arxiv-1308-3080 | Average Drift Analysis and Population Scalability | http://arxiv.org/abs/1308.3080 | id:1308.3080 author:Jun He, Xin Yao category:cs.NE  published:2013-08-14 summary:This paper aims to study how the population size affects the computation time of evolutionary algorithms in a rigorous way. The computation time of an evolutionary algorithm can be measured by either the expected number of generations (hitting time) or the expected number of fitness evaluations (running time) to find an optimal solution. Population scalability is the ratio of the expected hitting time between a benchmark algorithm and an algorithm using a larger population size. Average drift analysis is presented for comparing the expected hitting time of two algorithms and estimating lower and upper bounds on population scalability. Several intuitive beliefs are rigorously analysed. It is prove that (1) using a population sometimes increases rather than decreases the expected hitting time; (2) using a population cannot shorten the expected running time of any elitist evolutionary algorithm on unimodal functions in terms of the time-fitness landscape, but this is not true in terms of the distance-based fitness landscape; (3) using a population cannot always reduce the expected running time on fully-deceptive functions, which depends on the benchmark algorithm using elitist selection or random selection. version:4
arxiv-1606-03858 | Sorting out typicality with the inverse moment matrix SOS polynomial | http://arxiv.org/abs/1606.03858 | id:1606.03858 author:Jean-Bernard Lasserre, Edouard Pauwels category:cs.LG  published:2016-06-13 summary:We study a surprising phenomenon related to the representation of a cloud of data points using polynomials. We start with the previously unnoticed empirical observation that, given a collection (a cloud) of data points, the sublevel sets of a certain distinguished polynomial capture the shape of the cloud very accurately. This distinguished polynomial is a sum-of-squares (SOS) derived in a simple manner from the inverse of the empirical moment matrix. In fact, this SOS polynomial is directly related to orthogonal polynomials and the Christoffel function. This allows to generalize and interpret extremality properties of orthogonal polynomials and to provide a mathematical rationale for the observed phenomenon. Among diverse potential applications, we illustrate the relevance of our results on a network intrusion detection task for which we obtain performances similar to existing dedicated methods reported in the literature. version:2
arxiv-1606-03864 | Neural Associative Memory for Dual-Sequence Modeling | http://arxiv.org/abs/1606.03864 | id:1606.03864 author:Dirk Weissenborn category:cs.NE cs.AI cs.CL cs.LG  published:2016-06-13 summary:Many important NLP problems can be posed as dual-sequence or sequence-to-sequence modeling tasks. Recent advances in building end-to-end neural architectures have been highly successful in solving such tasks. In this work we propose a new architecture for dual-sequence modeling that is based on associative memory. We derive AM-RNNs, a recurrent associative memory (AM) which augments generic recurrent neural networks (RNN). This architecture is extended to the Dual AM-RNN which operates on two AMs at once. Our models achieve very competitive results on textual entailment. A qualitative analysis demonstrates that long range dependencies between source and target-sequence can be bridged effectively using Dual AM-RNNs. However, an initial experiment on auto-encoding reveals that these benefits are not exploited by the system when learning to solve sequence-to-sequence tasks which indicates that additional supervision or regularization is needed. version:2
arxiv-1606-04236 | Context-Aware Proactive Content Caching with Service Differentiation in Wireless Networks | http://arxiv.org/abs/1606.04236 | id:1606.04236 author:Sabrina Müller, Onur Atan, Mihaela van der Schaar, Anja Klein category:cs.NI cs.LG  published:2016-06-14 summary:Content caching in small base stations (SBSs) or wireless infostations is considered as a suitable approach to improve the efficiency in wireless content delivery. Due to storage limitations, placing the optimal content into local caches is crucial. Cache content placement is challenging since it requires knowledge about the content popularity distribution, which is often not available in advance. Moreover, content popularity is subject to fluctuations as mobile users with different interests connect to the caching entity over time. In this paper, we propose a novel algorithm for context-aware proactive cache content placement. By regularly observing context information of connected users, updating the cache content accordingly and observing the demands for cache content subsequently, the algorithm learns context-specific content popularity online over time. We derive a sub-linear regret bound, which characterizes the learning speed and proves that our algorithm asymptotically maximizes the average number of cache hits. Furthermore, our algorithm supports service differentiation by allowing operators of caching entities to prioritize groups of customers. Our numerical results confirm that by exploiting contextual information, our algorithm outperforms state-of-the-art algorithms in a real world data set, with an increase in the number of cache hits of at least 14%. version:1
arxiv-1606-04232 | DCNNs on a Diet: Sampling Strategies for Reducing the Training Set Size | http://arxiv.org/abs/1606.04232 | id:1606.04232 author:Maya Kabkab, Azadeh Alavi, Rama Chellappa category:cs.CV cs.LG  published:2016-06-14 summary:Large-scale supervised classification algorithms, especially those based on deep convolutional neural networks (DCNNs), require vast amounts of training data to achieve state-of-the-art performance. Decreasing this data requirement would significantly speed up the training process and possibly improve generalization. Motivated by this objective, we consider the task of adaptively finding concise training subsets which will be iteratively presented to the learner. We use convex optimization methods, based on an objective criterion and feedback from the current performance of the classifier, to efficiently identify informative samples to train on. We propose an algorithm to decompose the optimization problem into smaller per-class problems, which can be solved in parallel. We test our approach on standard classification tasks and demonstrate its effectiveness in decreasing the training set size without compromising performance. We also show that our approach can make the classifier more robust in the presence of label noise and class imbalance. version:1
arxiv-1606-04218 | Conditional Generative Moment-Matching Networks | http://arxiv.org/abs/1606.04218 | id:1606.04218 author:Yong Ren, Jialian Li, Yucen Luo, Jun Zhu category:cs.LG  published:2016-06-14 summary:Maximum mean discrepancy (MMD) has been successfully applied to learn deep generative models for characterizing a joint distribution of variables via kernel mean embedding. In this paper, we present conditional generative moment- matching networks (CGMMN), which learn a conditional distribution given some input variables based on a conditional maximum mean discrepancy (CMMD) criterion. The learning is performed by stochastic gradient descent with the gradient calculated by back-propagation. We evaluate CGMMN on a wide range of tasks, including predictive modeling, contextual generation, and Bayesian dark knowledge, which distills knowledge from a Bayesian model by learning a relatively small CGMMN student network. Our results demonstrate competitive performance in all the tasks. version:1
arxiv-1606-04217 | Word Representation Models for Morphologically Rich Languages in Neural Machine Translation | http://arxiv.org/abs/1606.04217 | id:1606.04217 author:Ekaterina Vylomova, Trevor Cohn, Xuanli He, Gholamreza Haffari category:cs.NE cs.CL  published:2016-06-14 summary:Dealing with the complex word forms in morphologically rich languages is an open problem in language processing, and is particularly important in translation. In contrast to most modern neural systems of translation, which discard the identity for rare words, in this paper we propose several architectures for learning word representations from character and morpheme level word decompositions. We incorporate these representations in a novel machine translation model which jointly learns word alignments and translations via a hard attention mechanism. Evaluating on translating from several morphologically rich languages into English, we show consistent improvements over strong baseline methods, of between 1 and 1.5 BLEU points. version:1
arxiv-1606-04212 | Active Discriminative Word Embedding Learning | http://arxiv.org/abs/1606.04212 | id:1606.04212 author:Ye Zhang, Byron Wallace category:cs.CL  published:2016-06-14 summary:We propose a new active learning (AL) method for text classification based on convolutional neural networks (CNNs). In AL, one selects the instances to be manually labeled with the aim of maximizing model performance with minimal effort. Neural models capitalize on word embeddings as features, tuning these to the task at hand. We argue that AL strategies for neural text classification should focus on selecting instances that most affect the embedding space (i.e., induce discriminative word representations). This is in contrast to traditional AL approaches (e.g.,uncertainty sampling), which specify higher level objectives. We propose a simple approach that selects instances containing words whose embeddings are likely to be updated with the greatest magnitude, thereby rapidly learning discriminative, task-specific embeddings. Empirical results show that our method outperforms baseline AL approaches. version:1
arxiv-1606-04052 | Dialog state tracking, a machine reading approach using a memory-enhanced neural network | http://arxiv.org/abs/1606.04052 | id:1606.04052 author:Julien Perez category:cs.CL cs.NE stat.ML  published:2016-06-13 summary:In an end-to-end dialog system, the aim of dialog state tracking is to accurately estimate a compact representation of the current dialog status from a sequence of noisy observations produced by the speech recognition and the natural language understanding modules. A state tracking module is primarily meant to act as support for a dialog policy but it can also be used as support for dialog corpus summarization and other kinds of information extraction from transcription of dialogs. From a probabilistic view, this is achieved by maintaining a posterior distribution over hidden dialog states composed, in the simplest case, of a set of context dependent variables. Once a dialog policy is defined, deterministic or learnt, it is in charge of selecting an optimal dialog act given the estimated dialog state and a defined reward function. This paper introduces a novel method of dialog state tracking based on the general paradigm of machine reading and proposes to solve it using a memory-enhanced neural network architecture. We evaluate the proposed approach on the second Dialog State Tracking Challenge (DSTC-2) dataset that has been converted for the occasion in order to fit the relaxed assumption of a machine reading formulation where the true state is only provided at the very end of each dialog instead of providing the state updates at the utterance level. We show that the proposed tracker gives encouraging results. Finally, we propose to extend the DSTC-2 dataset with specific reasoning capabilities requirement like counting, list maintenance, yes-no question answering and indefinite knowledge management. version:2
arxiv-1603-09643 | Multi-task Recurrent Model for Speech and Speaker Recognition | http://arxiv.org/abs/1603.09643 | id:1603.09643 author:Zhiyuan Tang, Lantian Li, Dong Wang category:cs.CL cs.LG cs.NE stat.ML  published:2016-03-31 summary:Although highly correlated, speech and speaker recognition have been regarded as two independent tasks and studied by two communities. This is certainly not the way that people behave: we decipher both speech content and speaker traits at the same time. This paper presents a unified model to perform speech and speaker recognition simultaneously and altogether. The model is based on a unified neural network where the output of one task is fed to the input of the other, leading to a multi-task recurrent network. Experiments show that the joint model outperforms the task-specific models on both the two tasks. version:3
arxiv-1606-04209 | A Systematic Approach to Blocking Convolutional Neural Networks | http://arxiv.org/abs/1606.04209 | id:1606.04209 author:Xuan Yang, Jing Pu, Blaine Burton Rister, Nikhil Bhagdikar, Stephen Richardson, Shahar Kvatinsky, Jonathan Ragan-Kelley, Ardavan Pedram, Mark Horowitz category:cs.DC cs.NE  published:2016-06-14 summary:Convolutional Neural Networks (CNNs) are the state of the art solution for many computer vision problems, and many researchers have explored optimized implementations. Most implementations heuristically block the computation to deal with the large data sizes and high data reuse of CNNs. This paper explores how to block CNN computations for memory locality by creating an analytical model for CNN-like loop nests. Using this model we automatically derive optimized blockings for common networks that improve the energy efficiency of custom hardware implementations by up to an order of magnitude. Compared to traditional CNN CPU implementations based on highly-tuned, hand-optimized BLAS libraries,our x86 programs implementing the optimal blocking reduce the number of memory accesses by up to 90%. version:1
arxiv-1511-04210 | On the Quality of the Initial Basin in Overspecified Neural Networks | http://arxiv.org/abs/1511.04210 | id:1511.04210 author:Itay Safran, Ohad Shamir category:cs.LG stat.ML  published:2015-11-13 summary:Deep learning, in the form of artificial neural networks, has achieved remarkable practical success in recent years, for a variety of difficult machine learning applications. However, a theoretical explanation for this remains a major open problem, since training neural networks involves optimizing a highly non-convex objective function, and is known to be computationally hard in the worst case. In this work, we study the \emph{geometric} structure of the associated non-convex objective function, in the context of ReLU networks and starting from a random initialization of the network parameters. We identify some conditions under which it becomes more favorable to optimization, in the sense of (i) High probability of initializing at a point from which there is a monotonically decreasing path to a global minimum; and (ii) High probability of initializing at a basin (suitably defined) with a small minimal objective value. A common theme in our results is that such properties are more likely to hold for larger ("overspecified") networks, which accords with some recent empirical and theoretical observations. version:3
arxiv-1604-04348 | Positive Definite Estimation of Large Covariance Matrix Using Generalized Nonconvex Penalties | http://arxiv.org/abs/1604.04348 | id:1604.04348 author:Fei Wen, Yuan Yang, Peilin Liu, Robert C. Qiu category:cs.IT cs.LG math.IT stat.ML  published:2016-04-15 summary:This work addresses the issue of large covariance matrix estimation in high-dimensional statistical analysis. Recently, improved iterative algorithms with positive-definite guarantee have been developed. However, these algorithms cannot be directly extended to use a nonconvex penalty for sparsity inducing. Generally, a nonconvex penalty has the capability of ameliorating the bias problem of the popular convex lasso penalty, and thus is more advantageous. In this work, we propose a class of positive-definite covariance estimators using generalized nonconvex penalties. We develop a first-order algorithm based on the alternating direction method (ADM) framework to solve the nonconvex optimization problem efficiently. The convergence of the proposed algorithm has been proved. Further, the statistical properties of the new estimators have been analyzed for generalized nonconvex penalties. Moreover, extension of the proposed algorithm to covariance estimation from sketched measurements has been considered. The performances of the proposed estimators have been demonstrated by both a simulation study and a gene clustering example for tumor tissues. version:2
arxiv-1603-07954 | Improving Information Extraction by Acquiring External Evidence with Reinforcement Learning | http://arxiv.org/abs/1603.07954 | id:1603.07954 author:Karthik Narasimhan, Adam Yala, Regina Barzilay category:cs.CL  published:2016-03-25 summary:Most successful information extraction systems operate with access to a large collection of documents. In this work, we explore the task of acquiring and incorporating external evidence to improve extraction accuracy in domains where the amount of training data is scarce. This process entails issuing search queries, extraction from new sources and reconciliation of extracted values, which are repeated until sufficient evidence is collected. We approach the problem using a reinforcement learning framework where our model learns to select optimal actions based on contextual information. We employ a deep Q-network, trained to optimize a reward function that reflects extraction accuracy while penalizing extra effort. Our experiments on two databases -- of shooting incidents, and food adulteration cases -- demonstrate that our system significantly outperforms traditional extractors and a competitive meta-classifier baseline. version:2
arxiv-1605-06069 | A Hierarchical Latent Variable Encoder-Decoder Model for Generating Dialogues | http://arxiv.org/abs/1605.06069 | id:1605.06069 author:Iulian Vlad Serban, Alessandro Sordoni, Ryan Lowe, Laurent Charlin, Joelle Pineau, Aaron Courville, Yoshua Bengio category:cs.CL cs.AI cs.LG cs.NE I.5.1; I.2.7  published:2016-05-19 summary:Sequential data often possesses a hierarchical structure with complex dependencies between subsequences, such as found between the utterances in a dialogue. In an effort to model this kind of generative process, we propose a neural network-based generative architecture, with latent stochastic variables that span a variable number of time steps. We apply the proposed model to the task of dialogue response generation and compare it with recent neural network architectures. We evaluate the model performance through automatic evaluation metrics and by carrying out a human evaluation. The experiments demonstrate that our model improves upon recently proposed models and that the latent variables facilitate the generation of long outputs and maintain the context. version:3
arxiv-1606-00776 | Multiresolution Recurrent Neural Networks: An Application to Dialogue Response Generation | http://arxiv.org/abs/1606.00776 | id:1606.00776 author:Iulian Vlad Serban, Tim Klinger, Gerald Tesauro, Kartik Talamadupula, Bowen Zhou, Yoshua Bengio, Aaron Courville category:cs.CL cs.AI cs.LG cs.NE stat.ML I.5.1; I.2.7  published:2016-06-02 summary:We introduce the multiresolution recurrent neural network, which extends the sequence-to-sequence framework to model natural language generation as two parallel discrete stochastic processes: a sequence of high-level coarse tokens, and a sequence of natural language tokens. There are many ways to estimate or learn the high-level coarse tokens, but we argue that a simple extraction procedure is sufficient to capture a wealth of high-level discourse semantics. Such procedure allows training the multiresolution recurrent neural network by maximizing the exact joint log-likelihood over both sequences. In contrast to the standard log- likelihood objective w.r.t. natural language tokens (word perplexity), optimizing the joint log-likelihood biases the model towards modeling high-level abstractions. We apply the proposed model to the task of dialogue response generation in two challenging domains: the Ubuntu technical support domain, and Twitter conversations. On Ubuntu, the model outperforms competing approaches by a substantial margin, achieving state-of-the-art results according to both automatic evaluation metrics and a human evaluation study. On Twitter, the model appears to generate more relevant and on-topic responses according to automatic evaluation metrics. Finally, our experiments demonstrate that the proposed model is more adept at overcoming the sparsity of natural language and is better able to capture long-term structure. version:2
arxiv-1606-04189 | Inverting face embeddings with convolutional neural networks | http://arxiv.org/abs/1606.04189 | id:1606.04189 author:Andrey Zhmoginov, Mark Sandler category:cs.CV cs.LG cs.NE  published:2016-06-14 summary:Deep neural networks have dramatically advanced the state of the art for many areas of machine learning. Recently they have been shown to have a remarkable ability to generate highly complex visual artifacts such as images and text rather than simply recognize them. In this work we use neural networks to effectively invert low-dimensional face embeddings while producing realistically looking consistent images. Our contribution is twofold, first we show that a gradient ascent style approaches can be used to reproduce consistent images, with a help of a guiding image. Second, we demonstrate that we can train a separate neural network to effectively solve the minimization problem in one pass, and generate images in real-time. We then evaluate the loss imposed by using a neural network instead of the gradient descent by comparing the final values of the minimized loss function. version:1
arxiv-1502-05890 | Contextual Semibandits via Supervised Learning Oracles | http://arxiv.org/abs/1502.05890 | id:1502.05890 author:Akshay Krishnamurthy, Alekh Agarwal, Miroslav Dudik category:cs.LG stat.ML  published:2015-02-20 summary:We study an online decision making problem where on each round a learner chooses a list of items based on some side information, receives a scalar feedback value for each individual item, and a reward that is linearly related to this feedback. These problems, known as contextual semibandits, arise in crowd-sourcing, recommendation, and many other domains. This paper reduces contextual semibandits to supervised learning, so that we can leverage powerful supervised learning methods in this partial-feedback setting. Our first reduction, which applies when the mapping from feedback to reward is known, leads to a computationally efficient algorithm with a near-optimal regret guarantee. We show that this algorithm outperforms state-of-the-art approaches on real-world learning-to-rank datasets, demonstrating the advantage of oracle-based algorithms. We also develop and analyze a novel algorithm for the setting where the linear transformation is unknown. version:3
arxiv-1603-06021 | A Fast Unified Model for Parsing and Sentence Understanding | http://arxiv.org/abs/1603.06021 | id:1603.06021 author:Samuel R. Bowman, Jon Gauthier, Abhinav Rastogi, Raghav Gupta, Christopher D. Manning, Christopher Potts category:cs.CL  published:2016-03-19 summary:Tree-structured neural networks exploit valuable syntactic parse information as they interpret the meanings of sentences. However, they suffer from two key technical problems that make them slow and unwieldy for large-scale NLP tasks: they usually operate on parsed sentences and they do not directly support batched computation. We address these issues by introducing the Stack-augmented Parser-Interpreter Neural Network (SPINN), which combines parsing and interpretation within a single tree-sequence hybrid model by integrating tree-structured sentence interpretation into the linear sequential structure of a shift-reduce parser. Our model supports batched computation for a speedup of up to 25 times over other tree-structured models, and its integrated parser can operate on unparsed data with little loss in accuracy. We evaluate it on the Stanford NLI entailment task and show that it significantly outperforms other sentence-encoding models. version:2
arxiv-1605-04056 | Causal Discovery for Manufacturing Domains | http://arxiv.org/abs/1605.04056 | id:1605.04056 author:Katerina Marazopoulou, Rumi Ghosh, Prasanth Lade, David Jensen category:cs.LG cs.AI  published:2016-05-13 summary:Yield and quality improvement is of paramount importance to any manufacturing company. One of the ways of improving yield is through discovery of the root causal factors affecting yield. We propose the use of data-driven interpretable causal models to identify key factors affecting yield. We focus on factors that are measured in different stages of production and testing in the manufacturing cycle of a product. We apply causal structure learning techniques on real data collected from this line. Specifically, the goal of this work is to learn interpretable causal models from observational data produced by manufacturing lines. Emphasis has been given to the interpretability of the models to make them actionable in the field of manufacturing. We highlight the challenges presented by assembly line data and propose ways to alleviate them.We also identify unique characteristics of data originating from assembly lines and how to leverage them in order to improve causal discovery. Standard evaluation techniques for causal structure learning shows that the learned causal models seem to closely represent the underlying latent causal relationship between different factors in the production process. These results were also validated by manufacturing domain experts who found them promising. This work demonstrates how data mining and knowledge discovery can be used for root cause analysis in the domain of manufacturing and connected industry. version:2
arxiv-1606-04166 | Modal-set estimation with an application to clustering | http://arxiv.org/abs/1606.04166 | id:1606.04166 author:Heinrich Jiang, Samory Kpotufe category:stat.ML cs.LG  published:2016-06-13 summary:We present a first procedure that can estimate -- with statistical consistency guarantees -- any local-maxima of a density, under benign distributional conditions. The procedure estimates all such local maxima, or $\textit{modal-sets}$, of any bounded shape or dimension, including usual point-modes. In practice, modal-sets can arise as dense low-dimensional structures in noisy data, and more generally serve to better model the rich variety of locally-high-density structures in data. The procedure is then shown to be competitive on clustering applications, and moreover is quite stable to a wide range of settings of its tuning parameter. version:1
arxiv-1606-04164 | Zero-Resource Translation with Multi-Lingual Neural Machine Translation | http://arxiv.org/abs/1606.04164 | id:1606.04164 author:Orhan Firat, Baskaran Sankaran, Yaser Al-Onaizan, Fatos T. Yarman Vural, Kyunghyun Cho category:cs.CL  published:2016-06-13 summary:In this paper, we propose a novel finetuning algorithm for the recently introduced multi-way, mulitlingual neural machine translate that enables zero-resource machine translation. When used together with novel many-to-one translation strategies, we empirically show that this finetuning algorithm allows the multi-way, multilingual model to translate a zero-resource language pair (1) as well as a single-pair neural translation model trained with up to 1M direct parallel sentences of the same language pair and (2) better than pivot-based translation strategy, while keeping only one additional copy of attention-related parameters. version:1
arxiv-1606-04160 | The Crossover Process: Learnability meets Protection from Inference Attacks | http://arxiv.org/abs/1606.04160 | id:1606.04160 author:Richard Nock, Giorgio Patrini, Finnian Lattimore, Tiberio Caetano category:cs.LG stat.ML I.2.6; K.4.1  published:2016-06-13 summary:It is usual to consider data protection and learnability as conflicting objectives. This is not always the case: we show how to jointly control causal inference --- seen as the attack --- \textit{and} learnability by a noise-free process that mixes training examples, the Crossover Process (cp). One key point is that the cp~is typically able to alter joint distributions without touching on marginals, nor altering the sufficient statistic for the class. In other words, it saves (and sometimes improves) generalization for supervised learning, but can alter the relationship between covariates --- and therefore fool statistical measures of (nonlinear) independence and causal inference into misleading ad-hoc conclusions. Experiments on a dozen readily available domains validate the theory. version:1
arxiv-1606-04155 | Rationalizing Neural Predictions | http://arxiv.org/abs/1606.04155 | id:1606.04155 author:Tao Lei, Regina Barzilay, Tommi Jaakkola category:cs.CL cs.NE  published:2016-06-13 summary:Prediction without justification has limited applicability. As a remedy, we learn to extract pieces of input text as justifications -- rationales -- that are tailored to be short and coherent, yet sufficient for making the same prediction. Our approach combines two modular components, generator and encoder, which are trained to operate well together. The generator specifies a distribution over text fragments as candidate rationales and these are passed through the encoder for prediction. Rationales are never given during training. Instead, the model is regularized by desiderata for rationales. We evaluate the approach on multi-aspect sentiment analysis against manually annotated test cases. Our approach outperforms attention-based baseline by a significant margin. We also successfully illustrate the method on the question retrieval task. version:1
arxiv-1605-04006 | A Gaussian Mixture MRF for Model-Based Iterative Reconstruction with Applications to Low-Dose X-ray CT | http://arxiv.org/abs/1605.04006 | id:1605.04006 author:Ruoqiao Zhang, Dong Hye Ye, Debashish Pal, Jean-Baptiste Thibault, Ken D. Sauer, Charles A. Bouman category:cs.CV math.OC physics.med-ph  published:2016-05-12 summary:Markov random fields (MRFs) have been widely used as prior models in various inverse problems such as tomographic reconstruction. While MRFs provide a simple and often effective way to model the spatial dependencies in images, they suffer from the fact that parameter estimation is difficult. In practice, this means that MRFs typically have very simple structure that cannot completely capture the subtle characteristics of complex images. In this paper, we present a novel Gaussian mixture Markov random field model (GM-MRF) that can be used as a very expressive prior model for inverse problems such as denoising and reconstruction. The GM-MRF forms a global image model by merging together individual Gaussian-mixture models (GMMs) for image patches. In addition, we present a novel analytical framework for computing MAP estimates using the GM-MRF prior model through the construction of surrogate functions that result in a sequence of quadratic optimizations. We also introduce a simple but effective method to adjust the GM-MRF so as to control the sharpness in low- and high-contrast regions of the reconstruction separately. We demonstrate the value of the model with experiments including image denoising and low-dose CT reconstruction. version:2
arxiv-1606-04145 | Sample Complexity of Automated Mechanism Design | http://arxiv.org/abs/1606.04145 | id:1606.04145 author:Maria-Florina Balcan, Tuomas Sandholm, Ellen Vitercik category:cs.LG cs.GT  published:2016-06-13 summary:The design of revenue-maximizing combinatorial auctions, i.e. multi-item auctions over bundles of goods, is one of the most fundamental problems in computational economics, unsolved even for two bidders and two items for sale. In the traditional economic models, it is assumed that the bidders' valuations are drawn from an underlying distribution and that the auction designer has perfect knowledge of this distribution. Despite this strong and oftentimes unrealistic assumption, it is remarkable that the revenue-maximizing combinatorial auction remains unknown. In recent years, automated mechanism design has emerged as one of the most practical and promising approaches to designing high-revenue combinatorial auctions. The most scalable automated mechanism design algorithms take as input samples from the bidders' valuation distribution and then search for a high-revenue auction in a rich auction class. In this work, we provide the first sample complexity analysis for the standard hierarchy of deterministic combinatorial auction classes used in automated mechanism design. In particular, we provide tight sample complexity bounds on the number of samples needed to guarantee that the empirical revenue of the designed mechanism on the samples is close to its expected revenue on the underlying, unknown distribution over bidder valuations, for each of the auction classes in the hierarchy. In addition to helping set automated mechanism design on firm foundations, our results also push the boundaries of learning theory. In particular, the hypothesis functions used in our contexts are defined through multi-stage combinatorial optimization procedures, rather than simple decision boundaries, as are common in machine learning. version:1
arxiv-1606-04142 | Mutual information for symmetric rank-one matrix estimation: A proof of the replica formula | http://arxiv.org/abs/1606.04142 | id:1606.04142 author:Jean Barbier, Mohamad Dia, Nicolas Macris, Florent Krzakala, Thibault Lesieur, Lenka Zdeborova category:cs.IT cond-mat.dis-nn cs.LG math-ph math.IT math.MP  published:2016-06-13 summary:Factorizing low-rank matrices has many applications in machine learning and statistics. For probabilistic models in the Bayes optimal setting, a general expression for the mutual information has been proposed using heuristic statistical physics computations, and proven in few specific cases. Here, we show how to rigorously prove the conjectured formula for the symmetric rank-one case. This allows to express the minimal mean-square-error and to characterize the detectability phase transitions in a large set of estimation problems ranging from community detection to sparse PCA. We also show that for a large set of parameters, an iterative algorithm called approximate message-passing is Bayes optimal. There exists, however, a gap between what currently known polynomial algorithms can do and what is expected information theoretically. Additionally, the proof technique has an interest of its own and exploits three essential ingredients: the interpolation method introduced in statistical physics by Guerra, the analysis of the approximate message-passing algorithm and the theory of spatial coupling and threshold saturation in coding. Our approach is generic and applicable to other open problems in statistical estimation where heuristic statistical physics predictions are available. version:1
arxiv-1606-04130 | Directly Modeling Missing Data in Sequences with RNNs: Improved Classification of Clinical Time Series | http://arxiv.org/abs/1606.04130 | id:1606.04130 author:Zachary C. Lipton, David C. Kale, Randall Wetzel category:cs.LG cs.IR cs.NE stat.ML  published:2016-06-13 summary:We demonstrate a simple strategy to cope with missing data in sequential inputs, addressing the task of multilabel classification of diagnoses given clinical time series. Collected from the intensive care unit (ICU) of a major urban medical center, our data consists of multivariate time series of observations. The data is irregularly sampled, leading to missingness patterns in re-sampled sequences. In this work, we show the remarkable ability of RNNs to make effective use of binary indicators to directly model missing data, improving AUC and F1 significantly. However, while RNNs can learn arbitrary functions of the missing data and observations, linear models can only learn substitution values. For linear models and MLPs, we show an alternative strategy to capture this signal. Additionally, we evaluate LSTMs, MLPs, and linear models trained on missingness patterns only, showing that for several diseases, what tests are run can be more predictive than the results themselves. version:1
arxiv-1508-02757 | De-biasing the Lasso: Optimal Sample Size for Gaussian Designs | http://arxiv.org/abs/1508.02757 | id:1508.02757 author:Adel Javanmard, Andrea Montanari category:math.ST stat.ML stat.TH  published:2015-08-11 summary:Performing statistical inference in high-dimension is an outstanding challenge. A major source of difficulty is the absence of precise information on the distribution of high-dimensional estimators. Here, we consider linear regression in the high-dimensional regime $p\gg n$. In this context, we would like to perform inference on a high-dimensional parameters vector $\theta^*\in{\mathbb R}^p$. Important progress has been achieved in computing confidence intervals for single coordinates $\theta^*_i$. A key role in these new methods is played by a certain debiased estimator $\hat{\theta}^{\rm d}$ that is constructed from the Lasso. Earlier work establishes that, under suitable assumptions on the design matrix, the coordinates of $\hat{\theta}^{\rm d}$ are asymptotically Gaussian provided $\theta^*$ is $s_0$-sparse with $s_0 = o(\sqrt{n}/\log p )$. The condition $s_0 = o(\sqrt{n}/ \log p )$ is stronger than the one for consistent estimation, namely $s_0 = o(n/ \log p)$. We study Gaussian designs with known or unknown population covariance. When the covariance is known, we prove that the debiased estimator is asymptotically Gaussian under the nearly optimal condition $s_0 = o(n/ (\log p)^2)$. Note that earlier work was limited to $s_0 = o(\sqrt{n}/\log p)$ even for perfectly known covariance. The same conclusion holds if the population covariance is unknown but can be estimated sufficiently well, e.g. under the same sparsity conditions on the inverse covariance as assumed by earlier work. For intermediate regimes, we describe the trade-off between sparsity in the coefficients and in the inverse covariance of the design. We further discuss several applications of our results to high-dimensional inference. In particular, we propose a new estimator that is minimax optimal up to a factor $1+o_n(1)$ for i.i.d. Gaussian designs. version:3
arxiv-1606-04081 | Graph-Community Detection for Cross-Document Topic Segment Relationship Identification | http://arxiv.org/abs/1606.04081 | id:1606.04081 author:Pedro Mota, Maxine Eskenazi, Luisa Coheur category:cs.CL cs.IR cs.SI  published:2016-06-13 summary:In this paper we propose a graph-community detection approach to identify cross-document relationships at the topic segment level. Given a set of related documents, we automatically find these relationships by clustering segments with similar content (topics). In this context, we study how different weighting mechanisms influence the discovery of word communities that relate to the different topics found in the documents. Finally, we test different mapping functions to assign topic segments to word communities, determining which topic segments are considered equivalent. By performing this task it is possible to enable efficient multi-document browsing, since when a user finds relevant content in one document we can provide access to similar topics in other documents. We deploy our approach in two different scenarios. One is an educational scenario where equivalence relationships between learning materials need to be found. The other consists of a series of dialogs in a social context where students discuss commonplace topics. Results show that our proposed approach better discovered equivalence relationships in learning material documents and obtained close results in the social speech domain, where the best performing approach was a clustering technique. version:1
arxiv-1606-04080 | Matching Networks for One Shot Learning | http://arxiv.org/abs/1606.04080 | id:1606.04080 author:Oriol Vinyals, Charles Blundell, Timothy Lillicrap, Koray Kavukcuoglu, Daan Wierstra category:cs.LG stat.ML  published:2016-06-13 summary:Learning from a few examples remains a key challenge in machine learning. Despite recent advances in important domains such as vision and language, the standard supervised deep learning paradigm does not offer a satisfactory solution for learning new concepts rapidly from little data. In this work, we employ ideas from metric learning based on deep neural features and from recent advances that augment neural networks with external memories. Our framework learns a network that maps a small labelled support set and an unlabelled example to its label, obviating the need for fine-tuning to adapt to new class types. We then define one-shot learning problems on vision (using Omniglot, ImageNet) and language tasks. Our algorithm improves one-shot accuracy on ImageNet from 87.6% to 93.2% and from 88.0% to 93.8% on Omniglot compared to competing approaches. We also demonstrate the usefulness of the same model on language modeling by introducing a one-shot task on the Penn Treebank. version:1
arxiv-1606-01305 | Zoneout: Regularizing RNNs by Randomly Preserving Hidden Activations | http://arxiv.org/abs/1606.01305 | id:1606.01305 author:David Krueger, Tegan Maharaj, János Kramár, Mohammad Pezeshki, Nicolas Ballas, Nan Rosemary Ke, Anirudh Goyal, Yoshua Bengio, Hugo Larochelle, Aaron Courville, Chris Pal category:cs.NE cs.CL cs.LG  published:2016-06-03 summary:We propose zoneout, a novel method for regularizing RNNs. At each timestep, zoneout stochastically forces some hidden units to maintain their previous values. Like dropout, zoneout uses random noise to train a pseudo-ensemble, improving generalization. But by preserving instead of dropping hidden units, gradient information and state information are more readily propagated through time, as in feedforward stochastic depth networks. We perform an empirical investigation of various RNN regularizers, and find encouraging results: zoneout gives significant performance improvements across tasks, yielding state-of-the-art results in character-level language modeling on the Penn Treebank dataset and competitive results on word-level Penn Treebank and permuted sequential MNIST classification tasks. version:2
arxiv-1606-04056 | On the exact learnability of graph parameters: The case of partition functions | http://arxiv.org/abs/1606.04056 | id:1606.04056 author:Nadia Labai, Johann A. Makowsky category:cs.LG math.CO I.2.6; G.2.1  published:2016-06-13 summary:We study the exact learnability of real valued graph parameters $f$ which are known to be representable as partition functions which count the number of weighted homomorphisms into a graph $H$ with vertex weights $\alpha$ and edge weights $\beta$. M. Freedman, L. Lov\'asz and A. Schrijver have given a characterization of these graph parameters in terms of the $k$-connection matrices $C(f,k)$ of $f$. Our model of learnability is based on D. Angluin's model of exact learning using membership and equivalence queries. Given such a graph parameter $f$, the learner can ask for the values of $f$ for graphs of their choice, and they can formulate hypotheses in terms of the connection matrices $C(f,k)$ of $f$. The teacher can accept the hypothesis as correct, or provide a counterexample consisting of a graph. Our main result shows that in this scenario, a very large class of partition functions, the rigid partition functions, can be learned in time polynomial in the size of $H$ and the size of the largest counterexample in the Blum-Shub-Smale model of computation over the reals with unit cost. version:1
arxiv-1606-04055 | Bacteria Foraging Algorithm with Genetic Operators for the Solution of QAP and mQAP | http://arxiv.org/abs/1606.04055 | id:1606.04055 author:Saeid Parvandeh, Ahmet Unveren, Bill C. White, Mohammadreza Boroumand, Parya Soltani category:cs.NE cs.AI  published:2016-06-13 summary:The Bacterial Foraging Optimization (BFO) is one of the metaheuristics algorithms that most widely used to solve optimization problems. The BFO is imitated from the behavior of the foraging bacteria group such as Ecoli. The main aim of algorithm is to eliminate those bacteria that have weak foraging methods and maintaining those bacteria that have strong foraging methods. In this extent, each bacterium communicates with other bacteria by sending signals such that bacterium change the position in the next step if prior factors have been satisfied. In fact, the process of algorithm allows bacteria to follow up nutrients toward the optimal. In this paper, the BFO is used for the solutions of Quadratic Assignment Problem (QAP), and multi- objective QAP (mQAP) by using updating mechanisms including mutation, crossover, and a local search. version:1
arxiv-1605-04135 | Online Optimization Methods for the Quantification Problem | http://arxiv.org/abs/1605.04135 | id:1605.04135 author:Purushottam Kar, Shuai Li, Harikrishna Narasimhan, Sanjay Chawla, Fabrizio Sebastiani category:stat.ML cs.AI cs.IR cs.LG  published:2016-05-13 summary:The estimation of class prevalence, i.e., the fraction of a population that belongs to a certain class, is a very useful tool in data analytics and learning, and finds applications in many domains such as sentiment analysis, epidemiology, etc. For example, in sentiment analysis, the objective is often not to estimate whether a specific text conveys a positive or a negative sentiment, but rather estimate the overall distribution of positive and negative sentiments during an event window. A popular way of performing the above task, often dubbed quantification, is to use supervised learning to train a prevalence estimator from labeled data. Contemporary literature cites several performance measures used to measure the success of such prevalence estimators. In this paper we propose the first online stochastic algorithms for directly optimizing these quantification-specific performance measures. We also provide algorithms that optimize hybrid performance measures that seek to balance quantification and classification performance. Our algorithms present a significant advancement in the theory of multivariate optimization and we show, by a rigorous theoretical analysis, that they exhibit optimal convergence. We also report extensive experiments on benchmark and real data sets which demonstrate that our methods significantly outperform existing optimization techniques used for these performance measures. version:3
arxiv-1606-04038 | Trace Norm Regularised Deep Multi-Task Learning | http://arxiv.org/abs/1606.04038 | id:1606.04038 author:Yongxin Yang, Timothy M. Hospedales category:cs.LG  published:2016-06-13 summary:In this paper, we propose a framework for training multiple neural networks simultaneously. The parameters from all models are regularised by the tensor trace norm, so that one neural network is encouraged to reuse others' parameters if possible -- this is the main motivation behind multi-task learning. In contrast to many deep multi-task learning work, we do not predefine a parameter sharing strategy by tying some (usually bottom) layers' parameters, instead, our framework allows the sharing for all shareable layers thus the sharing strategy is learned from a pure data-driven way. version:1
arxiv-1601-03916 | Multimodal Pivots for Image Caption Translation | http://arxiv.org/abs/1601.03916 | id:1601.03916 author:Julian Hitschler, Shigehiko Schamoni, Stefan Riezler category:cs.CL  published:2016-01-15 summary:We present an approach to improve statistical machine translation of image descriptions by multimodal pivots defined in visual space. The key idea is to perform image retrieval over a database of images that are captioned in the target language, and use the captions of the most similar images for crosslingual reranking of translation outputs. Our approach does not depend on the availability of large amounts of in-domain parallel data, but only relies on available large datasets of monolingually captioned images, and on state-of-the-art convolutional neural networks to compute image similarities. Our experimental evaluation shows improvements of 1 BLEU point over strong baselines. version:3
arxiv-1605-09186 | Does Multimodality Help Human and Machine for Translation and Image Captioning? | http://arxiv.org/abs/1605.09186 | id:1605.09186 author:Ozan Caglayan, Walid Aransa, Yaxing Wang, Marc Masana, Mercedes García-Martínez, Fethi Bougares, Loïc Barrault, Joost van de Weijer category:cs.CL cs.LG cs.NE  published:2016-05-30 summary:This paper presents the systems developed by LIUM and CVC for the WMT16 Multimodal Machine Translation challenge. We explored various comparative methods, namely phrase-based systems and attentional recurrent neural networks models trained using monomodal or multimodal data. We also performed a human evaluation in order to estimate the usefulness of multimodal data for human machine translation and image description generation. Our systems obtained the best results for both tasks according to the automatic evaluation metrics BLEU and METEOR. version:3
arxiv-1605-06376 | Fast $ε$-free Inference of Simulation Models with Bayesian Conditional Density Estimation | http://arxiv.org/abs/1605.06376 | id:1605.06376 author:George Papamakarios, Iain Murray category:stat.ML cs.LG stat.CO  published:2016-05-20 summary:Many statistical models can be simulated forwards but have intractable likelihoods. Approximate Bayesian Computation (ABC) methods are used to infer properties of these models from data. Traditionally these methods approximate the posterior over parameters by conditioning on data being inside an $\epsilon$-ball around the observed data, which is only correct in the limit $\epsilon\!\rightarrow\!0$. Monte Carlo methods can then draw samples from the approximate posterior to approximate predictions or error bars on parameters. These algorithms critically slow down as $\epsilon\!\rightarrow\!0$, and in practice draw samples from a broader distribution than the posterior. We propose a new approach to likelihood-free inference based on Bayesian conditional density estimation. Preliminary inferences based on limited simulation data are used to guide later simulations. In some cases, learning an accurate parametric representation of the entire true posterior distribution requires fewer model simulations than Monte Carlo ABC methods need to produce a single sample from an approximate posterior. version:2
arxiv-1606-03976 | Bounding and Minimizing Counterfactual Error | http://arxiv.org/abs/1606.03976 | id:1606.03976 author:Uri Shalit, Fredrik Johansson, David Sontag category:stat.ML cs.AI cs.LG  published:2016-06-13 summary:There is intense interest in applying machine learning methods to problems of causal inference which arise in applications such as healthcare, economic policy, and education. In this paper we use the counterfactual inference approach to causal inference, and propose new theoretical results and new algorithms for performing counterfactual inference. Building on an idea recently proposed by Johansson et al., our results and methods rely on learning so-called "balanced" representations: representations that are similar between the factual and counterfactual distributions. We give a novel, simple and intuitive bound, showing that the expected counterfactual error of a representation is bounded by a sum of the factual error of that representation and the distance between the factual and counterfactual distributions induced by the representation. We use Integral Probability Metrics to measure distances between distributions, and focus on two special cases: the Wasserstein distance and the Maximum Mean Discrepancy (MMD) distance. Our bound leads directly to new algorithms, which are simpler and easier to employ compared to those suggested in Johansson et al.. Experiments on real and simulated data show the new algorithms match or outperform state-of-the-art methods. version:1
arxiv-1606-03968 | Visual-Inertial Scene Representations | http://arxiv.org/abs/1606.03968 | id:1606.03968 author:Stefano Soatto category:cs.CV cs.AI  published:2016-06-13 summary:We describe a representation of a scene that captures geometric and semantic attributes of objects within, along with their uncertainty. Objects are assumed persistent in the scene, and their likelihood computed from intermittent visual data using a convolutional architecture, integrated within a Bayesian filtering framework with inertials and a context model. Our method yields a posterior estimate of geometry (attributed point cloud and associated uncertainty), semantics (identities and co-occurrence), and a point-estimate of topology for a variable number of objects within the scene, implemented causally and in real-time on commodity hardware. version:1
arxiv-1606-03966 | A Multiworld Testing Decision Service | http://arxiv.org/abs/1606.03966 | id:1606.03966 author:Alekh Agarwal, Sarah Bird, Markus Cozowicz, Luong Hoang, John Langford, Stephen Lee, Jiaji Li, Dan Melamed, Gal Oshri, Oswaldo Ribas, Siddhartha Sen, Alex Slivkins category:cs.LG cs.DC  published:2016-06-13 summary:Applications and systems are constantly faced with decisions to make, often using a policy to pick from a set of actions based on some contextual information. We create a service that uses machine learning to accomplish this goal. The service uses exploration, logging, and online learning to create a counterfactually sound system supporting a full data lifecycle. The system is general: it works for any discrete choices, with respect to any reward metric, and can work with many learning algorithms and feature representations. The service has a simple API, and was designed to be modular and reproducible to ease deployment and debugging, respectively. We demonstrate how these properties enable learning systems that are robust and safe. Our evaluation shows that the Decision Service makes decisions in real time and incorporates new data quickly into learned policies. A large-scale deployment for a personalized news website has been handling all traffic since Jan. 2016, resulting in a 25% relative lift in clicks. By making the Decision Service externally available, we hope to make optimal decision making available to all. version:1
arxiv-1606-03956 | Inferring Sparsity: Compressed Sensing using Generalized Restricted Boltzmann Machines | http://arxiv.org/abs/1606.03956 | id:1606.03956 author:Eric W. Tramel, Andre Manoel, Francesco Caltagirone, Marylou Gabrié, Florent Krzakala category:cs.IT cond-mat.dis-nn cs.LG math.IT stat.ML  published:2016-06-13 summary:In this work, we consider compressed sensing reconstruction from $M$ measurements of $K$-sparse structured signals which do not possess a writable correlation model. Assuming that a generative statistical model, such as a Boltzmann machine, can be trained in an unsupervised manner on example signals, we demonstrate how this signal model can be used within a Bayesian framework of signal reconstruction. By deriving a message-passing inference for general distribution restricted Boltzmann machines, we are able to integrate these inferred signal models into approximate message passing for compressed sensing reconstruction. Finally, we show for the MNIST dataset that this approach can be very effective, even for $M < K$. version:1
arxiv-1606-02228 | Systematic evaluation of CNN advances on the ImageNet | http://arxiv.org/abs/1606.02228 | id:1606.02228 author:Dmytro Mishkin, Nikolay Sergievskiy, Jiri Matas category:cs.NE cs.CV cs.LG  published:2016-06-07 summary:The paper systematically studies the impact of a range of recent advances in CNN architectures and learning methods on the object categorization (ILSVRC) problem. The evalution tests the influence of the following choices of the architecture: non-linearity (ReLU, ELU, maxout, compatibility with batch normalization), pooling variants (stochastic, max, average, mixed), network width, classifier design (convolutional, fully-connected, SPP), image pre-processing, and of learning parameters: learning rate, batch size, cleanliness of the data, etc. The performance gains of the proposed modifications are first tested individually and then in combination. The sum of individual gains is bigger than the observed improvement when all modifications are introduced, but the "deficit" is small suggesting independence of their benefits. We show that the use of 128x128 pixel images is sufficient to make qualitative conclusions about optimal network structure that hold for the full size Caffe and VGG nets. The results are obtained an order of magnitude faster than with the standard 224 pixel images. version:2
arxiv-1606-02617 | Efficient Estimation of k for the Nearest Neighbors Class of Methods | http://arxiv.org/abs/1606.02617 | id:1606.02617 author:Aleksander Lodwich, Faisal Shafait, Thomas Breuel category:cs.LG  published:2016-06-08 summary:The k Nearest Neighbors (kNN) method has received much attention in the past decades, where some theoretical bounds on its performance were identified and where practical optimizations were proposed for making it work fairly well in high dimensional spaces and on large datasets. From countless experiments of the past it became widely accepted that the value of k has a significant impact on the performance of this method. However, the efficient optimization of this parameter has not received so much attention in literature. Today, the most common approach is to cross-validate or bootstrap this value for all values in question. This approach forces distances to be recomputed many times, even if efficient methods are used. Hence, estimating the optimal k can become expensive even on modern systems. Frequently, this circumstance leads to a sparse manual search of k. In this paper we want to point out that a systematic and thorough estimation of the parameter k can be performed efficiently. The discussed approach relies on large matrices, but we want to argue, that in practice a higher space complexity is often much less of a problem than repetitive distance computations. version:2
arxiv-1606-03871 | Photo Stylistic Brush: Robust Style Transfer via Superpixel-Based Bipartite Graph | http://arxiv.org/abs/1606.03871 | id:1606.03871 author:Jiaying Liu, Wenhan Yang, Xiaoyan Sun, Wenjun Zeng category:cs.CV  published:2016-06-13 summary:With the rapid development of social network and multimedia technology, customized image and video stylization has been widely used for various social-media applications. In this paper, we explore the problem of exemplar-based photo style transfer, which provides a flexible and convenient way to invoke fantastic visual impression. Rather than investigating some fixed artistic patterns to represent certain styles as was done in some previous works, our work emphasizes styles related to a series of visual effects in the photograph, e.g. color, tone, and contrast. We propose a photo stylistic brush, an automatic robust style transfer approach based on Superpixel-based BIpartite Graph (SuperBIG). A two-step bipartite graph algorithm with different granularity levels is employed to aggregate pixels into superpixels and find their correspondences. In the first step, with the extracted hierarchical features, a bipartite graph is constructed to describe the content similarity for pixel partition to produce superpixels. In the second step, superpixels in the input/reference image are rematched to form a new superpixel-based bipartite graph, and superpixel-level correspondences are generated by a bipartite matching. Finally, the refined correspondence guides SuperBIG to perform the transformation in a decorrelated color space. Extensive experimental results demonstrate the effectiveness and robustness of the proposed method for transferring various styles of exemplar images, even for some challenging cases, such as night images. version:1
arxiv-1606-03860 | Reweighted Data for Robust Probabilistic Models | http://arxiv.org/abs/1606.03860 | id:1606.03860 author:Yixin Wang, Alp Kucukelbir, David M. Blei category:stat.ML cs.AI cs.LG  published:2016-06-13 summary:Probabilistic models analyze data by relying on a set of assumptions. When a model performs poorly, we challenge its assumptions. This approach has led to myriad hand-crafted robust models; they offer protection against small deviations from their assumptions. We propose a simple way to systematically mitigate mismatch of a large class of probabilistic models. The idea is to raise the likelihood of each observation to a weight. Inferring these weights allows a model to identify observations that match its assumptions; down-weighting others enables robust inference and improved predictive accuracy. We study four different forms of model mismatch, ranging from missing latent groups to structure misspecification. A Poisson factorization analysis of the Movielens dataset shows the benefits of reweighting in a real data scenario. version:1
arxiv-1511-01756 | "Pale as death" or "pâle comme la mort" : Frozen similes used as literary clichés | http://arxiv.org/abs/1511.01756 | id:1511.01756 author:Suzanne Mpouli, Jean-Gabriel Ganascia category:cs.CL  published:2015-11-05 summary:The present study is focused on the automatic identification and description of frozen similes in British and French novels written between the 19 th century and the beginning of the 20 th century. Two main patterns of frozen similes were considered: adjectival ground + simile marker + nominal vehicle (e.g. happy as a lark) and eventuality + simile marker + nominal vehicle (e.g. sleep like a top). All potential similes and their components were first extracted using a rule-based algorithm. Then, frozen similes were identified based on reference lists of existing similes and semantic distance between the tenor and the vehicle. The results obtained tend to confirm the fact that frozen similes are not used haphazardly in literary texts. In addition, contrary to how they are often presented, frozen similes often go beyond the ground or the eventuality and the vehicle to also include the tenor. version:2
arxiv-1606-03841 | Efficient Learning with a Family of Nonconvex Regularizers by Redistributing Nonconvexity | http://arxiv.org/abs/1606.03841 | id:1606.03841 author:Quanming Yao, James. T Kwok category:math.OC cs.LG stat.ML  published:2016-06-13 summary:The use of convex regularizers allow for easy optimization, though they often produce biased estimation and inferior prediction performance. Recently, nonconvex regularizers have attracted a lot of attention and outperformed convex ones. However, the resultant optimization problem is much harder. In this paper, for a large class of nonconvex regularizers, we propose to move the nonconvexity from the regularizer to the loss. The nonconvex regularizer is then transformed to a familiar convex regularizer, while the resultant loss function can still be guaranteed to be smooth. Learning with the convexified regularizer can be performed by existing efficient algorithms originally designed for convex regularizers (such as the standard proximal algorithm and Frank-Wolfe algorithm). Moreover, it can be shown that critical points of the transformed problem are also critical points of the original problem. Extensive experiments on a number of nonconvex regularization problems show that the proposed procedure is much faster than the state-of-the-art nonconvex solvers. version:1
arxiv-1606-03838 | Laplacian LRR on Product Grassmann Manifolds for Human Activity Clustering in Multi-Camera Video Surveillance | http://arxiv.org/abs/1606.03838 | id:1606.03838 author:Boyue Wang, Yongli Hu, Junbin Gao, Yanfeng Sun, Baocai Yin category:cs.CV  published:2016-06-13 summary:In multi-camera video surveillance, it is challenging to represent videos from different cameras properly and fuse them efficiently for specific applications such as human activity recognition and clustering. In this paper, a novel representation for multi-camera video data, namely the Product Grassmann Manifold (PGM), is proposed to model video sequences as points on the Grassmann manifold and integrate them as a whole in the product manifold form. Additionally, with a new geometry metric on the product manifold, the conventional Low Rank Representation (LRR) model is extended onto PGM and the new LRR model can be used for clustering non-linear data, such as multi-camera video data. To evaluate the proposed method, a number of clustering experiments are conducted on several multi-camera video datasets of human activity, including Dongzhimen Transport Hub Crowd action dataset, ACT 42 Human action dataset and SKIG action dataset. The experiment results show that the proposed method outperforms many state-of-the-art clustering methods. version:1
arxiv-1603-02740 | Pairwise Choice Markov Chains | http://arxiv.org/abs/1603.02740 | id:1603.02740 author:Stephen Ragain, Johan Ugander category:stat.ML cs.AI  published:2016-03-08 summary:As datasets capturing human choices grow in richness and scale---particularly in online domains---there is an increasing need for choice models that escape traditional choice-theoretic axioms such as regularity, stochastic transitivity, and Luce's choice axiom. In this work we introduce the Pairwise Choice Markov Chain (PCMC) model of discrete choice, an inferentially tractable model that does not assume any of the above axioms while still satisfying the foundational axiom of uniform expansion, a considerably weaker assumption than Luce's choice axiom. We show that the PCMC model significantly outperforms the Multinomial Logit (MNL) model in prediction tasks on both synthetic and empirical datasets known to exhibit violations of Luce's axiom. Our analysis also synthesizes several recent observations connecting the Multinomial Logit model and Markov chains; the PCMC model retains the Multinomial Logit model as a special case. version:2
arxiv-1604-06896 | Why and How to Pay Different Attention to Phrase Alignments of Different Intensities | http://arxiv.org/abs/1604.06896 | id:1604.06896 author:Wenpeng Yin, Hinrich Schütze category:cs.CL  published:2016-04-23 summary:This work studies comparatively two typical sentence pair classification tasks: textual entailment (TE) and answer selection (AS), observing that phrase alignments of different intensities contribute differently in these tasks. We address the problems of identifying phrase alignments of flexible granularity and pooling alignments of different intensities for these tasks. Examples for flexible granularity are alignments between two single words, between a single word and a phrase and between a short phrase and a long phrase. By intensity we roughly mean the degree of match, it ranges from identity over surface-form co-occurrence, rephrasing and other semantic relatedness to unrelated words as in lots of parenthesis text. Prior work (i) has limitations in phrase generation and representation, or (ii) conducts alignment at word and phrase levels by handcrafted features or (iii) utilizes a single attention mechanism over alignment intensities without considering the characteristics of specific tasks, which limits the system's effectiveness across tasks. We propose an architecture based on Gated Recurrent Unit that supports (i) representation learning of phrases of arbitrary granularity and (ii) task-specific focusing of phrase alignments between two sentences by attention pooling. Experimental results on TE and AS match our observation and are state-of-the-art. version:2
arxiv-1606-03821 | Learning to Generate Compositional Color Descriptions | http://arxiv.org/abs/1606.03821 | id:1606.03821 author:Will Monroe, Noah D. Goodman, Christopher Potts category:cs.CL  published:2016-06-13 summary:The production of color language is essential for grounded language generation. Color descriptions have many challenging properties: they can be vague, compositionally complex, and denotationally rich. We present an effective approach to generating color descriptions using recurrent neural networks and a Fourier-transformed color representation. Our model outperforms previous work on a conditional language modeling task over a large corpus of naturalistic color descriptions. In addition, probing the model's output reveals that it can accurately produce not only basic color terms but also descriptors with non-convex denotations ("greenish"), bare modifiers ("bright", "dull"), and compositional phrases ("faded teal") not seen in training. version:1
arxiv-1606-03803 | Tuning-Free Heterogeneity Pursuit in Massive Networks | http://arxiv.org/abs/1606.03803 | id:1606.03803 author:Zhao Ren, Yongjian Kang, Yingying Fan, Jinchi Lv category:stat.ME math.ST stat.ML stat.TH  published:2016-06-13 summary:Heterogeneity is often natural in many contemporary applications involving massive data. While posing new challenges to effective learning, it can play a crucial role in powering meaningful scientific discoveries through the understanding of important differences among subpopulations of interest. In this paper, we exploit multiple networks with Gaussian graphs to encode the connectivity patterns of a large number of features on the subpopulations. To uncover the heterogeneity of these structures across subpopulations, we suggest a new framework of tuning-free heterogeneity pursuit (THP) via large-scale inference, where the number of networks is allowed to diverge. In particular, two new tests, the chi-based test and the linear functional-based test, are introduced and their asymptotic null distributions are established. Under mild regularity conditions, we establish that both tests are optimal in achieving the testable region boundary and the sample size requirement for the latter test is minimal. Both theoretical guarantees and the tuning-free feature stem from efficient multiple-network estimation by our newly suggested approach of heterogeneous group square-root Lasso (HGSL) for high-dimensional multi-response regression with heterogeneous noises. To solve this convex program, we further introduce a tuning-free algorithm that is scalable and enjoys provable convergence to the global optimum. Both computational and theoretical advantages of our procedure are elucidated through simulation and real data examples. version:1
arxiv-1606-03802 | Specialized Support Vector Machines for open-set recognition | http://arxiv.org/abs/1606.03802 | id:1606.03802 author:Pedro Ribeiro Mendes Júnior, Jacques Wainer, Anderson Rocha category:cs.LG stat.ML  published:2016-06-13 summary:Recently, the open-set recognition problem has received more attention by the machine learning community given that most classification problems in practice require an open-set treatment. Thus far, many classifiers were mostly developed for the closed-set scenario, i.e., the scenario of classification in which it is assumed that all test samples belong to one of the classes the classifier was trained with. In the open-set scenario, however, a test sample can belong to none of the known classes and the classifier must properly reject it by classifying as unknown. It is a common scenario in practice because unknown samples can appear at usage time. In this work, we present an extension upon the well-known Support Vector Machines (SVM) classifier, called the Specialized SVM, suitable for recognition in open-set scenarios. The proposed method bounds the region of the feature space in which a test sample would be classified as known (one of the known classes), making it finite. The same cannot be guaranteed by the traditional SVM even using the Radial Basis Function (RBF) kernel. We conducted experiments comparing the proposed method with state-of-the-art open-set classifiers and show its effectiveness. version:1
arxiv-1606-03798 | Deep Image Homography Estimation | http://arxiv.org/abs/1606.03798 | id:1606.03798 author:Daniel DeTone, Tomasz Malisiewicz, Andrew Rabinovich category:cs.CV  published:2016-06-13 summary:We present a deep convolutional neural network for estimating the relative homography between a pair of images. Our feed-forward network has 10 layers, takes two stacked grayscale images as input, and produces an 8 degree of freedom homography which can be used to map the pixels from the first image to the second. We present two convolutional neural network architectures for HomographyNet: a regression network which directly estimates the real-valued homography parameters, and a classification network which produces a distribution over quantized homographies. We use a 4-point homography parameterization which maps the four corners from one image into the second image. Our networks are trained in an end-to-end fashion using warped MS-COCO images. Our approach works without the need for separate local feature detection and transformation estimation stages. Our deep models are compared to a traditional homography estimator based on ORB features and we highlight the scenarios where HomographyNet outperforms the traditional technique. We also describe a variety of applications powered by deep homography estimation, thus showcasing the flexibility of a deep learning approach. version:1
arxiv-1602-06468 | FLASH: Fast Bayesian Optimization for Data Analytic Pipelines | http://arxiv.org/abs/1602.06468 | id:1602.06468 author:Yuyu Zhang, Mohammad Taha Bahadori, Hang Su, Jimeng Sun category:cs.LG  published:2016-02-20 summary:Modern data science relies on data analytic pipelines to organize interdependent computational steps. Such analytic pipelines often involve different algorithms across multiple steps, each with its own hyperparameters. To achieve the best performance, it is often critical to select optimal algorithms and to set appropriate hyperparameters, which requires large computational efforts. Bayesian optimization provides a principled way for searching optimal hyperparameters for a single algorithm. However, many challenges remain in solving pipeline optimization problems with high-dimensional and highly conditional search space. In this work, we propose Fast LineAr SearcH (FLASH), an efficient method for tuning analytic pipelines. FLASH is a two-layer Bayesian optimization framework, which firstly uses a parametric model to select promising algorithms, then computes a nonparametric model to fine-tune hyperparameters of the promising algorithms. FLASH also includes an effective caching algorithm which can further accelerate the search process. Extensive experiments on a number of benchmark datasets have demonstrated that FLASH significantly outperforms previous state-of-the-art methods in both search speed and accuracy. Using 50% of the time budget, FLASH achieves up to 20% improvement on test error rate compared to the baselines. FLASH also yields state-of-the-art performance on a real-world application for healthcare predictive modeling. version:2
arxiv-1606-03788 | Unsupervised Non Linear Dimensionality Reduction Machine Learning methods applied to Multiparametric MRI in cerebral ischemia: Preliminary Results | http://arxiv.org/abs/1606.03788 | id:1606.03788 author:Vishwa S. Parekh, Jeremy R. Jacobs, Michael A. Jacobs category:cs.CV  published:2016-06-13 summary:The evaluation and treatment of acute cerebral ischemia requires a technique that can determine the total area of tissue at risk for infarction using diagnostic magnetic resonance imaging (MRI) sequences. Typical MRI data sets consist of T1- and T2-weighted imaging (T1WI, T2WI) along with advanced MRI parameters of diffusion-weighted imaging (DWI) and perfusion weighted imaging (PWI) methods. Each of these parameters has distinct radiological-pathological meaning. For example, DWI interrogates the movement of water in the tissue and PWI gives an estimate of the blood flow, both are critical measures during the evolution of stroke. In order to integrate these data and give an estimate of the tissue at risk or damaged, we have developed advanced machine learning methods based on unsupervised non-linear dimensionality reduction (NLDR) techniques. NLDR methods are a class of algorithms that uses mathematically defined manifolds for statistical sampling of multidimensional classes to generate a discrimination rule of guaranteed statistical accuracy and they can generate a two- or three-dimensional map, which represents the prominent structures of the data and provides an embedded image of meaningful low-dimensional structures hidden in their high-dimensional observations. In this manuscript, we develop NLDR methods on high dimensional MRI data sets of preclinical animals and clinical patients with stroke. On analyzing the performance of these methods, we observed that there was a high of similarity between multiparametric embedded images from NLDR methods and the ADC map and perfusion map. It was also observed that embedded scattergram of abnormal (infarcted or at risk) tissue can be visualized and provides a mechanism for automatic methods to delineate potential stroke volumes and early tissue at risk. version:1
arxiv-1606-03784 | MITRE at SemEval-2016 Task 6: Transfer Learning for Stance Detection | http://arxiv.org/abs/1606.03784 | id:1606.03784 author:Guido Zarrella, Amy Marsh category:cs.AI cs.CL  published:2016-06-13 summary:We describe MITRE's submission to the SemEval-2016 Task 6, Detecting Stance in Tweets. This effort achieved the top score in Task A on supervised stance detection, producing an average F1 score of 67.8 when assessing whether a tweet author was in favor or against a topic. We employed a recurrent neural network initialized with features learned via distant supervision on two large unlabeled datasets. We trained embeddings of words and phrases with the word2vec skip-gram method, then used those features to learn sentence representations via a hashtag prediction auxiliary task. These sentence vectors were then fine-tuned for stance detection on several hundred labeled examples. The result was a high performing system that used transfer learning to maximize the value of the available training data. version:1
arxiv-1606-03783 | Retrieving and Ranking Similar Questions from Question-Answer Archives Using Topic Modelling and Topic Distribution Regression | http://arxiv.org/abs/1606.03783 | id:1606.03783 author:Pedro Chahuara, Thomas Lampert, Pierre Gancarski category:cs.IR cs.CL  published:2016-06-12 summary:Presented herein is a novel model for similar question ranking within collaborative question answer platforms. The presented approach integrates a regression stage to relate topics derived from questions to those derived from question-answer pairs. This helps to avoid problems caused by the differences in vocabulary used within questions and answers, and the tendency for questions to be shorter than answers. The performance of the model is shown to outperform translation methods and topic modelling (without regression) on several real-world datasets. version:1
arxiv-1511-00146 | Faster Stochastic Variational Inference using Proximal-Gradient Methods with General Divergence Functions | http://arxiv.org/abs/1511.00146 | id:1511.00146 author:Mohammad Emtiyaz Khan, Reza Babanezhad, Wu Lin, Mark Schmidt, Masashi Sugiyama category:stat.ML cs.LG stat.CO  published:2015-10-31 summary:Several recent works have explored stochastic gradient methods for variational inference that exploit the geometry of the variational-parameter space. However, the theoretical properties of these methods are not well-understood and these methods typically only apply to conditionally-conjugate models. We present a new stochastic method for variational inference which exploits the geometry of the variational-parameter space and also yields simple closed-form updates even for non-conjugate models. We also give a convergence-rate analysis of our method and many other previous methods which exploit the geometry of the space. Our analysis generalizes existing convergence results for stochastic mirror-descent on non-convex objectives by using a more general class of divergence functions. Beyond giving a theoretical justification for a variety of recent methods, our experiments show that new algorithms derived in this framework lead to state of the art results on a variety of problems. Further, due to its generality, we expect that our theoretical analysis could also apply to other applications. version:2
arxiv-1606-03777 | Neural Belief Tracker: Data-Driven Dialogue State Tracking | http://arxiv.org/abs/1606.03777 | id:1606.03777 author:Nikola Mrkšić, Diarmuid Ó Séaghdha, Tsung-Hsien Wen, Blaise Thomson, Steve Young category:cs.CL cs.AI cs.LG  published:2016-06-12 summary:Belief tracking is a core component of modern spoken dialogue system pipelines. However, most current approaches would have difficulty scaling to larger, more complex dialogue domains. This is due to their dependency on either: a) Spoken Language Understanding models that require large amounts of annotated training data; or b) hand-crafted semantic lexicons that capture the lexical variation in users' language. We propose a novel Neural Belief Tracking (NBT) framework which aims to overcome these problems by building on recent advances in semantic representation learning. The NBT models reason over continuous distributed representations of words, utterances and dialogue context. Our evaluation on two datasets shows that this approach overcomes both limitations, matching the performance of state-of-the-art models that have greater resource requirements. version:1
arxiv-1606-03774 | Human Centred Object Co-Segmentation | http://arxiv.org/abs/1606.03774 | id:1606.03774 author:Chenxia Wu, Jiemi Zhang, Ashutosh Saxena, Silvio Savarese category:cs.CV  published:2016-06-12 summary:Co-segmentation is the automatic extraction of the common semantic regions given a set of images. Different from previous approaches mainly based on object visuals, in this paper, we propose a human centred object co-segmentation approach, which uses the human as another strong evidence. In order to discover the rich internal structure of the objects reflecting their human-object interactions and visual similarities, we propose an unsupervised fully connected CRF auto-encoder incorporating the rich object features and a novel human-object interaction representation. We propose an efficient learning and inference algorithm to allow the full connectivity of the CRF with the auto-encoder, that establishes pairwise relations on all pairs of the object proposals in the dataset. Moreover, the auto-encoder learns the parameters from the data itself rather than supervised learning or manually assigned parameters in the conventional CRF. In the extensive experiments on four datasets, we show that our approach is able to extract the common objects more accurately than the state-of-the-art co-segmentation algorithms. version:1
arxiv-1606-03765 | Adaptive Local Window for Level Set Segmentation of CT and MRI Liver Lesions | http://arxiv.org/abs/1606.03765 | id:1606.03765 author:Assaf Hoogi, Christopher F. Beaulieu, Guilherme M. Cunha, Elhamy Heba, Claude B. Sirlin, Sandy Napel, Daniel L. Rubin category:cs.CV  published:2016-06-12 summary:We propose a novel method, the adaptive local window, for improving level set segmentation technique. The window is estimated separately for each contour point, over iterations of the segmentation process, and for each individual object. Our method considers the object scale, the spatial texture, and changes of the energy functional over iterations. Global and local statistics are considered by calculating several gray level co-occurrence matrices. We demonstrate the capabilities of the method in the domain of medical imaging for segmenting 233 images with liver lesions. To illustrate the strength of our method, those images were obtained by either Computed Tomography or Magnetic Resonance Imaging. Moreover, we analyzed images using three different energy models. We compare our method to a global level set segmentation and to local framework that uses predefined fixed-size square windows. The results indicate that our proposed method outperforms the other methods in terms of agreement with the manual marking and dependence on contour initialization or the energy model used. In case of complex lesions, such as low contrast lesions, heterogeneous lesions, or lesions with a noisy background, our method shows significantly better segmentation with an improvement of 0.25+- 0.13 in Dice similarity coefficient, compared with state of the art fixed-size local windows (Wilcoxon, p < 0.001). version:1
arxiv-1507-06550 | Human Pose Estimation with Iterative Error Feedback | http://arxiv.org/abs/1507.06550 | id:1507.06550 author:Joao Carreira, Pulkit Agrawal, Katerina Fragkiadaki, Jitendra Malik category:cs.CV cs.LG cs.NE  published:2015-07-23 summary:Hierarchical feature extractors such as Convolutional Networks (ConvNets) have achieved impressive performance on a variety of classification tasks using purely feedforward processing. Feedforward architectures can learn rich representations of the input space but do not explicitly model dependencies in the output spaces, that are quite structured for tasks such as articulated human pose estimation or object segmentation. Here we propose a framework that expands the expressive power of hierarchical feature extractors to encompass both input and output spaces, by introducing top-down feedback. Instead of directly predicting the outputs in one go, we use a self-correcting model that progressively changes an initial solution by feeding back error predictions, in a process we call Iterative Error Feedback (IEF). IEF shows excellent performance on the task of articulated pose estimation in the challenging MPII and LSP benchmarks, matching the state-of-the-art without requiring ground truth scale annotation. version:3
arxiv-1606-03731 | A constrained clustering based approach for matching a collection of feature sets | http://arxiv.org/abs/1606.03731 | id:1606.03731 author:Junchi Yan, Zhe Ren, Hongyuan Zha, Stephen Chu category:cs.CV  published:2016-06-12 summary:In this paper, we consider the problem of finding the feature correspondences among a collection of feature sets, by using their point-wise unary features. This is a fundamental problem in computer vision and pattern recognition, which also closely relates to other areas such as operational research. Different from two-set matching which can be transformed to a quadratic assignment programming task that is known NP-hard, inclusion of merely unary attributes leads to a linear assignment problem for matching two feature sets. This problem has been well studied and there are effective polynomial global optimum solvers such as the Hungarian method. However, it becomes ill-posed when the unary attributes are (heavily) corrupted. The global optimal correspondence concerning the best score defined by the attribute affinity/cost between the two sets can be distinct to the ground truth correspondence since the score function is biased by noises. To combat this issue, we devise a method for matching a collection of feature sets by synergetically exploring the information across the sets. In general, our method can be perceived from a (constrained) clustering perspective: in each iteration, it assigns the features of one set to the clusters formed by the rest of feature sets, and updates the cluster centers in turn. Results on both synthetic data and real images suggest the efficacy of our method against state-of-the-arts. version:1
arxiv-1606-01609 | Deep Recurrent Convolutional Networks for Video-based Person Re-identification: An End-to-End Approach | http://arxiv.org/abs/1606.01609 | id:1606.01609 author:Lin Wu, Chunhua Shen, Anton van den Hengel category:cs.CV  published:2016-06-06 summary:In this paper, we present an end-to-end approach to simultaneously learn spatio-temporal features and corresponding similarity metric for video-based person re-identification. Given the video sequence of a person, features from each frame that are extracted from all levels of a deep convolutional network can preserve a higher spatial resolution from which we can model finer motion patterns. These low-level visual percepts are leveraged into a variant of recurrent model to characterize the temporal variation between time-steps. Features from all time-steps are then summarized using temporal pooling to produce an overall feature representation for the complete sequence. The deep convolutional network, recurrent layer, and the temporal pooling are jointly trained to extract comparable hidden-unit representations from input pair of time series to compute their corresponding similarity value. The proposed framework combines time series modeling and metric learning to jointly learn relevant features and a good similarity measure between time sequences of person. Experiments demonstrate that our approach achieves the state-of-the-art performance for video-based person re-identification on iLIDS-VID and PRID 2011, the two primary public datasets for this purpose. version:2
arxiv-1606-03685 | Efficient KLMS and KRLS Algorithms: A Random Fourier Feature Perspective | http://arxiv.org/abs/1606.03685 | id:1606.03685 author:Pantelis Bouboulis, Spyridon Pougkakiotis, Sergios Theodoridis category:cs.LG stat.ML K.3.2  I.5.4  published:2016-06-12 summary:We present a new framework for online Least Squares algorithms for nonlinear modeling in RKH spaces (RKHS). Instead of implicitly mapping the data to a RKHS (e.g., kernel trick), we map the data to a finite dimensional Euclidean space, using random features of the kernel's Fourier transform. The advantage is that, the inner product of the mapped data approximates the kernel function. The resulting "linear" algorithm does not require any form of sparsification, since, in contrast to all existing algorithms, the solution's size remains fixed and does not increase with the iteration steps. As a result, the obtained algorithms are computationally significantly more efficient compared to previously derived variants, while, at the same time, they converge at similar speeds and to similar error floors. version:1
arxiv-1412-4052 | The bag-of-frames approach: a not so sufficient model for urban soundscapes | http://arxiv.org/abs/1412.4052 | id:1412.4052 author:Mathieu Lagrange, Grégoire Lafay, Boris Defreville, Jean-Julien Aucouturier category:cs.SD stat.ML  published:2014-12-11 summary:The "bag-of-frames" approach (BOF), which encodes audio signals as the long-term statistical distribution of short-term spectral features, is commonly regarded as an effective and sufficient way to represent environmental sound recordings (soundscapes) since its introduction in an influential 2007 article. The present paper describes a concep-tual replication of this seminal article using several new soundscape datasets, with results strongly questioning the adequacy of the BOF approach for the task. We show that the good accuracy originally re-ported with BOF likely result from a particularly thankful dataset with low within-class variability, and that for more realistic datasets, BOF in fact does not perform significantly better than a mere one-point av-erage of the signal's features. Soundscape modeling, therefore, may not be the closed case it was once thought to be. Progress, we ar-gue, could lie in reconsidering the problem of considering individual acoustical events within each soundscape. version:2
arxiv-1606-03676 | External Lexical Information for Multilingual Part-of-Speech Tagging | http://arxiv.org/abs/1606.03676 | id:1606.03676 author:Benoît Sagot category:cs.CL  published:2016-06-12 summary:Morphosyntactic lexicons and word vector representations have both proven useful for improving the accuracy of statistical part-of-speech taggers. Here we compare the performances of four systems on datasets covering 16 languages, two of these systems being feature-based (MEMMs and CRFs) and two of them being neural-based (bi-LSTMs). We show that, on average, all four approaches perform similarly and reach state-of-the-art results. Yet better performances are obtained with our feature-based models on lexically richer datasets (e.g. for morphologically rich languages), whereas neural-based results are higher on datasets with less lexical variability (e.g. for English). These conclusions hold in particular for the MEMM models relying on our system MElt, which benefited from newly designed features. This shows that, under certain conditions, feature-based approaches enriched with morphosyntactic lexicons are competitive with respect to neural methods. version:1
arxiv-1606-03674 | Critical Echo State Networks that Anticipate Input using Adaptive Transfer Functions | http://arxiv.org/abs/1606.03674 | id:1606.03674 author:Norbert Michael Mayer category:cs.NE  published:2016-06-12 summary:The paper investigates a new type of truly critical echo state networks where individual transfer functions for every neuron can be modified to anticipate the expected next input. Deviations from expected input are only forgotten very slowly in power law fashion. The paper outlines the theory, numerically analyzes a one neuron model network and finally discusses technical and also biological implications of this type of approach. version:1
arxiv-1606-03672 | Comparison of Several Sparse Recovery Methods for Low Rank Matrices with Random Samples | http://arxiv.org/abs/1606.03672 | id:1606.03672 author:Ashkan Esmaeili, Farokh Marvasti category:cs.LG stat.ML  published:2016-06-12 summary:In this paper, we will investigate the efficacy of IMAT (Iterative Method of Adaptive Thresholding) in recovering the sparse signal (parameters) for linear models with missing data. Sparse recovery rises in compressed sensing and machine learning problems and has various applications necessitating viable reconstruction methods specifically when we work with big data. This paper will focus on comparing the power of IMAT in reconstruction of the desired sparse signal with LASSO. Additionally, we will assume the model has random missing information. Missing data has been recently of interest in big data and machine learning problems since they appear in many cases including but not limited to medical imaging datasets, hospital datasets, and massive MIMO. The dominance of IMAT over the well-known LASSO will be taken into account in different scenarios. Simulations and numerical results are also provided to verify the arguments. version:1
arxiv-1606-03671 | Segmentation of scanning electron microscopy images from natural rubber samples with gold nanoparticles using starlet wavelets | http://arxiv.org/abs/1606.03671 | id:1606.03671 author:Alexandre Fioravante de Siqueira, Flávio Camargo Cabrera, Aylton Pagamisse, Aldo Eloizo Job category:cs.CV  published:2016-06-12 summary:Electronic microscopy has been used for morphology evaluation of different materials structures. However, microscopy results may be affected by several factors. Image processing methods can be used to correct and improve the quality of these results. In this paper we propose an algorithm based on starlets to perform the segmentation of scanning electron microscopy images. An application is presented in order to locate gold nanoparticles in natural rubber membranes. In this application, our method showed accuracy greater than 85% for all test images. Results given by this method will be used in future studies, to computationally estimate the density distribution of gold nanoparticles in natural rubber samples and to predict reduction kinetics of gold nanoparticles at different time periods. version:1
arxiv-1601-06551 | Robust Influence Maximization | http://arxiv.org/abs/1601.06551 | id:1601.06551 author:Wei Chen, Tian Lin, Zihan Tan, Mingfei Zhao, Xuren Zhou category:cs.SI cs.LG  published:2016-01-25 summary:In this paper, we address the important issue of uncertainty in the edge influence probability estimates for the well studied influence maximization problem --- the task of finding $k$ seed nodes in a social network to maximize the influence spread. We propose the problem of robust influence maximization, which maximizes the worst-case ratio between the influence spread of the chosen seed set and the optimal seed set, given the uncertainty of the parameter input. We design an algorithm that solves this problem with a solution-dependent bound. We further study uniform sampling and adaptive sampling methods to effectively reduce the uncertainty on parameters and improve the robustness of the influence maximization task. Our empirical results show that parameter uncertainty may greatly affect influence maximization performance and prior studies that learned influence probabilities could lead to poor performance in robust influence maximization due to relatively large uncertainty in parameter estimates, and information cascade based adaptive sampling method may be an effective way to improve the robustness of influence maximization. version:2
arxiv-1606-03669 | Color-based Segmentation of Sky/Cloud Images From Ground-based Cameras | http://arxiv.org/abs/1606.03669 | id:1606.03669 author:Soumyabrata Dev, Yee Hui Lee, Stefan Winkler category:cs.CV  published:2016-06-12 summary:Sky/cloud images captured by ground-based cameras (a.k.a. whole sky imagers) are increasingly used nowadays because of their applications in a number of fields, including climate modeling, weather prediction, renewable energy generation, and satellite communications. Due to the wide variety of cloud types and lighting conditions in such images, accurate and robust segmentation of clouds is challenging. In this paper, we present a supervised segmentation framework for ground-based sky/cloud images based on a systematic analysis of different color spaces and components, using partial least squares (PLS) regression. Unlike other state-of-the-art methods, our proposed approach is entirely learning-based and does not require any manually-defined parameters. In addition, we release the Singapore Whole Sky IMaging SEGmentation Database (SWIMSEG), a large database of annotated sky/cloud images, to the research community. version:1
arxiv-1606-03667 | Deep Reinforcement Learning with a Combinatorial Action Space for Predicting and Tracking Popular Discussion Threads | http://arxiv.org/abs/1606.03667 | id:1606.03667 author:Ji He, Mari Ostendorf, Xiaodong He, Jianshu Chen, Jianfeng Gao, Lihong Li, Li Deng category:cs.CL cs.AI cs.LG  published:2016-06-12 summary:We introduce an online popularity prediction and tracking task as a benchmark task for reinforcement learning with a combinatorial, natural language action space. A specified number of discussion threads predicted to be popular are recommended, chosen from a fixed window of recent comments to track. Novel deep reinforcement learning architectures are studied for effective modeling of the value function associated with actions comprised of interdependent sub-actions. The proposed model, which represents dependence between sub-actions through a bi-directional LSTM, gives the best performance across different experimental configurations and domains, and it also generalizes well with varying numbers of recommendation requests. version:1
arxiv-1606-03664 | Weakly Supervised Scalable Audio Content Analysis | http://arxiv.org/abs/1606.03664 | id:1606.03664 author:Anurag Kumar, Bhiksha Raj category:cs.SD cs.LG cs.MM  published:2016-06-12 summary:Audio Event Detection is an important task for content analysis of multimedia data. Most of the current works on detection of audio events is driven through supervised learning approaches. We propose a weakly supervised learning framework which can make use of the tremendous amount of web multimedia data with significantly reduced annotation effort and expense. Specifically, we use several multiple instance learning algorithms to show that audio event detection through weak labels is feasible. We also propose a novel scalable multiple instance learning algorithm and show that its competitive with other multiple instance learning algorithms for audio event detection tasks. version:1
arxiv-1606-03657 | InfoGAN: Interpretable Representation Learning by Information Maximizing Generative Adversarial Nets | http://arxiv.org/abs/1606.03657 | id:1606.03657 author:Xi Chen, Yan Duan, Rein Houthooft, John Schulman, Ilya Sutskever, Pieter Abbeel category:cs.LG stat.ML  published:2016-06-12 summary:This paper describes InfoGAN, an information-theoretic extension to the Generative Adversarial Network that is able to learn disentangled representations in a completely unsupervised manner. InfoGAN is a generative adversarial network that also maximizes the mutual information between a small subset of the latent variables and the observation. We derive a lower bound to the mutual information objective that can be optimized efficiently, and show that our training procedure can be interpreted as a variation of the Wake-Sleep algorithm. Specifically, InfoGAN successfully disentangles writing styles from digit shapes on the MNIST dataset, pose from lighting of 3D rendered images, and background digits from the central digit on the SVHN dataset. It also discovers visual concepts that include hair styles, presence/absence of eyeglasses, and emotions on the CelebA face dataset. Experiments show that InfoGAN learns interpretable representations that are competitive with representations learned by existing fully supervised methods. version:1
arxiv-1606-03647 | Training Recurrent Answering Units with Joint Loss Minimization for VQA | http://arxiv.org/abs/1606.03647 | id:1606.03647 author:Hyeonwoo Noh, Bohyung Han category:cs.CV  published:2016-06-12 summary:We propose a novel algorithm for visual question answering based on a recurrent deep neural network, where every module in the network corresponds to a complete answering unit with attention mechanism by itself. The network is optimized by minimizing loss aggregated from all the units, which share model parameters while receiving different information to compute attention probability. For training, our model attends to a region within image feature map, updates its memory based on the question and attended image feature, and answers the question based on its memory state. This procedure is performed to compute loss in each step. The motivation of this approach is our observation that multi-step inferences are often required to answer questions while each problem may have a unique desirable number of steps, which is difficult to identify in practice. Hence, we always make the first unit in the network solve problems, but allow it to learn the knowledge from the rest of units by backpropagation unless it degrades the model. To implement this idea, we early-stop training each unit as soon as it starts to overfit. Note that, since more complex models tend to overfit on easier questions quickly, the last answering unit in the unfolded recurrent neural network is typically killed first while the first one remains last. We make a single-step prediction for a new question using the shared model. This strategy works better than the other options within our framework since the selected model is trained effectively from all units without overfitting. The proposed algorithm achieves the state-of-the-art performance on the standard benchmark dataset without data augmentation. version:1
arxiv-1602-04511 | Learning Granger Causality for Hawkes Processes | http://arxiv.org/abs/1602.04511 | id:1602.04511 author:Hongteng Xu, Mehrdad Farajtabar, Hongyuan Zha category:cs.LG stat.ML  published:2016-02-14 summary:Learning Granger causality for general point processes is a very challenging task. In this paper, we propose an effective method, learning Granger causality, for a special but significant type of point processes --- Hawkes process. We reveal the relationship between Hawkes process's impact function and its Granger causality graph. Specifically, our model represents impact functions using a series of basis functions and recovers the Granger causality graph via group sparsity of the impact functions' coefficients. We propose an effective learning algorithm combining a maximum likelihood estimator (MLE) with a sparse-group-lasso (SGL) regularizer. Additionally, the flexibility of our model allows to incorporate the clustering structure event types into learning framework. We analyze our learning algorithm and propose an adaptive procedure to select basis functions. Experiments on both synthetic and real-world data show that our method can learn the Granger causality graph and the triggering patterns of the Hawkes processes simultaneously. version:2
arxiv-1606-03632 | Natural Language Generation in Dialogue using Lexicalized and Delexicalized Data | http://arxiv.org/abs/1606.03632 | id:1606.03632 author:Shikhar Sharma, Jing He, Kaheer Suleman, Hannes Schulz, Philip Bachman category:cs.CL  published:2016-06-11 summary:Natural language generation plays a critical role in any spoken dialogue system. We present a new approach to natural language generation using recurrent neural networks in an encoder-decoder framework. In contrast with previous work, our model uses both lexicalized and delexicalized versions of slot-value pairs for each dialogue act. This allows our model to learn from all available data, rather than being restricted to learning only from delexicalized slot-value pairs. We show that this helps our model generate more natural sentences with better grammar. We further improve our model's performance by initializing its weights from a pretrained language model. Human evaluation of our best-performing model indicates that it generates sentences which users find more natural and appealing. version:1
arxiv-1606-03628 | metricDTW: local distance metric learning in Dynamic Time Warping | http://arxiv.org/abs/1606.03628 | id:1606.03628 author:Jiaping Zhao, Zerong Xi, Laurent Itti category:cs.LG  published:2016-06-11 summary:We propose to learn multiple local Mahalanobis distance metrics to perform k-nearest neighbor (kNN) classification of temporal sequences. Temporal sequences are first aligned by dynamic time warping (DTW); given the alignment path, similarity between two sequences is measured by the DTW distance, which is computed as the accumulated distance between matched temporal point pairs along the alignment path. Traditionally, Euclidean metric is used for distance computation between matched pairs, which ignores the data regularities and might not be optimal for applications at hand. Here we propose to learn multiple Mahalanobis metrics, such that DTW distance becomes the sum of Mahalanobis distances. We adapt the large margin nearest neighbor (LMNN) framework to our case, and formulate multiple metric learning as a linear programming problem. Extensive sequence classification results show that our proposed multiple metrics learning approach is effective, insensitive to the preceding alignment qualities, and reaches the state-of-the-art performances on UCR time series datasets. version:1
arxiv-1606-03623 | Drug response prediction by inferring pathway-response associations with Kernelized Bayesian Matrix Factorization | http://arxiv.org/abs/1606.03623 | id:1606.03623 author:Muhammad Ammad-ud-din, Suleiman A. Khan, Disha Malani, Astrid Murumägi, Olli Kallioniemi, Tero Aittokallio, Samuel Kaski category:stat.ML cs.LG q-bio.QM  published:2016-06-11 summary:A key goal of computational personalized medicine is to systematically utilize genomic and other molecular features of samples to predict drug responses for a previously unseen sample. Such predictions are valuable for developing hypotheses for selecting therapies tailored for individual patients. This is especially valuable in oncology, where molecular and genetic heterogeneity of the cells has a major impact on the response. However, the prediction task is extremely challenging, raising the need for methods that can effectively model and predict drug responses. In this study, we propose a novel formulation of multi-task matrix factorization that allows selective data integration for predicting drug responses. To solve the modeling task, we extend the state-of-the-art kernelized Bayesian matrix factorization (KBMF) method with component-wise multiple kernel learning. In addition, our approach exploits the known pathway information in a novel and biologically meaningful fashion to learn the drug response associations. Our method quantitatively outperforms the state of the art on predicting drug responses in two publicly available cancer data sets as well as on a synthetic data set. In addition, we validated our model predictions with lab experiments using an in-house cancer cell line panel. We finally show the practical applicability of the proposed method by utilizing prior knowledge to infer pathway-drug response associations, opening up the opportunity for elucidating drug action mechanisms. We demonstrate that pathway-response associations can be learned by the proposed model for the well known EGFR and MEK inhibitors. version:1
arxiv-1606-03622 | Data Recombination for Neural Semantic Parsing | http://arxiv.org/abs/1606.03622 | id:1606.03622 author:Robin Jia, Percy Liang category:cs.CL  published:2016-06-11 summary:Modeling crisp logical regularities is crucial in semantic parsing, making it difficult for neural models with no task-specific prior knowledge to achieve good results. In this paper, we introduce data recombination, a novel framework for injecting such prior knowledge into a model. From the training data, we induce a high-precision synchronous context-free grammar, which captures important conditional independence properties commonly found in semantic parsing. We then train a sequence-to-sequence recurrent network (RNN) model with a novel attention-based copying mechanism on datapoints sampled from this grammar, thereby teaching the model about these structural properties. Data recombination improves the accuracy of our RNN model on three semantic parsing datasets, leading to new state-of-the-art performance on the standard GeoQuery dataset for models with comparable supervision. version:1
arxiv-1507-00677 | Distributional Smoothing with Virtual Adversarial Training | http://arxiv.org/abs/1507.00677 | id:1507.00677 author:Takeru Miyato, Shin-ichi Maeda, Masanori Koyama, Ken Nakae, Shin Ishii category:stat.ML cs.LG  published:2015-07-02 summary:We propose local distributional smoothness (LDS), a new notion of smoothness for statistical model that can be used as a regularization term to promote the smoothness of the model distribution. We named the LDS based regularization as virtual adversarial training (VAT). The LDS of a model at an input datapoint is defined as the KL-divergence based robustness of the model distribution against local perturbation around the datapoint. VAT resembles adversarial training, but distinguishes itself in that it determines the adversarial direction from the model distribution alone without using the label information, making it applicable to semi-supervised learning. The computational cost for VAT is relatively low. For neural network, the approximated gradient of the LDS can be computed with no more than three pairs of forward and back propagations. When we applied our technique to supervised and semi-supervised learning for the MNIST dataset, it outperformed all the training methods other than the current state of the art method, which is based on a highly advanced generative model. We also applied our method to SVHN and NORB, and confirmed our method's superior performance over the current state of the art semi-supervised method applied to these datasets. version:9
arxiv-1606-03601 | TRex: A Tomography Reconstruction Proximal Framework for Robust Sparse View X-Ray Applications | http://arxiv.org/abs/1606.03601 | id:1606.03601 author:Mohamed Aly, Guangming Zang, Wolfgang Heidrich, Peter Wonka category:math.OC cs.CV cs.LG stat.ML  published:2016-06-11 summary:We present TRex, a flexible and robust Tomographic Reconstruction framework using proximal algorithms. We provide an overview and perform an experimental comparison between the famous iterative reconstruction methods in terms of reconstruction quality in sparse view situations. We then derive the proximal operators for the four best methods. We show the flexibility of our framework by deriving solvers for two noise models: Gaussian and Poisson; and by plugging in three powerful regularizers. We compare our framework to state of the art methods, and show superior quality on both synthetic and real datasets. version:1
arxiv-1605-02066 | Shape from Mixed Polarization | http://arxiv.org/abs/1605.02066 | id:1605.02066 author:Vage Taamazyan, Achuta Kadambi, Ramesh Raskar category:cs.CV  published:2016-05-06 summary:Shape from Polarization (SfP) estimates surface normals using photos captured at different polarizer rotations. Fundamentally, the SfP model assumes that light is reflected either diffusely or specularly. However, this model is not valid for many real-world surfaces exhibiting a mixture of diffuse and specular properties. To address this challenge, previous methods have used a sequential solution: first, use an existing algorithm to separate the scene into diffuse and specular components, then apply the appropriate SfP model. In this paper, we propose a new method that jointly uses viewpoint and polarization data to holistically separate diffuse and specular components, recover refractive index, and ultimately recover 3D shape. By involving the physics of polarization in the separation process, we demonstrate competitive results with a benchmark method, while recovering additional information (e.g. refractive index). version:2
arxiv-1606-03578 | Alternative Technique to Asymmetry Analysis-Based Overlapping for Foot Ulcer Examination: Scalable Scanning | http://arxiv.org/abs/1606.03578 | id:1606.03578 author:Naima Kaabouch, Wen-Chen Hu, Yi Chen category:cs.CV  published:2016-06-11 summary:Asymmetry analysis based on the overlapping of thermal images proved able to detect inflammation and, predict foot ulceration. This technique involves three main steps: segmentation, geometric transformation, and overlapping. However, the overlapping technique, which consists of subtracting the intensity levels of the right foot from those of the left foot, can also detect false abnormal areas if the projections of the left and right feet are not the same. In this paper, we present an alternative technique to asymmetry analysis-based overlapping. The proposed technique, scalable scanning, allows for an effective comparison even if the shapes and sizes of the feet projections appear differently in the image. The tested results show that asymmetry analysis- based scalable scanning provides fewer false abnormal areas than does asymmetry analysis -based overlapping. version:1
arxiv-1606-03568 | Word Sense Disambiguation using a Bidirectional LSTM | http://arxiv.org/abs/1606.03568 | id:1606.03568 author:Mikael Kågebäck, Hans Salomonsson category:cs.CL cs.AI  published:2016-06-11 summary:In this paper we present a model that leverages a bidirectional long short-term memory network to learn word sense disambiguation directly from data. The approach is end-to-end trainable and makes effective use of word order. Further, to improve the robustness of the model we introduce dropword, a regularization technique that randomly removes words from the text. The model is evaluated on two standard datasets and achieves state-of-the-art results on both datasets, using identical hyperparameter settings. version:1
arxiv-1606-03556 | Human Attention in Visual Question Answering: Do Humans and Deep Networks Look at the Same Regions? | http://arxiv.org/abs/1606.03556 | id:1606.03556 author:Abhishek Das, Harsh Agrawal, C. Lawrence Zitnick, Devi Parikh, Dhruv Batra category:cs.CV cs.CL  published:2016-06-11 summary:We conduct large-scale studies on `human attention' in Visual Question Answering (VQA) to understand where humans choose to look to answer questions about images. We design and test multiple game-inspired novel attention-annotation interfaces that require the subject to sharpen regions of a blurred image to answer a question. Thus, we introduce the VQA-HAT (Human ATtention) dataset. We evaluate attention maps generated by state-of-the-art VQA models against human attention both qualitatively (via visualizations) and quantitatively (via rank-order correlation). We find that depending on the implementation used, machine-generated attention maps are either \emph{negatively correlated} with human attention or have positive correlation worse than task-independent saliency. Overall, our experiments paint a bleak picture for the current generation of attention models in VQA. version:1
arxiv-1603-00982 | Audio Word2Vec: Unsupervised Learning of Audio Segment Representations using Sequence-to-sequence Autoencoder | http://arxiv.org/abs/1603.00982 | id:1603.00982 author:Yu-An Chung, Chao-Chung Wu, Chia-Hao Shen, Hung-Yi Lee, Lin-Shan Lee category:cs.SD cs.LG  published:2016-03-03 summary:The vector representations of fixed dimensionality for words (in text) offered by Word2Vec have been shown to be very useful in many application scenarios, in particular due to the semantic information they carry. This paper proposes a parallel version, the Audio Word2Vec. It offers the vector representations of fixed dimensionality for variable-length audio segments. These vector representations are shown to describe the sequential phonetic structures of the audio segments to a good degree, with very attractive real world applications such as query-by-example Spoken Term Detection (STD). In this STD application, the proposed approach significantly outperformed the conventional Dynamic Time Warping (DTW) based approaches at significantly lower computation requirements. We propose unsupervised learning of Audio Word2Vec from audio data without human annotation using Sequence-to-sequence Audoencoder (SA). SA consists of two RNNs equipped with Long Short-Term Memory (LSTM) units: the first RNN (encoder) maps the input audio sequence into a vector representation of fixed dimensionality, and the second RNN (decoder) maps the representation back to the input audio sequence. The two RNNs are jointly trained by minimizing the reconstruction error. Denoising Sequence-to-sequence Autoencoder (DSA) is furthered proposed offering more robust learning. version:4
arxiv-1602-01889 | Discovering Neuronal Cell Types and Their Gene Expression Profiles Using a Spatial Point Process Mixture Model | http://arxiv.org/abs/1602.01889 | id:1602.01889 author:Furong Huang, Animashree Anandkumar, Christian Borgs, Jennifer Chayes, Ernest Fraenkel, Michael Hawrylycz, Ed Lein, Alessandro Ingrosso, Srinivas Turaga category:q-bio.NC stat.ML  published:2016-02-04 summary:Cataloging the neuronal cell types that comprise circuitry of individual brain regions is a major goal of modern neuroscience and the BRAIN initiative. Single-cell RNA sequencing can now be used to measure the gene expression profiles of individual neurons and to categorize neurons based on their gene expression profiles. While the single-cell techniques are extremely powerful and hold great promise, they are currently still labor intensive, have a high cost per cell, and, most importantly, do not provide information on spatial distribution of cell types in specific regions of the brain. We propose a complementary approach that uses computational methods to infer the cell types and their gene expression profiles through analysis of brain-wide single-cell resolution in situ hybridization (ISH) imagery contained in the Allen Brain Atlas (ABA). We measure the spatial distribution of neurons labeled in the ISH image for each gene and model it as a spatial point process mixture, whose mixture weights are given by the cell types which express that gene. By fitting a point process mixture model jointly to the ISH images, we infer both the spatial point process distribution for each cell type and their gene expression profile. We validate our predictions of cell type-specific gene expression profiles using single cell RNA sequencing data, recently published for the mouse somatosensory cortex. Jointly with the gene expression profiles, cell features such as cell size, orientation, intensity and local density level are inferred per cell type. version:2
arxiv-1605-05365 | Dynamic Frame skip Deep Q Network | http://arxiv.org/abs/1605.05365 | id:1605.05365 author:Aravind S. Lakshminarayanan, Sahil Sharma, Balaraman Ravindran category:cs.LG cs.AI cs.NE  published:2016-05-17 summary:Deep Reinforcement Learning methods have achieved state of the art performance in learning control policies for the games in the Atari 2600 domain. One of the important parameters in the Arcade Learning Environment (ALE) is the frame skip rate. It decides the granularity at which agents can control game play. A frame skip value of $k$ allows the agent to repeat a selected action $k$ number of times. The current state of the art architectures like Deep Q-Network (DQN) and Dueling Network Architectures (DuDQN) consist of a framework with a static frame skip rate, where the action output from the network is repeated for a fixed number of frames regardless of the current state. In this paper, we propose a new architecture, Dynamic Frame skip Deep Q-Network (DFDQN) which makes the frame skip rate a dynamic learnable parameter. This allows us to choose the number of times an action is to be repeated based on the current state. We show empirically that such a setting improves the performance on relatively harder games like Seaquest. version:2
arxiv-1606-03508 | Distributed Machine Learning in Materials that Couple Sensing, Actuation, Computation and Communication | http://arxiv.org/abs/1606.03508 | id:1606.03508 author:Dana Hughes, Nikolaus Correll category:cs.LG cs.RO  published:2016-06-11 summary:This paper reviews machine learning applications and approaches to detection, classification and control of intelligent materials and structures with embedded distributed computation elements. The purpose of this survey is to identify desired tasks to be performed in each type of material or structure (e.g., damage detection in composites), identify and compare common approaches to learning such tasks, and investigate models and training paradigms used. Machine learning approaches and common temporal features used in the domains of structural health monitoring, morphable aircraft, wearable computing and robotic skins are explored. As the ultimate goal of this research is to incorporate the approaches described in this survey into a robotic material paradigm, the potential for adapting the computational models used in these applications, and corresponding training algorithms, to an amorphous network of computing nodes is considered. Distributed versions of support vector machines, graphical models and mixture models developed in the field of wireless sensor networks are reviewed. Potential areas of investigation, including possible architectures for incorporating machine learning into robotic nodes, training approaches, and the possibility of using deep learning approaches for automatic feature extraction, are discussed. version:1
arxiv-1606-03504 | Incoherent Tensor Norms and Their Applications in Higher Order Tensor Completion | http://arxiv.org/abs/1606.03504 | id:1606.03504 author:Ming Yuan, Cun-Hui Zhang category:math.ST cs.IT math.IT math.OC stat.ML stat.TH  published:2016-06-10 summary:In this paper, we investigate the sample size requirement for a general class of nuclear norm minimization methods for higher order tensor completion. We introduce a class of tensor norms by allowing for different levels of coherence, which allows us to leverage the incoherence of a tensor. In particular, we show that a $k$th order tensor of rank $r$ and dimension $d\times\cdots\times d$ can be recovered perfectly from as few as $O((r^{(k-1)/2}d^{3/2}+r^{k-1}d)(\log(d))^2)$ uniformly sampled entries through an appropriate incoherent nuclear norm minimization. Our results demonstrate some key differences between completing a matrix and a higher order tensor: They not only point to potential room for improvement over the usual nuclear norm minimization but also highlight the importance of explicitly accounting for incoherence, when dealing with higher order tensors. version:1
arxiv-1603-02754 | XGBoost: A Scalable Tree Boosting System | http://arxiv.org/abs/1603.02754 | id:1603.02754 author:Tianqi Chen, Carlos Guestrin category:cs.LG  published:2016-03-09 summary:Tree boosting is a highly effective and widely used machine learning method. In this paper, we describe a scalable end-to-end tree boosting system called XGBoost, which is used widely by data scientists to achieve state-of-the-art results on many machine learning challenges. We propose a novel sparsity-aware algorithm for sparse data and weighted quantile sketch for approximate tree learning. More importantly, we provide insights on cache access patterns, data compression and sharding to build a scalable tree boosting system. By combining these insights, XGBoost scales beyond billions of examples using far fewer resources than existing systems. version:3
arxiv-1606-03498 | Improved Techniques for Training GANs | http://arxiv.org/abs/1606.03498 | id:1606.03498 author:Tim Salimans, Ian Goodfellow, Wojciech Zaremba, Vicki Cheung, Alec Radford, Xi Chen category:cs.LG cs.CV cs.NE  published:2016-06-10 summary:We present a variety of new architectural features and training procedures that we apply to the generative adversarial networks (GANs) framework. We focus on two applications of GANs: semi-supervised learning, and the generation of images that humans find visually realistic. Unlike most work on generative models, our primary goal is not to train a model that assigns high likelihood to test data, nor do we require the model to be able to learn well without using any labels. Using our new techniques, we achieve state-of-the-art results in semi-supervised classification on MNIST, CIFAR-10 and SVHN. The generated images are of high quality as confirmed by a visual Turing test: our model generates MNIST samples that humans cannot distinguish from real data, and CIFAR-10 samples that yield a human error rate of 21.3%. We also present ImageNet samples with unprecedented resolution and show that our methods enable the model to learn recognizable features of ImageNet classes. version:1
arxiv-1510-03055 | A Diversity-Promoting Objective Function for Neural Conversation Models | http://arxiv.org/abs/1510.03055 | id:1510.03055 author:Jiwei Li, Michel Galley, Chris Brockett, Jianfeng Gao, Bill Dolan category:cs.CL  published:2015-10-11 summary:Sequence-to-sequence neural network models for generation of conversational responses tend to generate safe, commonplace responses (e.g., "I don't know") regardless of the input. We suggest that the traditional objective function, i.e., the likelihood of output (response) given input (message) is unsuited to response generation tasks. Instead we propose using Maximum Mutual Information (MMI) as the objective function in neural models. Experimental results demonstrate that the proposed MMI models produce more diverse, interesting, and appropriate responses, yielding substantive gains in BLEU scores on two conversational datasets and in human evaluations. version:3
arxiv-1512-01139 | Kalman-based Stochastic Gradient Method with Stop Condition and Insensitivity to Conditioning | http://arxiv.org/abs/1512.01139 | id:1512.01139 author:Vivak Patel category:math.OC stat.CO stat.ML  published:2015-12-03 summary:Modern proximal and stochastic gradient descent (SGD) methods are believed to efficiently minimize large composite objective functions, but such methods have two algorithmic challenges: (1) a lack of fast or justified stop conditions, and (2) sensitivity to the objective function's conditioning. In response to the first challenge, modern proximal and SGD methods guarantee convergence only after multiple epochs, but such a guarantee renders proximal and SGD methods infeasible when the number of component functions is very large or infinite. In response to the second challenge, second order SGD methods have been developed, but they are marred by the complexity of their analysis. In this work, we address these challenges on the limited, but important, linear regression problem by introducing and analyzing a second order proximal/SGD method based on Kalman Filtering (kSGD). Through our analysis, we show kSGD is asymptotically optimal, develop a fast algorithm for very large, infinite or streaming data sources with a justified stop condition, prove that kSGD is insensitive to the problem's conditioning, and develop a unique approach for analyzing the complex second order dynamics. Our theoretical results are supported by numerical experiments on three regression problems (linear, nonparametric wavelet, and logistic) using three large publicly available datasets. Moreover, our analysis and experiments lay a foundation for embedding kSGD in multiple epoch algorithms, extending kSGD to other problem classes, and developing parallel and low memory kSGD implementations. version:2
arxiv-1602-04105 | Convolutional Radio Modulation Recognition Networks | http://arxiv.org/abs/1602.04105 | id:1602.04105 author:Timothy J O'Shea, Johnathan Corgan, T. Charles Clancy category:cs.LG cs.CV  published:2016-02-12 summary:We study the adaptation of convolutional neural networks to the complex temporal radio signal domain. We compare the efficacy of radio modulation classification using naively learned features against using expert features which are widely used in the field today and we show significant performance improvements. We show that blind temporal learning on large and densely encoded time series using deep convolutional neural networks is viable and a strong candidate approach for this task especially at low signal to noise ratio. version:3
arxiv-1606-03490 | The Mythos of Model Interpretability | http://arxiv.org/abs/1606.03490 | id:1606.03490 author:Zachary C. Lipton category:cs.LG cs.AI cs.CV cs.NE stat.ML  published:2016-06-10 summary:Supervised machine learning models boast remarkable predictive capabilities. But can you trust your model? Will it work in deployment? What else can it tell you about the world? We want models to be not only good, but interpretable. And yet the task of interpretation appears underspecified. Papers provide diverse and sometimes non-overlapping motivations for interpretability, and offer myriad notions of what attributes render models interpretable. Despite this ambiguity, many papers proclaim interpretability axiomatically, absent further explanation. In this paper, we seek to refine the discourse on interpretability. First, we examine the motivations underlying interest in interpretability, finding them to be diverse and occasionally discordant. Then, we address model properties and techniques thought to confer interpretability, identifying transparency to humans and post-hoc explanations as competing notions. Throughout, we discuss the feasibility and desirability of different notions, and question the oft-made assertions that linear models are interpretable and that deep neural networks are not. version:1
arxiv-1606-02245 | Iterative Alternating Neural Attention for Machine Reading | http://arxiv.org/abs/1606.02245 | id:1606.02245 author:Alessandro Sordoni, Phillip Bachman, Yoshua Bengio category:cs.CL cs.NE  published:2016-06-07 summary:We propose a novel neural attention architecture to tackle machine comprehension tasks, such as answering Cloze-style queries with respect to a document. Unlike previous models, we do not collapse the query into a single vector, instead we deploy an iterative alternating attention mechanism that allows a fine-grained exploration of both the query and the document. Our model outperforms state-of-the-art baselines in standard machine comprehension benchmarks such as CNN news articles and the Children's Book Test (CBT) dataset. version:3
arxiv-1602-00575 | Multi-object Classification via Crowdsourcing with a Reject Option | http://arxiv.org/abs/1602.00575 | id:1602.00575 author:Qunwei Li, Aditya Vempaty, Lav R. Varshney, Pramod K. Varshney category:cs.LG  published:2016-02-01 summary:Consider designing an effective crowdsourcing system for an $M$-ary classification task. Crowd workers complete simple binary microtasks whose results are aggregated to give the final result. We consider the novel scenario where workers have a reject option so they may skip microtasks when they are unable or choose not to respond. For example, in mismatched speech transcription, workers who do not know the language may not be able to respond to microtasks focused on phonological dimensions outside their categorical perception. We present an aggregation approach using a weighted majority voting rule, where each worker's response is assigned an optimized weight to maximize the crowd's classification performance. We evaluate system performance in both exact and asymptotic forms. Further, we consider the setting where there may be a set of greedy workers that complete microtasks even when they are unable to perform it reliably. We consider an oblivious and an expurgation strategy to deal with greedy workers, developing an algorithm to adaptively switch between the two based on the estimated fraction of greedy workers in the anonymous crowd. Simulation results show improved performance compared with conventional majority voting. version:2
arxiv-1606-03476 | Generative Adversarial Imitation Learning | http://arxiv.org/abs/1606.03476 | id:1606.03476 author:Jonathan Ho, Stefano Ermon category:cs.LG cs.AI  published:2016-06-10 summary:Consider learning a policy from example expert behavior, without interaction with the expert or access to reinforcement signal. One approach is to recover the expert's cost function with inverse reinforcement learning, then extract a policy from that cost function with reinforcement learning. This approach is indirect and can be slow. We propose a new general framework for directly extracting a policy from data, as if it were obtained by reinforcement learning following inverse reinforcement learning. We show that a certain instantiation of our framework draws an analogy between imitation learning and generative adversarial networks, from which we derive a model-free imitation learning algorithm that obtains significant performance gains over existing model-free methods in imitating complex behaviors in large, high-dimensional environments. version:1
arxiv-1510-03164 | Context-Aware Bandits | http://arxiv.org/abs/1510.03164 | id:1510.03164 author:Shuai Li, Purushottam Kar category:cs.LG cs.AI stat.ML  published:2015-10-12 summary:We propose an efficient Context-Aware clustering of Bandits (CAB) algorithm, which can capture collaborative effects. CAB can be easily deployed in a real-world recommendation system, where multi-armed bandits have been shown to perform well in particular with respect to the cold-start problem. CAB utilizes a context-aware clustering augmented by exploration-exploitation strategies. CAB dynamically clusters the users based on the content universe under consideration. We give a theoretical analysis in the standard stochastic multi-armed bandits setting. We show the efficiency of our approach on production and real-world datasets, demonstrate the scalability, and, more importantly, the significant increased prediction performance against several state-of-the-art methods. version:4
arxiv-1606-03475 | De-identification of Patient Notes with Recurrent Neural Networks | http://arxiv.org/abs/1606.03475 | id:1606.03475 author:Franck Dernoncourt, Ji Young Lee, Ozlem Uzuner, Peter Szolovits category:cs.CL cs.AI cs.NE stat.ML  published:2016-06-10 summary:Objective: Patient notes in electronic health records (EHRs) may contain critical information for medical investigations. However, the vast majority of medical investigators can only access de-identified notes, in order to protect the confidentiality of patients. In the United States, the Health Insurance Portability and Accountability Act (HIPAA) defines 18 types of protected health information (PHI) that needs to be removed to de-identify patient notes. Manual de-identification is impractical given the size of EHR databases, the limited number of researchers with access to the non-de-identified notes, and the frequent mistakes of human annotators. A reliable automated de-identification system would consequently be of high value. Materials and Methods: We introduce the first de-identification system based on artificial neural networks (ANNs), which requires no handcrafted features or rules, unlike existing systems. We compare the performance of the system with state-of-the-art systems on two datasets: the i2b2 2014 de-identification challenge dataset, which is the largest publicly available de-identification dataset, and the MIMIC de-identification dataset, which we assembled and is twice as large as the i2b2 2014 dataset. Results: Our ANN model outperforms the state-of-the-art systems. It yields an F1-score of 97.85 on the i2b2 2014 dataset, with a recall 97.38 and a precision of 97.32, and an F1-score of 99.23 on the MIMIC de-identification dataset, with a recall 99.25 and a precision of 99.06. Conclusion: Our findings support the use of ANNs for de-identification of patient notes, as they show better performance than previously published systems while requiring no feature engineering. version:1
arxiv-1606-03474 | On degeneracy control in overcomplete ICA | http://arxiv.org/abs/1606.03474 | id:1606.03474 author:Jesse A. Livezey, Alejandro F. Bujan, Friedrich T. Sommer category:cs.LG  published:2016-06-10 summary:Understanding the effects of degeneracy control mechanisms when learning overcomplete representations is crucial for applying Independent Components Analysis (ICA) in machine learning and theoretical neuroscience. A number of approaches to degeneracy control have been proposed which can learn non-degenerate complete representations, however some of these methods can fall into bad local minima when extended to overcomplete ICA. Furthermore, they may have unintended side-effects on the distribution of learned basis elements, which may lead to a biased exploration of the data manifold. In this work, we identify and theoretically analyze the cause of these failures and propose a framework that can be used to evaluate arbitrary degeneracy control mechanisms. We evaluate different methods for degeneracy control in overcomplete ICA and suggest two novel approaches, one of which can learn highly orthonormal bases. Finally, we compare all methods on the task of estimating an overcomplete basis on natural images. version:1
arxiv-1606-03473 | Face Detection with the Faster R-CNN | http://arxiv.org/abs/1606.03473 | id:1606.03473 author:Huaizu Jiang, Erik Learned-Miller category:cs.CV  published:2016-06-10 summary:The Faster R-CNN has recently demonstrated impressive results on various object detection benchmarks. By training a Faster R-CNN model on the large scale WIDER face dataset, we report state-of-the-art results on two widely used face detection benchmarks, FDDB and the recently released IJB-A. version:1
arxiv-1606-03439 | Deep Directed Generative Models with Energy-Based Probability Estimation | http://arxiv.org/abs/1606.03439 | id:1606.03439 author:Taesup Kim, Yoshua Bengio category:cs.LG stat.ML  published:2016-06-10 summary:Training energy-based probabilistic models is confronted with apparently intractable sums, whose Monte Carlo estimation requires sampling from the estimated probability distribution in the inner loop of training. This can be approximately achieved by Markov chain Monte Carlo methods, but may still face a formidable obstacle that is the difficulty of mixing between modes with sharp concentrations of probability. Whereas an MCMC process is usually derived from a given energy function based on mathematical considerations and requires an arbitrarily long time to obtain good and varied samples, we propose to train a deep directed generative model (not a Markov chain) so that its sampling distribution approximately matches the energy function that is being trained. Inspired by generative adversarial networks, the proposed framework involves training of two models that represent dual views of the estimated probability distribution: the energy function (mapping an input configuration to a scalar energy value) and the generator (mapping a noise vector to a generated configuration), both represented by deep neural networks. version:1
arxiv-1606-03432 | Scan Order in Gibbs Sampling: Models in Which it Matters and Bounds on How Much | http://arxiv.org/abs/1606.03432 | id:1606.03432 author:Bryan He, Christopher De Sa, Ioannis Mitliagkas, Christopher Ré category:cs.LG cs.AI stat.ML  published:2016-06-10 summary:Gibbs sampling is a Markov Chain Monte Carlo sampling technique that iteratively samples variables from their conditional distributions. There are two common scan orders for the variables: random scan and systematic scan. Due to the benefits of locality in hardware, systematic scan is commonly used, even though most statistical guarantees are only for random scan. While it has been conjectured that the mixing times of random scan and systematic scan do not differ by more than a logarithmic factor, we show by counterexample that this is not the case, and we prove that that the mixing times do not differ by more than a polynomial factor under mild conditions. To prove these relative bounds, we introduce a method of augmenting the state space to study systematic scan using conductance. version:1
arxiv-1605-07246 | Adaptive ADMM with Spectral Penalty Parameter Selection | http://arxiv.org/abs/1605.07246 | id:1605.07246 author:Zheng Xu, Mario A. T. Figueiredo, Tom Goldstein category:cs.LG cs.AI cs.NA  published:2016-05-24 summary:The alternating direction method of multipliers (ADMM) is a versatile tool for solving a wide range of constrained optimization problems, with differentiable or non-differentiable objective functions. Unfortunately, its performance is highly sensitive to a penalty parameter, which makes ADMM often unreliable and hard to automate for a non-expert user. We tackle this weakness of ADMM by proposing a method to adaptively tune the penalty parameters to achieve fast convergence. The resulting adaptive ADMM (AADMM) algorithm, inspired by the successful Barzilai-Borwein spectral method for gradient descent, yields fast convergence and relative insensitivity to the initial stepsize and problem scaling. version:2
arxiv-1603-03629 | Square Root Graphical Models: Multivariate Generalizations of Univariate Exponential Families that Permit Positive Dependencies | http://arxiv.org/abs/1603.03629 | id:1603.03629 author:David I. Inouye, Pradeep Ravikumar, Inderjit S. Dhillon category:stat.ML  published:2016-03-11 summary:We develop Square Root Graphical Models (SQR), a novel class of parametric graphical models that provides multivariate generalizations of univariate exponential family distributions. Previous multivariate graphical models [Yang et al. 2015] did not allow positive dependencies for the exponential and Poisson generalizations. However, in many real-world datasets, variables clearly have positive dependencies. For example, the airport delay time in New York---modeled as an exponential distribution---is positively related to the delay time in Boston. With this motivation, we give an example of our model class derived from the univariate exponential distribution that allows for almost arbitrary positive and negative dependencies with only a mild condition on the parameter matrix---a condition akin to the positive definiteness of the Gaussian covariance matrix. Our Poisson generalization allows for both positive and negative dependencies without any constraints on the parameter values. We also develop parameter estimation methods using node-wise regressions with $\ell_1$ regularization and likelihood approximation methods using sampling. Finally, we demonstrate our exponential generalization on a synthetic dataset and a real-world dataset of airport delay times. version:2
arxiv-1511-08498 | Iterative Instance Segmentation | http://arxiv.org/abs/1511.08498 | id:1511.08498 author:Ke Li, Bharath Hariharan, Jitendra Malik category:cs.CV cs.LG  published:2015-11-26 summary:Existing methods for pixel-wise labelling tasks generally disregard the underlying structure of labellings, often leading to predictions that are visually implausible. While incorporating structure into the model should improve prediction quality, doing so is challenging - manually specifying the form of structural constraints may be impractical and inference often becomes intractable even if structural constraints are given. We sidestep this problem by reducing structured prediction to a sequence of unconstrained prediction problems and demonstrate that this approach is capable of automatically discovering priors on shape, contiguity of region predictions and smoothness of region contours from data without any a priori specification. On the instance segmentation task, this method outperforms the state-of-the-art, achieving a mean $\mathrm{AP}^{r}$ of 63.6% at 50% overlap and 43.3% at 70% overlap. version:3
arxiv-1512-00442 | Fast k-Nearest Neighbour Search via Dynamic Continuous Indexing | http://arxiv.org/abs/1512.00442 | id:1512.00442 author:Ke Li, Jitendra Malik category:cs.DS cs.AI cs.IR cs.LG stat.ML  published:2015-12-01 summary:Existing methods for retrieving k-nearest neighbours suffer from the curse of dimensionality. We argue this is caused in part by inherent deficiencies of space partitioning, which is the underlying strategy used by most existing methods. We devise a new strategy that avoids partitioning the vector space and present a novel randomized algorithm that runs in time linear in dimensionality of the space and sub-linear in the intrinsic dimensionality and the size of the dataset and takes space constant in dimensionality of the space and linear in the size of the dataset. The proposed algorithm allows fine-grained control over accuracy and speed on a per-query basis, automatically adapts to variations in data density, supports dynamic updates to the dataset and is easy-to-implement. We show appealing theoretical properties and demonstrate empirically that the proposed algorithm outperforms locality-sensitivity hashing (LSH) in terms of approximation quality, speed and space efficiency. version:2
arxiv-1606-03402 | Length bias in Encoder Decoder Models and a Case for Global Conditioning | http://arxiv.org/abs/1606.03402 | id:1606.03402 author:Pavel Sountsov, Sunita Sarawagi category:cs.AI cs.CL  published:2016-06-10 summary:Encoder-decoder networks are popular for probabilistic modeling sequences in many applications. These models use the power of the Long Short-Term Memory (LSTM) architecture to capture the full dependence among variables and are not subject to label bias of locally conditioned models that assume partial conditional independence. However in practice they exhibit a bias towards short sequences even when using a beam search to find the optimal sequence. Surprisingly, sometimes there is even a decline in accuracy with increasing the beam size. In this paper we show that such phenomena are due to a discrepancy between the full sequence margin and the per-element margin enforced by the locally conditioned training objective of a encoder-decoder model. The discrepancy more adversely impacts long sequences, explaining the bias towards predicting short sequences. For the case where the predicted sequences come from a closed set, we show that a globally conditioned model alleviates the above problems of encoder-decoder models. From a practical point of view, our proposed model also eliminates the need for a beam-search during inference, which reduces to an efficient dot-product based search in a vector-space. version:1
arxiv-1606-03401 | Memory-Efficient Backpropagation Through Time | http://arxiv.org/abs/1606.03401 | id:1606.03401 author:Audrūnas Gruslys, Remi Munos, Ivo Danihelka, Marc Lanctot, Alex Graves category:cs.NE cs.LG  published:2016-06-10 summary:We propose a novel approach to reduce memory consumption of the backpropagation through time (BPTT) algorithm when training recurrent neural networks (RNNs). Our approach uses dynamic programming to balance a trade-off between caching of intermediate results and recomputation. The algorithm is capable of tightly fitting within almost any user-set memory budget while finding an optimal execution policy minimizing the computational cost. Computational devices have limited memory capacity and maximizing a computational performance given a fixed memory budget is a practical use-case. We provide asymptotic computational upper bounds for various regimes. The algorithm is particularly effective for long sequences. For sequences of length 1000, our algorithm saves 95\% of memory usage while using only one third more time per iteration than the standard BPTT. version:1
arxiv-1606-03398 | Bootstrapping Distantly Supervised IE using Joint Learning and Small Well-structured Corpora | http://arxiv.org/abs/1606.03398 | id:1606.03398 author:Lidong Bing, Bhuwan Dhingra, Kathryn Mazaitis, Jong Hyuk Park, William W. Cohen category:cs.CL  published:2016-06-10 summary:We propose a framework to improve performance of distantly-supervised relation extraction, by jointly learning to solve two related tasks: concept-instance extraction and relation extraction. We combine this with a novel use of document structure: in some small, well-structured corpora, sections can be identified that correspond to relation arguments, and distantly-labeled examples from such sections tend to have good precision. Using these as seeds we extract additional relation examples by applying label propagation on a graph composed of noisy examples extracted from a large unstructured testing corpus. Combined with the soft constraint that concept examples should have the same type as the second argument of the relation, we get significant improvements over several state-of-the-art approaches to distantly-supervised relation extraction. version:1
arxiv-1606-03391 | Simple Question Answering by Attentive Convolutional Neural Network | http://arxiv.org/abs/1606.03391 | id:1606.03391 author:Wenpeng Yin, Mo Yu, Bing Xiang, Bowen Zhou, Hinrich Schütze category:cs.CL  published:2016-06-10 summary:This work focuses on answering single-relation factoid questions over Freebase. Each question can acquire the answer from a single fact of form (subject, predicate, object) in Freebase. This task, simple question answering (SimpleQA), can be addressed via a two-step pipeline: entity linking and fact selection. In fact selection, we match the subject entity in fact with the entity mention in question by a character-level convolutional neural network (char-CNN), and match the predicate in fact with the question by a word-level CNN (word-CNN). This work makes two main contributions. (i) A simple and effective entity linker over Freebase is proposed. Our entity linker outperforms the state-of-the-art entity linker of SimpleQA task. (ii) A novel attentive maxpooling is stacked over word-CNN, so that the predicate representation can be matched with the predicate-focused question representation more effectively. Experiments show that our system sets new state-of-the-art in this task. version:1
arxiv-1606-02270 | Natural Language Comprehension with the EpiReader | http://arxiv.org/abs/1606.02270 | id:1606.02270 author:Adam Trischler, Zheng Ye, Xingdi Yuan, Kaheer Suleman category:cs.CL  published:2016-06-07 summary:We present the EpiReader, a novel model for machine comprehension of text. Machine comprehension of unstructured, real-world text is a major research goal for natural language processing. Current tests of machine comprehension pose questions whose answers can be inferred from some supporting text, and evaluate a model's response to the questions. The EpiReader is an end-to-end neural model comprising two components: the first component proposes a small set of candidate answers after comparing a question to its supporting text, and the second component formulates hypotheses using the proposed candidates and the question, then reranks the hypotheses based on their estimated concordance with the supporting text. We present experiments demonstrating that the EpiReader sets a new state-of-the-art on the CNN and Children's Book Test machine comprehension benchmarks, outperforming previous neural models by a significant margin. version:2
arxiv-1606-03369 | FOMTrace: Interactive Video Segmentation By Image Graphs and Fuzzy Object Models | http://arxiv.org/abs/1606.03369 | id:1606.03369 author:Thiago Vallin Spina, Alexandre Xavier Falcão category:cs.CV  published:2016-06-10 summary:Common users have changed from mere consumers to active producers of multimedia data content. Video editing plays an important role in this scenario, calling for simple segmentation tools that can handle fast-moving and deformable video objects with possible occlusions, color similarities with the background, among other challenges. We present an interactive video segmentation method, named FOMTrace, which addresses the problem in an effective and efficient way. From a user-provided object mask in a first frame, the method performs semi-automatic video segmentation on a spatiotemporal superpixel-graph, and then estimates a Fuzzy Object Model (FOM), which refines segmentation of the second frame by constraining delineation on a pixel-graph within a region where the object's boundary is expected to be. The user can correct/accept the refined object mask in the second frame, which is then similarly used to improve the spatiotemporal video segmentation of the remaining frames. Both steps are repeated alternately, within interactive response times, until the segmentation refinement of the final frame is accepted by the user. Extensive experiments demonstrate FOMTrace's ability for tracing objects in comparison with state-of-the-art approaches for interactive video segmentation, supervised, and unsupervised object tracking. version:1
arxiv-1606-03358 | Extended Gauss-Newton and Gauss-Newton-ADMM Algorithms for Low-Rank Matrix Optimization | http://arxiv.org/abs/1606.03358 | id:1606.03358 author:Quoc Tran-Dinh, Zheqi Zhang category:math.OC stat.ML  published:2016-06-10 summary:We develop a generic Gauss-Newton (GN) framework for solving a class of nonconvex optimization problems involving low-rank matrix variables. As opposed to standard Gauss-Newton method, our framework allows one to handle general smooth convex cost function via its surrogate. The main complexity-per-iteration consists of the inverse of two rank-size matrices and at most six small matrix multiplications to compute a closed form Gauss-Newton direction, and a backtracking linesearch. We show, under mild conditions, that the proposed algorithm globally and locally converges to a stationary point of the original nonconvex problem. We also show empirically that the Gauss-Newton algorithm achieves much higher accurate solutions compared to the well studied alternating direction method (ADM). Then, we specify our Gauss-Newton framework to handle the symmetric case and prove its convergence, where ADM is not applicable without lifting variables. Next, we incorporate our Gauss-Newton scheme into the alternating direction method of multipliers (ADMM) to design a GN-ADMM algorithm for solving the low-rank optimization problem. We prove that, under mild conditions and a proper choice of the penalty parameter, our GN-ADMM globally converges to a stationary point of the original problem. Finally, we apply our algorithms to solve several problems in practice such as low-rank approximation, matrix completion, robust low-rank matrix recovery, and matrix recovery in quantum tomography. The numerical experiments provide encouraging results to motivate the use of nonconvex optimization. version:1
arxiv-1606-03352 | Conditional Generation and Snapshot Learning in Neural Dialogue Systems | http://arxiv.org/abs/1606.03352 | id:1606.03352 author:Tsung-Hsien Wen, Milica Gasic, Nikola Mrksic, Lina M. Rojas-Barahona, Pei-Hao Su, Stefan Ultes, David Vandyke, Steve Young category:cs.CL cs.NE stat.ML  published:2016-06-10 summary:Recently a variety of LSTM-based conditional language models (LM) have been applied across a range of language generation tasks. In this work we study various model architectures and different ways to represent and aggregate the source information in an end-to-end neural dialogue system framework. A method called snapshot learning is also proposed to facilitate learning from supervised sequential signals by applying a companion cross-entropy objective function to the conditioning vector. The experimental and analytical results demonstrate firstly that competition occurs between the conditioning vector and the LM, and the differing architectures provide different trade-offs between the two. Secondly, the discriminative power and transparency of the conditioning vector is key to providing both model interpretability and better performance. Thirdly, snapshot learning leads to consistent performance improvements independent of which architecture is used. version:1
arxiv-1508-07909 | Neural Machine Translation of Rare Words with Subword Units | http://arxiv.org/abs/1508.07909 | id:1508.07909 author:Rico Sennrich, Barry Haddow, Alexandra Birch category:cs.CL  published:2015-08-31 summary:Neural machine translation (NMT) models typically operate with a fixed vocabulary, but translation is an open-vocabulary problem. Previous work addresses the translation of out-of-vocabulary words by backing off to a dictionary. In this paper, we introduce a simpler and more effective approach, making the NMT model capable of open-vocabulary translation by encoding rare and unknown words as sequences of subword units. This is based on the intuition that various word classes are translatable via smaller units than words, for instance names (via character copying or transliteration), compounds (via compositional translation), and cognates and loanwords (via phonological and morphological transformations). We discuss the suitability of different word segmentation techniques, including simple character n-gram models and a segmentation based on the byte pair encoding compression algorithm, and empirically show that subword models improve over a back-off dictionary baseline for the WMT 15 translation tasks English-German and English-Russian by 1.1 and 1.3 BLEU, respectively. version:5
arxiv-1606-03335 | WordNet2Vec: Corpora Agnostic Word Vectorization Method | http://arxiv.org/abs/1606.03335 | id:1606.03335 author:Roman Bartusiak, Łukasz Augustyniak, Tomasz Kajdanowicz, Przemysław Kazienko, Maciej Piasecki category:cs.CL cs.AI cs.DC  published:2016-06-10 summary:A complex nature of big data resources demands new methods for structuring especially for textual content. WordNet is a good knowledge source for comprehensive abstraction of natural language as its good implementations exist for many languages. Since WordNet embeds natural language in the form of a complex network, a transformation mechanism WordNet2Vec is proposed in the paper. It creates vectors for each word from WordNet. These vectors encapsulate general position - role of a given word towards all other words in the natural language. Any list or set of such vectors contains knowledge about the context of its component within the whole language. Such word representation can be easily applied to many analytic tasks like classification or clustering. The usefulness of the WordNet2Vec method was demonstrated in sentiment analysis, i.e. classification with transfer learning for the real Amazon opinion textual dataset. version:1
arxiv-1606-03333 | Automatic Genre and Show Identification of Broadcast Media | http://arxiv.org/abs/1606.03333 | id:1606.03333 author:Mortaza Doulaty, Oscar Saz, Raymond W. M. Ng, Thomas Hain category:cs.MM cs.CL cs.IR  published:2016-06-10 summary:Huge amounts of digital videos are being produced and broadcast every day, leading to giant media archives. Effective techniques are needed to make such data accessible further. Automatic meta-data labelling of broadcast media is an essential task for multimedia indexing, where it is standard to use multi-modal input for such purposes. This paper describes a novel method for automatic detection of media genre and show identities using acoustic features, textual features or a combination thereof. Furthermore the inclusion of available meta-data, such as time of broadcast, is shown to lead to very high performance. Latent Dirichlet Allocation is used to model both acoustics and text, yielding fixed dimensional representations of media recordings that can then be used in Support Vector Machines based classification. Experiments are conducted on more than 1200 hours of TV broadcasts from the British Broadcasting Corporation (BBC), where the task is to categorise the broadcasts into 8 genres or 133 show identities. On a 200-hour test set, accuracies of 98.6% and 85.7% were achieved for genre and show identification respectively, using a combination of acoustic and textual features with meta-data. version:1
arxiv-1606-03326 | A Lower Bound Analysis of Population-based Evolutionary Algorithms for Pseudo-Boolean Functions | http://arxiv.org/abs/1606.03326 | id:1606.03326 author:Chao Qian, Yang Yu, Zhi-Hua Zhou category:cs.NE cs.CC  published:2016-06-10 summary:Evolutionary algorithms (EAs) are population-based general-purpose optimization algorithms, and have been successfully applied in various real-world optimization tasks. However, previous theoretical studies often employ EAs with only a parent or offspring population and focus on specific problems. Furthermore, they often only show upper bounds on the running time, while lower bounds are also necessary to get a complete understanding of an algorithm. In this paper, we analyze the running time of the ($\mu$+$\lambda$)-EA (a general population-based EA with mutation only) on the class of pseudo-Boolean functions with a unique global optimum. By applying the recently proposed switch analysis approach, we prove the lower bound $\Omega(n \ln n+ \mu + \lambda n\ln\ln n/ \ln n)$ for the first time. Particularly on the two widely-studied problems, OneMax and LeadingOnes, the derived lower bound discloses that the ($\mu$+$\lambda$)-EA will be strictly slower than the (1+1)-EA when the population size $\mu$ or $\lambda$ is above a moderate order. Our results imply that the increase of population size, while usually desired in practice, bears the risk of increasing the lower bound of the running time and thus should be carefully considered. version:1
arxiv-1606-01039 | Gaussian Processes for Music Audio Modelling and Content Analysis | http://arxiv.org/abs/1606.01039 | id:1606.01039 author:Pablo A. Alvarado, Dan Stowell category:stat.ML cs.SD  published:2016-06-03 summary:Real music signals are highly variable, yet they have strong statistical structure. Prior information about the underlying physical mechanisms by which sounds are generated and rules by which complex sound structure is constructed (notes, chords, a complete musical score), can be naturally unified using Bayesian modelling techniques. Typically algorithms for Automatic Music Transcription independently carry out individual tasks such as multiple-F0 detection and beat tracking. The challenge remains to perform joint estimation of all parameters. We present a Bayesian approach for modelling music audio, and content analysis. The proposed methodology based on Gaussian processes seeks joint estimation of multiple music concepts by incorporating into the kernel prior information about non-stationary behaviour, dynamics, and rich spectral content present in the modelled music signal. We illustrate the benefits of this approach via two tasks: pitch estimation, and inferring missing segments in a polyphonic audio recording. version:2
arxiv-1605-08228 | Predict or classify: The deceptive role of time-locking in brain signal classification | http://arxiv.org/abs/1605.08228 | id:1605.08228 author:Marco Rusconi, Angelo Valleriani category:q-bio.NC physics.bio-ph stat.ML  published:2016-05-26 summary:Several experimental studies claim to be able to predict the outcome of simple decisions from brain signals measured before subjects are aware of their decision. Often, these studies use multivariate pattern recognition methods with the underlying assumption that the ability to classify the brain signal is equivalent to predict the decision itself. Here we show instead that it is possible to correctly classify a signal even if it does not contain any predictive information about the decision. We first define a simple stochastic model that mimics the random decision process between two equivalent alternatives, and generate a large number of independent trials that contain no choice-predictive information. The trials are first time-locked to the time point of the final event and then classified using standard machine-learning techniques. The resulting classification accuracy is above chance level long before the time point of time-locking. We then analyze the same trials using information theory. We demonstrate that the high classification accuracy is a consequence of time-locking and that its time behavior is simply related to the large relaxation time of the process. We conclude that when time-locking is a crucial step in the analysis of neural activity patterns, both the emergence and the timing of the classification accuracy are affected by structural properties of the network that generates the signal. version:2
arxiv-1506-03172 | A Scheme for Molecular Computation of Maximum Likelihood Estimators for Log-Linear Models | http://arxiv.org/abs/1506.03172 | id:1506.03172 author:Manoj Gopalkrishnan category:cs.NE math.ST q-bio.MN stat.TH  published:2015-06-10 summary:We propose a novel molecular computing scheme for statistical inference. We focus on the much-studied statistical inference problem of computing maximum likelihood estimators for log-linear models. Our scheme takes log-linear models to reaction systems, and the observed data to initial conditions, so that the corresponding equilibrium of each reaction system encodes the corresponding maximum likelihood estimator. The main idea is to exploit the coincidence between thermodynamic entropy and statistical entropy. We map a Maximum Entropy characterization of the maximum likelihood estimator onto a Maximum Entropy characterization of the equilibrium concentrations for the reaction system. This allows for an efficient encoding of the problem, and reveals that reaction networks are superbly suited to statistical inference tasks. Such a scheme may also provide a template to understanding how in vivo biochemical signaling pathways integrate extensive information about their environment and history. version:2
arxiv-1606-03276 | Network Lasso Optimization For Smart City Ride Share Prediction | http://arxiv.org/abs/1606.03276 | id:1606.03276 author:Shaona Ghosh category:cs.CY cs.LG stat.ML  published:2016-06-10 summary:Ride sharing has important implications in terms of environmental, social and individual goals by reducing carbon footprint, fostering social interactions and economizing commuter costs. Most big city government councils and commercial enterprises that prioritize traffic, commuter satisfaction and environmental health, gather large scale data in the order of millions of records, that can be potentially analysed to predict significant ride share opportunities. The ride sharing systems that are commonly available lack adaptive and scalable techniques that can simultaneously learn from the large scale data and predict in real-time dynamic fashion. In this paper, we study such a problem towards a Smart Society initiative, where a generic ride sharing system is conceived capable of making predictions about ride share opportunities based on the historically recorded data while satisfying real-time ride requests. Underpinning the system is an application of a powerful machine learning algorithm called Network Lasso that uses fully scalable Alternate Direction Method of Multipliers (ADMM) optimization for model based dynamic prediction. The three major contributions of this paper are: 1. A machine learning enabled ride sharing system is proposed that can learn from historical data to infer and predict on new ride share opportunities manifested in real time ride requests. 2. For generalization, we allow the model to utilize spatio-temporal structural similarity across the data records induced by the network topology, thus enabling the prediction to accommodate demand surge, economical viability and correlations in feature space. 3. The strategy adapted for the optimization is fully scalable and robust for heterogeneous Big Data and Internet of Things enabled ride share systems. 4. We provide an empirical evaluation on real and simulated data that validates our method. version:1
arxiv-1511-06068 | Reducing Overfitting in Deep Networks by Decorrelating Representations | http://arxiv.org/abs/1511.06068 | id:1511.06068 author:Michael Cogswell, Faruk Ahmed, Ross Girshick, Larry Zitnick, Dhruv Batra category:cs.LG stat.ML  published:2015-11-19 summary:One major challenge in training Deep Neural Networks is preventing overfitting. Many techniques such as data augmentation and novel regularizers such as Dropout have been proposed to prevent overfitting without requiring a massive amount of training data. In this work, we propose a new regularizer called DeCov which leads to significantly reduced overfitting (as indicated by the difference between train and val performance), and better generalization. Our regularizer encourages diverse or non-redundant representations in Deep Neural Networks by minimizing the cross-covariance of hidden activations. This simple intuition has been explored in a number of past works but surprisingly has never been applied as a regularizer in supervised learning. Experiments across a range of datasets and network architectures show that this loss always reduces overfitting while almost always maintaining or increasing generalization performance and often improving performance over Dropout. version:4
arxiv-1606-03254 | Natural Language Generation enhances human decision-making with uncertain information | http://arxiv.org/abs/1606.03254 | id:1606.03254 author:Dimitra Gkatzia, Oliver Lemon, Verena Rieser category:cs.CL cs.AI  published:2016-06-10 summary:Decision-making is often dependent on uncertain data, e.g. data associated with confidence scores or probabilities. We present a comparison of different information presentations for uncertain data and, for the first time, measure their effects on human decision-making. We show that the use of Natural Language Generation (NLG) improves decision-making under uncertainty, compared to state-of-the-art graphical-based representation methods. In a task-based study with 442 adults, we found that presentations using NLG lead to 24% better decision-making on average than the graphical presentations, and to 44% better decision-making when NLG is combined with graphics. We also show that women achieve significantly better results when presented with NLG output (an 87% increase on average compared to graphical presentations). version:1
arxiv-1606-03237 | Survey on RGB, 3D, Thermal, and Multimodal Approaches for Facial Expression Recognition: History, Trends, and Affect-related Applications | http://arxiv.org/abs/1606.03237 | id:1606.03237 author:Ciprian Corneanu, Marc Oliu, Jeffrey F. Cohn, Sergio Escalera category:cs.CV  published:2016-06-10 summary:Facial expressions are an important way through which humans interact socially. Building a system capable of automatically recognizing facial expressions from images and video has been an intense field of study in recent years. Interpreting such expressions remains challenging and much research is needed about the way they relate to human affect. This paper presents a general overview of automatic RGB, 3D, thermal and multimodal facial expression analysis. We define a new taxonomy for the field, encompassing all steps from face detection to facial expression recognition, and describe and classify the state of the art methods accordingly. We also present the important datasets and the bench-marking of most influential methods. We conclude with a general discussion about trends, important questions and future lines of research. version:1
arxiv-1606-03212 | Discovery of Latent Factors in High-dimensional Data Using Tensor Methods | http://arxiv.org/abs/1606.03212 | id:1606.03212 author:Furong Huang category:cs.LG  published:2016-06-10 summary:Unsupervised learning aims at the discovery of hidden structure that drives the observations in the real world. It is essential for success in modern machine learning. Latent variable models are versatile in unsupervised learning and have applications in almost every domain. Training latent variable models is challenging due to the non-convexity of the likelihood objective. An alternative method is based on the spectral decomposition of low order moment tensors. This versatile framework is guaranteed to estimate the correct model consistently. My thesis spans both theoretical analysis of tensor decomposition framework and practical implementation of various applications. This thesis presents theoretical results on convergence to globally optimal solution of tensor decomposition using the stochastic gradient descent, despite non-convexity of the objective. This is the first work that gives global convergence guarantees for the stochastic gradient descent on non-convex functions with exponentially many local minima and saddle points. This thesis also presents large-scale deployment of spectral methods carried out on various platforms. Dimensionality reduction techniques such as random projection are incorporated for a highly parallel and scalable tensor decomposition algorithm. We obtain a gain in both accuracies and in running times by several orders of magnitude compared to the state-of-art variational methods. To solve real world problems, more advanced models and learning algorithms are proposed. This thesis discusses generalization of LDA model to mixed membership stochastic block model for learning user communities in social network, convolutional dictionary model for learning word-sequence embeddings, hierarchical tensor decomposition and latent tree structure model for learning disease hierarchy, and spatial point process mixture model for detecting cell types in neuroscience. version:1
arxiv-1606-03207 | Deep CNNs along the Time Axis with Intermap Pooling for Robustness to Spectral Variations | http://arxiv.org/abs/1606.03207 | id:1606.03207 author:Hwaran Lee, Geonmin Kim, Ho-Gyeong Kim, Sang-Hoon Oh, Soo-Young Lee category:cs.CL cs.LG cs.NE  published:2016-06-10 summary:Convolutional neural networks (CNNs) with convolutional and pooling operations along the frequency axis have been proposed to attain invariance to frequency shifts of features. However, this is inappropriate with regard to the fact that acoustic features vary in frequency. In this paper, we contend that convolution along the time axis is more effective. We also propose the addition of an intermap pooling (IMP) layer to deep CNNs. In this layer, filters in each group extract common but spectrally variant features, then the layer pools the feature maps of each group. As a result, the proposed IMP CNN can achieve insensitivity to spectral variations characteristic of different speakers and utterances. The effectiveness of the IMP CNN architecture is demonstrated on several LVCSR tasks. Even without speaker adaptation techniques, the architecture achieved a WER of 12.7% on the SWB part of the Hub5'2000 evaluation test set, which is competitive with other state-of-the-art methods. version:1
