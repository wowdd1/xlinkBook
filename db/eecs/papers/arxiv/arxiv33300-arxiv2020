arxiv-1709-02448 | Network Vector: Distributed Representations of Networks with Global Context | http://arxiv.org/abs/1709.02448 | id:1709.02448 author:Hao Wu, Kristina Lerman category:cs.SI cs.LG I.2.6  published:2017-09-07 summary:We propose a neural embedding algorithm called Network Vector, which learns distributed representations of nodes and the entire networks simultaneously. By embedding networks in a low-dimensional space, the algorithm allows us to compare networks in terms of structural similarity and to solve outstanding predictive problems. Unlike alternative approaches that focus on node level features, we learn a continuous global vector that captures each node's global context by maximizing the predictive likelihood of random walk paths in the network. Our algorithm is scalable to real world graphs with many nodes. We evaluate our algorithm on datasets from diverse domains, and compare it with state-of-the-art techniques in node classification, role discovery and concept analogy tasks. The empirical results show the effectiveness and the efficiency of our algorithm. version:1
arxiv-1709-02432 | Deep Learning the Physics of Transport Phenomena | http://arxiv.org/abs/1709.02432 | id:1709.02432 author:Amir Barati Farimani, Joseph Gomes, Vijay S. Pande category:cs.LG physics.comp-ph  published:2017-09-07 summary:We have developed a new data-driven paradigm for the rapid inference, modeling and simulation of the physics of transport phenomena by deep learning. Using conditional generative adversarial networks (cGAN), we train models for the direct generation of solutions to steady state heat conduction and incompressible fluid flow purely on observation without knowledge of the underlying governing equations. Rather than using iterative numerical methods to approximate the solution of the constitutive equations, cGANs learn to directly generate the solutions to these phenomena, given arbitrary boundary conditions and domain, with high test accuracy (MAE$<$1\%) and state-of-the-art computational performance. The cGAN framework can be used to learn causal models directly from experimental observations where the underlying physical model is complex or unknown. version:1
arxiv-1708-07576 | Learning the Enigma with Recurrent Neural Networks | http://arxiv.org/abs/1708.07576 | id:1708.07576 author:Sam Greydanus category:cs.NE  published:2017-08-24 summary:Recurrent neural networks (RNNs) represent the state of the art in translation, image captioning, and speech recognition. They are also capable of learning algorithmic tasks such as long addition, copying, and sorting from a set of training examples. We demonstrate that RNNs can learn decryption algorithms -- the mappings from plaintext to ciphertext -- for three polyalphabetic ciphers (Vigen\`ere, Autokey, and Enigma). Most notably, we demonstrate that an RNN with a 3000-unit Long Short-Term Memory (LSTM) cell can learn the decryption function of the Enigma machine. We argue that our model learns efficient internal representations of these ciphers 1) by exploring activations of individual memory neurons and 2) by comparing memory usage across the three ciphers. To be clear, our work is not aimed at 'cracking' the Enigma cipher. However, we do show that our model can perform elementary cryptanalysis by running known-plaintext attacks on the Vigen\`ere and Autokey ciphers. Our results indicate that RNNs can learn algorithmic representations of black box polyalphabetic ciphers and that these representations are useful for cryptanalysis. version:2
arxiv-1708-03425 | Argument Labeling of Explicit Discourse Relations using LSTM Neural Networks | http://arxiv.org/abs/1708.03425 | id:1708.03425 author:Sohail Hooda, Leila Kosseim category:cs.CL  published:2017-08-11 summary:Argument labeling of explicit discourse relations is a challenging task. The state of the art systems achieve slightly above 55% F-measure but require hand-crafted features. In this paper, we propose a Long Short Term Memory (LSTM) based model for argument labeling. We experimented with multiple configurations of our model. Using the PDTB dataset, our best model achieved an F1 measure of 23.05% without any feature engineering. This is significantly higher than the 20.52% achieved by the state of the art RNN approach, but significantly lower than the feature based state of the art systems. On the other hand, because our approach learns only from the raw dataset, it is more widely applicable to multiple textual genres and languages. version:2
arxiv-1709-02371 | PWC-Net: CNNs for Optical Flow Using Pyramid, Warping, and Cost Volume | http://arxiv.org/abs/1709.02371 | id:1709.02371 author:Deqing Sun, Xiaodong Yang, Ming-Yu Liu, Jan Kautz category:cs.CV  published:2017-09-07 summary:We design a compact but effective CNN model for optical flow by exploiting the well-known design principles: pyramid, warping, and cost volume. Cast in a learnable feature pyramid, our network uses the current optical flow estimate to warp the CNN features of the second image. It then uses the warped features and features of the first image to construct the cost volume, which is processed by a CNN network to decode the optical flow. As the cost volume is a more discriminative representation of the search space for the optical flow than raw images, a compact CNN decoder network is sufficient. Our model performs on par with the recent FlowNet2 method on the MPI Sintel and KITTI 2015 benchmarks, while being 17 times smaller in size and 2 times faster in inference. Our model protocol and learned parameters will be publicly available. version:1
arxiv-1709-02291 | Basic Filters for Convolutional Neural Networks: Training or Design? | http://arxiv.org/abs/1709.02291 | id:1709.02291 author:Monika Doerfler, Thomas Grill, Roswitha Bammer, Arthur Flexer category:cs.LG cs.IR  published:2017-09-07 summary:When convolutional neural networks are used to tackle learning problems based on time series, e.g., audio data, raw one-dimensional data are commonly pre-processed to obtain spectrogram or mel-spectrogram coefficients, which are then used as input to the actual neural network. In this contribution, we investigate, both theoretically and experimentally, the influence of this pre-processing step on the network's performance and pose the question, whether replacing it by applying adaptive or learned filters directly to the raw data, can improve learning success. The theoretical results show that approximately reproducing mel-spectrogram coefficients by applying adaptive filters and subsequent time-averaging is in principle possible. On the other hand, extensive experimental work leads to the conclusion, that the invariance induced by mel-spectrogram coefficients is both desirable and hard to infer by the learning process. Thus, the results achieved by adaptive end-to-end learning approaches are close to but slightly worse than results achieved by state-of-the-art reference architectures using standard input coefficients derived from the spectrogram. version:1
arxiv-1709-02285 | Monocular Navigation in Large Scale Dynamic Environments | http://arxiv.org/abs/1709.02285 | id:1709.02285 author:Darius Burschka category:cs.CV  published:2017-09-07 summary:We present a processing technique for a robust reconstruction of motion properties for single points in large scale, dynamic environments. We assume that the acquisition camera is moving and that there are other independently moving agents in a large environment, like road scenarios. The separation of direction and magnitude of the reconstructed motion allows for robust reconstruction of the dynamic state of the objects in situations, where conventional binocular systems fail due to a small signal (disparity) from the images due to a constant detection error, and where structure from motion approaches fail due to unobserved motion of other agents between the camera frames. We present the mathematical framework and the sensitivity analysis for the resulting system. version:1
arxiv-1709-02280 | Transfer Learning for Performance Modeling of Configurable Systems: An Exploratory Analysis | http://arxiv.org/abs/1709.02280 | id:1709.02280 author:Pooyan Jamshidi, Norbert Siegmund, Miguel Velez, Christian Kästner, Akshay Patel, Yuvraj Agarwal category:stat.ML cs.PF cs.SE  published:2017-09-07 summary:Modern software systems provide many configuration options which significantly influence their non-functional properties. To understand and predict the effect of configuration options, several sampling and learning strategies have been proposed, albeit often with significant cost to cover the highly dimensional configuration space. Recently, transfer learning has been applied to reduce the effort of constructing performance models by transferring knowledge about performance behavior across environments. While this line of research is promising to learn more accurate models at a lower cost, it is unclear why and when transfer learning works for performance modeling. To shed light on when it is beneficial to apply transfer learning, we conducted an empirical study on four popular software systems, varying software configurations and environmental conditions, such as hardware, workload, and software versions, to identify the key knowledge pieces that can be exploited for transfer learning. Our results show that in small environmental changes (e.g., homogeneous workload change), by applying a linear transformation to the performance model, we can understand the performance behavior of the target environment, while for severe environmental changes (e.g., drastic workload change) we can transfer only knowledge that makes sampling more efficient, e.g., by reducing the dimensionality of the configuration space. version:1
arxiv-1709-02279 | Cynical Selection of Language Model Training Data | http://arxiv.org/abs/1709.02279 | id:1709.02279 author:Amittai Axelrod category:cs.CL  published:2017-09-07 summary:The Moore-Lewis method of "intelligent selection of language model training data" is very effective, cheap, efficient... and also has structural problems. (1) The method defines relevance by playing language models trained on the in-domain and the out-of-domain (or data pool) corpora against each other. This powerful idea-- which we set out to preserve-- treats the two corpora as the opposing ends of a single spectrum. This lack of nuance does not allow for the two corpora to be very similar. In the extreme case where the come from the same distribution, all of the sentences have a Moore-Lewis score of zero, so there is no resulting ranking. (2) The selected sentences are not guaranteed to be able to model the in-domain data, nor to even cover the in-domain data. They are simply well-liked by the in-domain model; this is necessary, but not sufficient. (3) There is no way to tell what is the optimal number of sentences to select, short of picking various thresholds and building the systems. We present a greedy, lazy, approximate, and generally efficient information-theoretic method of accomplishing the same goal using only vocabulary counts. The method has the following properties: (1) Is responsive to the extent to which two corpora differ. (2) Quickly reaches near-optimal vocabulary coverage. (3) Takes into account what has already been selected. (4) Does not involve defining any kind of domain, nor any kind of classifier. (6) Knows approximately when to stop. This method can be used as an inherently-meaningful measure of similarity, as it measures the bits of information to be gained by adding one text to another. version:1
arxiv-1709-02271 | Leveraging Discourse Information Effectively for Authorship Attribution | http://arxiv.org/abs/1709.02271 | id:1709.02271 author:Su Wang, Elisa Ferracane, Raymond J. Mooney category:cs.CL  published:2017-09-07 summary:We explore techniques to maximize the effectiveness of discourse information in the task of authorship attribution. We present a novel method to embed discourse features in a Convolutional Neural Network text classifier, which achieves a state-of-the-art result by a substantial margin. We empirically investigate several featurization methods to understand the conditions under which discourse features contribute non-trivial performance gains, and analyze discourse embeddings. version:1
arxiv-1709-02232 | RNN-based Early Cyber-Attack Detection for the Tennessee Eastman Process | http://arxiv.org/abs/1709.02232 | id:1709.02232 author:Pavel Filonov, Fedor Kitashov, Andrey Lavrentyev category:cs.CR cs.LG  published:2017-09-07 summary:An RNN-based forecasting approach is used to early detect anomalies in industrial multivariate time series data from a simulated Tennessee Eastman Process (TEP) with many cyber-attacks. This work continues a previously proposed LSTM-based approach to the fault detection in simpler data. It is considered necessary to adapt the RNN network to deal with data containing stochastic, stationary, transitive and a rich variety of anomalous behaviours. There is particular focus on early detection with special NAB-metric. A comparison with the DPCA approach is provided. The generated data set is made publicly available. version:1
arxiv-1709-02228 | FingerNet: An Unified Deep Network for Fingerprint Minutiae Extraction | http://arxiv.org/abs/1709.02228 | id:1709.02228 author:Yao Tang, Fei Gao, Jufu Feng, Yuhang Liu category:cs.CV  published:2017-09-07 summary:Minutiae extraction is of critical importance in automated fingerprint recognition. Previous works on rolled/slap fingerprints failed on latent fingerprints due to noisy ridge patterns and complex background noises. In this paper, we propose a new way to design deep convolutional network combining domain knowledge and the representation ability of deep learning. In terms of orientation estimation, segmentation, enhancement and minutiae extraction, several typical traditional methods performed well on rolled/slap fingerprints are transformed into convolutional manners and integrated as an unified plain network. We demonstrate that this pipeline is equivalent to a shallow network with fixed weights. The network is then expanded to enhance its representation ability and the weights are released to learn complex background variance from data, while preserving end-to-end differentiability. Experimental results on NIST SD27 latent database and FVC 2004 slap database demonstrate that the proposed algorithm outperforms the state-of-the-art minutiae extraction algorithms. Code is made publicly available at: https://github.com/felixTY/FingerNet. version:1
arxiv-1709-02194 | Approximating meta-heuristics with homotopic recurrent neural networks | http://arxiv.org/abs/1709.02194 | id:1709.02194 author:Alessandro Bay, Biswa Sengupta category:stat.ML cs.DM cs.LG  published:2017-09-07 summary:Much combinatorial optimisation problems constitute a non-polynomial (NP) hard optimisation problem, i.e., they can not be solved in polynomial time. One such problem is finding the shortest route between two nodes on a graph. Meta-heuristic algorithms such as $A^{*}$ along with mixed-integer programming (MIP) methods are often employed for these problems. Our work demonstrates that it is possible to approximate solutions generated by a meta-heuristic algorithm using a deep recurrent neural network. We compare different methodologies based on reinforcement learning (RL) and recurrent neural networks (RNN) to gauge their respective quality of approximation. We show the viability of recurrent neural network solutions on a graph that has over 300 nodes and argue that a sequence-to-sequence network rather than other recurrent networks has improved approximation quality. Additionally, we argue that homotopy continuation -- that increases chances of hitting an extremum -- further improves the estimate generated by a vanilla RNN. version:1
arxiv-1709-02184 | Translating Domain-Specific Expressions in Knowledge Bases with Neural Machine Translation | http://arxiv.org/abs/1709.02184 | id:1709.02184 author:Mihael Arcan, Paul Buitelaar category:cs.CL  published:2017-09-07 summary:Our work presented in this paper focuses on the translation of domain-specific expressions represented in semantically structured resources, like ontologies or knowledge graphs. To make knowledge accessible beyond language borders, these resources need to be translated into different languages. The challenge of translating labels or terminological expressions represented in ontologies lies in the highly specific vocabulary and the lack of contextual information, which can guide a machine translation system to translate ambiguous words into the targeted domain. Due to the challenges, we train and translate the terminological expressions in the medial and financial domain with statistical as well as with neural machine translation methods. We evaluate the translation quality of domain-specific expressions with translation systems trained on a generic dataset and experiment domain adaptation with terminological expressions. Furthermore we perform experiments on the injection of external knowledge into the translation systems. Through these experiments, we observed a clear advantage in domain adaptation and terminology injection of NMT methods over SMT. Nevertheless, through the specific and unique terminological expressions, subword segmentation within NMT does not outperform a word based neural translation model. version:1
arxiv-1709-02142 | Rotational Subgroup Voting and Pose Clustering for Robust 3D Object Recognition | http://arxiv.org/abs/1709.02142 | id:1709.02142 author:Anders Glent Buch, Lilita Kiforenko, Dirk Kraft category:cs.CV  published:2017-09-07 summary:It is possible to associate a highly constrained subset of relative 6 DoF poses between two 3D shapes, as long as the local surface orientation, the normal vector, is available at every surface point. Local shape features can be used to find putative point correspondences between the models due to their ability to handle noisy and incomplete data. However, this correspondence set is usually contaminated by outliers in practical scenarios, which has led to many past contributions based on robust detectors such as the Hough transform or RANSAC. The key insight of our work is that a single correspondence between oriented points on the two models is constrained to cast votes in a 1 DoF rotational subgroup of the full group of poses, SE(3). Kernel density estimation allows combining the set of votes efficiently to determine a full 6 DoF candidate pose between the models. This modal pose with the highest density is stable under challenging conditions, such as noise, clutter, and occlusions, and provides the output estimate of our method. We first analyze the robustness of our method in relation to noise and show that it handles high outlier rates much better than RANSAC for the task of 6 DoF pose estimation. We then apply our method to four state of the art data sets for 3D object recognition that contain occluded and cluttered scenes. Our method achieves perfect recall on two LIDAR data sets and outperforms competing methods on two RGB-D data sets, thus setting a new standard for general 3D object recognition using point cloud data. version:1
arxiv-1709-01057 | To Learn or Not to Learn Features for Deformable Registration? | http://arxiv.org/abs/1709.01057 | id:1709.01057 author:Aabhas Majumdar, Raghav Mehta, Jayanthi Sivaswamy category:cs.CV  published:2017-09-04 summary:Feature-based registration has been popular with a variety of features ranging from voxel intensity to Self-Similarity Context (SSC). In this paper, we examine the question on how features learnt using various Deep Learning (DL) frameworks can be used for deformable registration and whether this feature learning is necessary or not. We investigate the use of features learned by different DL methods in the current state-of-the-art discrete registration framework and analyze its performance on 2 publicly available datasets. We draw insights into the type of DL framework useful for feature learning and the impact, if any, of the complexity of different DL models and brain parcellation methods on the performance of discrete registration. Our results indicate that the registration performance with DL features and SSC are comparable and stable across datasets whereas this does not hold for low level features. version:2
arxiv-1709-02123 | Integrating Specialized Classifiers Based on Continuous Time Markov Chain | http://arxiv.org/abs/1709.02123 | id:1709.02123 author:Zhizhong Li, Dahua Lin category:cs.LG cs.CV  published:2017-09-07 summary:Specialized classifiers, namely those dedicated to a subset of classes, are often adopted in real-world recognition systems. However, integrating such classifiers is nontrivial. Existing methods, e.g. weighted average, usually implicitly assume that all constituents of an ensemble cover the same set of classes. Such methods can produce misleading predictions when used to combine specialized classifiers. This work explores a novel approach. Instead of combining predictions from individual classifiers directly, it first decomposes the predictions into sets of pairwise preferences, treating them as transition channels between classes, and thereon constructs a continuous-time Markov chain, and use the equilibrium distribution of this chain as the final prediction. This way allows us to form a coherent picture over all specialized predictions. On large public datasets, the proposed method obtains considerable improvement compared to mainstream ensemble methods, especially when the classifier coverage is highly unbalanced. version:1
arxiv-1708-08989 | Deep Residual Bidir-LSTM for Human Activity Recognition Using Wearable Sensors | http://arxiv.org/abs/1708.08989 | id:1708.08989 author:Yu Zhao, Rennong Yang, Guillaume Chevalier, Maoguo Gong category:cs.CV cs.LG  published:2017-08-22 summary:Human activity recognition (HAR) has become a popular topic in research because of its wide application. With the development of deep learning, new ideas have appeared to address HAR problems. Here, a deep network architecture using residual bidirectional long short-term memory (LSTM) cells is proposed. The advantages of the new network include that a bidirectional connection can concatenate the positive time direction (forward state) and the negative time direction (backward state). Second, residual connections between stacked cells act as highways for gradients, which can pass underlying information directly to the upper layer, effectively avoiding the gradient vanishing problem. Generally, the proposed network shows improvements on both the temporal (using bidirectional cells) and the spatial (residual connections stacked deeply) dimensions, aiming to enhance the recognition rate. When tested with the Opportunity data set and the public domain UCI data set, the accuracy was increased by 4.78% and 3.68%, respectively, compared with previously reported results. Finally, the confusion matrix of the public domain UCI data set was analyzed. version:2
arxiv-1709-01584 | Using Posters to Recommend Anime and Mangas in a Cold-Start Scenario | http://arxiv.org/abs/1709.01584 | id:1709.01584 author:Jill-Jênn Vie, Florian Yger, Ryan Lahfa, Basile Clement, Kévin Cocchi, Thomas Chalumeau, Hisashi Kashima category:cs.IR cs.LG stat.ML  published:2017-09-03 summary:Item cold-start is a classical issue in recommender systems that affects anime and manga recommendations as well. This problem can be framed as follows: how to predict whether a user will like a manga that received few ratings from the community? Content-based techniques can alleviate this issue but require extra information, that is usually expensive to gather. In this paper, we use a deep learning technique, Illustration2Vec, to easily extract tag information from the manga and anime posters (e.g., sword, or ponytail). We propose BALSE (Blended Alternate Least Squares with Explanation), a new model for collaborative filtering, that benefits from this extra information to recommend mangas. We show, using real data from an online manga recommender system called Mangaki, that our model improves substantially the quality of recommendations, especially for less-known manga, and is able to provide an interpretation of the taste of the users. version:2
arxiv-1709-02087 | Sharp Bounds for Generalized Uniformity Testing | http://arxiv.org/abs/1709.02087 | id:1709.02087 author:Ilias Diakonikolas, Daniel M. Kane, Alistair Stewart category:cs.DS cs.IT cs.LG math.IT math.ST stat.TH  published:2017-09-07 summary:We study the problem of generalized uniformity testing \cite{BC17} of a discrete probability distribution: Given samples from a probability distribution $p$ over an {\em unknown} discrete domain $\mathbf{\Omega}$, we want to distinguish, with probability at least $2/3$, between the case that $p$ is uniform on some {\em subset} of $\mathbf{\Omega}$ versus $\epsilon$-far, in total variation distance, from any such uniform distribution. We establish tight bounds on the sample complexity of generalized uniformity testing. In more detail, we present a computationally efficient tester whose sample complexity is optimal, up to constant factors, and a matching information-theoretic lower bound. Specifically, we show that the sample complexity of generalized uniformity testing is $\Theta\left(1/(\epsilon^{4/3}\ p\ _3) + 1/(\epsilon^{2} \ p\ _2) \right)$. version:1
arxiv-1709-01703 | Conditional Generative Adversarial Networks for Speech Enhancement and Noise-Robust Speaker Verification | http://arxiv.org/abs/1709.01703 | id:1709.01703 author:Daniel Michelsanti, Zheng-Hua Tan category:eess.AS cs.LG cs.SD eess.SP stat.ML  published:2017-09-06 summary:Improving speech system performance in noisy environments remains a challenging task, and speech enhancement (SE) is one of the effective techniques to solve the problem. Motivated by the promising results of generative adversarial networks (GANs) in a variety of image processing tasks, we explore the potential of conditional GANs (cGANs) for SE, and in particular, we make use of the image processing framework proposed by Isola et al. [1] to learn a mapping from the spectrogram of noisy speech to an enhanced counterpart. The SE cGAN consists of two networks, trained in an adversarial manner: a generator that tries to enhance the input noisy spectrogram, and a discriminator that tries to distinguish between enhanced spectrograms provided by the generator and clean ones from the database using the noisy spectrogram as a condition. We evaluate the performance of the cGAN method in terms of perceptual evaluation of speech quality (PESQ), short-time objective intelligibility (STOI), and equal error rate (EER) of speaker verification (an example application). Experimental results show that the cGAN method overall outperforms the classical short-time spectral amplitude minimum mean square error (STSA-MMSE) SE algorithm, and is comparable to a deep neural network-based SE approach (DNN-SE). version:2
arxiv-1709-02081 | An unsupervised long short-term memory neural network for event detection in cell videos | http://arxiv.org/abs/1709.02081 | id:1709.02081 author:Ha Tran Hong Phan, Ashnil Kumar, David Feng, Michael Fulham, Jinman Kim category:cs.CV  published:2017-09-07 summary:We propose an automatic unsupervised cell event detection and classification method, which expands convolutional Long Short-Term Memory (LSTM) neural networks, for cellular events in cell video sequences. Cells in images that are captured from various biomedical applications usually have different shapes and motility, which pose difficulties for the automated event detection in cell videos. Current methods to detect cellular events are based on supervised machine learning and rely on tedious manual annotation from investigators with specific expertise. So that our LSTM network could be trained in an unsupervised manner, we designed it with a branched structure where one branch learns the frequent, regular appearance and movements of objects and the second learns the stochastic events, which occur rarely and without warning in a cell video sequence. We tested our network on a publicly available dataset of densely packed stem cell phase-contrast microscopy images undergoing cell division. This dataset is considered to be more challenging that a dataset with sparse cells. We compared our method to several published supervised methods evaluated on the same dataset and to a supervised LSTM method with a similar design and configuration to our unsupervised method. We used an F1-score, which is a balanced measure for both precision and recall. Our results show that our unsupervised method has a higher or similar F1-score when compared to two fully supervised methods that are based on Hidden Conditional Random Fields (HCRF), and has comparable accuracy with the current best supervised HCRF-based method. Our method was generalizable as after being trained on one video it could be applied to videos where the cells were in different conditions. The accuracy of our unsupervised method approached that of its supervised counterpart. version:1
arxiv-1709-02076 | Composition by Conversation | http://arxiv.org/abs/1709.02076 | id:1709.02076 author:Donya Quick, Clayton T. Morrison category:cs.SD cs.CL cs.IR cs.PL  published:2017-09-07 summary:Most musical programming languages are developed purely for coding virtual instruments or algorithmic compositions. Although there has been some work in the domain of musical query languages for music information retrieval, there has been little attempt to unify the principles of musical programming and query languages with cognitive and natural language processing models that would facilitate the activity of composition by conversation. We present a prototype framework, called MusECI, that merges these domains, permitting score-level algorithmic composition in a text editor while also supporting connectivity to existing natural language processing frameworks. version:1
arxiv-1709-02073 | Deep Embedding Convolutional Neural Network for Synthesizing CT Image from T1-Weighted MR Image | http://arxiv.org/abs/1709.02073 | id:1709.02073 author:Lei Xiang, Qian Wang, Dong Nie, Yu Qiao, Dinggang Shen category:cs.CV  published:2017-09-07 summary:Recently, more and more attention is drawn to the field of medical image synthesis across modalities. Among them, the synthesis of computed tomography (CT) image from T1-weighted magnetic resonance (MR) image is of great importance, although the mapping between them is highly complex due to large gaps of appearances of the two modalities. In this work, we aim to tackle this MR-to-CT synthesis by a novel deep embedding convolutional neural network (DECNN). Specifically, we generate the feature maps from MR images, and then transform these feature maps forward through convolutional layers in the network. We can further compute a tentative CT synthesis from the midway of the flow of feature maps, and then embed this tentative CT synthesis back to the feature maps. This embedding operation results in better feature maps, which are further transformed forward in DECNN. After repeat-ing this embedding procedure for several times in the network, we can eventually synthesize a final CT image in the end of the DECNN. We have validated our proposed method on both brain and prostate datasets, by also compar-ing with the state-of-the-art methods. Experimental results suggest that our DECNN (with repeated embedding op-erations) demonstrates its superior performances, in terms of both the perceptive quality of the synthesized CT image and the run-time cost for synthesizing a CT image. version:1
arxiv-1706-03160 | Deep Adaptive Feature Embedding with Local Sample Distributions for Person Re-identification | http://arxiv.org/abs/1706.03160 | id:1706.03160 author:Lin Wu, Yang Wang, Junbin Gao, Xue Li category:cs.CV  published:2017-06-10 summary:Person re-identification (re-id) aims to match pedestrians observed by disjoint camera views. It attracts increasing attention in computer vision due to its importance to surveillance system. To combat the major challenge of cross-view visual variations, deep embedding approaches are proposed by learning a compact feature space from images such that the Euclidean distances correspond to their cross-view similarity metric. However, the global Euclidean distance cannot faithfully characterize the ideal similarity in a complex visual feature space because features of pedestrian images exhibit unknown distributions due to large variations in poses, illumination and occlusion. Moreover, intra-personal training samples within a local range are robust to guide deep embedding against uncontrolled variations, which however, cannot be captured by a global Euclidean distance. In this paper, we study the problem of person re-id by proposing a novel sampling to mine suitable \textit{positives} (i.e. intra-class) within a local range to improve the deep embedding in the context of large intra-class variations. Our method is capable of learning a deep similarity metric adaptive to local sample structure by minimizing each sample's local distances while propagating through the relationship between samples to attain the whole intra-class minimization. To this end, a novel objective function is proposed to jointly optimize similarity metric learning, local positive mining and robust deep embedding. This yields local discriminations by selecting local-ranged positive samples, and the learned features are robust to dramatic intra-class variations. Experiments on benchmarks show state-of-the-art results achieved by our method. version:2
arxiv-1709-02043 | The Mating Rituals of Deep Neural Networks: Learning Compact Feature Representations through Sexual Evolutionary Synthesis | http://arxiv.org/abs/1709.02043 | id:1709.02043 author:Audrey Chung, Mohammad Javad Shafiee, Paul Fieguth, Alexander Wong category:cs.NE cs.CV  published:2017-09-07 summary:Evolutionary deep intelligence was recently proposed as a method for achieving highly efficient deep neural network architectures over successive generations. Drawing inspiration from nature, we propose the incorporation of sexual evolutionary synthesis. Rather than the current asexual synthesis of networks, we aim to produce more compact feature representations by synthesizing more diverse and generalizable offspring networks in subsequent generations via the combination of two parent networks. Experimental results were obtained using the MNIST and CIFAR-10 datasets, and showed improved architectural efficiency and comparable testing accuracy relative to the baseline asexual evolutionary neural networks. In particular, the network synthesized via sexual evolutionary synthesis for MNIST had approximately double the architectural efficiency (cluster efficiency of 34.29X and synaptic efficiency of 258.37X) in comparison to the network synthesized via asexual evolutionary synthesis, with both networks achieving a testing accuracy of ~97%. version:1
arxiv-1709-01300 | Boosting the kernelized shapelets: Theory and algorithms for local features | http://arxiv.org/abs/1709.01300 | id:1709.01300 author:Daiki Suehiro, Kohei Hatano, Eiji Takimoto, Shuji Yamamoto, Kenichi Bannai, Akiko Takeda category:cs.LG  published:2017-09-05 summary:We consider binary classification problems using local features of objects. One of motivating applications is time-series classification, where features reflecting some local closeness measure between a time series and a pattern sequence called shapelet are useful. Despite the empirical success of such approaches using local features, the generalization ability of resulting hypotheses is not fully understood and previous work relies on a bunch of heuristics. In this paper, we formulate a class of hypotheses using local features, where the richness of features is controlled by kernels. We derive generalization bounds of sparse ensembles over the class which is exponentially better than a standard analysis in terms of the number of possible local features. The resulting optimization problem is well suited to the boosting approach and the weak learning problem is formulated as a DC program, for which practical algorithms exist. In preliminary experiments on time-series data sets, our method achieves competitive accuracy with the state-of-the-art algorithms with small parameter-tuning cost. version:3
arxiv-1709-02039 | Capturing natural-colour 3D models of insects for species discovery | http://arxiv.org/abs/1709.02039 | id:1709.02039 author:Chuong V. Nguyen, David R. Lovell, Matt Adcock, John La Salle category:cs.CV  published:2017-09-07 summary:Collections of biological specimens are fundamental to scientific understanding and characterization of natural diversity. This paper presents a system for liberating useful information from physical collections by bringing specimens into the digital domain so they can be more readily shared, analyzed, annotated and compared. It focuses on insects and is strongly motivated by the desire to accelerate and augment current practices in insect taxonomy which predominantly use text, 2D diagrams and images to describe and characterize species. While these traditional kinds of descriptions are informative and useful, they cannot cover insect specimens "from all angles" and precious specimens are still exchanged between researchers and collections for this reason. Furthermore, insects can be complex in structure and pose many challenges to computer vision systems. We present a new prototype for a practical, cost-effective system of off-the-shelf components to acquire natural-colour 3D models of insects from around 3mm to 30mm in length. Colour images are captured from different angles and focal depths using a digital single lens reflex (DSLR) camera rig and two-axis turntable. These 2D images are processed into 3D reconstructions using software based on a visual hull algorithm. The resulting models are compact (around 10 megabytes), afford excellent optical resolution, and can be readily embedded into documents and web pages, as well as viewed on mobile devices. The system is portable, safe, relatively affordable, and complements the sort of volumetric data that can be acquired by computed tomography. This system provides a new way to augment the description and documentation of insect species holotypes, reducing the need to handle or ship specimens. It opens up new opportunities to collect data for research, education, art, entertainment, biodiversity assessment and biosecurity control. version:1
arxiv-1709-02033 | Towards high-throughput 3D insect capture for species discovery and diagnostics | http://arxiv.org/abs/1709.02033 | id:1709.02033 author:Chuong Nguyen, Matt Adcock, Stuart Anderson, David Lovell, Nicole Fisher, John La Salle category:cs.CV  published:2017-09-07 summary:Digitisation of natural history collections not only preserves precious information about biological diversity, it also enables us to share, analyse, annotate and compare specimens to gain new insights. High-resolution, full-colour 3D capture of biological specimens yields color and geometry information complementary to other techniques (e.g., 2D capture, electron scanning and micro computed tomography). However 3D colour capture of small specimens is slow for reasons including specimen handling, the narrow depth of field of high magnification optics, and the large number of images required to resolve complex shapes of specimens. In this paper, we outline techniques to accelerate 3D image capture, including using a desktop robotic arm to automate the insect handling process; using a calibrated pan-tilt rig to avoid attaching calibration targets to specimens; using light field cameras to capture images at an extended depth of field in one shot; and using 3D Web and mixed reality tools to facilitate the annotation, distribution and visualisation of 3D digital models. version:1
arxiv-1709-02016 | Image Splicing Localization Using A Multi-Task Fully Convolutional Network (MFCN) | http://arxiv.org/abs/1709.02016 | id:1709.02016 author:Ronald Salloum, Yuzhuo Ren, C. -C. Jay Kuo category:cs.CV  published:2017-09-06 summary:In this work, we propose a technique that utilizes a fully convolutional network (FCN) to localize image splicing attacks. We first evaluated a single-task FCN (SFCN) trained only on the surface label. Although the SFCN is shown to provide superior performance over existing methods, it still provides a coarse localization output in certain cases. Therefore, we propose the use of a multi-task FCN (MFCN) that utilizes two output branches for multi-task learning. One branch is used to learn the surface label, while the other branch is used to learn the edge or boundary of the spliced region. We trained the networks using the CASIA v2.0 dataset, and tested the trained models on the CASIA v1.0, Columbia Uncompressed, Carvalho, and the DARPA/NIST Nimble Challenge 2016 SCI datasets. Experiments show that the SFCN and MFCN outperform existing splicing localization algorithms, and that the MFCN can achieve finer localization than the SFCN. version:1
arxiv-1709-02012 | On Fairness and Calibration | http://arxiv.org/abs/1709.02012 | id:1709.02012 author:Geoff Pleiss, Manish Raghavan, Felix Wu, Jon Kleinberg, Kilian Q. Weinberger category:cs.LG cs.CY stat.ML  published:2017-09-06 summary:The machine learning community has become increasingly concerned with the potential for bias and discrimination in predictive models, and this has motivated a growing line of work on what it means for a classification procedure to be "fair." In particular, we investigate the tension between minimizing error disparity across different population groups while maintaining calibrated probability estimates. We show that calibration is compatible only with a single error constraint (i.e. equal false-negatives rates across groups), and show that any algorithm that satisfies this relaxation is no better than randomizing a percentage of predictions for an existing classifier. These unsettling findings, which extend and generalize existing results, are empirically confirmed on several datasets. version:1
arxiv-1709-01993 | Label Denoising Adversarial Network (LDAN) for Inverse Lighting of Face Images | http://arxiv.org/abs/1709.01993 | id:1709.01993 author:Hao Zhou, Jin Sun, Yaser Yacoob, David W. Jacobs category:cs.CV  published:2017-09-06 summary:Lighting estimation from face images is an important task and has applications in many areas such as image editing, intrinsic image decomposition, and image forgery detection. We propose to train a deep Convolutional Neural Network (CNN) to regress lighting parameters from a single face image. Lacking massive ground truth lighting labels for face images in the wild, we use an existing method to estimate lighting parameters, which are treated as ground truth with unknown noises. To alleviate the effect of such noises, we utilize the idea of Generative Adversarial Networks (GAN) and propose a Label Denoising Adversarial Network (LDAN) to make use of synthetic data with accurate ground truth to help train a deep CNN for lighting regression on real face images. Experiments show that our network outperforms existing methods in producing consistent lighting parameters of different faces under similar lighting conditions. Moreover, our method is 100,000 times faster in execution time than prior optimization-based lighting estimation approaches. version:1
arxiv-1707-09285 | Simplified Energy Landscape for Modularity Using Total Variation | http://arxiv.org/abs/1707.09285 | id:1707.09285 author:Zachary Boyd, Egil Bae, Xue-Cheng Tai, Andrea L. Bertozzi category:math.OC stat.ML  published:2017-07-28 summary:Networks capture pairwise interactions between entities and are frequently used in applications such as social networks, food networks, and protein interaction networks, to name a few. Communities, cohesive groups of nodes, often form in these applications, and identifying them gives insight into the overall organization of the network. One common quality function used to identify community structure is modularity. In Hu et al. [SIAM J. App. Math., 73(6), 2013], it was shown that modularity optimization is equivalent to minimizing a particular nonconvex total variation (TV) based functional over a discrete domain. They solve this problem---assuming the number of communities is known---using a Merriman, Bence, Osher (MBO) scheme. We show that modularity optimization is equivalent to minimizing a convex TV-based functional over a discrete domain---again, assuming the number of communities is known. Furthermore, we show that modularity has no convex relaxation satisfying certain natural conditions. Despite this, we partially relax the discrete constraint using a Ginzburg Landau functional, yielding an optimization problem that is more nearly convex. We then derive an MBO algorithm with fewer parameters than in Hu et al. and which is 7 times faster at solving the associated diffusion equation due to the fact that the underlying discretization is unconditionally stable. Our numerical tests include a hyperspectral video whose associated graph has 29 million edges, which is roughly 37 times larger than was handled in the paper of Hu et al. version:2
arxiv-1709-01956 | Learning Dilation Factors for Semantic Segmentation of Street Scenes | http://arxiv.org/abs/1709.01956 | id:1709.01956 author:Yang He, Margret Keuper, Bernt Schiele, Mario Fritz category:cs.CV  published:2017-09-06 summary:Contextual information is crucial for semantic segmentation. However, finding the optimal trade-off between keeping desired fine details and at the same time providing sufficiently large receptive fields is non trivial. This is even more so, when objects or classes present in an image significantly vary in size. Dilated convolutions have proven valuable for semantic segmentation, because they allow to increase the size of the receptive field without sacrificing image resolution. However, in current state-of-the-art methods, dilation parameters are hand-tuned and fixed. In this paper, we present an approach for learning dilation parameters adaptively per channel, consistently improving semantic segmentation results on street-scene datasets like Cityscapes and Camvid. version:1
arxiv-1709-01950 | "Having 2 hours to write a paper is fun!": Detecting Sarcasm in Numerical Portions of Text | http://arxiv.org/abs/1709.01950 | id:1709.01950 author:Lakshya Kumar, Arpan Somani, Pushpak Bhattacharyya category:cs.CL  published:2017-09-06 summary:Sarcasm occurring due to the presence of numerical portions in text has been quoted as an error made by automatic sarcasm detection approaches in the past. We present a first study in detecting sarcasm in numbers, as in the case of the sentence 'Love waking up at 4 am'. We analyze the challenges of the problem, and present Rule-based, Machine Learning and Deep Learning approaches to detect sarcasm in numerical portions of text. Our Deep Learning approach outperforms four past works for sarcasm detection and Rule-based and Machine learning approaches on a dataset of tweets, obtaining an F1-score of 0.93. This shows that special attention to text containing numbers may be useful to improve state-of-the-art in sarcasm detection. version:1
arxiv-1709-01919 | An Influence-Receptivity Model for Topic based Information Cascades | http://arxiv.org/abs/1709.01919 | id:1709.01919 author:Ming Yu, Varun Gupta, Mladen Kolar category:stat.ML cs.LG cs.SI  published:2017-09-06 summary:We consider the problem of estimating the latent structure of a social network based on observational data on information diffusion processes, or {\it cascades}. Here for a given cascade, we only observe the time a node/agent is infected but not the source of infection. Existing literature has focused on estimating network diffusion matrix without any underlying assumptions on the structure of the network. We propose a novel model for inferring network diffusion matrix based on the intuition that an information datum is more likely to propagate among two nodes if they are interested in similar topics, which are common with the information. In particular, our model endows each node with an influence vector (how authoritative they are on each topic) and a receptivity vector (how susceptible they are on each topic). We show how this node-topic structure can be estimated from observed cascades. The estimated model can be used to build recommendation system based on the receptivity vectors, as well as for marketing based on the influence vectors. version:1
arxiv-1709-01907 | Deep and Confident Prediction for Time Series at Uber | http://arxiv.org/abs/1709.01907 | id:1709.01907 author:Lingxue Zhu, Nikolay Laptev category:stat.ML  published:2017-09-06 summary:Reliable uncertainty estimation for time series prediction is critical in many fields, including physics, biology, and manufacturing. At Uber, probabilistic time series forecasting is used for robust prediction of number of trips during special events, driver incentive allocation, as well as real-time anomaly detection across millions of metrics. Classical time series models are often used in conjunction with a probabilistic formulation for uncertainty estimation. However, such models are hard to tune, scale, and add exogenous variables to. Motivated by the recent resurgence of Long Short Term Memory networks, we propose a novel end-to-end Bayesian deep model that provides time series prediction along with uncertainty estimation. We provide detailed experiments of the proposed solution on completed trips data, and successfully apply it to large-scale time series anomaly detection at Uber. version:1
arxiv-1709-01894 | Convolutional Gaussian Processes | http://arxiv.org/abs/1709.01894 | id:1709.01894 author:Mark van der Wilk, Carl Edward Rasmussen, James Hensman category:stat.ML cs.LG  published:2017-09-06 summary:We present a practical way of introducing convolutional structure into Gaussian processes, making them more suited to high-dimensional inputs like images. The main contribution of our work is the construction of an inter-domain inducing point approximation that is well-tailored to the convolutional kernel. This allows us to gain the generalisation benefit of a convolutional kernel, together with fast but accurate posterior inference. We investigate several variations of the convolutional kernel, and apply it to MNIST and CIFAR-10, which have both been known to be challenging for Gaussian processes. We also show how the marginal likelihood can be used to find an optimal weighting between convolutional and RBF kernels to further improve performance. We hope that this illustration of the usefulness of a marginal likelihood will help automate discovering architectures in larger models. version:1
arxiv-1709-01889 | Polar Transformer Networks | http://arxiv.org/abs/1709.01889 | id:1709.01889 author:Carlos Esteves, Christine Allen-Blanchette, Xiaowei Zhou, Kostas Daniilidis category:cs.CV  published:2017-09-06 summary:Convolutional neural networks (CNNs) are equivariant with respect to translation; a translation in the input causes a translation in the output. Attempts to generalize equivariance have concentrated on rotations. In this paper, we combine the idea of the spatial transformer, and the canonical coordinate representations of groups (polar transform) to realize a network that is invariant to translation, and equivariant to rotation and scale. A conventional CNN is used to predict the origin of a polar transform. The polar transform is performed in a differentiable way, similar to the Spatial Transformer Networks, and the resulting polar representation is fed into a second CNN. The model is trained end-to-end with a classification loss. We apply the method on variations of MNIST, obtained by perturbing it with clutter, translation, rotation, and scaling. We achieve state of the art performance in the rotated MNIST, with fewer parameters and faster training time than previous methods, and we outperform all tested methods in the SIM2MNIST dataset, which we introduce. version:1
arxiv-1709-01872 | Synthetic Medical Images from Dual Generative Adversarial Networks | http://arxiv.org/abs/1709.01872 | id:1709.01872 author:John T. Guibas, Tejpal S. Virdi, Peter S. Li category:cs.CV  published:2017-09-06 summary:Currently there is strong interest in data-driven approaches to medical image classification. However, medical imaging data is scarce, expensive, and fraught with legal concerns regarding patient privacy. Typical patient data consent forms only allow images to be used in medical journals or for education purposes, meaning the majority of medical data is not available for general public research. Synthetic medical images promise a solution to these problems. We propose a novel, two-stage pipeline for generating synthetic medical images from a pair of generative adversarial networks (GANs), which we test in practice on retinal fundi images. The first stage generates synthetic segmentation masks and the second stage converts the masks to photorealistic images. The images from Stage-II, along with their corresponding segmentations from Stage-I, are used to train a u-net segmentation network. On the u-net, our synthetic data pipeline received an F1 score of 0.8877, in comparison to a score of 0.8988 when tested with ground truth data, showing a negligible difference between synthetic and real patient datasets. version:1
arxiv-1709-01870 | Clustering of Data with Missing Entries using Non-convex Fusion Penalties | http://arxiv.org/abs/1709.01870 | id:1709.01870 author:Sunrita Poddar, Mathews Jacob category:cs.CV cs.LG stat.ML  published:2017-09-06 summary:The presence of missing entries in data often creates challenges for pattern recognition algorithms. Traditional algorithms for clustering data assume that all the feature values are known for every data point. We propose a method to cluster data in the presence of missing information. Unlike conventional clustering techniques where every feature is known for each point, our algorithm can handle cases where a few feature values are unknown for every point. For this more challenging problem, we provide theoretical guarantees for clustering using a $\ell_0$ fusion penalty based optimization problem. Furthermore, we propose an algorithm to solve a relaxation of this problem using saturating non-convex fusion penalties. It is observed that this algorithm produces solutions that degrade gradually with an increase in the fraction of missing feature values. We demonstrate the utility of the proposed method using a simulated dataset, the Wine dataset and also an under-sampled cardiac MRI dataset. It is shown that the proposed method is a promising clustering technique for datasets with large fractions of missing entries. version:1
arxiv-1709-01860 | The low-rank hurdle model | http://arxiv.org/abs/1709.01860 | id:1709.01860 author:Christopher Dienes category:stat.ML cs.LG  published:2017-09-06 summary:A composite loss framework is proposed for low-rank modeling of data consisting of interesting and common values, such as excess zeros or missing values. The methodology is motivated by the generalized low-rank framework and the hurdle method which is commonly used to analyze zero-inflated counts. The model is demonstrated on a manufacturing data set and applied to the problem of missing value imputation. version:1
arxiv-1709-01848 | Depression and Self-Harm Risk Assessment in Online Forums | http://arxiv.org/abs/1709.01848 | id:1709.01848 author:Andrew Yates, Arman Cohan, Nazli Goharian category:cs.CL  published:2017-09-06 summary:Users suffering from mental health conditions often turn to online resources for support, including specialized online support communities or general communities such as Twitter and Reddit. In this work, we present a neural framework for supporting and studying users in both types of communities. We propose methods for identifying posts in support communities that may indicate a risk of self-harm, and demonstrate that our approach outperforms strong previously proposed methods for identifying such posts. Self-harm is closely related to depression, which makes identifying depressed users on general forums a crucial related task. We introduce a large-scale general forum dataset ("RSDD") consisting of users with self-reported depression diagnoses matched with control users. We show how our method can be applied to effectively identify depressed users from their use of language alone. We demonstrate that our method outperforms strong baselines on this general forum dataset. version:1
arxiv-1709-01846 | Symmetric Variational Autoencoder and Connections to Adversarial Learning | http://arxiv.org/abs/1709.01846 | id:1709.01846 author:Yunchen Pu, Liqun Chen, Shuyang Dai, Weiyao Wang, Chunyuan Li, Lawrence Carin category:stat.ML cs.LG  published:2017-09-06 summary:A new form of the variational autoencoder (VAE) is proposed, based on the symmetric Kullback-Leibler divergence. It is demonstrated that learning of the resulting symmetric VAE (sVAE) has close connections to previously developed adversarial-learning methods. This relationship helps unify the previously distinct techniques of VAE and adversarially learning, and provides insights that allow us to ameliorate shortcomings with some previously developed adversarial methods. In addition to an analysis that motivates and explains the sVAE, an extensive set of experiments validate the utility of the approach. version:1
arxiv-1709-01841 | An inner-loop free solution to inverse problems using deep neural networks | http://arxiv.org/abs/1709.01841 | id:1709.01841 author:Qi Wei, Kai Fan, Lawrence Carin, Katherine A. Heller category:cs.CV  published:2017-09-06 summary:We propose a new method that uses deep learning techniques to accelerate the popular alternating direction method of multipliers (ADMM) solution for inverse problems. The ADMM updates consist of a proximity operator, a least squares regression that includes a big matrix inversion, and an explicit solution for updating the dual variables. Typically, inner loops are required to solve the first two sub-minimization problems due to the intractability of the prior and the matrix inversion. To avoid such drawbacks or limitations, we propose an inner-loop free update rule with two pre-trained deep convolutional architectures. More specifically, we learn a conditional denoising auto-encoder which imposes an implicit data-dependent prior/regularization on ground-truth in the first sub-minimization problem. This design follows an empirical Bayesian strategy, leading to so-called amortized inference. For matrix inversion in the second sub-problem, we learn a convolutional neural network to approximate the matrix inversion, i.e., the inverse mapping is learned by feeding the input through the learned forward network. Note that training this neural network does not require ground-truth or measurements, i.e., it is data-independent. Extensive experiments on both synthetic data and real datasets demonstrate the efficiency and accuracy of the proposed method compared with the conventional ADMM solution using inner loops for solving inverse problems. version:1
arxiv-1709-01829 | Soft Proposal Networks for Weakly Supervised Object Localization | http://arxiv.org/abs/1709.01829 | id:1709.01829 author:Yi Zhu, Yanzhao Zhou, Qixiang Ye, Qiang Qiu, Jianbin Jiao category:cs.CV  published:2017-09-06 summary:Weakly supervised object localization remains challenging, where only image labels instead of bounding boxes are available during training. Object proposal is an effective component in localization, but often computationally expensive and incapable of joint optimization with some of the remaining modules. In this paper, to the best of our knowledge, we for the first time integrate weakly supervised object proposal into convolutional neural networks (CNNs) in an end-to-end learning manner. We design a network component, Soft Proposal (SP), to be plugged into any standard convolutional architecture to introduce the nearly cost-free object proposal, orders of magnitude faster than state-of-the-art methods. In the SP-augmented CNNs, referred to as Soft Proposal Networks (SPNs), iteratively evolved object proposals are generated based on the deep feature maps then projected back, and further jointly optimized with network parameters, with image-level supervision only. Through the unified learning process, SPNs learn better object-centric filters, discover more discriminative visual evidence, and suppress background interference, significantly boosting both weakly supervised object localization and classification performance. We report the best results on popular benchmarks, including PASCAL VOC, MS COCO, and ImageNet. version:1
arxiv-1705-02883 | A Dual-Source Approach for 3D Human Pose Estimation from a Single Image | http://arxiv.org/abs/1705.02883 | id:1705.02883 author:Umar Iqbal, Andreas Doering, Hashim Yasin, Björn Krüger, Andreas Weber, Juergen Gall category:cs.CV  published:2017-05-08 summary:In this work we address the challenging problem of 3D human pose estimation from single images. Recent approaches learn deep neural networks to regress 3D pose directly from images. One major challenge for such methods, however, is the collection of training data. Specifically, collecting large amounts of training data containing unconstrained images annotated with accurate 3D poses is infeasible. We therefore propose to use two independent training sources. The first source consists of accurate 3D motion capture data, and the second source consists of unconstrained images with annotated 2D poses. To integrate both sources, we propose a dual-source approach that combines 2D pose estimation with efficient 3D pose retrieval. To this end, we first convert the motion capture data into a normalized 2D pose space, and separately learn a 2D pose estimation model from the image data. During inference, we estimate the 2D pose and efficiently retrieve the nearest 3D poses. We then jointly estimate a mapping from the 3D pose space to the image and reconstruct the 3D pose. We provide a comprehensive evaluation of the proposed method and experimentally demonstrate the effectiveness of our approach, even when the skeleton structures of the two sources differ substantially. version:2
arxiv-1709-01813 | Towards Automated Cadastral Boundary Delineation from UAV Data | http://arxiv.org/abs/1709.01813 | id:1709.01813 author:Sophie Crommelinck, Michael Ying Yang, Mila Koeva, Markus Gerke, Rohan Bennett, George Vosselman category:cs.CV  published:2017-09-06 summary:Unmanned aerial vehicles (UAV) are evolving as an alternative tool to acquire land tenure data. UAVs can capture geospatial data at high quality and resolution in a cost-effective, transparent and flexible manner, from which visible land parcel boundaries, i.e., cadastral boundaries are delineable. This delineation is to no extent automated, even though physical objects automatically retrievable through image analysis methods mark a large portion of cadastral boundaries. This study proposes (i) a workflow that automatically extracts candidate cadastral boundaries from UAV orthoimages and (ii) a tool for their semi-automatic processing to delineate final cadastral boundaries. The workflow consists of two state-of-the-art computer vision methods, namely gPb contour detection and SLIC superpixels that are transferred to remote sensing in this study. The tool combines the two methods, allows a semi-automatic final delineation and is implemented as a publicly available QGIS plugin. The approach does not yet aim to provide a comparable alternative to manual cadastral mapping procedures. However, the methodological development of the tool towards this goal is developed in this paper. A study with 13 volunteers investigates the design and implementation of the approach and gathers initial qualitative as well as quantitate results. The study revealed points for improvement, which are prioritized based on the study results and which will be addressed in future work. version:1
arxiv-1709-02268 | Phylogenetic Convolutional Neural Networks in Metagenomics | http://arxiv.org/abs/1709.02268 | id:1709.02268 author:Diego Fioravanti, Ylenia Giarratano, Valerio Maggio, Claudio Agostinelli, Marco Chierici, Giuseppe Jurman, Cesare Furlanello category:q-bio.QM cs.LG cs.NE q-bio.GN  published:2017-09-06 summary:Background: Convolutional Neural Networks can be effectively used only when data are endowed with an intrinsic concept of neighbourhood in the input space, as is the case of pixels in images. We introduce here Ph-CNN, a novel deep learning architecture for the classification of metagenomics data based on the Convolutional Neural Networks, with the patristic distance defined on the phylogenetic tree being used as the proximity measure. The patristic distance between variables is used together with a sparsified version of MultiDimensional Scaling to embed the phylogenetic tree in a Euclidean space. Results: Ph-CNN is tested with a domain adaptation approach on synthetic data and on a metagenomics collection of gut microbiota of 38 healthy subjects and 222 Inflammatory Bowel Disease patients, divided in 6 subclasses. Classification performance is promising when compared to classical algorithms like Support Vector Machines and Random Forest and a baseline fully connected neural network, e.g. the Multi-Layer Perceptron. Conclusion: Ph-CNN represents a novel deep learning approach for the classification of metagenomics data. Operatively, the algorithm has been implemented as a custom Keras layer taking care of passing to the following convolutional layer not only the data but also the ranked list of neighbourhood of each sample, thus mimicking the case of image data, transparently to the user. Keywords: Metagenomics; Deep learning; Convolutional Neural Networks; Phylogenetic trees version:1
arxiv-1709-01809 | CNN-Based Projected Gradient Descent for Consistent Image Reconstruction | http://arxiv.org/abs/1709.01809 | id:1709.01809 author:Harshit Gupta, Kyong Hwan Jin, Ha Q. Nguyen, Michael T. McCann, Michael Unser category:cs.CV  published:2017-09-06 summary:We present a new method for image reconstruction which replaces the projector in a projected gradient descent (PGD) with a convolutional neural network (CNN). CNNs trained as high-dimensional (image-to-image) regressors have recently been used to efficiently solve inverse problems in imaging. However, these approaches lack a feedback mechanism to enforce that the reconstructed image is consistent with the measurements. This is crucial for inverse problems, and more so in biomedical imaging, where the reconstructions are used for diagnosis. In our scheme, the gradient descent enforces measurement consistency, while the CNN recursively projects the solution closer to the space of desired reconstruction images. We provide a formal framework to ensure that the classical PGD converges to a local minimizer of a non-convex constrained least-squares problem. When the projector is replaced with a CNN, we propose a relaxed PGD, which always converges. Finally, we propose a simple scheme to train a CNN to act like a projector. Our experiments on sparse view Computed Tomography (CT) reconstruction for both noiseless and noisy measurements show an improvement over the total-variation (TV) method and a recent CNN-based technique. version:1
arxiv-1709-01922 | A Comparison on Audio Signal Preprocessing Methods for Deep Neural Networks on Music Tagging | http://arxiv.org/abs/1709.01922 | id:1709.01922 author:Keunwoo Choi, George Fazekas, Kyunghyun Cho, Mark Sandler category:cs.SD cs.CV cs.IR cs.LG  published:2017-09-06 summary:Deep neural networks (DNN) have been successfully applied for music classification tasks including music tagging. In this paper, we investigate the effect of audio preprocessing on music tagging with neural networks. We perform comprehensive experiments involving audio preprocessing using different time-frequency representations, logarithmic magnitude compression, frequency weighting and scaling. We show that many commonly used input preprocessing techniques are redundant except magnitude compression. version:1
arxiv-1709-01788 | Radial Line Fourier Descriptor for Handwritten Word Representation | http://arxiv.org/abs/1709.01788 | id:1709.01788 author:Anders Hast, Ekta Vats category:cs.CV cs.IR  published:2017-09-06 summary:Automatic recognition of historical handwritten manuscripts is a daunting task due to paper degradation over time. The performance of information retrieval algorithms depends heavily on feature detection and representation methods. Although there exist popular feature descriptors such as Scale Invariant Feature Transform and Speeded Up Robust Features, in order to represent handwritten words in a document, a robust descriptor is required that is not over-precise. This is because handwritten words across different documents are indeed similar, but not identical. Therefore, this paper introduces a Radial Line Fourier (RLF) descriptor for handwritten word feature representation, which is fast to construct and short-length with 32 elements only. The effectiveness of the proposed RLF descriptor is empirically evaluated using the VLFeat benchmarking framework (VLBenchmarks), and for handwritten word image representation using a historical marriage records dataset. version:1
arxiv-1709-01784 | Cross-Domain Image Retrieval with Attention Modeling | http://arxiv.org/abs/1709.01784 | id:1709.01784 author:Xin Ji, Wei Wang, Meihui Zhang, Yang Yang category:cs.MM cs.CV cs.IR 68 I.4.7; I.4.10  published:2017-09-06 summary:With the proliferation of e-commerce websites and the ubiquitousness of smart phones, cross-domain image retrieval using images taken by smart phones as queries to search products on e-commerce websites is emerging as a popular application. One challenge of this task is to locate the attention of both the query and database images. In particular, database images, e.g. of fashion products, on e-commerce websites are typically displayed with other accessories, and the images taken by users contain noisy background and large variations in orientation and lighting. Consequently, their attention is difficult to locate. In this paper, we exploit the rich tag information available on the e-commerce websites to locate the attention of database images. For query images, we use each candidate image in the database as the context to locate the query attention. Novel deep convolutional neural network architectures, namely TagYNet and CtxYNet, are proposed to learn the attention weights and then extract effective representations of the images. Experimental results on public datasets confirm that our approaches have significant improvement over the existing methods in terms of the retrieval accuracy and efficiency. version:1
arxiv-1704-07632 | Joint Layout Estimation and Global Multi-View Registration for Indoor Reconstruction | http://arxiv.org/abs/1704.07632 | id:1704.07632 author:Jeong-Kyun Lee, Jae-Won Yea, Min-Gyu Park, Kuk-Jin Yoon category:cs.CV  published:2017-04-25 summary:In this paper, we propose a novel method to jointly solve scene layout estimation and global registration problems for accurate indoor 3D reconstruction. Given a sequence of range data, we first build a set of scene fragments using KinectFusion and register them through pose graph optimization. Afterwards, we alternate between layout estimation and layout-based global registration processes in iterative fashion to complement each other. We extract the scene layout through hierarchical agglomerative clustering and energy-based multi-model fitting in consideration of noisy measurements. Having the estimated scene layout in one hand, we register all the range data through the global iterative closest point algorithm where the positions of 3D points that belong to the layout such as walls and a ceiling are constrained to be close to the layout. We experimentally verify the proposed method with the publicly available synthetic and real-world datasets in both quantitative and qualitative ways. version:2
arxiv-1709-01779 | Deep learning from crowds | http://arxiv.org/abs/1709.01779 | id:1709.01779 author:Filipe Rodrigues, Francisco Pereira category:stat.ML cs.CV cs.HC cs.LG  published:2017-09-06 summary:Over the last few years, deep learning has revolutionized the field of machine learning by dramatically improving the state-of-the-art in various domains. However, as the size of supervised artificial neural networks grows, typically so does the need for larger labeled datasets. Recently, crowdsourcing has established itself as an efficient and cost-effective solution for labeling large sets of data in a scalable manner, but it often requires aggregating labels from multiple noisy contributors with different levels of expertise. In this paper, we address the problem of learning deep neural networks from crowds. We begin by describing an EM algorithm for jointly learning the parameters of the network and the confusion matrices of the different annotators for classification settings. Then, a novel general-purpose crowd layer is proposed, which allows us to train deep neural networks end-to-end, directly from the noisy labels of multiple annotators, using backpropagation. We empirically show that the proposed approach is able to internally capture the reliability and biases of different annotators and achieve new state-of-the-art results for various crowdsourced datasets across different settings, namely classification, regression and sequence labeling. version:1
arxiv-1709-01766 | Information-Propogation-Enhanced Neural Machine Translation by Relation Model | http://arxiv.org/abs/1709.01766 | id:1709.01766 author:Wen Zhang, Jiawei Hu, Yang Feng, Qun Liu category:cs.CL  published:2017-09-06 summary:Even though sequence-to-sequence neural machine translation (NMT) model have achieved state-of-art performance in the recent fewer years, but it is widely concerned that the recurrent neural network (RNN) units are very hard to capture the long-distance state information, which means RNN can hardly find the feature with long term dependency as the sequence becomes longer. Similarly, convolutional neural network (CNN) is introduced into NMT for speeding recently, however, CNN focus on capturing the local feature of the sequence; To relieve this issue, we incorporate a relation network into the standard encoder-decoder framework to enhance information-propogation in neural network, ensuring that the information of the source sentence can flow into the decoder adequately. Experiments show that proposed framework outperforms the statistical MT model and the state-of-art NMT model significantly on two data sets with different scales. version:1
arxiv-1709-01041 | Domain-adaptive deep network compression | http://arxiv.org/abs/1709.01041 | id:1709.01041 author:Marc Masana, Joost van de Weijer, Luis Herranz, Andrew D. Bagdanov, Jose M Alvarez category:cs.CV  published:2017-09-04 summary:Deep Neural Networks trained on large datasets can be easily transferred to new domains with far fewer labeled examples by a process called fine-tuning. This has the advantage that representations learned in the large source domain can be exploited on smaller target domains. However, networks designed to be optimal for the source task are often prohibitively large for the target task. In this work we address the compression of networks after domain transfer. We focus on compression algorithms based on low-rank matrix decomposition. Existing methods base compression solely on learned network weights and ignore the statistics of network activations. We show that domain transfer leads to large shifts in network activations and that it is desirable to take this into account when compressing. We demonstrate that considering activation statistics when compressing weights leads to a rank-constrained regression problem with a closed-form solution. Because our method takes into account the target domain, it can more optimally remove the redundancy in the weights. Experiments show that our Domain Adaptive Low Rank (DALR) method significantly outperforms existing low-rank compression techniques. With our approach, the fc6 layer of VGG19 can be compressed more than 4x more than using truncated SVD alone -- with only a minor or no loss in accuracy. When applied to domain-transferred networks it allows for compression down to only 5-20% of the original number of parameters with only a minor drop in performance. version:2
arxiv-1709-01727 | Scene Text Recognition with Sliding Convolutional Character Models | http://arxiv.org/abs/1709.01727 | id:1709.01727 author:Fei Yin, Yi-Chao Wu, Xu-Yao Zhang, Cheng-Lin Liu category:cs.CV  published:2017-09-06 summary:Scene text recognition has attracted great interests from the computer vision and pattern recognition community in recent years. State-of-the-art methods use concolutional neural networks (CNNs), recurrent neural networks with long short-term memory (RNN-LSTM) or the combination of them. In this paper, we investigate the intrinsic characteristics of text recognition, and inspired by human cognition mechanisms in reading texts, we propose a scene text recognition method with character models on convolutional feature map. The method simultaneously detects and recognizes characters by sliding the text line image with character models, which are learned end-to-end on text line images labeled with text transcripts. The character classifier outputs on the sliding windows are normalized and decoded with Connectionist Temporal Classification (CTC) based algorithm. Compared to previous methods, our method has a number of appealing properties: (1) It avoids the difficulty of character segmentation which hinders the performance of segmentation-based recognition methods; (2) The model can be trained simply and efficiently because it avoids gradient vanishing/exploding in training RNN-LSTM based models; (3) It bases on character models trained free of lexicon, and can recognize unknown words. (4) The recognition process is highly parallel and enables fast recognition. Our experiments on several challenging English and Chinese benchmarks, including the IIIT-5K, SVT, ICDAR03/13 and TRW15 datasets, demonstrate that the proposed method yields superior or comparable performance to state-of-the-art methods while the model size is relatively small. version:1
arxiv-1709-01177 | Random Subspace with Trees for Feature Selection Under Memory Constraints | http://arxiv.org/abs/1709.01177 | id:1709.01177 author:Antonio Sutera, Célia Châtel, Gilles Louppe, Louis Wehenkel, Pierre Geurts category:stat.ML cs.LG  published:2017-09-04 summary:Dealing with datasets of very high dimension is a major challenge in machine learning. In this paper, we consider the problem of feature selection in applications where the memory is not large enough to contain all features. In this setting, we propose a novel tree-based feature selection approach that builds a sequence of randomized trees on small subsamples of variables mixing both variables already identified as relevant by previous models and variables randomly selected among the other variables. As our main contribution, we provide an in-depth theoretical analysis of this method in infinite sample setting. In particular, we study its soundness with respect to common definitions of feature relevance and its convergence speed under various variable dependance scenarios. We also provide some preliminary empirical results highlighting the potential of the approach. version:2
arxiv-1709-01722 | Detecting animals in African Savanna with UAVs and the crowds | http://arxiv.org/abs/1709.01722 | id:1709.01722 author:Nicolas Rey, Michele Volpi, Stéphane Joost, Devis Tuia category:cs.CV  published:2017-09-06 summary:Unmanned aerial vehicles (UAVs) offer new opportunities for wildlife monitoring, with several advantages over traditional field-based methods. They have readily been used to count birds, marine mammals and large herbivores in different environments, tasks which are routinely performed through manual counting in large collections of images. In this paper, we propose a semi-automatic system able to detect large mammals in semi-arid Savanna. It relies on an animal-detection system based on machine learning, trained with crowd-sourced annotations provided by volunteers who manually interpreted sub-decimeter resolution color images. The system achieves a high recall rate and a human operator can then eliminate false detections with limited effort. Our system provides good perspectives for the development of data-driven management practices in wildlife conservation. It shows that the detection of large mammals in semi-arid Savanna can be approached by processing data provided by standard RGB cameras mounted on affordable fixed wings UAVs. version:1
arxiv-1709-01720 | Temporal Pattern Discovery for Accurate Sepsis Diagnosis in ICU Patients | http://arxiv.org/abs/1709.01720 | id:1709.01720 author:Eitam Sheetrit, Nir Nissim, Denis Klimov, Lior Fuchs, Yuval Elovici, Yuval Shahar category:cs.LG stat.AP  published:2017-09-06 summary:Sepsis is a condition caused by the body's overwhelming and life-threatening response to infection, which can lead to tissue damage, organ failure, and finally death. Common signs and symptoms include fever, increased heart rate, increased breathing rate, and confusion. Sepsis is difficult to predict, diagnose, and treat. Patients who develop sepsis have an increased risk of complications and death and face higher health care costs and longer hospitalization. Today, sepsis is one of the leading causes of mortality among populations in intensive care units (ICUs). In this paper, we look at the problem of early detection of sepsis by using temporal data mining. We focus on the use of knowledge-based temporal abstraction to create meaningful interval-based abstractions, and on time-interval mining to discover frequent interval-based patterns. We used 2,560 cases derived from the MIMIC-III database. We found that the distribution of the temporal patterns whose frequency is above 10% discovered in the records of septic patients during the last 6 and 12 hours before onset of sepsis is significantly different from that distribution within a similar period, during an equivalent time window during hospitalization, in the records of non-septic patients. This discovery is encouraging for the purpose of performing an early diagnosis of sepsis using the discovered patterns as constructed features. version:1
arxiv-1709-01716 | Optimal Sub-sampling with Influence Functions | http://arxiv.org/abs/1709.01716 | id:1709.01716 author:Daniel Ting, Eric Brochu category:stat.ML cs.LG  published:2017-09-06 summary:Sub-sampling is a common and often effective method to deal with the computational challenges of large datasets. However, for most statistical models, there is no well-motivated approach for drawing a non-uniform subsample. We show that the concept of an asymptotically linear estimator and the associated influence function leads to optimal sampling procedures for a wide class of popular models. Furthermore, for linear regression models which have well-studied procedures for non-uniform sub-sampling, we show our optimal influence function based method outperforms previous approaches. We empirically show the improved performance of our method on real datasets. version:1
arxiv-1709-01710 | Blind image deblurring using class-adapted image priors | http://arxiv.org/abs/1709.01710 | id:1709.01710 author:Marina Ljubenović, Mário A. T. Figueiredo category:cs.CV  published:2017-09-06 summary:Blind image deblurring (BID) is an ill-posed inverse problem, usually addressed by imposing prior knowledge on the (unknown) image and on the blurring filter. Most of the work on BID has focused on natural images, using image priors based on statistical properties of generic natural images. However, in many applications, it is known that the image being recovered belongs to some specific class (e.g., text, face, fingerprints), and exploiting this knowledge allows obtaining more accurate priors. In this work, we propose a method where a Gaussian mixture model (GMM) is used to learn a class-adapted prior, by training on a dataset of clean images of that class. Experiments show the competitiveness of the proposed method in terms of restoration quality when dealing with images containing text, faces, or fingerprints. Additionally, experiments show that the proposed method is able to handle text images at high noise levels, outperforming state-of-the-art methods specifically designed for BID of text images. version:1
arxiv-1709-02797 | On the exact relationship between the denoising function and the data distribution | http://arxiv.org/abs/1709.02797 | id:1709.02797 author:Heikki Arponen, Matti Herranen, Harri Valpola category:cs.NE cs.LG stat.ML  published:2017-09-06 summary:We prove an exact relationship between the optimal denoising function and the data distribution in the case of additive Gaussian noise, showing that denoising implicitly models the structure of data allowing it to be exploited in the unsupervised learning of representations. This result generalizes a known relationship [2], which is valid only in the limit of small corruption noise. version:1
arxiv-1709-02260 | Embedded Binarized Neural Networks | http://arxiv.org/abs/1709.02260 | id:1709.02260 author:Bradley McDanel, Surat Teerapittayanon, H. T. Kung category:cs.CV cs.LG  published:2017-09-06 summary:We study embedded Binarized Neural Networks (eBNNs) with the aim of allowing current binarized neural networks (BNNs) in the literature to perform feedforward inference efficiently on small embedded devices. We focus on minimizing the required memory footprint, given that these devices often have memory as small as tens of kilobytes (KB). Beyond minimizing the memory required to store weights, as in a BNN, we show that it is essential to minimize the memory used for temporaries which hold intermediate results between layers in feedforward inference. To accomplish this, eBNN reorders the computation of inference while preserving the original BNN structure, and uses just a single floating-point temporary for the entire neural network. All intermediate results from a layer are stored as binary values, as opposed to floating-points used in current BNN implementations, leading to a 32x reduction in required temporary space. We provide empirical evidence that our proposed eBNN approach allows efficient inference (10s of ms) on devices with severely limited memory (10s of KB). For example, eBNN achieves 95\% accuracy on the MNIST dataset running on an Intel Curie with only 15 KB of usable memory with an inference runtime of under 50 ms per sample. To ease the development of applications in embedded contexts, we make our source code available that allows users to train and discover eBNN models for a learning task at hand, which fit within the memory constraint of the target device. version:1
arxiv-1709-01687 | Semi-Supervised Recurrent Neural Network for Adverse Drug Reaction Mention Extraction | http://arxiv.org/abs/1709.01687 | id:1709.01687 author:Shashank Gupta, Sachin Pawar, Nitin Ramrakhiyani, Girish Palshikar, Vasudeva Varma category:cs.IR cs.CL  published:2017-09-06 summary:Social media is an useful platform to share health-related information due to its vast reach. This makes it a good candidate for public-health monitoring tasks, specifically for pharmacovigilance. We study the problem of extraction of Adverse-Drug-Reaction (ADR) mentions from social media, particularly from twitter. Medical information extraction from social media is challenging, mainly due to short and highly information nature of text, as compared to more technical and formal medical reports. Current methods in ADR mention extraction relies on supervised learning methods, which suffers from labeled data scarcity problem. The State-of-the-art method uses deep neural networks, specifically a class of Recurrent Neural Network (RNN) which are Long-Short-Term-Memory networks (LSTMs) \cite{hochreiter1997long}. Deep neural networks, due to their large number of free parameters relies heavily on large annotated corpora for learning the end task. But in real-world, it is hard to get large labeled data, mainly due to heavy cost associated with manual annotation. Towards this end, we propose a novel semi-supervised learning based RNN model, which can leverage unlabeled data also present in abundance on social media. Through experiments we demonstrate the effectiveness of our method, achieving state-of-the-art performance in ADR mention extraction. version:1
arxiv-1709-01686 | BranchyNet: Fast Inference via Early Exiting from Deep Neural Networks | http://arxiv.org/abs/1709.01686 | id:1709.01686 author:Surat Teerapittayanon, Bradley McDanel, H. T. Kung category:cs.NE cs.CV cs.LG  published:2017-09-06 summary:Deep neural networks are state of the art methods for many learning tasks due to their ability to extract increasingly better features at each network layer. However, the improved performance of additional layers in a deep network comes at the cost of added latency and energy usage in feedforward inference. As networks continue to get deeper and larger, these costs become more prohibitive for real-time and energy-sensitive applications. To address this issue, we present BranchyNet, a novel deep network architecture that is augmented with additional side branch classifiers. The architecture allows prediction results for a large portion of test samples to exit the network early via these branches when samples can already be inferred with high confidence. BranchyNet exploits the observation that features learned at an early layer of a network may often be sufficient for the classification of many data points. For more difficult samples, which are expected less frequently, BranchyNet will use further or all network layers to provide the best likelihood of correct prediction. We study the BranchyNet architecture using several well-known networks (LeNet, AlexNet, ResNet) and datasets (MNIST, CIFAR10) and show that it can both improve accuracy and significantly reduce the inference time of the network. version:1
arxiv-1709-01674 | Probabilistic Rule Realization and Selection | http://arxiv.org/abs/1709.01674 | id:1709.01674 author:Haizi Yu, Tianxi Li, Lav R. Varshney category:cs.LG stat.ML  published:2017-09-06 summary:Abstraction and realization are bilateral processes that are key in deriving intelligence and creativity. In many domains, the two processes are approached through rules: high-level principles that reveal invariances within similar yet diverse examples. Under a probabilistic setting for discrete input spaces, we focus on the rule realization problem which generates input sample distributions that follow the given rules. More ambitiously, we go beyond a mechanical realization that takes whatever is given, but instead ask for proactively selecting reasonable rules to realize. This goal is demanding in practice, since the initial rule set may not always be consistent and thus intelligent compromises are needed. We formulate both rule realization and selection as two strongly connected components within a single and symmetric bi-convex problem, and derive an efficient algorithm that works at large scale. Taking music compositional rules as the main example throughout the paper, we demonstrate our model's efficiency in not only music realization (composition) but also music interpretation and understanding (analysis). version:1
arxiv-1708-00812 | Predictive Coding for Dynamic Visual Processing: Development of Functional Hierarchy in a Multiple Spatio-Temporal Scales RNN Model | http://arxiv.org/abs/1708.00812 | id:1708.00812 author:Minkyu Choi, Jun Tani category:cs.CV  published:2017-08-02 summary:The current paper proposes a novel predictive coding type neural network model, the predictive multiple spatio-temporal scales recurrent neural network (P-MSTRNN). The P-MSTRNN learns to predict visually perceived human whole-body cyclic movement patterns by exploiting multiscale spatio-temporal constraints imposed on network dynamics by using differently sized receptive fields as well as different time constant values for each layer. After learning, the network becomes able to proactively imitate target movement patterns by inferring or recognizing corresponding intentions by means of the regression of prediction error. Results show that the network can develop a functional hierarchy by developing a different type of dynamic structure at each layer. The paper examines how model performance during pattern generation as well as predictive imitation varies depending on the stage of learning. The number of limit cycle attractors corresponding to target movement patterns increases as learning proceeds. And, transient dynamics developing early in the learning process successfully perform pattern generation and predictive imitation tasks. The paper concludes that exploitation of transient dynamics facilitates successful task performance during early learning periods. version:2
arxiv-1709-00483 | Iteratively Linearized Reweighted Alternating Direction Method of Multipliers for a Class of Nonconvex Problems | http://arxiv.org/abs/1709.00483 | id:1709.00483 author:Tao Sun, Hao Jiang, Lizhi Cheng category:cs.NA cs.CV math.NA math.OC stat.ML  published:2017-09-01 summary:In this paper, we consider solving a class of nonconvex and nonsmooth problems frequently appearing in signal processing and machine learning research. The traditional alternating direction method of multipliers encounter troubles in both mathematics and computations in solving the nonconvex and nonsmooth subproblem. In view of this, we propose a reweighted alternating direction method of multipliers. In this algorithm, all subproblems are convex and easy to calculate. We also provide several guarantees for the convergence and prove that the algorithm globally converges to a critical point of an auxiliary function with the help of the Kurdyka- Lojasiewicz property. Several numerical results are presented to demonstrate the efficiency of the proposed algorithm. version:2
arxiv-1709-01664 | Deep Convolutional Neural Network for Age Estimation based on VGG-Face Model | http://arxiv.org/abs/1709.01664 | id:1709.01664 author:Zakariya Qawaqneh, Arafat Abu Mallouh, Buket D. Barkana category:cs.CV  published:2017-09-06 summary:Automatic age estimation from real-world and unconstrained face images is rapidly gaining importance. In our proposed work, a deep CNN model that was trained on a database for face recognition task is used to estimate the age information on the Adience database. This paper has three significant contributions in this field. (1) This work proves that a CNN model, which was trained for face recognition task, can be utilized for age estimation to improve performance; (2) Over fitting problem can be overcome by employing a pretrained CNN on a large database for face recognition task; (3) Not only the number of training images and the number subjects in a training database effect the performance of the age estimation model, but also the pre-training task of the employed CNN determines the performance of the model. version:1
arxiv-1709-01249 | Inhomogeneous Hypergraph Clustering with Applications | http://arxiv.org/abs/1709.01249 | id:1709.01249 author:Pan Li, Olgica Milenkovic category:cs.LG stat.ML  published:2017-09-05 summary:Hypergraph partitioning is an important problem in machine learning, computer vision and network analytics. A widely used method for hypergraph partitioning relies on minimizing a normalized sum of the costs of partitioning hyperedges across clusters. Algorithmic solutions based on this approach assume that different partitions of a hyperedge incur the same cost. However, this assumption fails to leverage the fact that different subsets of vertices within the same hyperedge may have different structural importance. We hence propose a new hypergraph clustering technique, termed inhomogeneous hypergraph partitioning, which assigns different costs to different hyperedge cuts. We prove that inhomogeneous partitioning produces a quadratic approximation to the optimal solution if the inhomogeneous costs satisfy submodularity constraints. Moreover, we demonstrate that inhomogenous partitioning offers significant performance improvements in applications such as structure learning of rankings, subspace segmentation and motif clustering. version:2
arxiv-1709-01648 | Boosting Deep Learning Risk Prediction with Generative Adversarial Networks for Electronic Health Records | http://arxiv.org/abs/1709.01648 | id:1709.01648 author:Zhengping Che, Yu Cheng, Shuangfei Zhai, Zhaonan Sun, Yan Liu category:cs.LG stat.ML  published:2017-09-06 summary:The rapid growth of Electronic Health Records (EHRs), as well as the accompanied opportunities in Data-Driven Healthcare (DDH), has been attracting widespread interests and attentions. Recent progress in the design and applications of deep learning methods has shown promising results and is forcing massive changes in healthcare academia and industry, but most of these methods rely on massive labeled data. In this work, we propose a general deep learning framework which is able to boost risk prediction performance with limited EHR data. Our model takes a modified generative adversarial network namely ehrGAN, which can provide plausible labeled EHR data by mimicking real patient records, to augment the training dataset in a semi-supervised learning manner. We use this generative model together with a convolutional neural network (CNN) based prediction model to improve the onset prediction performance. Experiments on two real healthcare datasets demonstrate that our proposed framework produces realistic data samples and achieves significant improvements on classification tasks with the generated data over several stat-of-the-art baselines. version:1
arxiv-1709-01630 | Using Cross-Model EgoSupervision to Learn Cooperative Basketball Intention | http://arxiv.org/abs/1709.01630 | id:1709.01630 author:Gedas Bertasius, Jianbo Shi category:cs.CV  published:2017-09-05 summary:We present a first-person method for cooperative basketball intention prediction: we predict with whom the camera wearer will cooperate in the near future from unlabeled first-person images. This is a challenging task that requires inferring the camera wearer's visual attention, and decoding the social cues of other players. Our key observation is that a first-person view provides strong cues to infer the camera wearer's momentary visual attention, and his/her intentions. We exploit this observation by proposing a new cross-model EgoSupervision learning scheme that allows us to predict with whom the camera wearer will cooperate in the near future, without using manually labeled intention labels. Our cross-model EgoSupervision operates by transforming the outputs of a pretrained pose-estimation network, into pseudo ground truth labels, which are then used as a supervisory signal to train a new network for a cooperative intention task. We evaluate our method, and show that it achieves similar or even better accuracy than the fully supervised methods do. version:1
arxiv-1709-01625 | Exploring and Exploiting Diversity for Image Segmentation | http://arxiv.org/abs/1709.01625 | id:1709.01625 author:Payman Yadollahpour category:cs.CV  published:2017-09-05 summary:Semantic image segmentation is an important computer vision task that is difficult because it consists of both recognition and segmentation. The task is often cast as a structured output problem on an exponentially large output-space, which is typically modeled by a discrete probabilistic model. The best segmentation is found by inferring the Maximum a-Posteriori (MAP) solution over the output distribution defined by the model. Due to limitations in optimization, the model cannot be arbitrarily complex. This leads to a trade-off: devise a more accurate model that incorporates rich high-order interactions between image elements at the cost of inaccurate and possibly intractable optimization OR leverage a tractable model which produces less accurate MAP solutions but may contain high quality solutions as other modes of its output distribution. This thesis investigates the latter and presents a two stage approach to semantic segmentation. In the first stage a tractable segmentation model outputs a set of high probability segmentations from the underlying distribution that are not just minor perturbations of each other. Critically the output of this stage is a diverse set of plausible solutions and not just a single one. In the second stage, a discriminatively trained re-ranking model selects the best segmentation from this set. The re-ranking stage can use much more complex features than what could be tractably used in the segmentation model, allowing a better exploration of the solution space than simply returning the MAP solution. The formulation is agnostic to the underlying segmentation model (e.g. CRF, CNN, etc.) and optimization algorithm, which makes it applicable to a wide range of models and inference methods. Evaluation of the approach on a number of semantic image segmentation benchmark datasets highlight its superiority over inferring the MAP solution. version:1
arxiv-1709-01620 | Deep Learning Techniques for Music Generation - A Survey | http://arxiv.org/abs/1709.01620 | id:1709.01620 author:Jean-Pierre Briot, Gaëtan Hadjeres, François Pachet category:cs.SD cs.LG  published:2017-09-05 summary:This book is a survey and an analysis of different ways of using deep learning (deep artificial neural networks) to generate musical content. At first, we propose a methodology based on four dimensions for our analysis: - objective - What musical content is to be generated? (e.g., melody, accompaniment...); - representation - What are the information formats used for the corpus and for the expected generated output? (e.g., MIDI, piano roll, text...); - architecture - What type of deep neural network is to be used? (e.g., recurrent network, autoencoder, generative adversarial networks...); - strategy - How to model and control the process of generation (e.g., direct feedforward, sampling, unit selection...). For each dimension, we conduct a comparative analysis of various models and techniques. For the strategy dimension, we propose some tentative typology of possible approaches and mechanisms. This classification is bottom-up, based on the analysis of many existing deep-learning based systems for music generation, which are described in this book. The last part of the book includes discussion and prospects. version:1
arxiv-1709-01618 | PageNet: Page Boundary Extraction in Historical Handwritten Documents | http://arxiv.org/abs/1709.01618 | id:1709.01618 author:Chris Tensmeyer, Brian Davis, Curtis Wigington, Iain Lee, Bill Barrett category:cs.CV  published:2017-09-05 summary:When digitizing a document into an image, it is common to include a surrounding border region to visually indicate that the entire document is present in the image. However, this border should be removed prior to automated processing. In this work, we present a deep learning based system, PageNet, which identifies the main page region in an image in order to segment content from both textual and non-textual border noise. In PageNet, a Fully Convolutional Network obtains a pixel-wise segmentation which is post-processed into the output quadrilateral region. We evaluate PageNet on 4 collections of historical handwritten documents and obtain over 94% mean intersection over union on all datasets and approach human performance on 2 of these collections. Additionally, we show that PageNet can segment documents that are overlayed on top of other documents. version:1
arxiv-1709-01602 | Dynamic Multiscale Tree Learning Using Ensemble Strong Classifiers for Multi-label Segmentation of Medical Images with Lesions | http://arxiv.org/abs/1709.01602 | id:1709.01602 author:Samya Amiri, Mohamed Ali Mahjoub, Islem Rekik category:cs.CV  published:2017-09-05 summary:We introduce a dynamic multiscale tree (DMT) architecture that learns how to leverage the strengths of different existing classifiers for supervised multi-label image segmentation. Unlike previous works that simply aggregate or cascade classifiers for addressing image segmentation and labeling tasks, we propose to embed strong classifiers into a tree structure that allows bi-directional flow of information between its classifier nodes to gradually improve their performances. Our DMT is a generic classification model that inherently embeds different cascades of classifiers while enhancing learning transfer between them to boost up their classification accuracies. Specifically, each node in our DMT can nest a Structured Random Forest (SRF) classifier or a Bayesian Network (BN) classifier. The proposed SRF-BN DMT architecture has several appealing properties. First, while SRF operates at a patch-level (regular image region), BN operates at the super-pixel level (irregular image region), thereby enabling the DMT to integrate multi-level image knowledge in the learning process. Second, although BN is powerful in modeling dependencies between image elements (superpixels, edges) and their features, the learning of its structure and parameters is challenging. On the other hand, SRF may fail to accurately detect very irregular object boundaries. The proposed DMT robustly overcomes these limitations for both classifiers through the ascending and descending flow of contextual information between each parent node and its children nodes. Third, we train DMT using different scales, where we progressively decrease the patch and superpixel sizes as we go deeper along the tree edges nearing its leaf nodes. Last, DMT demonstrates its outperformance in comparison to several state-of-the-art segmentation methods for multi-labeling of brain images with gliomas. version:1
arxiv-1709-02255 | Intraoperative Organ Motion Models with an Ensemble of Conditional Generative Adversarial Networks | http://arxiv.org/abs/1709.02255 | id:1709.02255 author:Yipeng Hu, Eli Gibson, Tom Vercauteren, Hashim U. Ahmed, Mark Emberton, Caroline M. Moore, J. Alison Noble, Dean C. Barratt category:cs.CV cs.LG  published:2017-09-05 summary:In this paper, we describe how a patient-specific, ultrasound-probe-induced prostate motion model can be directly generated from a single preoperative MR image. Our motion model allows for sampling from the conditional distribution of dense displacement fields, is encoded by a generative neural network conditioned on a medical image, and accepts random noise as additional input. The generative network is trained by a minimax optimisation with a second discriminative neural network, tasked to distinguish generated samples from training motion data. In this work, we propose that 1) jointly optimising a third conditioning neural network that pre-processes the input image, can effectively extract patient-specific features for conditioning; and 2) combining multiple generative models trained separately with heuristically pre-disjointed training data sets can adequately mitigate the problem of mode collapse. Trained with diagnostic T2-weighted MR images from 143 real patients and 73,216 3D dense displacement fields from finite element simulations of intraoperative prostate motion due to transrectal ultrasound probe pressure, the proposed models produced physically-plausible patient-specific motion of prostate glands. The ability to capture biomechanically simulated motion was evaluated using two errors representing generalisability and specificity of the model. The median values, calculated from a 10-fold cross-validation, were 2.8+/-0.3 mm and 1.7+/-0.1 mm, respectively. We conclude that the introduced approach demonstrates the feasibility of applying state-of-the-art machine learning algorithms to generate organ motion models from patient images, and shows significant promise for future research. version:1
arxiv-1704-05426 | A Broad-Coverage Challenge Corpus for Sentence Understanding through Inference | http://arxiv.org/abs/1704.05426 | id:1704.05426 author:Adina Williams, Nikita Nangia, Samuel R. Bowman category:cs.CL  published:2017-04-18 summary:This paper introduces the Multi-Genre Natural Language Inference (MultiNLI) corpus, a dataset designed for use in the development and evaluation of machine learning models for sentence understanding. In addition to being one of the largest corpora available for the task of NLI, at 433k examples, this corpus improves upon available resources in its coverage: it offers data from ten distinct genres of written and spoken English--making it possible to evaluate systems on nearly the full complexity of the language--and it offers an explicit setting for the evaluation of cross-genre domain adaptation. version:3
arxiv-1709-01507 | Squeeze-and-Excitation Networks | http://arxiv.org/abs/1709.01507 | id:1709.01507 author:Jie Hu, Li Shen, Gang Sun category:cs.CV  published:2017-09-05 summary:Convolutional neural networks are built upon the convolution operation, which extracts informative features by fusing spatial and channel-wise information together within local receptive fields. In order to boost the representational power of a network, much existing work has shown the benefits of enhancing spatial encoding. In this work, we focus on channels and propose a novel architectural unit, which we term the "Squeeze-and-Excitation" (SE) block, that adaptively recalibrates channel-wise feature responses by explicitly modelling interdependencies between channels. We demonstrate that by stacking these blocks together, we can construct SENet architectures that generalise extremely well across challenging datasets. Crucially, we find that SE blocks produce significant performance improvements for existing state-of-the-art deep architectures at slight computational cost. SENets formed the foundation of our ILSVRC 2017 classification submission which won first place and significantly reduced the top-5 error to 2.251%, achieving a 25% relative improvement over the winning entry of 2016. version:1
arxiv-1709-01472 | Leveraging multiple datasets for deep leaf counting | http://arxiv.org/abs/1709.01472 | id:1709.01472 author:Andrei Dobrescu, Mario Valerio Giuffrida, Sotirios A Tsaftaris category:cs.CV  published:2017-09-05 summary:The number of leaves a plant has is one of the key traits (phenotypes) describing its development and growth. Here, we propose an automated, deep learning based approach for counting leaves in model rosette plants. While state-of-the-art results on leaf counting with deep learning methods have recently been reported, they obtain the count as a result of leaf segmentation and thus require per-leaf (instance) segmentation to train the models (a rather strong annotation). Instead, our method treats leaf counting as a direct regression problem and thus only requires as annotation the total leaf count per plant. We argue that combining different datasets when training a deep neural network is beneficial and improves the results of the proposed approach. We evaluate our method on the CVPPP 2017 Leaf Counting Challenge dataset, which contains images of Arabidopsis and tobacco plants. Experimental results show that the proposed method significantly outperforms the winner of the previous CVPPP challenge, improving the results by a minimum of ~50% on each of the test datasets, and can achieve this performance without knowing the experimental origin of the data (i.e. in the wild setting of the challenge). We also compare the counting accuracy of our model with that of per leaf segmentation algorithms, achieving a 20% decrease in mean absolute difference in count ( DiC ). version:1
arxiv-1709-01471 | Learning the PE Header, Malware Detection with Minimal Domain Knowledge | http://arxiv.org/abs/1709.01471 | id:1709.01471 author:Edward Raff, Jared Sylvester, Charles Nicholas category:stat.ML cs.LG  published:2017-09-05 summary:Many efforts have been made to use various forms of domain knowledge in malware detection. Currently there exist two common approaches to malware detection without domain knowledge, namely byte n-grams and strings. In this work we explore the feasibility of applying neural networks to malware detection and feature learning. We do this by restricting ourselves to a minimal amount of domain knowledge in order to extract a portion of the Portable Executable (PE) header. By doing this we show that neural networks can learn from raw bytes without explicit feature construction, and perform even better than a domain knowledge approach that parses the PE header into explicit features. version:1
arxiv-1709-01467 | Subspace Segmentation by Successive Approximations: A Method for Low-Rank and High-Rank Data with Missing Entries | http://arxiv.org/abs/1709.01467 | id:1709.01467 author:João Carvalho, Manuel Marques, João P. Costeira category:cs.CV  published:2017-09-05 summary:We propose a method to reconstruct and cluster incomplete high-dimensional data lying in a union of low-dimensional subspaces. Exploring the sparse representation model, we jointly estimate the missing data while imposing the intrinsic subspace structure. Since we have a non-convex problem, we propose an iterative method to reconstruct the data and provide a sparse similarity affinity matrix. This method is robust to initialization and achieves greater reconstruction accuracy than current methods, which dramatically improves clustering performance. Extensive experiments with synthetic and real data show that our approach leads to significant improvements in the reconstruction and segmentation, outperforming current state of the art for both low and high-rank data. version:1
arxiv-1709-01459 | 6D Object Pose Estimation with Depth Images: A Seamless Approach for Robotic Interaction and Augmented Reality | http://arxiv.org/abs/1709.01459 | id:1709.01459 author:David Joseph Tan, Nassir Navab, Federico Tombari category:cs.CV  published:2017-09-05 summary:To determine the 3D orientation and 3D location of objects in the surroundings of a camera mounted on a robot or mobile device, we developed two powerful algorithms in object detection and temporal tracking that are combined seamlessly for robotic perception and interaction as well as Augmented Reality (AR). A separate evaluation of, respectively, the object detection and the temporal tracker demonstrates the important stride in research as well as the impact on industrial robotic applications and AR. When evaluated on a standard dataset, the detector produced the highest f1-score with a large margin while the tracker generated the best accuracy at a very low latency of approximately 2 ms per frame with one CPU core: both algorithms outperforming the state of the art. When combined, we achieve a powerful framework that is robust to handle multiple instances of the same object under occlusion and clutter while attaining real-time performance. Aiming at stepping beyond the simple scenarios used by current systems, often constrained by having a single object in absence of clutter, averting to touch the object to prevent close-range partial occlusion, selecting brightly colored objects to easily segment them individually or assuming that the object has simple geometric structure, we demonstrate the capacity to handle challenging cases under clutter, partial occlusion and varying lighting conditions with objects of different shapes and sizes. version:1
arxiv-1709-01450 | The Devil is in the Tails: Fine-grained Classification in the Wild | http://arxiv.org/abs/1709.01450 | id:1709.01450 author:Grant Van Horn, Pietro Perona category:cs.CV  published:2017-09-05 summary:The world is long-tailed. What does this mean for computer vision and visual recognition? The main two implications are (1) the number of categories we need to consider in applications can be very large, and (2) the number of training examples for most categories can be very small. Current visual recognition algorithms have achieved excellent classification accuracy. However, they require many training examples to reach peak performance, which suggests that long-tailed distributions will not be dealt with well. We analyze this question in the context of eBird, a large fine-grained classification dataset, and a state-of-the-art deep network classification algorithm. We find that (a) peak classification performance on well-represented categories is excellent, (b) given enough data, classification performance suffers only minimally from an increase in the number of classes, (c) classification performance decays precipitously as the number of training examples decreases, (d) surprisingly, transfer learning is virtually absent in current methods. Our findings suggest that our community should come to grips with the question of long tails. version:1
arxiv-1709-01447 | Conditional independence testing based on a nearest-neighbor estimator of conditional mutual information | http://arxiv.org/abs/1709.01447 | id:1709.01447 author:Jakob Runge category:stat.ML cs.IT math.IT stat.ME  published:2017-09-05 summary:Conditional independence testing is a fundamental problem underlying causal discovery and a particularly challenging task in the presence of nonlinear and high-dimensional dependencies. Here a fully non-parametric test for continuous data based on conditional mutual information combined with a local permutation scheme is presented. Through a nearest neighbor approach, the test efficiently adapts also to non-smooth distributions due to strongly nonlinear dependencies. Numerical experiments demonstrate that the test reliably simulates the null distribution even for small sample sizes and with high-dimensional conditioning sets. The test is better calibrated than kernel-based tests utilizing an analytical approximation of the null distribution, especially for non-smooth densities, and reaches the same or higher power levels. Combining the local permutation scheme with the kernel tests leads to better calibration, but suffers in power. For smaller sample sizes and lower dimensions, the test is faster than random fourier feature-based kernel tests if the permutation scheme is (embarrassingly) parallelized, but the runtime increases more sharply with sample size and dimensionality. Thus, more theoretical research to analytically approximate the null distribution and speed up the estimation for larger sample sizes is desirable. version:1
arxiv-1709-01442 | Dense Face Alignment | http://arxiv.org/abs/1709.01442 | id:1709.01442 author:Yaojie Liu, Amin Jourabloo, William Ren, Xiaoming Liu category:cs.CV  published:2017-09-05 summary:Face alignment is a classic problem in the computer vision field. Previous works mostly focus on sparse alignment with a limited number of facial landmark points, i.e., facial landmark detection. In this paper, for the first time, we aim at providing a very dense 3D alignment for large-pose face images. To achieve this, we train a CNN to estimate the 3D face shape, which not only aligns limited facial landmarks but also fits face contours and SIFT feature points. Moreover, we also address the bottleneck of training CNN with multiple datasets, due to different landmark markups on different datasets, such as 5, 34, 68. Experimental results show our method not only provides high-quality, dense 3D face fitting but also outperforms the state-of-the-art facial landmark detection methods on the challenging datasets. Our model can run at real time during testing. version:1
arxiv-1709-01439 | A Statistical Approach to Increase Classification Accuracy in Supervised Learning Algorithms | http://arxiv.org/abs/1709.01439 | id:1709.01439 author:Gustavo A Valencia-Zapata, Daniel Mejia, Gerhard Klimeck, Michael Zentner, Okan Ersoy category:cs.LG stat.ML  published:2017-09-05 summary:Probabilistic mixture models have been widely used for different machine learning and pattern recognition tasks such as clustering, dimensionality reduction, and classification. In this paper, we focus on trying to solve the most common challenges related to supervised learning algorithms by using mixture probability distribution functions. With this modeling strategy, we identify sub-labels and generate synthetic data in order to reach better classification accuracy. It means we focus on increasing the training data synthetically to increase the classification accuracy. version:1
arxiv-1709-01427 | Stochastic Gradient Descent: Going As Fast As Possible But Not Faster | http://arxiv.org/abs/1709.01427 | id:1709.01427 author:Alice Schoenauer-Sebag, Marc Schoenauer, Michèle Sebag category:stat.ML cs.LG cs.NE  published:2017-09-05 summary:When applied to training deep neural networks, stochastic gradient descent (SGD) often incurs steady progression phases, interrupted by catastrophic episodes in which loss and gradient norm explode. A possible mitigation of such events is to slow down the learning process. This paper presents a novel approach to control the SGD learning rate, that uses two statistical tests. The first one, aimed at fast learning, compares the momentum of the normalized gradient vectors to that of random unit vectors and accordingly gracefully increases or decreases the learning rate. The second one is a change point detection test, aimed at the detection of catastrophic learning episodes; upon its triggering the learning rate is instantly halved. Both abilities of speeding up and slowing down the learning rate allows the proposed approach, called SALeRA, to learn as fast as possible but not faster. Experiments on standard benchmarks show that SALeRA performs well in practice, and compares favorably to the state of the art. version:1
arxiv-1709-01421 | Multi-label Class-imbalanced Action Recognition in Hockey Videos via 3D Convolutional Neural Networks | http://arxiv.org/abs/1709.01421 | id:1709.01421 author:Konstantin Sozykin, Adil Mehmood Khan, Stanislav Protasov, Rasheed Hussain category:cs.CV cs.LG  published:2017-09-05 summary:Automatic analysis of the video is one of most complex problems in the fields of computer vision and machine learning. A significant part of this research deals with (human) activity recognition (HAR) since humans, and the activities that they perform, generate most of the video semantics. Video-based HAR has applications in various domains, but one of the most important and challenging is HAR in sports videos. Some of the major issues include high inter- and intra-class variations, large class imbalance, the presence of both group actions and single player actions, and recognizing simultaneous actions, i.e., the multi-label learning problem. Keeping in mind these challenges and the recent success of CNNs in solving various computer vision problems, in this work, we implement a 3D CNN based multi-label deep HAR system for multi-label class-imbalanced action recognition in hockey videos. We test our system for two different scenarios: an ensemble of k binary networks vs. a single k-output network, on a publicly available dataset. We also compare our results with the system that was originally designed for the chosen dataset. Experimental results show that the proposed approach performs better than the existing solution. version:1
arxiv-1705-02798 | Reinforced Mnemonic Reader for Machine Comprehension | http://arxiv.org/abs/1705.02798 | id:1705.02798 author:Minghao Hu, Yuxing Peng, Xipeng Qiu category:cs.CL  published:2017-05-08 summary:In this paper, we introduce the Reinforced Mnemonic Reader for machine comprehension (MC) task, which aims to answer a query about a given context document. We propose several novel mechanisms that address critical problems in MC that are not adequately solved by previous works, such as enhancing the capacity of encoder, modeling long-term dependencies of contexts, refining the predicted answer span, and directly optimizing the evaluation metric. Extensive experiments on TriviaQA and Stanford Question Answering Dataset (SQuAD) show that our model achieves state-of-the-art results. version:3
arxiv-1708-07819 | Semantic Foggy Scene Understanding with Synthetic Data | http://arxiv.org/abs/1708.07819 | id:1708.07819 author:Christos Sakaridis, Dengxin Dai, Luc Van Gool category:cs.CV  published:2017-08-25 summary:This work addresses the problem of semantic foggy scene understanding (SFSU). Although extensive research has been performed on image dehazing and on semantic scene understanding with weather-clear images, little attention has been paid to SFSU. Due to the difficulty of collecting and annotating foggy images, we choose to generate synthetic fog on real images that depict weather-clear outdoor scenes, and then leverage these synthetic data for SFSU by employing state-of-the-art convolutional neural networks (CNN). In particular, a complete pipeline to generate synthetic fog on real, weather-clear images using incomplete depth information is developed. We apply our fog synthesis on the Cityscapes dataset and generate Foggy Cityscapes with 20550 images. SFSU is tackled in two fashions: 1) with typical supervised learning, and 2) with a novel semi-supervised learning, which combines 1) with an unsupervised supervision transfer from weather-clear images to their synthetic foggy counterparts. In addition, this work carefully studies the usefulness of image dehazing for SFSU. For evaluation, we present Foggy Driving, a dataset with 101 real-world images depicting foggy driving scenes, which come with ground truth annotations for semantic segmentation and object detection. Extensive experiments show that 1) supervised learning with our synthetic data significantly improves the performance of state-of-the-art CNN for SFSU on Foggy Driving; 2) our semi-supervised learning strategy further improves performance; and 3) image dehazing marginally benefits SFSU with our learning strategy. The datasets, models and code will be made publicly available to encourage further research in this direction. version:2
arxiv-1709-01362 | Predicting Visual Features from Text for Image and Video Caption Retrieval | http://arxiv.org/abs/1709.01362 | id:1709.01362 author:Jianfeng Dong, Xirong Li, Cees G. M. Snoek category:cs.CV  published:2017-09-05 summary:This paper strives to find amidst a set of sentences the one best describing the content of a given image or video. Different from existing works, which rely on a joint subspace for their image and video caption retrieval, we propose to do so in a visual space exclusively. Apart from this conceptual novelty, we contribute \emph{Word2VisualVec}, a deep neural network architecture that learns to predict a visual feature representation from textual input. Example captions are encoded into a textual embedding based on multi-scale sentence vectorization and further transferred into a deep visual feature of choice via a simple multi-layer perceptron. We further generalize Word2VisualVec for video caption retrieval, by predicting from text both 3-D convolutional neural network features as well as a visual-audio representation. Experiments on Flickr8k, Flickr30k, the Microsoft Video Description dataset and the very recent NIST TrecVid challenge for video caption retrieval detail Word2VisualVec's properties, its benefit over textual embeddings, the potential for multimodal query composition and its state-of-the-art results. version:1
arxiv-1709-01357 | Photometric stereo for strong specular highlights | http://arxiv.org/abs/1709.01357 | id:1709.01357 author:Maryam Khanian, Ali Sharifi Boroujerdi, Michael Breuß category:cs.CV math.OC  published:2017-09-05 summary:Photometric stereo (PS) is a fundamental technique in computer vision known to produce 3-D shape with high accuracy. The setting of PS is defined by using several input images of a static scene taken from one and the same camera position but under varying illumination. The vast majority of studies in this 3-D reconstruction method assume orthographic projection for the camera model. In addition, they mainly consider the Lambertian reflectance model as the way that light scatters at surfaces. So, providing reliable PS results from real world objects still remains a challenging task. We address 3-D reconstruction by PS using a more realistic set of assumptions combining for the first time the complete Blinn-Phong reflectance model and perspective projection. To this end, we will compare two different methods of incorporating the perspective projection into our model. Experiments are performed on both synthetic and real world images. Note that our real-world experiments do not benefit from laboratory conditions. The results show the high potential of our method even for complex real world applications such as medical endoscopy images which may include high amounts of specular highlights. version:1
arxiv-1709-01355 | Visualizing and Improving Scattering Networks | http://arxiv.org/abs/1709.01355 | id:1709.01355 author:Fergal Cotter, Nick Kingsbury category:cs.CV  published:2017-09-05 summary:Scattering Transforms (or ScatterNets) introduced by Mallat are a promising start into creating a well-defined feature extractor to use for pattern recognition and image classification tasks. They are of particular interest due to their architectural similarity to Convolutional Neural Networks (CNNs), while requiring no parameter learning and still performing very well (particularly in constrained classification tasks). In this paper we visualize what the deeper layers of a ScatterNet are sensitive to using a 'DeScatterNet'. We show that the higher orders of ScatterNets are sensitive to complex, edge-like patterns (checker-boards and rippled edges). These complex patterns may be useful for texture classification, but are quite dissimilar from the patterns visualized in second and third layers of Convolutional Neural Networks (CNNs) - the current state of the art Image Classifiers. We propose that this may be the source of the current gaps in performance between ScatterNets and CNNs (83% vs 93% on CIFAR-10 for ScatterNet+SVM vs ResNet). We then use these visualization tools to propose possible enhancements to the ScatterNet design, which show they have the power to extract features more closely resembling CNNs, while still being well-defined and having the invariance properties fundamental to ScatterNets. version:1
arxiv-1709-01353 | Learning Non-Metric Visual Similarity for Image Retrieval | http://arxiv.org/abs/1709.01353 | id:1709.01353 author:Noa Garcia, George Vogiatzis category:cs.CV  published:2017-09-05 summary:Can a neural network learn the concept of visual similarity? In this work, this question is addressed by training a deep learning model for the specific task of measuring the similarity between a pair of pictures in content-based image retrieval datasets. Traditionally, content-based image retrieval systems rely on two fundamental tasks: 1) computing meaningful image representations from pixels and 2) measuring accurate visual similarity between those representations. Whereas in the last few years several methods have been proposed to find high quality image representations including SIFT, VLAD or RMAC, most techniques still depend on standard metrics such as Euclidean distance or cosine similarity for the visual similarity task. However, standard metrics are independent from data and might be missing the nonlinear inner structure of visual representations. In this paper, we propose to learn a non-metric visual similarity function directly from image representations to measure how alike two images are. Experiments on standard image retrieval datasets show that results are boosted when using the proposed method over standard metrics. version:1
arxiv-1708-09230 | TANKER: Distributed Architecture for Named Entity Recognition and Disambiguation | http://arxiv.org/abs/1708.09230 | id:1708.09230 author:Sandro A. Coelho, Diego Moussallem, Gustavo C. Publio, Diego Esteves category:cs.CL  published:2017-08-30 summary:Named Entity Recognition and Disambiguation (NERD) systems have recently been widely researched to deal with the significant growth of the Web. NERD systems are crucial for several Natural Language Processing (NLP) tasks such as summarization, understanding, and machine translation. However, there is no standard interface specification, i.e. these systems may vary significantly either for exporting their outputs or for processing the inputs. Thus, when a given company desires to implement more than one NERD system, the process is quite exhaustive and prone to failure. In addition, industrial solutions demand critical requirements, e.g., large-scale processing, completeness, versatility, and licenses. Commonly, these requirements impose a limitation, making good NERD models to be ignored by companies. This paper presents TANKER, a distributed architecture which aims to overcome scalability, reliability and failure tolerance limitations related to industrial needs by combining NERD systems. To this end, TANKER relies on a micro-services oriented architecture, which enables agile development and delivery of complex enterprise applications. In addition, TANKER provides a standardized API which makes possible to combine several NERD systems at once. version:2
arxiv-1709-01305 | Cross-Media Similarity Evaluation for Web Image Retrieval in the Wild | http://arxiv.org/abs/1709.01305 | id:1709.01305 author:Jianfeng Dong, Xirong Li, Duanqing Xu category:cs.CV  published:2017-09-05 summary:In order to retrieve unlabeled images by textual queries, cross-media similarity computation is a key ingredient. Although novel methods are continuously introduced, little has been done to evaluate these methods together with large-scale query log analysis. Consequently, how far have these methods brought us in answering real-user queries is unclear. Given baseline methods that compute cross-media similarity using relatively simple text/image matching, how much progress have advanced models made is also unclear. This paper takes a pragmatic approach to answering the two questions. Queries are automatically categorized according to the proposed query visualness measure, and later connected to the evaluation of multiple cross-media similarity models on three test sets. Such a connection reveals that the success of the state-of-the-art is mainly attributed to their good performance on visual-oriented queries, while these queries account for only a small part of real-user queries. To quantify the current progress, we propose a simple text2image method, representing a novel test query by a set of images selected from large-scale query log. Consequently, computing cross-media similarity between the test query and a given image boils down to comparing the visual similarity between the given image and the selected images. Image retrieval experiments on the challenging Clickture dataset show that the proposed text2image compares favorably to recent deep learning based alternatives. version:1
arxiv-1709-01298 | Spectral Mixture Kernels for Multi-Output Gaussian Processes | http://arxiv.org/abs/1709.01298 | id:1709.01298 author:Gabriel Parra, Felipe Tobar category:stat.ML cs.LG  published:2017-09-05 summary:Initially, multiple-output Gaussian processes models (MOGPs) were constructed as linear combinations of independent, latent, single-output Gaussian processes (GPs). This resulted in cross-covariance functions with limited parametric interpretation, thus conflicting with single-output GPs and their intuitive understanding of lengthscales, frequencies and magnitudes to name but a few. On the contrary, current approaches to MOGP are able to better interpret the relationship between different channels by directly modelling the cross-covariances as a spectral mixture kernel with a phase shift. We propose a parametric family of complex-valued crossspectral densities and then build on Cramer's Theorem, the multivariate version of Bochner's Theorem, to provide a principled approach to design multivariate covariance functions. The so-constructed kernels are able to model delays among channels in addition to phase differences and are thus more expressive than previous methods, while also providing full parametric interpretation of the relationship across channels. The proposed method is first validated on synthetic data and then compared to existing MOGP methods on two real-world examples. version:1
arxiv-1709-01295 | SketchParse : Towards Rich Descriptions for Poorly Drawn Sketches using Multi-Task Hierarchical Deep Networks | http://arxiv.org/abs/1709.01295 | id:1709.01295 author:Ravi Kiran Sarvadevabhatla, Isht Dwivedi, Abhijat Biswas, Sahil Manocha, R. Venkatesh Babu category:cs.CV cs.GR cs.MM  published:2017-09-05 summary:The ability to semantically interpret hand-drawn line sketches, although very challenging, can pave way for novel applications in multimedia. We propose SketchParse, the first deep-network architecture for fully automatic parsing of freehand object sketches. SketchParse is configured as a two-level fully convolutional network. The first level contains shared layers common to all object categories. The second level contains a number of expert sub-networks. Each expert specializes in parsing sketches from object categories which contain structurally similar parts. Effectively, the two-level configuration enables our architecture to scale up efficiently as additional categories are added. We introduce a router layer which (i) relays sketch features from shared layers to the correct expert (ii) eliminates the need to manually specify object category during inference. To bypass laborious part-level annotation, we sketchify photos from semantic object-part image datasets and use them for training. Our architecture also incorporates object pose prediction as a novel auxiliary task which boosts overall performance while providing supplementary information regarding the sketch. We demonstrate SketchParse's abilities (i) on two challenging large-scale sketch datasets (ii) in parsing unseen, semantically related object categories (iii) in improving fine-grained sketch-based image retrieval. As a novel application, we also outline how SketchParse's output can be used to generate caption-style descriptions for hand-drawn sketches. version:1
arxiv-1706-08474 | Paying More Attention to Saliency: Image Captioning with Saliency and Context Attention | http://arxiv.org/abs/1706.08474 | id:1706.08474 author:Marcella Cornia, Lorenzo Baraldi, Giuseppe Serra, Rita Cucchiara category:cs.CV  published:2017-06-26 summary:Image captioning has been recently gaining a lot of attention thanks to the impressive achievements shown by deep captioning architectures, which combine Convolutional Neural Networks to extract image representations, and Recurrent Neural Networks to generate the corresponding captions. At the same time, a significant research effort has been dedicated to the development of saliency prediction models, which can predict human eye fixations. Despite saliency information could be useful to condition an image captioning architecture, by providing an indication of what is salient and what is not, no model has yet succeeded in effectively incorporating these two techniques. In this work, we propose an image captioning approach in which a generative recurrent neural network can focus on different parts of the input image during the generation of the caption, by exploiting the conditioning given by a saliency prediction model on which parts of the image are salient and which are contextual. We demonstrate, through extensive quantitative and qualitative experiments on large scale datasets, that our model achieves superior performances with respect to different image captioning baselines with and without saliency. version:2
arxiv-1709-01256 | Semantic Document Distance Measures and Unsupervised Document Revision Detection | http://arxiv.org/abs/1709.01256 | id:1709.01256 author:Xiaofeng Zhu, Diego Klabjan, Patrick Bless category:cs.IR cs.CL  published:2017-09-05 summary:In this paper, we model the document revision detection problem as a minimum cost branching problem that relies on computing document distances. Furthermore, we propose two new document distance measures, word vector-based Dynamic Time Warping (wDTW) and word vector-based Tree Edit Distance (wTED). Our revision detection system is designed for a large scale corpus and implemented in Apache Spark. We demonstrate that our system can more precisely detect revisions than state-of-the-art methods by utilizing the Wikipedia revision dumps https://snap.stanford.edu/data/wiki-meta.html and simulated data sets. version:1
arxiv-1709-01237 | Newton-type Methods for Inference in Higher-Order Markov Random Fields | http://arxiv.org/abs/1709.01237 | id:1709.01237 author:Hariprasad Kannan, Nikos Komodakis, Nikos Paragios category:cs.CV cs.LG cs.NA  published:2017-09-05 summary:Linear programming relaxations are central to {\sc map} inference in discrete Markov Random Fields. The ability to properly solve the Lagrangian dual is a critical component of such methods. In this paper, we study the benefit of using Newton-type methods to solve the Lagrangian dual of a smooth version of the problem. We investigate their ability to achieve superior convergence behavior and to better handle the ill-conditioned nature of the formulation, as compared to first order methods. We show that it is indeed possible to efficiently apply a trust region Newton method for a broad range of {\sc map} inference problems. In this paper we propose a provably convergent and efficient framework that includes (i) excellent compromise between computational complexity and precision concerning the Hessian matrix construction, (ii) a damping strategy that aids efficient optimization, (iii) a truncation strategy coupled with a generic pre-conditioner for Conjugate Gradients, (iv) efficient sum-product computation for sparse clique potentials. Results for higher-order Markov Random Fields demonstrate the potential of this approach. version:1
arxiv-1709-01231 | Discriminative Similarity for Clustering and Semi-Supervised Learning | http://arxiv.org/abs/1709.01231 | id:1709.01231 author:Yingzhen Yang, Feng Liang, Nebojsa Jojic, Shuicheng Yan, Jiashi Feng, Thomas S. Huang category:stat.ML cs.LG  published:2017-09-05 summary:Similarity-based clustering and semi-supervised learning methods separate the data into clusters or classes according to the pairwise similarity between the data, and the pairwise similarity is crucial for their performance. In this paper, we propose a novel discriminative similarity learning framework which learns discriminative similarity for either data clustering or semi-supervised learning. The proposed framework learns classifier from each hypothetical labeling, and searches for the optimal labeling by minimizing the generalization error of the learned classifiers associated with the hypothetical labeling. Kernel classifier is employed in our framework. By generalization analysis via Rademacher complexity, the generalization error bound for the kernel classifier learned from hypothetical labeling is expressed as the sum of pairwise similarity between the data from different classes, parameterized by the weights of the kernel classifier. Such pairwise similarity serves as the discriminative similarity for the purpose of clustering and semi-supervised learning, and discriminative similarity with similar form can also be induced by the integrated squared error bound for kernel density classification. Based on the discriminative similarity induced by the kernel classifier, we propose new clustering and semi-supervised learning methods. version:1
arxiv-1709-01230 | On the Suboptimality of Proximal Gradient Descent for $\ell^{0}$ Sparse Approximation | http://arxiv.org/abs/1709.01230 | id:1709.01230 author:Yingzhen Yang, Jiashi Feng, Nebojsa Jojic, Jianchao Yang, Thomas S. Huang category:math.OC cs.LG  published:2017-09-05 summary:We study the proximal gradient descent (PGD) method for $\ell^{0}$ sparse approximation problem as well as its accelerated optimization with randomized algorithms in this paper. We first offer theoretical analysis of PGD showing the bounded gap between the sub-optimal solution by PGD and the globally optimal solution for the $\ell^{0}$ sparse approximation problem under conditions weaker than Restricted Isometry Property widely used in compressive sensing literature. Moreover, we propose randomized algorithms to accelerate the optimization by PGD using randomized low rank matrix approximation (PGD-RMA) and randomized dimension reduction (PGD-RDR). Our randomized algorithms substantially reduces the computation cost of the original PGD for the $\ell^{0}$ sparse approximation problem, and the resultant sub-optimal solution still enjoys provable suboptimality, namely, the sub-optimal solution to the reduced problem still has bounded gap to the globally optimal solution to the original problem. version:1
arxiv-1706-04496 | Learning Local Shape Descriptors from Part Correspondences With Multi-view Convolutional Networks | http://arxiv.org/abs/1706.04496 | id:1706.04496 author:Haibin Huang, Evangelos Kalogerakis, Siddhartha Chaudhuri, Duygu Ceylan, Vladimir G. Kim, Ersin Yumer category:cs.CV cs.GR  published:2017-06-14 summary:We present a new local descriptor for 3D shapes, directly applicable to a wide range of shape analysis problems such as point correspondences, semantic segmentation, affordance prediction, and shape-to-scan matching. The descriptor is produced by a convolutional network that is trained to embed geometrically and semantically similar points close to one another in descriptor space. The network processes surface neighborhoods around points on a shape that are captured at multiple scales by a succession of progressively zoomed out views, taken from carefully selected camera positions. We leverage two extremely large sources of data to train our network. First, since our network processes rendered views in the form of 2D images, we repurpose architectures pre-trained on massive image datasets. Second, we automatically generate a synthetic dense point correspondence dataset by non-rigid alignment of corresponding shape parts in a large collection of segmented 3D models. As a result of these design choices, our network effectively encodes multi-scale local context and fine-grained surface detail. Our network can be trained to produce either category-specific descriptors or more generic descriptors by learning from multiple shape categories. Once trained, at test time, the network extracts local descriptors for shapes without requiring any part segmentation as input. Our method can produce effective local descriptors even for shapes whose category is unknown or different from the ones used while training. We demonstrate through several experiments that our learned local descriptors are more discriminative compared to state of the art alternatives, and are effective in a variety of shape analysis applications. version:2
arxiv-1706-04284 | When Image Denoising Meets High-Level Vision Tasks: A Deep Learning Approach | http://arxiv.org/abs/1706.04284 | id:1706.04284 author:Ding Liu, Bihan Wen, Xianming Liu, Thomas S. Huang category:cs.CV  published:2017-06-14 summary:Conventionally, image denoising and high-level vision tasks are handled separately in computer vision, and their connection is fragile. In this paper, we cope with the two jointly and explore the mutual influence between them with the focus on two questions, namely (1) how image denoising can help solving high-level vision problems, and (2) how the semantic information from high-level vision tasks can be used to guide image denoising. First we propose a deep convolutional neural network for image denoising which is able to outperform the state-of-the-art. Second we propose a deep neural network solution that cascades two modules for image denoising and various high-level tasks, respectively, and propose the use of joint loss for updating only the denoising network to allow the semantic information flowing into the optimization of the denoising network via back-propagation. Our experimental results demonstrate that on one hand, the proposed architecture is able to overcome the performance degradation of different high-level vision tasks, e.g., image classification and semantic segmentation, due to image noise or artifacts caused by conventional denoising approaches such as over-smoothing. On the other hand, with the guidance of high-level vision information, the denoising network can further preserve more fine details and generate more visually appealing results. To the best of our knowledge, this is the first work to systematically investigate the benefit of using high-level vision semantics for image denoising via deep learning. version:2
arxiv-1709-01220 | Multi-Modal Multi-Scale Deep Learning for Large-Scale Image Annotation | http://arxiv.org/abs/1709.01220 | id:1709.01220 author:Yulei Niu, Zhiwu Lu, Ji-Rong Wen, Tao Xiang, Shih-Fu Chang category:cs.CV  published:2017-09-05 summary:Large-scale image annotation is a challenging task in image content analysis, which aims to annotate each image of a very large dataset with multiple class labels. In this paper, we focus on two main issues in large-scale image annotation: 1) how to learn stronger features for multifarious images; 2) how to annotate an image with an automatically-determined number of class labels. To address the first issue, we propose a multi-modal multi-scale deep learning model for extracting descriptive features from multifarious images. Specifically, the visual features extracted by a multi-scale deep learning subnetwork are refined with the textual features extracted from social tags along with images by a simple multi-layer perception subnetwork. Since we have extracted very powerful features by multi-modal multi-scale deep learning, we simplify the second issue and decompose large-scale image annotation into multi-class classification and label quantity prediction. Note that the label quantity prediction subproblem can be implicitly solved when a recurrent neural network (RNN) model is used for image annotation. However, in this paper, we choose to explicitly solve this subproblem directly using our deep learning model, resulting in that we can pay more attention to deep feature learning. Experimental results demonstrate the superior performance of our model as compared to the state-of-the-art (including RNN-based models). version:1
arxiv-1709-01888 | Language Modeling by Clustering with Word Embeddings for Text Readability Assessment | http://arxiv.org/abs/1709.01888 | id:1709.01888 author:Miriam Cha, Youngjune Gwon, H. T. Kung category:cs.CL cs.LG  published:2017-09-05 summary:We present a clustering-based language model using word embeddings for text readability prediction. Presumably, an Euclidean semantic space hypothesis holds true for word embeddings whose training is done by observing word co-occurrences. We argue that clustering with word embeddings in the metric space should yield feature representations in a higher semantic space appropriate for text regression. Also, by representing features in terms of histograms, our approach can naturally address documents of varying lengths. An empirical evaluation using the Common Core Standards corpus reveals that the features formed on our clustering-based language model significantly improve the previously known results for the same corpus in readability prediction. We also evaluate the task of sentence matching based on semantic relatedness using the Wiki-SimpleWiki corpus and find that our features lead to superior matching performance. version:1
arxiv-1709-01212 | Multi-View Spectral Clustering via Structured Low-Rank Matrix Factorization | http://arxiv.org/abs/1709.01212 | id:1709.01212 author:Yang Wang, Lin Wu category:cs.CV  published:2017-09-05 summary:Multi-view data clustering attracts more attention than their single view counterparts due to the fact that leveraging multiple independent and complementary information from multi-view feature spaces outperforms the single one. Multi-view Spectral Clustering aims at yielding the data partition agreement over their local manifold structures by seeking eigenvalue-eigenvector decompositions. However, as we observed, such classical paradigm still suffers from (1) overlooking the flexible local manifold structure, caused by (2) enforcing the low-rank data correlation agreement among all views; worse still, (3) LRR is not intuitively flexible to capture the latent data clustering structures. In this paper, we present the structured LRR by factorizing into the latent low-dimensional data-cluster representations, which characterize the data clustering structure for each view. Upon such representation, (b) the laplacian regularizer is imposed to be capable of preserving the flexible local manifold structure for each view. (c) We present an iterative multi-view agreement strategy by minimizing the divergence objective among all factorized latent data-cluster representations during each iteration of optimization process, where such latent representation from each view serves to regulate those from other views, such intuitive process iteratively coordinates all views to be agreeable. (d) We remark that such data-cluster representation can flexibly encode the data clustering structure from any view with adaptive input cluster number. To this end, (e) a novel non-convex objective function is proposed via the efficient alternating minimization strategy. The complexity analysis are also presented. The extensive experiments conducted against the real-world multi-view datasets demonstrate the superiority over state-of-the-arts. version:1
arxiv-1709-01199 | Using $k$-way Co-occurrences for Learning Word Embeddings | http://arxiv.org/abs/1709.01199 | id:1709.01199 author:Danushka Bollegala, Yuichi Yoshida, Ken-ichi Kawarabayashi category:cs.CL  published:2017-09-05 summary:Co-occurrences between two words provide useful insights into the semantics of those words. Consequently, numerous prior work on word embedding learning have used co-occurrences between two words as the training signal for learning word embeddings. However, in natural language texts it is common for multiple words to be related and co-occurring in the same context. We extend the notion of co-occurrences to cover $k(\geq\!\!2)$-way co-occurrences among a set of $k$-words. Specifically, we prove a theoretical relationship between the joint probability of $k(\geq\!\!2)$ words, and the sum of $\ell_2$ norms of their embeddings. Next, we propose a learning objective motivated by our theoretical result that utilises $k$-way co-occurrences for learning word embeddings. Our experimental results show that the derived theoretical relationship does indeed hold empirically, and despite data sparsity, for some smaller $k$ values, $k$-way embeddings perform comparably or better than $2$-way embeddings in a range of tasks. version:1
arxiv-1709-01193 | Compositional Approaches for Representing Relations Between Words: A Comparative Study | http://arxiv.org/abs/1709.01193 | id:1709.01193 author:Huda Hakami, Danushka Bollegala category:cs.CL  published:2017-09-04 summary:Identifying the relations that exist between words (or entities) is important for various natural language processing tasks such as, relational search, noun-modifier classification and analogy detection. A popular approach to represent the relations between a pair of words is to extract the patterns in which the words co-occur with from a corpus, and assign each word-pair a vector of pattern frequencies. Despite the simplicity of this approach, it suffers from data sparseness, information scalability and linguistic creativity as the model is unable to handle previously unseen word pairs in a corpus. In contrast, a compositional approach for representing relations between words overcomes these issues by using the attributes of each individual word to indirectly compose a representation for the common relations that hold between the two words. This study aims to compare different operations for creating relation representations from word-level representations. We investigate the performance of the compositional methods by measuring the relational similarities using several benchmark datasets for word analogy. Moreover, we evaluate the different relation representations in a knowledge base completion task. version:1
arxiv-1709-01189 | Satirical News Detection and Analysis using Attention Mechanism and Linguistic Features | http://arxiv.org/abs/1709.01189 | id:1709.01189 author:Fan Yang, Arjun Mukherjee, Eduard Dragut category:cs.CL  published:2017-09-04 summary:Satirical news is considered to be entertainment, but it is potentially deceptive and harmful. Despite the embedded genre in the article, not everyone can recognize the satirical cues and therefore believe the news as true news. We observe that satirical cues are often reflected in certain paragraphs rather than the whole document. Existing works only consider document-level features to detect the satire, which could be limited. We consider paragraph-level linguistic features to unveil the satire by incorporating neural network and attention mechanism. We investigate the difference between paragraph-level features and document-level features, and analyze them on a large satirical news dataset. The evaluation shows that the proposed model detects satirical news effectively and reveals what features are important at which level. version:1
arxiv-1709-01188 | Storytelling Agents with Personality and Adaptivity | http://arxiv.org/abs/1709.01188 | id:1709.01188 author:Zhichao Hu, Marilyn A. Walker, Michael Neff, Jean E. Fox Tree category:cs.HC cs.CL  published:2017-09-04 summary:We explore the expression of personality and adaptivity through the gestures of virtual agents in a storytelling task. We conduct two experiments using four different dialogic stories. We manipulate agent personality on the extraversion scale, whether the agents adapt to one another in their gestural performance and agent gender. Our results show that subjects are able to perceive the intended variation in extraversion between different virtual agents, independently of the story they are telling and the gender of the agent. A second study shows that subjects also prefer adaptive to nonadaptive virtual agents. version:1
arxiv-1709-01186 | Learning Neural Word Salience Scores | http://arxiv.org/abs/1709.01186 | id:1709.01186 author:Krasen Samardzhiev, Andrew Gargett, Danushka Bollegala category:cs.CL  published:2017-09-04 summary:Measuring the salience of a word is an essential step in numerous NLP tasks. Heuristic approaches such as tfidf have been used so far to estimate the salience of words. We propose \emph{Neural Word Salience} (NWS) scores, unlike heuristics, are learnt from a corpus. Specifically, we learn word salience scores such that, using pre-trained word embeddings as the input, can accurately predict the words that appear in a sentence, given the words that appear in the sentences preceding or succeeding that sentence. Experimental results on sentence similarity prediction show that the learnt word salience scores perform comparably or better than some of the state-of-the-art approaches for representing sentences on benchmark datasets for sentence similarity, while using only a fraction of the training and prediction times required by prior methods. Moreover, our NWS scores positively correlate with psycholinguistic measures such as concreteness, and imageability implying a close connection to the salience as perceived by humans. version:1
arxiv-1709-01182 | Is human face processing a feature- or pattern-based task? Evidence using a unified computational method driven by eye movements | http://arxiv.org/abs/1709.01182 | id:1709.01182 author:Carlos E. Thomaz, Vagner Amaral, Gilson A. Giraldi, Duncan F. Gillies, Daniel Rueckert category:cs.CV  published:2017-09-04 summary:Research on human face processing using eye movements has provided evidence that we recognize face images successfully focusing our visual attention on a few inner facial regions, mainly on the eyes, nose and mouth. To understand how we accomplish this process of coding high-dimensional faces so efficiently, this paper proposes and implements a multivariate extraction method that combines face images variance with human spatial attention maps modeled as feature- and pattern-based information sources. It is based on a unified multidimensional representation of the well-known face-space concept. The spatial attention maps are summary statistics of the eye-tracking fixations of a number of participants and trials to frontal and well-framed face images during separate gender and facial expression recognition tasks. Our experimental results carried out on publicly available face databases have indicated that we might emulate the human extraction system as a pattern-based computational method rather than a feature-based one to properly explain the proficiency of the human system in recognizing visual face information. version:1
arxiv-1709-01180 | A Convergence Analysis for A Class of Practical Variance-Reduction Stochastic Gradient MCMC | http://arxiv.org/abs/1709.01180 | id:1709.01180 author:Changyou Chen, Wenlin Wang, Yizhe Zhang, Qinliang Su, Lawrence Carin category:stat.ML  published:2017-09-04 summary:Stochastic gradient Markov Chain Monte Carlo (SG-MCMC) has been developed as a flexible family of scalable Bayesian sampling algorithms. However, there has been little theoretical analysis of the impact of minibatch size to the algorithm's convergence rate. In this paper, we prove that under a limited computational budget/time, a larger minibatch size leads to a faster decrease of the mean squared error bound (thus the fastest one corresponds to using full gradients), which motivates the necessity of variance reduction in SG-MCMC. Consequently, by borrowing ideas from stochastic optimization, we propose a practical variance-reduction technique for SG-MCMC, that is efficient in both computation and storage. We develop theory to prove that our algorithm induces a faster convergence rate than standard SG-MCMC. A number of large-scale experiments, ranging from Bayesian learning of logistic regression to deep neural networks, validate the theory and demonstrate the superiority of the proposed variance-reduction SG-MCMC framework. version:1
arxiv-1709-01179 | Continuous-Time Flows for Deep Generative Models | http://arxiv.org/abs/1709.01179 | id:1709.01179 author:Changyou Chen, Chunyuan Li, Liqun Chen, Wenlin Wang, Yunchen Pu, Lawrence Carin category:stat.ML  published:2017-09-04 summary:Normalizing flows have been developed recently as a method for drawing samples from an arbitrary distribution. This method is attractive due to its intrinsic ability to approximate a target distribution arbitrarily well. In practice, however, normalizing flows only consist of a finite number of deterministic transformations, and thus there is no guarantees on the approximation accuracy. In this paper we study the problem of learning deep generative models with {\em continuous-time} flows (CTFs), a family of diffusion-based methods that are able to asymptotically approach a target distribution. We discretize the CTF to make training feasible, and develop theory on the approximation error. A framework is then adopted to distill knowledge from a CTF to an efficient inference network. We apply the technique to deep generative models, including a CTF-based variational autoencoder and an adversarial-network-like density estimator. Experiments on various tasks demonstrate the superiority of the proposed CTF framework compared to existing techniques. version:1
arxiv-1708-06238 | Stochastic IMT (insulator-metal-transition) neurons: An interplay of thermal and threshold noise at bifurcation | http://arxiv.org/abs/1708.06238 | id:1708.06238 author:Abhinav Parihar, Matthew Jerry, Suman Datta, Arijit Raychowdhury category:cs.ET cs.NE  published:2017-08-16 summary:A stochastic neuron, a key hardware kernel for implementing stochastic neural networks, is constructed using an insulator-metal-transition (IMT) device based on electrically induced phase-transition in series with a tunable resistance. We show that such an IMT neuron has dynamics similar to a piecewise linear FitzHugh-Nagumo (FHN) neuron. Spiking statistics of such neurons are demonstrated experimentally using Vanadium Dioxide (VO$_{2}$) based IMT neurons, and modeled as an Ornstein-Uhlenbeck (OU) process with a fluctuating boundary. The stochastic spiking is explained by thermal noise and threshold fluctuations acting as precursors of bifurcation which result in a sigmoid-like transfer function. Moments of interspike intervals are calculated analytically by extending the first-passage-time (FPT) models for Ornstein-Uhlenbeck (OU) process to include a fluctuating boundary. We find that the coefficient of variation of interspike intervals depend on the relative proportion of thermal and threshold noise. In the current experimental demonstrations where both kinds of noise are present, the coefficient of variation is about an order of magnitude higher compared to the case where only thermal noise were present. version:3
arxiv-1709-01148 | Link the head to the "beak": Zero Shot Learning from Noisy Text Description at Part Precision | http://arxiv.org/abs/1709.01148 | id:1709.01148 author:Mohamed Elhoseiny, Yizhe Zhu, Han Zhang, Ahmed Elgammal category:cs.CV  published:2017-09-04 summary:In this paper, we study learning visual classifiers from unstructured text descriptions at part precision with no training images. We propose a learning framework that is able to connect text terms to its relevant parts and suppress connections to non-visual text terms without any part-text annotations. For instance, this learning process enables terms like "beak" to be sparsely linked to the visual representation of parts like head, while reduces the effect of non-visual terms like "migrate" on classifier prediction. Images are encoded by a part-based CNN that detect bird parts and learn part-specific representation. Part-based visual classifiers are predicted from text descriptions of unseen visual classifiers to facilitate classification without training images (also known as zero-shot recognition). We performed our experiments on CUBirds 2011 dataset and improves the state-of-the-art text-based zero-shot recognition results from 34.7\% to 43.6\%. We also created large scale benchmarks on North American Bird Images augmented with text descriptions, where we also show that our approach outperforms existing methods. Our code, data, and models are publically available. version:1
arxiv-1709-01147 | Balancing Interpretability and Predictive Accuracy for Unsupervised Tensor Mining | http://arxiv.org/abs/1709.01147 | id:1709.01147 author:Ishmam Zabir, Evangelos E. Papalexakis category:stat.ML cs.LG  published:2017-09-04 summary:The PARAFAC tensor decomposition has enjoyed an increasing success in exploratory multi-aspect data mining scenarios. A major challenge remains the estimation of the number of latent factors (i.e., the rank) of the decomposition, which yields high-quality, interpretable results. Previously, we have proposed an automated tensor mining method which leverages a well-known quality heuristic from the field of Chemometrics, the Core Consistency Diagnostic (CORCONDIA), in order to automatically determine the rank for the PARAFAC decomposition. In this work we set out to explore the trade-off between 1) the interpretability/quality of the results (as expressed by CORCONDIA), and 2) the predictive accuracy of the results, in order to further improve the rank estimation quality. Our preliminary results indicate that striking a good balance in that trade-off benefits rank estimation. version:1
arxiv-1709-01140 | A Multilayer-Based Framework for Online Background Subtraction with Freely Moving Cameras | http://arxiv.org/abs/1709.01140 | id:1709.01140 author:Yizhe Zhu, Ahmed Elgammal category:cs.CV  published:2017-09-04 summary:The exponentially increasing use of moving platforms for video capture introduces the urgent need to develop the general background subtraction algorithms with the capability to deal with the moving background. In this paper, we propose a multilayer-based framework for online background subtraction for videos captured by moving cameras. Unlike the previous treatments of the problem, the proposed method is not restricted to binary segmentation of background and foreground, but formulates it as a multi-label segmentation problem by modeling multiple foreground objects in different layers when they appear simultaneously in the scene. We assign an independent processing layer to each foreground object, as well as the background, where both motion and appearance models are estimated, and a probability map is inferred using a Bayesian filtering framework. Finally, Multi-label Graph-cut on Markov Random Field is employed to perform pixel-wise labeling. Extensive evaluation results show that the proposed method outperforms state-of-the-art methods on challenging video sequences. version:1
arxiv-1709-01134 | WRPN: Wide Reduced-Precision Networks | http://arxiv.org/abs/1709.01134 | id:1709.01134 author:Asit Mishra, Eriko Nurvitadhi, Jeffrey J Cook, Debbie Marr category:cs.CV cs.LG cs.NE  published:2017-09-04 summary:For computer vision applications, prior works have shown the efficacy of reducing numeric precision of model parameters (network weights) in deep neural networks. Activation maps, however, occupy a large memory footprint during both the training and inference step when using mini-batches of inputs. One way to reduce this large memory footprint is to reduce the precision of activations. However, past works have shown that reducing the precision of activations hurts model accuracy. We study schemes to train networks from scratch using reduced-precision activations without hurting accuracy. We reduce the precision of activation maps (along with model parameters) and increase the number of filter maps in a layer, and find that this scheme matches or surpasses the accuracy of the baseline full-precision network. As a result, one can significantly improve the execution efficiency (e.g. reduce dynamic memory footprint, memory bandwidth and computational energy) and speed up the training and inference process with appropriate hardware support. We call our scheme WRPN - wide reduced-precision networks. We report results and show that WRPN scheme is better than previously reported accuracies on ILSVRC-12 dataset while being computationally less expensive compared to previously reported reduced-precision networks. version:1
arxiv-1708-08755 | Multi-task Neural Networks for Personalized Pain Recognition from Physiological Signals | http://arxiv.org/abs/1708.08755 | id:1708.08755 author:Daniel Lopez-Martinez, Rosalind Picard category:cs.CY cs.LG q-bio.NC  published:2017-08-17 summary:Pain is a complex and subjective experience that poses a number of measurement challenges. While self-report by the patient is viewed as the gold standard of pain assessment, this approach fails when patients cannot verbally communicate pain intensity or lack normal mental abilities. Here, we present a pain intensity measurement method based on physiological signals. Specifically, we implement a multi-task learning approach based on neural networks that accounts for individual differences in pain responses while still leveraging data from across the population. We test our method in a dataset containing multi-modal physiological responses to nociceptive pain. version:2
arxiv-1709-01121 | Learning to parse from a semantic objective: It works. Is it syntax? | http://arxiv.org/abs/1709.01121 | id:1709.01121 author:Adina Williams, Andrew Drozdov, Samuel R. Bowman category:cs.CL  published:2017-09-04 summary:Recent work on reinforcement learning and other gradient estimators for latent tree learning has made it possible to train neural networks that learn to both parse a sentence and use the resulting parse to interpret the sentence, all without exposure to ground-truth parse trees at training time. Surprisingly, these models often perform better at sentence understanding tasks than models that use parse trees from conventional parsers. This paper aims to investigate what these latent tree learning models learn. We replicate two such models in a shared codebase and find that (i) they do outperform baselines on sentence classification, but that (ii) their parsing strategies are not especially consistent across random restarts, (iii) the parses they produce tend to be shallower than PTB parses, and (iv) these do not resemble those of PTB or of any other recognizable semantic or syntactic grammar formalism. version:1
arxiv-1709-01118 | WESPE: Weakly Supervised Photo Enhancer for Digital Cameras | http://arxiv.org/abs/1709.01118 | id:1709.01118 author:Andrey Ignatov, Nikolay Kobyshev, Radu Timofte, Kenneth Vanhoey, Luc Van Gool category:cs.CV  published:2017-09-04 summary:Low-end and compact mobile cameras demonstrate limited photo quality mainly due to space, hardware and budget constraints. In this work, we propose a deep learning solution that translates photos taken by cameras with limited capabilities into DSLR-quality photos automatically. We tackle this problem by introducing a weakly supervised photo enhancer (WESPE) - a novel image-to-image Generative Adversarial Network-based architecture. The proposed model is trained by weakly supervised learning: unlike previous works, there is no need for strong supervision in the form of a large annotated dataset of aligned original/enhanced photo pairs. The sole requirement is two distinct datasets: one from the source camera, and one composed of arbitrary high-quality images that can be generally crawled from the Internet - the visual content they exhibit may be unrelated. Hence, our solution is repeatable for any camera: collecting the data and training can be achieved in a couple of hours. Our experiments on the DPED, Kitti and Cityscapes datasets as well as pictures from several generations of smartphones demonstrate that WESPE produces comparable qualitative results with state-of-the-art strongly supervised methods, while not requiring the tedious work to obtain aligned datasets. version:1
arxiv-1709-01058 | A Unified Query-based Generative Model for Question Generation and Question Answering | http://arxiv.org/abs/1709.01058 | id:1709.01058 author:Linfeng Song, Zhiguo Wang, Wael Hamza category:cs.CL  published:2017-09-04 summary:We propose a query-based generative model for solving both tasks of question generation (QG) and question an- swering (QA). The model follows the classic encoder- decoder framework. The encoder takes a passage and a query as input then performs query understanding by matching the query with the passage from multiple per- spectives. The decoder is an attention-based Long Short Term Memory (LSTM) model with copy and coverage mechanisms. In the QG task, a question is generated from the system given the passage and the target answer, whereas in the QA task, the answer is generated given the question and the passage. During the training stage, we leverage a policy-gradient reinforcement learning algorithm to overcome exposure bias, a major prob- lem resulted from sequence learning with cross-entropy loss. For the QG task, our experiments show higher per- formances than the state-of-the-art results. When used as additional training data, the automatically generated questions even improve the performance of a strong ex- tractive QA system. In addition, our model shows bet- ter performance than the state-of-the-art baselines of the generative QA task. version:1
arxiv-1707-01018 | LED-based Photometric Stereo: Modeling, Calibration and Numerical Solution | http://arxiv.org/abs/1707.01018 | id:1707.01018 author:Yvain Quéau, Bastien Durix, Tao Wu, Daniel Cremers, François Lauze, Jean-Denis Durou category:cs.CV  published:2017-07-04 summary:We conduct a thorough study of photometric stereo under nearby point light source illumination, from modeling to numerical solution, through calibration. In the classical formulation of photometric stereo, the luminous fluxes are assumed to be directional, which is very difficult to achieve in practice. Rather, we use light-emitting diodes (LEDs) to illuminate the scene to reconstruct. Such point light sources are very convenient to use, yet they yield a more complex photometric stereo model which is arduous to solve. We first derive in a physically sound manner this model, and show how to calibrate its parameters. Then, we discuss two state-of-the-art numerical solutions. The first one alternatingly estimates the albedo and the normals, and then integrates the normals into a depth map. It is shown empirically to be independent from the initialization, but convergence of this sequential approach is not established. The second one directly recovers the depth, by formulating photometric stereo as a system of PDEs which are partially linearized using image ratios. Although the sequential approach is avoided, initialization matters a lot and convergence is not established either. Therefore, we introduce a provably convergent alternating reweighted least-squares scheme for solving the original system of PDEs, without resorting to image ratios for linearization. Finally, we extend this study to the case of RGB images. version:2
arxiv-1709-01077 | A Nonparametric Model for Multimodal Collaborative Activities Summarization | http://arxiv.org/abs/1709.01077 | id:1709.01077 author:Guy Rosman, John W. Fisher III, Daniela Rus category:cs.CV  published:2017-09-04 summary:Ego-centric data streams provide a unique opportunity to reason about joint behavior by pooling data across individuals. This is especially evident in urban environments teeming with human activities, but which suffer from incomplete and noisy data. Collaborative human activities exhibit common spatial, temporal, and visual characteristics facilitating inference across individuals from multiple sensory modalities as we explore in this paper from the perspective of meetings. We propose a new Bayesian nonparametric model that enables us to efficiently pool video and GPS data towards collaborative activities analysis from multiple individuals. We demonstrate the utility of this model for inference tasks such as activity detection, classification, and summarization. We further demonstrate how spatio-temporal structure embedded in our model enables better understanding of partial and noisy observations such as localization and face detections based on social interactions. We show results on both synthetic experiments and a new dataset of egocentric video and noisy GPS data from multiple individuals. version:1
arxiv-1709-01042 | Getting Reliable Annotations for Sarcasm in Online Dialogues | http://arxiv.org/abs/1709.01042 | id:1709.01042 author:Reid Swanson, Stephanie Lukin, Luke Eisenberg, Thomas Chase Corcoran, Marilyn A. Walker category:cs.CL  published:2017-09-04 summary:The language used in online forums differs in many ways from that of traditional language resources such as news. One difference is the use and frequency of nonliteral, subjective dialogue acts such as sarcasm. Whether the aim is to develop a theory of sarcasm in dialogue, or engineer automatic methods for reliably detecting sarcasm, a major challenge is simply the difficulty of getting enough reliably labelled examples. In this paper we describe our work on methods for achieving highly reliable sarcasm annotations from untrained annotators on Mechanical Turk. We explore the use of a number of common statistical reliability measures, such as Kappa, Karger's, Majority Class, and EM. We show that more sophisticated measures do not appear to yield better results for our data than simple measures such as assuming that the correct label is the one that a majority of Turkers apply. version:1
arxiv-1708-05980 | Attentive Semantic Video Generation using Captions | http://arxiv.org/abs/1708.05980 | id:1708.05980 author:Tanya Marwah, Gaurav Mittal, Vineeth N. Balasubramanian category:cs.CV  published:2017-08-20 summary:This paper proposes a network architecture to perform variable length semantic video generation using captions. We adopt a new perspective towards video generation where we allow the captions to be combined with the long-term and short-term dependencies between video frames and thus generate a video in an incremental manner. Our experiments demonstrate our network architecture's ability to distinguish between objects, actions and interactions in a video and combine them to generate videos for unseen captions. The network also exhibits the capability to perform spatio-temporal style transfer when asked to generate videos for a sequence of captions. We also show that the network's ability to learn a latent representation allows it generate videos in an unsupervised manner and perform other tasks such as action recognition. version:2
arxiv-1709-00300 | Telepath: Understanding Users from a Human Vision Perspective in Large-Scale Recommender Systems | http://arxiv.org/abs/1709.00300 | id:1709.00300 author:Yu Wang, Jixing Xu, Aohan Wu, Mantian Li, Yang He, Jinghe Hu, Weipeng P. Yan category:cs.IR cs.CV cs.LG  published:2017-09-01 summary:Designing an e-commerce recommender system that serves hundreds of millions of active users is a daunting challenge. From a human vision perspective, there're two key factors that affect users' behaviors: items' attractiveness and their matching degree with users' interests. This paper proposes Telepath, a vision-based bionic recommender system model, which understands users from such perspective. Telepath is a combination of a convolutional neural network (CNN), a recurrent neural network (RNN) and deep neural networks (DNNs). Its CNN subnetwork simulates the human vision system to extract key visual signals of items' attractiveness and generate corresponding activations. Its RNN and DNN subnetworks simulate cerebral cortex to understand users' interest based on the activations generated from browsed items. In practice, the Telepath model has been launched to JD's recommender system and advertising system. For one of the major item recommendation blocks on the JD app, click-through rate (CTR), gross merchandise value (GMV) and orders have increased 1.59%, 8.16% and 8.71% respectively. For several major ads publishers of JD demand-side platform, CTR, GMV and return on investment have increased 6.58%, 61.72% and 65.57% respectively by the first launch, and further increased 2.95%, 41.75% and 41.37% respectively by the second launch. version:2
arxiv-1709-01076 | Learning mutational graphs of individual tumor evolution from multi-sample sequencing data | http://arxiv.org/abs/1709.01076 | id:1709.01076 author:Daniele Ramazzotti, Alex Graudenzi, Luca De Sano, Marco Antoniotti, Giulio Caravagna category:q-bio.GN cs.LG  published:2017-09-04 summary:Phylogenetic techniques quantify intra-tumor heterogeneity by deconvolving either clonal or mutational trees from multi-sample sequencing data of individual tumors. Most of these methods rely on the well-known infinite sites assumption, and are limited to process either multi-region or single-cell sequencing data. Here, we improve over those methods with TRaIT, a unified statistical framework for the inference of the accumula- tion order of multiple types of genomic alterations driving tumor development. TRaIT supports both multi-region and single-cell sequencing data, and output mutational graphs accounting for violations of the infinite sites assumption due to convergent evolution, and other complex phenomena that cannot be detected with phylogenetic tools. Our method displays better accuracy, performance and robustness to noise and small sample size than state-of-the-art phylogenetic methods. We show with single-cell data from breast cancer and multi-region data from colorectal cancer that TRaIT can quantify the extent of intra-tumor heterogeneity and generate new testable experimental hypotheses. version:1
arxiv-1709-01006 | Learning Implicit Generative Models Using Differentiable Graph Tests | http://arxiv.org/abs/1709.01006 | id:1709.01006 author:Josip Djolonga, Andreas Krause category:stat.ML cs.LG  published:2017-09-04 summary:Recently, there has been a growing interest in the problem of learning rich implicit models - those from which we can sample, but can not evaluate their density. These models apply some parametric function, such as a deep network, to a base measure, and are learned end-to-end using stochastic optimization. One strategy of devising a loss function is through the statistics of two sample tests - if we can fool a statistical test, the learned distribution should be a good model of the true data. However, not all tests can easily fit into this framework, as they might not be differentiable with respect to the data points, and hence with respect to the parameters of the implicit model. Motivated by this problem, in this paper we show how two such classical tests, the Friedman-Rafsky and k-nearest neighbour tests, can be effectively smoothed using ideas from undirected graphical models - the matrix tree theorem and cardinality potentials. Moreover, as we show experimentally, smoothing can significantly increase the power of the test, which might of of independent interest. Finally, we apply our method to learn implicit models. version:1
arxiv-1709-02252 | A Geometric Approach to Harmonic Color Palette Design | http://arxiv.org/abs/1709.02252 | id:1709.02252 author:Carlos Lara-Alvarez, Tania Reyes category:cs.CV  published:2017-09-04 summary:We address the problem of finding harmonic colors, this problem has many applications, from fashion to industrial design. In order to solve this problem we consider that colors follow normal distributions in tone (chroma and lightness) and hue. The proposed approach relies in the CIE standard for representing colors and evaluate proximity. Other approaches to this problem use a set of rules. Experimental results show that lines with specific parameters angles of inclination, and distance from the reference point are preferred over others, and that uncertain line patterns outperform non-linear patterns. version:1
arxiv-1709-00966 | Towards Around-Device Interaction using Corneal Imaging | http://arxiv.org/abs/1709.00966 | id:1709.00966 author:Daniel Schneider, Jens Grubert category:cs.HC cs.CV H.5.2  published:2017-09-04 summary:Around-device interaction techniques aim at extending the input space using various sensing modalities on mobile and wearable devices. In this paper, we present our work towards extending the input area of mobile devices using front-facing device-centered cameras that capture reflections in the human eye. As current generation mobile devices lack high resolution front-facing cameras we study the feasibility of around-device interaction using corneal reflective imaging based on a high resolution camera. We present a workflow, a technical prototype and an evaluation, including a migration path from high resolution to low resolution imagers. Our study indicates, that under optimal conditions a spatial sensing resolution of 5 cm in the vicinity of a mobile phone is possible. version:1
arxiv-1709-00965 | Feasibility of Corneal Imaging for Handheld Augmented Reality | http://arxiv.org/abs/1709.00965 | id:1709.00965 author:Daniel Schneider, Jens Grubert category:cs.HC cs.CV  published:2017-09-04 summary:Smartphones are a popular device class for mobile Augmented Reality but suffer from a limited input space. Around-device interaction techniques aim at extending this input space using various sensing modalities. In this paper we present our work towards extending the input area of mobile devices using front-facing device-centered cameras that capture reflections in the cornea. As current generation mobile devices lack high resolution front-facing cameras, we study the feasibility of around-device interaction using corneal reflective imaging based on a high resolution camera. We present a workflow, a technical prototype and a feasibility evaluation. version:1
arxiv-1709-00962 | A Reproducible Study on Remote Heart Rate Measurement | http://arxiv.org/abs/1709.00962 | id:1709.00962 author:Guillaume Heusch, André Anjos, Sébastien Marcel category:cs.CV  published:2017-09-04 summary:This paper studies the problem of reproducible research in remote photoplethysmography (rPPG). Most of the work published in this domain is assessed on privately-owned databases, making it difficult to evaluate proposed algorithms in a standard and principled manner. As a consequence, we present a new, publicly available database containing a relatively large number of subjects recorded under two different lighting conditions. Also, three state-of-the-art rPPG algorithms from the literature were selected, implemented and released as open source free software. After a thorough, unbiased experimental evaluation in various settings, it is shown that none of the selected algorithms is precise enough to be used in a real-world scenario. version:1
arxiv-1709-04495 | The inverse Ising problem in continuous time: A latent variable approach | http://arxiv.org/abs/1709.04495 | id:1709.04495 author:Christian Donner, Manfred Opper category:stat.ML physics.data-an 82C20  62F15  92C42  published:2017-09-04 summary:We consider the inverse Ising problem, i.e. the inference of network couplings from observed spin trajectories for a model with continuous time Glauber dynamics. By introducing two sets of auxiliary latent random variables we render the likelihood into a form, which allows for simple iterative inference algorithms with analytical updates. The variables are: (1) Poisson variables to linearise an exponential term which is typical for point process likelihoods. (2) P\'olya-Gamma variables, which make the likelihood quadratic in the coupling parameters. Using the augmented likelihood, we derive an Expectation-Maximization (EM) algorithm to obtain the maximum likelihood estimate (MLE) of network parameters. Using a third set of latent variables we extend the EM algorithm to sparse couplings via L1-regularization. Finally, we develop an efficient approximate Bayesian inference algorithm using a variational approach. We demonstrate the performance of our algorithms on data simulated from an Ising model. For data which are simulated from a more biologically plausible network with spiking neurons, we show that the Ising model captures well the low order statistics of the data and how the Ising couplings are related to the underlying synaptic structure of the simulated network. version:1
arxiv-1709-00947 | Learning Word Embeddings from the Portuguese Twitter Stream: A Study of some Practical Aspects | http://arxiv.org/abs/1709.00947 | id:1709.00947 author:Pedro Saleiro, Luís Sarmento, Eduarda Mendes Rodrigues, Carlos Soares, Eugénio Oliveira category:cs.CL cs.LG  published:2017-09-04 summary:This paper describes a preliminary study for producing and distributing a large-scale database of embeddings from the Portuguese Twitter stream. We start by experimenting with a relatively small sample and focusing on three challenges: volume of training data, vocabulary size and intrinsic evaluation metrics. Using a single GPU, we were able to scale up vocabulary size from 2048 words embedded and 500K training examples to 32768 words over 10M training examples while keeping a stable validation loss and approximately linear trend on training time per epoch. We also observed that using less than 50\% of the available training examples for each vocabulary size might result in overfitting. Results on intrinsic evaluation show promising performance for a vocabulary size of 32768 words. Nevertheless, intrinsic evaluation metrics suffer from over-sensitivity to their corresponding cosine similarity thresholds, indicating that a wider range of metrics need to be developed to track progress. version:1
arxiv-1709-00938 | ARIGAN: Synthetic Arabidopsis Plants using Generative Adversarial Network | http://arxiv.org/abs/1709.00938 | id:1709.00938 author:Mario Valerio Giuffrida, Hanno Scharr, Sotirios A Tsaftaris category:cs.CV  published:2017-09-04 summary:In recent years, there has been an increasing interest in image-based plant phenotyping, applying state-of-the-art machine learning approaches to tackle challenging problems, such as leaf segmentation (a multi-instance problem) and counting. Most of these algorithms need labelled data to learn a model for the task at hand. Despite the recent release of a few plant phenotyping datasets, large annotated plant image datasets for the purpose of training deep learning algorithms are lacking. One common approach to alleviate the lack of training data is dataset augmentation. Herein, we propose an alternative solution to dataset augmentation for plant phenotyping, creating artificial images of plants using generative neural networks. We propose the Arabidopsis Rosette Image Generator (through) Adversarial Network: a deep convolutional network that is able to generate synthetic rosette-shaped plants, inspired by DCGAN (a recent adversarial network model using convolutional layers). Specifically, we trained the network using A1, A2, and A4 of the CVPPP 2017 LCC dataset, containing Arabidopsis Thaliana plants. We show that our model is able to generate realistic 128x128 colour images of plants. We train our network conditioning on leaf count, such that it is possible to generate plants with a given number of leaves suitable, among others, for training regression based models. We propose a new Ax dataset of artificial plants images, obtained by our ARIGAN. We evaluate this new dataset using a state-of-the-art leaf counting algorithm, showing that the testing error is reduced when Ax is used as part of the training data. version:1
arxiv-1709-00930 | Self-Supervised Learning for Stereo Matching with Self-Improving Ability | http://arxiv.org/abs/1709.00930 | id:1709.00930 author:Yiran Zhong, Yuchao Dai, Hongdong Li category:cs.CV  published:2017-09-04 summary:Exiting deep-learning based dense stereo matching methods often rely on ground-truth disparity maps as the training signals, which are however not always available in many situations. In this paper, we design a simple convolutional neural network architecture that is able to learn to compute dense disparity maps directly from the stereo inputs. Training is performed in an end-to-end fashion without the need of ground-truth disparity maps. The idea is to use image warping error (instead of disparity-map residuals) as the loss function to drive the learning process, aiming to find a depth-map that minimizes the warping error. While this is a simple concept well-known in stereo matching, to make it work in a deep-learning framework, many non-trivial challenges must be overcome, and in this work we provide effective solutions. Our network is self-adaptive to different unseen imageries as well as to different camera settings. Experiments on KITTI and Middlebury stereo benchmark datasets show that our method outperforms many state-of-the-art stereo matching methods with a margin, and at the same time significantly faster. version:1
arxiv-1709-00917 | Using Optimal Ratio Mask as Training Target for Supervised Speech Separation | http://arxiv.org/abs/1709.00917 | id:1709.00917 author:Shasha Xia, Hao Li, Xueliang Zhang category:cs.SD cs.CL  published:2017-09-04 summary:Supervised speech separation uses supervised learning algorithms to learn a mapping from an input noisy signal to an output target. With the fast development of deep learning, supervised separation has become the most important direction in speech separation area in recent years. For the supervised algorithm, training target has a significant impact on the performance. Ideal ratio mask is a commonly used training target, which can improve the speech intelligibility and quality of the separated speech. However, it does not take into account the correlation between noise and clean speech. In this paper, we use the optimal ratio mask as the training target of the deep neural network (DNN) for speech separation. The experiments are carried out under various noise environments and signal to noise ratio (SNR) conditions. The results show that the optimal ratio mask outperforms other training targets in general. version:1
arxiv-1709-00911 | Neural Networks for Safety-Critical Applications - Challenges, Experiments and Perspectives | http://arxiv.org/abs/1709.00911 | id:1709.00911 author:Chih-Hong Cheng, Frederik Diehl, Yassine Hamza, Gereon Hinz, Georg Nührenberg, Markus Rickert, Harald Ruess, Michael Troung-Le category:cs.SE cs.LG  published:2017-09-04 summary:We propose a methodology for designing dependable Artificial Neural Networks (ANN) by extending the concepts of understandability, correctness, and validity that are crucial ingredients in existing certification standards. We apply the concept in a concrete case study in designing a high-way ANN-based motion predictor to guarantee safety properties such as impossibility for the ego vehicle to suggest moving to the right lane if there exists another vehicle on its right. version:1
arxiv-1709-02251 | Multi-modal Conditional Attention Fusion for Dimensional Emotion Prediction | http://arxiv.org/abs/1709.02251 | id:1709.02251 author:Shizhe Chen, Qin Jin category:cs.CV cs.LG cs.MM  published:2017-09-04 summary:Continuous dimensional emotion prediction is a challenging task where the fusion of various modalities usually achieves state-of-the-art performance such as early fusion or late fusion. In this paper, we propose a novel multi-modal fusion strategy named conditional attention fusion, which can dynamically pay attention to different modalities at each time step. Long-short term memory recurrent neural networks (LSTM-RNN) is applied as the basic uni-modality model to capture long time dependencies. The weights assigned to different modalities are automatically decided by the current input features and recent history information rather than being fixed at any kinds of situation. Our experimental results on a benchmark dataset AVEC2015 show the effectiveness of our method which outperforms several common fusion strategies for valence prediction. version:1
arxiv-1709-00907 | CSSTag: Optical Nanoscale Radar and Particle Tracking for In-Body and Microfluidic Systems with Vibrating Graphene and Resonance Energy Transfer | http://arxiv.org/abs/1709.00907 | id:1709.00907 author:Burhan Gulbahar, Gorkem Memisoglu category:q-bio.QM cs.CV  published:2017-09-04 summary:Single particle tracking systems monitor cellular processes with great accuracy in nano-biological systems. The emissions of the fluorescent molecules are detected with cameras or photodetectors. However, state-of-the-art imaging systems have challenges in the detection capability, collection and analysis of imaging data, penetration depth and complicated set-ups. In this article, a \textit{signaling based nanoscale acousto-optic radar and microfluidic particle tracking system} is proposed based on the theoretical design providing nanoscale optical modulator with vibrating F{\"{o}}rster resonance energy transfer (VFRET) and vibrating CdSe/ZnS quantum dots (QDs) on graphene resonators. The modulator structure combines the significant advantages of graphene membranes having wideband resonance frequencies with QDs having broad absorption spectrum and tunable properties. The solution denoted by chirp spread spectrum (CSS) Tag (\textit{CSSTag}) utilizes classical radar target tracking approaches in nanoscale environments based on the capability to generate CSS sequences to identify different bio-particles. Numerical and Monte-Carlo simulations are realized showing the significant performance for multiple particle tracking (MPT) with a modulator of $10 \, \mu$m $\times$ $10 \, \mu$m $\times$ $10 \, \mu$m dimension and several picograms of weight, signal to noise ratio (SNR) in the range $-7$ dB to $10$ dB and high speed tracking capability for microfluidic and in-body environments. version:1
arxiv-1708-09666 | Generating Video Descriptions with Topic Guidance | http://arxiv.org/abs/1708.09666 | id:1708.09666 author:Shizhe Chen, Jia Chen, Qin Jin category:cs.CV cs.CL  published:2017-08-31 summary:Generating video descriptions in natural language (a.k.a. video captioning) is a more challenging task than image captioning as the videos are intrinsically more complicated than images in two aspects. First, videos cover a broader range of topics, such as news, music, sports and so on. Second, multiple topics could coexist in the same video. In this paper, we propose a novel caption model, topic-guided model (TGM), to generate topic-oriented descriptions for videos in the wild via exploiting topic information. In addition to predefined topics, i.e., category tags crawled from the web, we also mine topics in a data-driven way based on training captions by an unsupervised topic mining model. We show that data-driven topics reflect a better topic schema than the predefined topics. As for testing video topic prediction, we treat the topic mining model as teacher to train the student, the topic prediction model, by utilizing the full multi-modalities in the video especially the speech modality. We propose a series of caption models to exploit topic guidance, including implicitly using the topics as input features to generate words related to the topic and explicitly modifying the weights in the decoder with topics to function as an ensemble of topic-aware language decoders. Our comprehensive experimental results on the current largest video caption dataset MSR-VTT prove the effectiveness of our topic-guided model, which significantly surpasses the winning performance in the 2016 MSR video to language challenge. version:2
arxiv-1709-00890 | Theoretical Analysis of Stochastic Search Algorithms | http://arxiv.org/abs/1709.00890 | id:1709.00890 author:Per Kristian Lehre, Pietro S. Oliveto category:cs.NE  published:2017-09-04 summary:Theoretical analyses of stochastic search algorithms, albeit few, have always existed since these algorithms became popular. Starting in the nineties a systematic approach to analyse the performance of stochastic search heuristics has been put in place. This quickly increasing basis of results allows, nowadays, the analysis of sophisticated algorithms such as population-based evolutionary algorithms, ant colony optimisation and artificial immune systems. Results are available concerning problems from various domains including classical combinatorial and continuous optimisation, single and multi-objective optimisation, and noisy and dynamic optimisation. This chapter introduces the mathematical techniques that are most commonly used in the runtime analysis of stochastic search heuristics. Careful attention is given to the very popular artificial fitness levels and drift analyses techniques for which several variants are presented. To aid the reader's comprehension of the presented mathematical methods, these are applied to the analysis of simple evolutionary algorithms for artificial example functions. The chapter is concluded by providing references to more complex applications and further extensions of the techniques for the obtainment of advanced results. version:1
arxiv-1709-02250 | Medical Image Analysis using Convolutional Neural Networks: A Review | http://arxiv.org/abs/1709.02250 | id:1709.02250 author:Adnan Qayyum, Syed Muhammad Anwar, Muhammad Majid, Muhammad Awais, Majdi Alnowami category:cs.CV  published:2017-09-04 summary:Medical image analysis is the science of analyzing or solving medical problems using different image analysis techniques for affective and efficient extraction of information. It has emerged as one of the top research area in the field of engineering and medicine. Recent years have witnessed rapid use of machine learning algorithms in medical image analysis. These machine learning techniques are used to extract compact information for improved performance of medical image analysis system, when compared to the traditional methods that use extraction of handcrafted features. Deep learning is a breakthrough in machine learning techniques that has overwhelmed the field of pattern recognition and computer vision research by providing state-of-the-art results. Deep learning provides different machine learning algorithms that model high level data abstractions and do not rely on handcrafted features. Recently, deep learning methods utilizing deep convolutional neural networks have been applied to medical image analysis providing promising results. The application area covers the whole spectrum of medical image analysis including detection, segmentation, classification, and computer aided diagnosis. This paper presents a review of the state-of-the-art convolutional neural network based techniques used for medical image analysis. version:1
arxiv-1709-00848 | Neural Distributed Autoassociative Memories: A Survey | http://arxiv.org/abs/1709.00848 | id:1709.00848 author:V. I. Gritsenko, D. A. Rachkovskij, A. A. Frolov, R. Gayler, D. Kleyko, E. Osipov category:cs.NE  published:2017-09-04 summary:Introduction. Neural network models of autoassociative, distributed memory allow storage and retrieval of many items (vectors) where the number of stored items can exceed the vector dimension (the number of neurons in the network). This opens the possibility of a sublinear time search (in the number of stored items) for approximate nearest neighbors among vectors of high dimension. The purpose of this paper is to review models of autoassociative, distributed memory that can be naturally implemented by neural networks (mainly with local learning rules and iterative dynamics based on information locally available to neurons). Scope. The survey is focused mainly on the networks of Hopfield, Willshaw and Potts, that have connections between pairs of neurons and operate on sparse binary vectors. We discuss not only autoassociative memory, but also the generalization properties of these networks. We also consider neural networks with higher-order connections and networks with a bipartite graph structure for non-binary data with linear constraints. Conclusions. In conclusion we discuss the relations to similarity search, advantages and drawbacks of these techniques, and topics for further research. An interesting and still not completely resolved question is whether neural autoassociative memories can search for approximate nearest neighbors faster than other index structures for similarity search, in particular for the case of very high dimensional vectors. version:1
arxiv-1709-00845 | Semi-supervised Learning with Deep Generative Models for Asset Failure Prediction | http://arxiv.org/abs/1709.00845 | id:1709.00845 author:Andre S. Yoon, Taehoon Lee, Yongsub Lim, Deokwoo Jung, Philgyun Kang, Dongwon Kim, Keuntae Park, Yongjin Choi category:cs.LG I.2.6; H.2.8  published:2017-09-04 summary:This work presents a novel semi-supervised learning approach for data-driven modeling of asset failures when health status is only partially known in historical data. We combine a generative model parameterized by deep neural networks with non-linear embedding technique. It allows us to build prognostic models with the limited amount of health status information for the precise prediction of future asset reliability. The proposed method is evaluated on a publicly available dataset for remaining useful life (RUL) estimation, which shows significant improvement even when a fraction of the data with known health status is as sparse as 1% of the total. Our study suggests that the non-linear embedding based on a deep generative model can efficiently regularize a complex model with deep architectures while achieving high prediction accuracy that is far less sensitive to the availability of health status information. version:1
arxiv-1709-00843 | Extending the small-ball method | http://arxiv.org/abs/1709.00843 | id:1709.00843 author:Shahar Mendelson category:stat.ML  published:2017-09-04 summary:The small-ball method was introduced as a way of obtaining a high probability, isomorphic lower bound on the quadratic empirical process, under weak assumptions on the indexing class. The key assumption was that class members satisfy a uniform small-ball estimate, that is, $Pr( f \geq \kappa\ f\ _{L_2}) \geq \delta$ for given constants $\kappa$ and $\delta$. Here we extend the small-ball method and obtain a high probability, almost-isometric (rather than isomorphic) lower bound on the quadratic empirical process. The scope of the result is considerably wider than the small-ball method: there is no need for class members to satisfy a uniform small-ball condition, and moreover, motivated by the notion of tournament learning procedures, the result is stable under a `majority vote'. As applications, we study the performance of empirical risk minimization in learning problems involving bounded subsets of $L_p$ that satisfy a Bernstein condition, and of the tournament procedure in problems involving bounded subsets of $L_\infty$. version:1
arxiv-1709-00835 | Hyperspectral Light Field Stereo Matching | http://arxiv.org/abs/1709.00835 | id:1709.00835 author:Kang Zhu, Yujia Xue, Qiang Fu, Sing Bing Kang, Xilin Chen, Jingyi Yu category:cs.CV  published:2017-09-04 summary:In this paper, we describe how scene depth can be extracted using a hyperspectral light field capture (H-LF) system. Our H-LF system consists of a 5 x 6 array of cameras, with each camera sampling a different narrow band in the visible spectrum. There are two parts to extracting scene depth. The first part is our novel cross-spectral pairwise matching technique, which involves a new spectral-invariant feature descriptor and its companion matching metric we call bidirectional weighted normalized cross correlation (BWNCC). The second part, namely, H-LF stereo matching, uses a combination of spectral-dependent correspondence and defocus cues that rely on BWNCC. These two new cost terms are integrated into a Markov Random Field (MRF) for disparity estimation. Experiments on synthetic and real H-LF data show that our approach can produce high-quality disparity maps. We also show that these results can be used to produce the complete plenoptic cube in addition to synthesizing all-focus and defocused color images under different sensor spectral responses. version:1
arxiv-1709-00831 | Hypothesis Testing based Intrinsic Evaluation of Word Embeddings | http://arxiv.org/abs/1709.00831 | id:1709.00831 author:Nishant Gurnani category:cs.CL  published:2017-09-04 summary:We introduce the cross-match test - an exact, distribution free, high-dimensional hypothesis test as an intrinsic evaluation metric for word embeddings. We show that cross-match is an effective means of measuring distributional similarity between different vector representations and of evaluating the statistical significance of different vector embedding models. Additionally, we find that cross-match can be used to provide a quantitative measure of linguistic similarity for selecting bridge languages for machine translation. We demonstrate that the results of the hypothesis test align with our expectations and note that the framework of two sample hypothesis testing is not limited to word embeddings and can be extended to all vector representations. version:1
arxiv-1709-00813 | From Review to Rating: Exploring Dependency Measures for Text Classification | http://arxiv.org/abs/1709.00813 | id:1709.00813 author:Samuel Cunningham-Nelson, Mahsa Baktashmotlagh, Wageeh Boles category:cs.CL  published:2017-09-04 summary:Various text analysis techniques exist, which attempt to uncover unstructured information from text. In this work, we explore using statistical dependence measures for textual classification, representing text as word vectors. Student satisfaction scores on a 3-point scale and their free text comments written about university subjects are used as the dataset. We have compared two textual representations: a frequency word representation and term frequency relationship to word vectors, and found that word vectors provide a greater accuracy. However, these word vectors have a large number of features which aggravates the burden of computational complexity. Thus, we explored using a non-linear dependency measure for feature selection by maximizing the dependence between the text reviews and corresponding scores. Our quantitative and qualitative analysis on a student satisfaction dataset shows that our approach achieves comparable accuracy to the full feature vector, while being an order of magnitude faster in testing. These text analysis and feature reduction techniques can be used for other textual data applications such as sentiment analysis. version:1
arxiv-1709-00799 | Non-rigid image registration using fully convolutional networks with deep self-supervision | http://arxiv.org/abs/1709.00799 | id:1709.00799 author:Hongming Li, Yong Fan category:cs.CV  published:2017-09-04 summary:We propose a novel non-rigid image registration algorithm that is built upon fully convolutional networks (FCNs) to optimize and learn spatial transformations between pairs of images to be registered. Different from most existing deep learning based image registration methods that learn spatial transformations from training data with known corresponding spatial transformations, our method directly estimates spatial transformations between pairs of images by maximizing an image-wise similarity metric between fixed and deformed moving images, similar to conventional image registration algorithms. At the same time, our method also learns FCNs for encoding the spatial transformations at the same spatial resolution of images to be registered, rather than learning coarse-grained spatial transformation information. The image registration is implemented in a multi-resolution image registration framework to jointly optimize and learn spatial transformations and FCNs at different resolutions with deep self-supervision through typical feedforward and backpropagation computation. Since our method simultaneously optimizes and learns spatial transformations for the image registration, our method can be directly used to register a pair of images, and the registration of a set of images is also a training procedure for FCNs so that the trained FCNs can be directly adopted to register new images by feedforward computation of the learned FCNs without any optimization. The proposed method has been evaluated for registering 3D structural brain magnetic resonance (MR) images and obtained better performance than state-of-the-art image registration algorithms. version:1
arxiv-1709-00786 | Machine learning methods for histopathological image analysis | http://arxiv.org/abs/1709.00786 | id:1709.00786 author:Daisuke Komura, Shumpei Ishikawa category:cs.CV  published:2017-09-04 summary:Abundant accumulation of digital histopathological images has led to the increased demand for their analysis, such as computer-aided diagnosis using machine learning techniques. However, digital pathological images and related tasks have some issues to be considered. In this mini-review, we introduce the application of digital pathological image analysis using machine learning algorithms, address some problems specific to such analysis, and propose possible solutions. version:1
arxiv-1709-00408 | Lensless-camera based machine learning for image classification | http://arxiv.org/abs/1709.00408 | id:1709.00408 author:Ganghun Kim, Stefan Kapetanovic, Rachael Palmer, Rajesh Menon category:cs.CV physics.optics  published:2017-09-03 summary:Machine learning (ML) has been widely applied to image classification. Here, we extend this application to data generated by a camera comprised of only a standard CMOS image sensor with no lens. We first created a database of lensless images of handwritten digits. Then, we trained a ML algorithm on this dataset. Finally, we demonstrated that the trained ML algorithm is able to classify the digits with accuracy as high as 99% for 2 digits. Our approach clearly demonstrates the potential for non-human cameras in machine-based decision-making scenarios. version:1
arxiv-1709-00776 | Estimation of interventional effects of features on prediction | http://arxiv.org/abs/1709.00776 | id:1709.00776 author:Patrick Blöbaum, Shohei Shimizu category:stat.ML  published:2017-09-03 summary:The interpretability of prediction mechanisms with respect to the underlying prediction problem is often unclear. While several studies have focused on developing prediction models with meaningful parameters, the causal relationships between the predictors and the actual prediction have not been considered. Here, we connect the underlying causal structure of a data generation process and the causal structure of a prediction mechanism. To achieve this, we propose a framework that identifies the feature with the greatest causal influence on the prediction and estimates the necessary causal intervention of a feature such that a desired prediction is obtained. The general concept of the framework has no restrictions regarding data linearity; however, we focus on an implementation for linear data here. The framework applicability is evaluated using artificial data and demonstrated using real-world data. version:1
arxiv-1707-03133 | Underwater object classification using scattering transform of sonar signals | http://arxiv.org/abs/1707.03133 | id:1707.03133 author:Naoki Saito, David S. Weber category:cs.CV  published:2017-07-11 summary:In this paper, we apply the scattering transform (ST), a nonlinear map based off of a convolutional neural network (CNN), to classification of underwater objects using sonar signals. The ST formalizes the observation that the filters learned by a CNN have wavelet like structure. We achieve effective binary classification both on a real dataset of Unexploded Ordinance (UXOs), as well as synthetically generated examples. We also explore the effects on the waveforms with respect to changes in the object domain (e.g., translation, rotation, and acoustic impedance, etc.), and examine the consequences coming from theoretical results for the scattering transform. We show that the scattering transform is capable of excellent classification on both the synthetic and real problems, thanks to having more quasi-invariance properties that are well-suited to translation and rotation of the object. version:3
arxiv-1709-00770 | Understanding the Logical and Semantic Structure of Large Documents | http://arxiv.org/abs/1709.00770 | id:1709.00770 author:Muhammad Mahbubur Rahman, Tim Finin category:cs.CL cs.IR cs.LG  published:2017-09-03 summary:Current language understanding approaches focus on small documents, such as newswire articles, blog posts, product reviews and discussion forum entries. Understanding and extracting information from large documents like legal briefs, proposals, technical manuals and research articles is still a challenging task. We describe a framework that can analyze a large document and help people to know where a particular information is in that document. We aim to automatically identify and classify semantic sections of documents and assign consistent and human-understandable labels to similar sections across documents. A key contribution of our research is modeling the logical and semantic structure of an electronic document. We apply machine learning techniques, including deep learning, in our prototype system. We also make available a dataset of information about a collection of scholarly articles from the arXiv eprints collection that includes a wide range of metadata for each article, including a table of contents, section labels, section summarizations and more. We hope that this dataset will be a useful resource for the machine learning and NLP communities in information retrieval, content-based question answering and language modeling. version:1
arxiv-1709-00753 | Compressed Sensing MRI Reconstruction with Cyclic Loss in Generative Adversarial Networks | http://arxiv.org/abs/1709.00753 | id:1709.00753 author:Tran Minh Quan, Thanh Nguyen-Duc, Won-Ki Jeong category:cs.CV  published:2017-09-03 summary:Compressed Sensing MRI (CS-MRI) has provided theoretical foundations upon which the time-consuming MRI acquisition process can be accelerated. However, it primarily relies on iterative numerical solvers which still hinders their adaptation in time-critical applications. In addition, recent advances in deep neural networks have shown their potential in computer vision and image processing, but their adaptation to MRI reconstruction is still in an early stage. In this paper, we propose a novel deep learning-based generative adversarial model, RefineGAN, for fast and accurate CS-MRI reconstruction. The proposed model is a variant of fully-residual convolutional autoencoder and generative adversarial networks (GANs), specifically designed for CS-MRI formulation; it employs deeper generator and discriminator networks with cyclic data consistency loss for faithful interpolation in the given under-sampled k-space data. In addition, our solution leverages a chained network to further enhance the reconstruction quality. RefineGAN is fast and accurate - the reconstruction process is extremely rapid, as low as tens of milliseconds for reconstruction of a 256 x 256 image, because it is one-way deployment on a feedforward network, and the image quality is superior even for extremely low sampling rate (as low as 10%) due to the data-driven nature of the method. We demonstrate that RefineGAN outperforms the state-of-the-art CS-MRI methods by a large margin in terms of both running time and image quality via evaluation using several open-source MRI databases. version:1
arxiv-1704-07657 | Decision Stream: Cultivating Deep Decision Trees | http://arxiv.org/abs/1704.07657 | id:1704.07657 author:Dmitry Ignatov, Andrey Ignatov category:cs.LG  published:2017-04-25 summary:Various modifications of decision trees have been extensively used during the past years due to their high efficiency and interpretability. Tree node splitting based on relevant feature selection is a key step of decision tree learning, at the same time being their major shortcoming: the recursive nodes partitioning leads to geometric reduction of data quantity in the leaf nodes, which causes an excessive model complexity and data overfitting. In this paper, we present a novel architecture - a Decision Stream, - aimed to overcome this problem. Instead of building a tree structure during the learning process, we propose merging nodes from different branches based on their similarity that is estimated with two-sample test statistics, which leads to generation of a deep directed acyclic graph of decision rules that can consist of hundreds of levels. To evaluate the proposed solution, we test it on several common machine learning problems - credit scoring, twitter sentiment analysis, aircraft flight control, MNIST and CIFAR image classification, synthetic data classification and regression. Our experimental results reveal that the proposed approach significantly outperforms the standard decision tree learning methods on both regression and classification tasks, yielding a prediction error decrease up to 35%. version:3
arxiv-1709-00728 | Formalising Type-Logical Grammars in Agda | http://arxiv.org/abs/1709.00728 | id:1709.00728 author:Wen Kokke category:cs.LO cs.CL  published:2017-09-03 summary:In recent years, the interest in using proof assistants to formalise and reason about mathematics and programming languages has grown. Type-logical grammars, being closely related to type theories and systems used in functional programming, are a perfect candidate to next apply this curiosity to. The advantages of using proof assistants is that they allow one to write formally verified proofs about one's type-logical systems, and that any theory, once implemented, can immediately be computed with. The downside is that in many cases the formal proofs are written as an afterthought, are incomplete, or use obtuse syntax. This makes it that the verified proofs are often much more difficult to read than the pen-and-paper proofs, and almost never directly published. In this paper, we will try to remedy that by example. Concretely, we use Agda to model the Lambek-Grishin calculus, a grammar logic with a rich vocabulary of type-forming operations. We then present a verified procedure for cut elimination in this system. Then we briefly outline a CPS translation from proofs in the Lambek-Grishin calculus to programs in Agda. And finally, we will put our system to use in the analysis of a simple example sentence. version:1
arxiv-1709-00726 | Human Detection and Tracking for Video Surveillance A Cognitive Science Approach | http://arxiv.org/abs/1709.00726 | id:1709.00726 author:Vandit Gajjar, Ayesha Gurnani, Yash Khandhediya category:cs.CV  published:2017-09-03 summary:With crimes on the rise all around the world, video surveillance is becoming more important day by day. Due to the lack of human resources to monitor this increasing number of cameras manually new computer vision algorithms to perform lower and higher level tasks are being developed. We have developed a new method incorporating the most acclaimed Histograms of Oriented Gradients the theory of Visual Saliency and the saliency prediction model Deep Multi Level Network to detect human beings in video sequences. Furthermore we implemented the k Means algorithm to cluster the HOG feature vectors of the positively detected windows and determined the path followed by a person in the video. We achieved a detection precision of 83.11% and a recall of 41.27%. We obtained these results 76.866 times faster than classification on normal images. version:1
arxiv-1709-00725 | Blind Stereo Image Quality Assessment Inspired by Brain Sensory-Motor Fusion | http://arxiv.org/abs/1709.00725 | id:1709.00725 author:Maryam Karimi, Najmeh Soltanian, Shadrokh Samavi, Nader Karimi, S. M. Reza Soroushmehr, Kayvan Najarian category:cs.CV  published:2017-09-03 summary:The use of 3D and stereo imaging is rapidly increasing. Compression, transmission, and processing could degrade the quality of stereo images. Quality assessment of such images is different than their 2D counterparts. Metrics that represent 3D perception by human visual system (HVS) are expected to assess stereoscopic quality more accurately. In this paper, inspired by brain sensory/motor fusion process, two stereo images are fused together. Then from every fused image two synthesized images are extracted. Effects of different distortions on statistical distributions of the synthesized images are shown. Based on the observed statistical changes, features are extracted from these synthesized images. These features can reveal type and severity of distortions. Then, a stacked neural network model is proposed, which learns the extracted features and accurately evaluates the quality of stereo images. This model is tested on 3D images of popular databases. Experimental results show the superiority of this method over state of the art stereo image quality assessment approaches version:1
arxiv-1709-02247 | Complete End-To-End Low Cost Solution To a 3D Scanning System with Integrated Turntable | http://arxiv.org/abs/1709.02247 | id:1709.02247 author:Saed Khawaldeh, Tajwar Abrar Aleef, Usama Pervaiz, Vu Hoang Minh, Yeman Brhane Hagos category:cs.CV  published:2017-09-03 summary:3D reconstruction is a technique used in computer vision which has a wide range of applications in areas like object recognition, city modelling, virtual reality, physical simulations, video games and special effects. Previously, to perform a 3D reconstruction, specialized hardwares were required. Such systems were often very expensive and was only available for industrial or research purpose. With the rise of the availability of high-quality low cost 3D sensors, it is now possible to design inexpensive complete 3D scanning systems. The objective of this work was to design an acquisition and processing system that can perform 3D scanning and reconstruction of objects seamlessly. In addition, the goal of this work also included making the 3D scanning process fully automated by building and integrating a turntable alongside the software. This means the user can perform a full 3D scan only by a press of a few buttons from our dedicated graphical user interface. Three main steps were followed to go from acquisition of point clouds to the finished reconstructed 3D model. First, our system acquires point cloud data of a person/object using inexpensive camera sensor. Second, align and convert the acquired point cloud data into a watertight mesh of good quality. Third, export the reconstructed model to a 3D printer to obtain a proper 3D print of the model. version:1
arxiv-1709-01402 | Recovery Conditions and Sampling Strategies for Network Lasso | http://arxiv.org/abs/1709.01402 | id:1709.01402 author:Alexandru Mara, Alexander Jung category:stat.ML cs.LG  published:2017-09-03 summary:The network Lasso is a recently proposed convex optimization method for machine learning from massive network structured datasets, i.e., big data over networks. It is a variant of the well-known least absolute shrinkage and selection operator (Lasso), which is underlying many methods in learning and signal processing involving sparse models. Highly scalable implementations of the network Lasso can be obtained by state-of-the art proximal methods, e.g., the alternating direction method of multipliers (ADMM). By generalizing the concept of the compatibility condition put forward by van de Geer and Buehlmann as a powerful tool for the analysis of plain Lasso, we derive a sufficient condition, i.e., the network compatibility condition, on the underlying network topology such that network Lasso accurately learns a clustered underlying graph signal. This network compatibility condition relates the location of the sampled nodes with the clustering structure of the network. In particular, the NCC informs the choice of which nodes to sample, or in machine learning terms, which data points provide most information if labeled. version:1
arxiv-1708-08712 | Neural Machine Translation Training in a Multi-Domain Scenario | http://arxiv.org/abs/1708.08712 | id:1708.08712 author:Hassan Sajjad, Nadir Durrani, Fahim Dalvi, Yonatan Belinkov, Stephan Vogel category:cs.CL  published:2017-08-29 summary:In this paper, we explore alternative ways to train a neural machine translation system in a multi-domain scenario. We investigate data concatenation (with fine tuning), model stacking (multi-level fine tuning), data selection and weighted ensemble. We evaluate these methods based on three criteria: i) translation quality, ii) training time, and iii) robustness towards out-of-domain tests. Our findings on Arabic-English and German-English language pairs show that the best translation quality can be achieved by building an initial system on a concatenation of available out-of-domain data and then fine-tuning it on in-domain data. Model stacking works best when training begins with the furthest out-of-domain data and the model is incrementally fine-tuned with the next furthest domain and so on. Data selection did not give the best results, but can be considered as a decent compromise between training time and translation quality. A weighted ensemble of different individual models performed better than data selection. It is beneficial in a scenario when there is no time for fine-tuning. version:2
arxiv-1709-00678 | Disentangling ASR and MT Errors in Speech Translation | http://arxiv.org/abs/1709.00678 | id:1709.00678 author:Ngoc-Tien Le, Benjamin Lecouteux, Laurent Besacier category:cs.CL  published:2017-09-03 summary:The main aim of this paper is to investigate automatic quality assessment for spoken language translation (SLT). More precisely, we investigate SLT errors that can be due to transcription (ASR) or to translation (MT) modules. This paper investigates automatic detection of SLT errors using a single classifier based on joint ASR and MT features. We evaluate both 2-class (good/bad) and 3-class (good/badASR/badMT ) labeling tasks. The 3-class problem necessitates to disentangle ASR and MT errors in the speech translation output and we propose two label extraction methods for this non trivial step. This enables - as a by-product - qualitative analysis on the SLT errors and their origin (are they due to transcription or to translation step?) on our large in-house corpus for French-to-English speech translation. version:1
arxiv-1709-00672 | Unsupervised feature learning with discriminative encoder | http://arxiv.org/abs/1709.00672 | id:1709.00672 author:Gaurav Pandey, Ambedkar Dukkipati category:cs.CV  published:2017-09-03 summary:In recent years, deep discriminative models have achieved extraordinary performance on supervised learning tasks, significantly outperforming their generative counterparts. However, their success relies on the presence of a large amount of labeled data. How can one use the same discriminative models for learning useful features in the absence of labels? We address this question in this paper, by jointly modeling the distribution of data and latent features in a manner that explicitly assigns zero probability to unobserved data. Rather than maximizing the marginal probability of observed data, we maximize the joint probability of the data and the latent features using a two step EM-like procedure. To prevent the model from overfitting to our initial selection of latent features, we use adversarial regularization. Depending on the task, we allow the latent features to be one-hot or real-valued vectors and define a suitable prior on the features. For instance, one-hot features correspond to class labels and are directly used for the unsupervised and semi-supervised classification task, whereas real-valued feature vectors are fed as input to simple classifiers for auxiliary supervised discrimination tasks. The proposed model, which we dub discriminative encoder (or DisCoder), is flexible in the type of latent features that it can capture. The proposed model achieves state-of-the-art performance on several challenging tasks. version:1
arxiv-1709-01895 | A Semi-Supervised Approach to Detecting Stance in Tweets | http://arxiv.org/abs/1709.01895 | id:1709.01895 author:Amita Misra, Brian Ecker, Theodore Handleman, Nicolas Hahn, Marilyn Walker category:cs.CL  published:2017-09-03 summary:Stance classification aims to identify, for a particular issue under discussion, whether the speaker or author of a conversational turn has Pro (Favor) or Con (Against) stance on the issue. Detecting stance in tweets is a new task proposed for SemEval-2016 Task6, involving predicting stance for a dataset of tweets on the topics of abortion, atheism, climate change, feminism and Hillary Clinton. Given the small size of the dataset, our team created our own topic-specific training corpus by developing a set of high precision hashtags for each topic that were used to query the twitter API, with the aim of developing a large training corpus without additional human labeling of tweets for stance. The hashtags selected for each topic were predicted to be stance-bearing on their own. Experimental results demonstrate good performance for our features for opinion-target pairs based on generalizing dependency features using sentiment lexicons. version:1
arxiv-1709-00663 | A Generative Model For Zero Shot Learning Using Conditional Variational Autoencoders | http://arxiv.org/abs/1709.00663 | id:1709.00663 author:Ashish Mishra, M Shiva Krishna Reddy, Anurag Mittal, Hema A Murthy category:cs.CV  published:2017-09-03 summary:Zero shot learning in image classification refers to the setting where images from some novel classes are absent in the training data. Images from the novel classes can still be correctly classified by taking cues from other modalities such as language. This setting is important in the real world since one cannot account for all the possible classes during training. We present a novel generative model for zero shot learning using conditional variational autoencoders. By extensive testing on four benchmark datasets, we show that our model can outperform the state of the art, particularly in the more realistic generalized setting where training classes can also appear at the test time along with novel classes. version:1
arxiv-1709-00659 | Investigating how well contextual features are captured by bi-directional recurrent neural network models | http://arxiv.org/abs/1709.00659 | id:1709.00659 author:Kushal Chawla, Sunil Kumar Sahu, Ashish Anand category:cs.CL  published:2017-09-03 summary:Learning algorithms for natural language processing (NLP) tasks traditionally rely on manually defined appropriate contextual features. On the other hand, neural network models learn these features automatically and have been successfully applied for several NLP tasks. Such models only consider vector representation of words and thus do not require efforts for manual feature engineering. This makes neural models a natural choice to be used across several domains. But this flexibility comes at the cost of interpretability. The motivation of this work is to enhance understanding of neural models towards their ability to capture contextual features. In particular, we analyze the performance of bi-directional recurrent neural models for sequence tagging task by defining several measures based on word erasure technique and investigate their ability to capture relevant features. We perform a comprehensive analysis of these measures on general as well as biomedical domain datasets. Our experiments focus on important contextual words as features, which can easily be extended to analyze various other feature types. Not only this, we also investigate positional effects of context words and show how the developed methods can be used for error analysis. version:1
arxiv-1709-00657 | Detection of Moving Object in Dynamic Background Using Gaussian Max-Pooling and Segmentation Constrained RPCA | http://arxiv.org/abs/1709.00657 | id:1709.00657 author:Yang Li, Guangcan Liu, Shengyong Chen category:cs.CV  published:2017-09-03 summary:Due to its efficiency and stability, Robust Principal Component Analysis (RPCA) has been emerging as a promising tool for moving object detection. Unfortunately, existing RPCA based methods assume static or quasi-static background, and thereby they may have trouble in coping with the background scenes that exhibit a persistent dynamic behavior. In this work, we shall introduce two techniques to fill in the gap. First, instead of using the raw pixel-value as features that are brittle in the presence of dynamic background, we devise a so-called Gaussian max-pooling operator to estimate a "stable-value" for each pixel. Those stable-values are robust to various background changes and can therefore distinguish effectively the foreground objects from the background. Then, to obtain more accurate results, we further propose a Segmentation Constrained RPCA (SC-RPCA) model, which incorporates the temporal and spatial continuity in images into RPCA. The inference process of SC-RPCA is a group sparsity constrained nuclear norm minimization problem, which is convex and easy to solve. Experimental results on seven videos from the CDCNET 2014 database show the superior performance of the proposed method. version:1
arxiv-1706-04074 | Convergence Analysis of Belief Propagation for Pairwise Linear Gaussian Models | http://arxiv.org/abs/1706.04074 | id:1706.04074 author:Jian Du, Shaodan Ma, Yik-Chung Wu, Soummya Kar, José M. F. Moura category:cs.LG stat.ML  published:2017-06-12 summary:Gaussian belief propagation (BP) has been widely used for distributed inference in large-scale networks such as the smart grid, sensor networks, and social networks, where local measurements/observations are scattered over a wide geographical area. One particular case is when two neighboring agents share a common observation. For example, to estimate voltage in the direct current (DC) power flow model, the current measurement over a power line is proportional to the voltage difference between two neighboring buses. When applying the Gaussian BP algorithm to this type of problem, the convergence condition remains an open issue. In this paper, we analyze the convergence properties of Gaussian BP for this pairwise linear Gaussian model. We show analytically that the updating information matrix converges at a geometric rate to a unique positive definite matrix with arbitrary positive semidefinite initial value and further provide the necessary and sufficient convergence condition for the belief mean vector to the optimal estimate. version:3
arxiv-1709-00649 | Simulated Annealing for JPEG Quantization | http://arxiv.org/abs/1709.00649 | id:1709.00649 author:Max Hopkins, Michael Mitzenmacher, Sebastian Wagner-Carena category:cs.MM cs.CV cs.GR  published:2017-09-03 summary:JPEG is one of the most widely used image formats, but in some ways remains surprisingly unoptimized, perhaps because some natural optimizations would go outside the standard that defines JPEG. We show how to improve JPEG compression in a standard-compliant, backward-compatible manner, by finding improved default quantization tables. We describe a simulated annealing technique that has allowed us to find several quantization tables that perform better than the industry standard, in terms of both compressed size and image fidelity. Specifically, we derive tables that reduce the FSIM error by over 10% while improving compression by over 20% at quality level 95 in our tests; we also provide similar results for other quality levels. While we acknowledge our approach can in some images lead to visible artifacts under large magnification, we believe use of these quantization tables, or additional tables that could be found using our methodology, would significantly reduce JPEG file sizes with improved overall image quality. version:1
arxiv-1709-00643 | Fast Image Processing with Fully-Convolutional Networks | http://arxiv.org/abs/1709.00643 | id:1709.00643 author:Qifeng Chen, Jia Xu, Vladlen Koltun category:cs.CV cs.GR cs.LG  published:2017-09-02 summary:We present an approach to accelerating a wide variety of image processing operators. Our approach uses a fully-convolutional network that is trained on input-output pairs that demonstrate the operator's action. After training, the original operator need not be run at all. The trained network operates at full resolution and runs in constant time. We investigate the effect of network architecture on approximation accuracy, runtime, and memory footprint, and identify a specific architecture that balances these considerations. We evaluate the presented approach on ten advanced image processing operators, including multiple variational models, multiscale tone and detail manipulation, photographic style transfer, nonlocal dehazing, and nonphotorealistic stylization. All operators are approximated by the same model. Experiments demonstrate that the presented approach is significantly more accurate than prior approximation schemes. It increases approximation accuracy as measured by PSNR across the evaluated operators by 8.5 dB on the MIT-Adobe dataset (from 27.5 to 36 dB) and reduces DSSIM by a multiplicative factor of 3 compared to the most accurate prior approximation scheme, while being the fastest. We show that our models generalize across datasets and across resolutions, and investigate a number of extensions of the presented approach. The results are shown in the supplementary video at https://youtu.be/eQyfHgLx8Dc version:1
arxiv-1709-00640 | When can Multi-Site Datasets be Pooled for Regression? Hypothesis Tests, $\ell_2$-consistency and Neuroscience Applications | http://arxiv.org/abs/1709.00640 | id:1709.00640 author:Hao Henry Zhou, Yilin Zhang, Vamsi K. Ithapu, Sterling C. Johnson, Grace Wahba, Vikas Singh category:stat.ME stat.ML  published:2017-09-02 summary:Many studies in biomedical and health sciences involve small sample sizes due to logistic or financial constraints. Often, identifying weak (but scientifically interesting) associations between a set of predictors and a response necessitates pooling datasets from multiple diverse labs or groups. While there is a rich literature in statistical machine learning to address distributional shifts and inference in multi-site datasets, it is less clear ${\it when}$ such pooling is guaranteed to help (and when it does not) -- independent of the inference algorithms we use. In this paper, we present a hypothesis test to answer this question, both for classical and high dimensional linear regression. We precisely identify regimes where pooling datasets across multiple sites is sensible, and how such policy decisions can be made via simple checks executable on each site before any data transfer ever happens. With a focus on Alzheimer's disease studies, we present empirical results showing that in regimes suggested by our analysis, pooling a local dataset with data from an international study improves power. version:1
arxiv-1707-09468 | Zero-Shot Activity Recognition with Verb Attribute Induction | http://arxiv.org/abs/1707.09468 | id:1707.09468 author:Rowan Zellers, Yejin Choi category:cs.CL cs.CV  published:2017-07-29 summary:In this paper, we investigate large-scale zero-shot activity recognition by modeling the visual and linguistic attributes of action verbs. For example, the verb "salute" has several properties, such as being a light movement, a social act, and short in duration. We use these attributes as the internal mapping between visual and textual representations to reason about a previously unseen action. In contrast to much prior work that assumes access to gold standard attributes for zero-shot classes and focuses primarily on object attributes, our model uniquely learns to infer action attributes from dictionary definitions and distributed word representations. Experimental results confirm that action attributes inferred from language can provide a predictive signal for zero-shot prediction of previously unseen activities. version:2
arxiv-1709-00616 | Challenging Language-Dependent Segmentation for Arabic: An Application to Machine Translation and Part-of-Speech Tagging | http://arxiv.org/abs/1709.00616 | id:1709.00616 author:Hassan Sajjad, Fahim Dalvi, Nadir Durrani, Ahmed Abdelali, Yonatan Belinkov, Stephan Vogel category:cs.CL  published:2017-09-02 summary:Word segmentation plays a pivotal role in improving any Arabic NLP application. Therefore, a lot of research has been spent in improving its accuracy. Off-the-shelf tools, however, are: i) complicated to use and ii) domain/dialect dependent. We explore three language-independent alternatives to morphological segmentation using: i) data-driven sub-word units, ii) characters as a unit of learning, and iii) word embeddings learned using a character CNN (Convolution Neural Network). On the tasks of Machine Translation and POS tagging, we found these methods to achieve close to, and occasionally surpass state-of-the-art performance. In our analysis, we show that a neural machine translation system is sensitive to the ratio of source and target tokens, and a ratio close to 1 or greater, gives optimal performance. version:1
arxiv-1709-00614 | On Identifiability of Nonnegative Matrix Factorization | http://arxiv.org/abs/1709.00614 | id:1709.00614 author:Xiao Fu, Kejun Huang, Nicholas D. Sidiropoulos category:cs.LG stat.ML  published:2017-09-02 summary:In this letter, we propose a new identification criterion that guarantees the recovery of the low-rank latent factors in the nonnegative matrix factorization (NMF) model, under mild conditions. Specifically, using the proposed criterion, it suffices to identify the latent factors if the rows of one factor are \emph{sufficiently scattered} over the nonnegative orthant, while no structural assumption is imposed on the other factor except being full-rank. This is by far the mildest condition under which the latent factors are provably identifiable from the NMF model. version:1
arxiv-1709-00609 | Security Evaluation of Pattern Classifiers under Attack | http://arxiv.org/abs/1709.00609 | id:1709.00609 author:Battista Biggio, Giorgio Fumera, Fabio Roli category:cs.LG cs.CR  published:2017-09-02 summary:Pattern classification systems are commonly used in adversarial applications, like biometric authentication, network intrusion detection, and spam filtering, in which data can be purposely manipulated by humans to undermine their operation. As this adversarial scenario is not taken into account by classical design methods, pattern classification systems may exhibit vulnerabilities, whose exploitation may severely affect their performance, and consequently limit their practical utility. Extending pattern classification theory and design methods to adversarial settings is thus a novel and very relevant research direction, which has not yet been pursued in a systematic way. In this paper, we address one of the main open issues: evaluating at design phase the security of pattern classifiers, namely, the performance degradation under potential attacks they may incur during operation. We propose a framework for empirical evaluation of classifier security that formalizes and generalizes the main ideas proposed in the literature, and give examples of its use in three real applications. Reported results show that security evaluation can provide a more complete understanding of the classifier's behavior in adversarial environments, and lead to better design choices. version:1
arxiv-1709-00599 | First-Order Adaptive Sample Size Methods to Reduce Complexity of Empirical Risk Minimization | http://arxiv.org/abs/1709.00599 | id:1709.00599 author:Aryan Mokhtari, Alejandro Ribeiro category:cs.LG math.OC  published:2017-09-02 summary:This paper studies empirical risk minimization (ERM) problems for large-scale datasets and incorporates the idea of adaptive sample size methods to improve the guaranteed convergence bounds for first-order stochastic and deterministic methods. In contrast to traditional methods that attempt to solve the ERM problem corresponding to the full dataset directly, adaptive sample size schemes start with a small number of samples and solve the corresponding ERM problem to its statistical accuracy. The sample size is then grown geometrically -- e.g., scaling by a factor of two -- and use the solution of the previous ERM as a warm start for the new ERM. Theoretical analyses show that the use of adaptive sample size methods reduces the overall computational cost of achieving the statistical accuracy of the whole dataset for a broad range of deterministic and stochastic first-order methods. The gains are specific to the choice of method. When particularized to, e.g., accelerated gradient descent and stochastic variance reduce gradient, the computational cost advantage is a logarithm of the number of training samples. Numerical experiments on various datasets confirm theoretical claims and showcase the gains of using the proposed adaptive sample size scheme. version:1
arxiv-1708-09667 | Video Captioning with Guidance of Multimodal Latent Topics | http://arxiv.org/abs/1708.09667 | id:1708.09667 author:Shizhe Chen, Jia Chen, Qin Jin, Alexander Hauptmann category:cs.CV cs.CL  published:2017-08-31 summary:The topic diversity of open-domain videos leads to various vocabularies and linguistic expressions in describing video contents, and therefore, makes the video captioning task even more challenging. In this paper, we propose an unified caption framework, M&M TGM, which mines multimodal topics in unsupervised fashion from data and guides the caption decoder with these topics. Compared to pre-defined topics, the mined multimodal topics are more semantically and visually coherent and can reflect the topic distribution of videos better. We formulate the topic-aware caption generation as a multi-task learning problem, in which we add a parallel task, topic prediction, in addition to the caption task. For the topic prediction task, we use the mined topics as the teacher to train a student topic prediction model, which learns to predict the latent topics from multimodal contents of videos. The topic prediction provides intermediate supervision to the learning process. As for the caption task, we propose a novel topic-aware decoder to generate more accurate and detailed video descriptions with the guidance from latent topics. The entire learning procedure is end-to-end and it optimizes both tasks simultaneously. The results from extensive experiments conducted on the MSR-VTT and Youtube2Text datasets demonstrate the effectiveness of our proposed model. M&M TGM not only outperforms prior state-of-the-art methods on multiple evaluation metrics and on both benchmark datasets, but also achieves better generalization ability. version:2
arxiv-1709-02246 | A Survey of Efficient Regression of General-Activity Human Poses from Depth Images | http://arxiv.org/abs/1709.02246 | id:1709.02246 author:Wenye He category:cs.CV  published:2017-09-02 summary:This paper presents a comprehensive review on regression-based method for human pose estimation. The problem of human pose estimation has been intensively studied and enabled many application from entertainment to training. Traditional methods often rely on color image only which cannot completely ambiguity of joint 3D position, especially in the complex context. With the popularity of depth sensors, the precision of 3D estimation has significant improvement. In this paper, we give a detailed analysis of state-of-the-art on human pose estimation, including depth image based and RGB-D based approaches. The experimental results demonstrate their advantages and limitation for different scenarios. version:1
arxiv-1709-00584 | Deep Learning-Guided Image Reconstruction from Incomplete Data | http://arxiv.org/abs/1709.00584 | id:1709.00584 author:Brendan Kelly, Thomas P. Matthews, Mark A. Anastasio category:cs.CV cs.LG  published:2017-09-02 summary:An approach to incorporate deep learning within an iterative image reconstruction framework to reconstruct images from severely incomplete measurement data is presented. Specifically, we utilize a convolutional neural network (CNN) as a quasi-projection operator within a least squares minimization procedure. The CNN is trained to encode high level information about the class of images being imaged; this information is utilized to mitigate artifacts in intermediate images produced by use of an iterative method. The structure of the method was inspired by the proximal gradient descent method, where the proximal operator is replaced by a deep CNN and the gradient descent step is generalized by use of a linear reconstruction operator. It is demonstrated that this approach improves image quality for several cases of limited-view image reconstruction and that using a CNN in an iterative method increases performance compared to conventional image reconstruction approaches. We test our method on several limited-view image reconstruction problems. Qualitative and quantitative results demonstrate state-of-the-art performance. version:1
arxiv-1709-00583 | Training Spiking Neural Networks for Cognitive Tasks: A Versatile Framework Compatible to Various Temporal Codes | http://arxiv.org/abs/1709.00583 | id:1709.00583 author:Chaofei Hong category:q-bio.NC cs.NE stat.ML  published:2017-09-02 summary:Conventional modeling approaches have found limitations in matching the increasingly detailed neural network structures and dynamics recorded in experiments to the diverse brain functionalities. On another approach, studies have demonstrated to train spiking neural networks for simple functions using supervised learning. Here, we introduce a modified SpikeProp learning algorithm, which achieved better learning stability in different activity states. In addition, we show biological realistic features such as lateral connections and sparse activities can be included in the network. We demonstrate the versatility of this framework by implementing three well-known temporal codes for different types of cognitive tasks, which are MNIST digits recognition, spatial coordinate transformation, and motor sequence generation. Moreover, we find several characteristic features have evolved alongside the task training, such as selective activity, excitatory-inhibitory balance, and weak pair-wise correlation. The coincidence between the self-evolved and experimentally observed features indicates their importance on the brain functionality. Our results suggest a unified setting in which diverse cognitive computations and mechanisms can be studied. version:1
arxiv-1709-00575 | Grasping the Finer Point: A Supervised Similarity Network for Metaphor Detection | http://arxiv.org/abs/1709.00575 | id:1709.00575 author:Marek Rei, Luana Bulat, Douwe Kiela, Ekaterina Shutova category:cs.CL cs.LG cs.NE I.2.7; I.2.6; I.5.1  published:2017-09-02 summary:The ubiquity of metaphor in our everyday communication makes it an important problem for natural language understanding. Yet, the majority of metaphor processing systems to date rely on hand-engineered features and there is still no consensus in the field as to which features are optimal for this task. In this paper, we present the first deep learning architecture designed to capture metaphorical composition. Our results demonstrate that it outperforms the existing approaches in the metaphor identification task. version:1
arxiv-1709-00566 | Adaptive Scaling | http://arxiv.org/abs/1709.00566 | id:1709.00566 author:Ting Li, Bingyi Jing, Ningchen Ying, Xianshi Yu category:stat.ML stat.AP  published:2017-09-02 summary:Preprocessing data is an important step before any data analysis. In this paper, we focus on one particular aspect, namely scaling or normalization. We analyze various scaling methods in common use and study their effects on different statistical learning models. We will propose a new two-stage scaling method. First, we use some training data to fit linear regression model and then scale the whole data based on the coefficients of regression. Simulations are conducted to illustrate the advantages of our new scaling method. Some real data analysis will also be given. version:1
arxiv-1709-02245 | Deep Galaxy: Classification of Galaxies based on Deep Convolutional Neural Networks | http://arxiv.org/abs/1709.02245 | id:1709.02245 author:Nour Eldeen M. Khalifa, Mohamed Hamed N. Taha, Aboul Ella Hassanien, I. M. Selim category:cs.CV  published:2017-09-02 summary:In this paper, a deep convolutional neural network architecture for galaxies classification is presented. The galaxy can be classified based on its features into main three categories Elliptical, Spiral, and Irregular. The proposed deep galaxies architecture consists of 8 layers, one main convolutional layer for features extraction with 96 filters, followed by two principles fully connected layers for classification. It is trained over 1356 images and achieved 97.272% in testing accuracy. A comparative result is made and the testing accuracy was compared with other related works. The proposed architecture outperformed other related works in terms of testing accuracy. version:1
arxiv-1709-00541 | Patterns versus Characters in Subword-aware Neural Language Modeling | http://arxiv.org/abs/1709.00541 | id:1709.00541 author:Rustem Takhanov, Zhenisbek Assylbekov category:cs.CL cs.LG  published:2017-09-02 summary:Words in some natural languages can have a composite structure. Elements of this structure include the root (that could also be composite), prefixes and suffixes with which various nuances and relations to other words can be expressed. Thus, in order to build a proper word representation one must take into account its internal structure. From a corpus of texts we extract a set of frequent subwords and from the latter set we select patterns, i.e. subwords which encapsulate information on character $n$-gram regularities. The selection is made using the pattern-based Conditional Random Field model with $l_1$ regularization. Further, for every word we construct a new sequence over an alphabet of patterns. The new alphabet's symbols confine a local statistical context stronger than the characters, therefore they allow better representations in ${\mathbb{R}}^n$ and are better building blocks for word representation. In the task of subword-aware language modeling, pattern-based models outperform character-based analogues by 2-20 perplexity points. Also, a recurrent neural network in which a word is represented as a sum of embeddings of its patterns is on par with a competitive and significantly more sophisticated character-based convolutional architecture. version:1
arxiv-1709-00536 | Learning Dense Facial Correspondences in Unconstrained Images | http://arxiv.org/abs/1709.00536 | id:1709.00536 author:Ronald Yu, Shunsuke Saito, Haoxiang Li, Duygu Ceylan, Hao Li category:cs.CV  published:2017-09-02 summary:We present a minimalistic but effective neural network that computes dense facial correspondences in highly unconstrained RGB images. Our network learns a per-pixel flow and a matchability mask between 2D input photographs of a person and the projection of a textured 3D face model. To train such a network, we generate a massive dataset of synthetic faces with dense labels using renderings of a morphable face model with variations in pose, expressions, lighting, and occlusions. We found that a training refinement using real photographs is required to drastically improve the ability to handle real images. When combined with a facial detection and 3D face fitting step, we show that our approach outperforms the state-of-the-art face alignment methods in terms of accuracy and speed. By directly estimating dense correspondences, we do not rely on the full visibility of sparse facial landmarks and are not limited to the model space of regression-based approaches. We also assess our method on video frames and demonstrate successful per-frame processing under extreme pose variations, occlusions, and lighting conditions. Compared to existing 3D facial tracking techniques, our fitting does not rely on previous frames or frontal facial initialization and is robust to imperfect face detections. version:1
arxiv-1709-00531 | Facial 3D Model Registration Under Occlusions With SensiblePoints-based Reinforced Hypothesis Refinement | http://arxiv.org/abs/1709.00531 | id:1709.00531 author:Yuhang Wu, Ioannis A. Kakadiaris category:cs.CV  published:2017-09-02 summary:Registering a 3D facial model to a 2D image under occlusion is difficult. First, not all of the detected facial landmarks are accurate under occlusions. Second, the number of reliable landmarks may not be enough to constrain the problem. We propose a method to synthesize additional points (SensiblePoints) to create pose hypotheses. The visual clues extracted from the fiducial points, non-fiducial points, and facial contour are jointly employed to verify the hypotheses. We define a reward function to measure whether the projected dense 3D model is well-aligned with the confidence maps generated by two fully convolutional networks, and use the function to train recurrent policy networks to move the SensiblePoints. The same reward function is employed in testing to select the best hypothesis from a candidate pool of hypotheses. Experimentation demonstrates that the proposed approach is very promising in solving the facial model registration problem under occlusion. version:1
arxiv-1709-00516 | Gaussian Filter in CRF Based Semantic Segmentation | http://arxiv.org/abs/1709.00516 | id:1709.00516 author:Yichi Gu, Qisheng Wu, Jing Li, Kai Cheng category:cs.CV 68T04  published:2017-09-02 summary:Artificial intelligence is making great changes in academy and industry with the fast development of deep learning, which is a branch of machine learning and statistical learning. Fully convolutional network [1] is the standard model for semantic segmentation. Conditional random fields coded as CNN [2] or RNN [3] and connected with FCN has been successfully applied in object detection [4]. In this paper, we introduce a multi-resolution neural network for FCN and apply Gaussian filter to the extended CRF kernel neighborhood and the label image to reduce the oscillating effect of CRF neural network segmentation, thus achieve higher precision and faster training speed. version:1
arxiv-1709-01062 | Hierarchical loss for classification | http://arxiv.org/abs/1709.01062 | id:1709.01062 author:Cinna Wu, Mark Tygert, Yann LeCun category:cs.LG cs.CV stat.ML 62H30  68T05  65K10  published:2017-09-01 summary:Failing to distinguish between a sheepdog and a skyscraper should be worse and penalized more than failing to distinguish between a sheepdog and a poodle; after all, sheepdogs and poodles are both breeds of dogs. However, existing metrics of failure (so-called "loss" or "win") used in textual or visual classification/recognition via neural networks seldom view a sheepdog as more similar to a poodle than to a skyscraper. We define a metric that, inter alia, can penalize failure to distinguish between a sheepdog and a skyscraper more than failure to distinguish between a sheepdog and a poodle. Unlike previously employed possibilities, this metric is based on an ultrametric tree associated with any given tree organization into a semantically meaningful hierarchy of a classifier's classes. version:1
arxiv-1709-00507 | Learning to look around | http://arxiv.org/abs/1709.00507 | id:1709.00507 author:Dinesh Jayaraman, Kristen Grauman category:cs.CV  published:2017-09-01 summary:Visual perception requires not only making inferences from observations, but also making decisions about what to observe. Though much of the computer vision literature implicitly assumes a well-captured visual observation as input, in reality a single view of a complex visual environment---or even multiple arbitrarily chosen views---may provide too little information for perception tasks. We aim to address the problem of "learning to look around" in the first place. Specifically, in a setting where a visual agent has the ability to voluntarily acquire new views to observe its environment, how can we train it to exhibit efficient exploratory behaviors to acquire informative observations? We treat this as a reinforcement learning problem, where a system is rewarded for actions that reduce its uncertainty about the unobserved portions of its environment. Based on this principle, we develop recurrent neural network-based systems to perform active completion of panoramic natural scenes and 3-D object shapes. Crucially, the learned policies are not closely tied to the particular semantic content seen during training; as a result, 1) the learned "look around" behavior is relevant even for new tasks in unseen environments, and 2) training data acquisition involves no manual labeling. Through tests in diverse settings, we demonstrate that our system learns useful and generic exploratory policies that transfer to new unseen tasks, an important step for autonomous embodied visual agents. version:1
arxiv-1709-00505 | Unsupervised learning through one-shot image-based shape reconstruction | http://arxiv.org/abs/1709.00505 | id:1709.00505 author:Dinesh Jayaraman, Ruohan Gao, Kristen Grauman category:cs.CV  published:2017-09-01 summary:Objects are three-dimensional entities, but visual observations are largely 2D. Inferring 3D properties from individual 2D views is thus a generically useful skill that is critical to object perception. We ask the question: can we learn useful image representations by explicitly training a system to infer 3D shape from 2D views? The few prior attempts at single view 3D reconstruction all target the reconstruction task as an end in itself, and largely build category-specific models to get better reconstructions. In contrast, we are interested in this task as a means to learn generic visual representations that embed knowledge of 3D shape properties from arbitrary object views. We train a single category-agnostic neural network from scratch to produce a complete image-based shape representation from one view of a generic object in a single forward pass. Through comparison against several baselines on widely used shape datasets, we show that our system learns to infer shape for generic objects including even those from categories that are not present in the training set. In order to perform this "mental rotation" task, our system is forced to learn intermediate image representations that embed object geometry, without requiring any manual supervision. We show that these learned representations outperform other unsupervised representations on various semantic tasks, such as object recognition and object retrieval. version:1
arxiv-1709-00489 | Arc-Standard Spinal Parsing with Stack-LSTMs | http://arxiv.org/abs/1709.00489 | id:1709.00489 author:Miguel Ballesteros, Xavier Carreras category:cs.CL  published:2017-09-01 summary:We present a neural transition-based parser for spinal trees, a dependency representation of constituent trees. The parser uses Stack-LSTMs that compose constituent nodes with dependency-based derivations. In experiments, we show that this model adapts to different styles of dependency relations, but this choice has little effect for predicting constituent structure, suggesting that LSTMs induce useful states by themselves. version:1
arxiv-1709-00443 | End-to-End Multi-View Lipreading | http://arxiv.org/abs/1709.00443 | id:1709.00443 author:Stavros Petridis, Yujiang Wang, Zuwei Li, Maja Pantic category:cs.CV  published:2017-09-01 summary:Non-frontal lip views contain useful information which can be used to enhance the performance of frontal view lipreading. However, the vast majority of recent lipreading works, including the deep learning approaches which significantly outperform traditional approaches, have focused on frontal mouth images. As a consequence, research on joint learning of visual features and speech classification from multiple views is limited. In this work, we present an end-to-end multi-view lipreading system based on Bidirectional Long-Short Memory (BLSTM) networks. To the best of our knowledge, this is the first model which simultaneously learns to extract features directly from the pixels and performs visual speech classification from multiple views and also achieves state-of-the-art performance. The model consists of multiple identical streams, one for each view, which extract features directly from different poses of mouth images. The temporal dynamics in each stream/view are modelled by a BLSTM and the fusion of multiple streams/views takes place via another BLSTM. An absolute average improvement of 3% and 3.8% over the frontal view performance is reported on the OuluVS2 database when the best two (frontal and profile) and three views (frontal, profile, 45) are combined, respectively. The best three-view model results in a 10.5% absolute improvement over the current multi-view state-of-the-art performance on OuluVS2, without using external databases for training, achieving a maximum classification accuracy of 96.9%. version:1
arxiv-1709-00440 | PassGAN: A Deep Learning Approach for Password Guessing | http://arxiv.org/abs/1709.00440 | id:1709.00440 author:Briland Hitaj, Paolo Gasti, Giuseppe Ateniese, Fernando Perez-Cruz category:cs.CR cs.LG stat.ML  published:2017-09-01 summary:State-of-the-art password guessing tools, such as HashCat and John the Ripper (JTR), enable users to check billions of passwords per second against password hashes. In addition to straightforward dictionary attacks, these tools can expand dictionaries using password generation rules. Although these rules perform well on current password datasets, creating new rules that are optimized for new datasets is a laborious task that requires specialized expertise. In this paper, we devise how to replace human-generated password rules with a theory-grounded password generation approach based on machine learning. The result of this effort is PassGAN, a novel technique that leverages Generative Adversarial Networks (GANs) to enhance password guessing. PassGAN generates password guesses by training a GAN on a list of leaked passwords. Because the output of the GAN is distributed closely to its training set, the password generated using PassGAN are likely to match passwords that have not been leaked yet. PassGAN represents a substantial improvement on rule-based password generation tools because it infers password distribution information autonomously from password data rather than via manual analysis. As a result, it can effortlessly take advantage of new password leaks to generate richer password distributions. Our experiments show that this approach is very promising. When we evaluated PassGAN on two large password datasets, we were able to outperform JTR's rules by a 2x factor, and we were competitive with HashCat's rules - within a 2x factor. More importantly, when we combined the output of PassGAN with the output of HashCat, we were able to match 18%-24% more passwords than HashCat alone. This is remarkable because it shows that PassGAN can generate a considerable number of passwords that are out of reach for current tools. version:1
arxiv-1709-00407 | Estimating Mixed Memberships with Sharp Eigenvector Deviations | http://arxiv.org/abs/1709.00407 | id:1709.00407 author:Xueyu Mao, Purnamrita Sarkar, Deepayan Chakrabarti category:stat.ML cs.SI math.ST physics.soc-ph stat.TH  published:2017-09-01 summary:Real world networks often have nodes belonging to multiple communities. While traditional community detection methods focus on non-overlapping communities (where a node can belong to exactly one community), the problem of finding overlapping communities has gained attention recently. While provably consistent algorithms exists, they either make assumptions about the population that are hard to check \citep{zhang2014detecting}, or are too computationally expensive \citep{MMSBAnandkumar2014}. We consider the detection of overlapping communities under the popular Mixed Membership Stochastic Blockmodel (MMSB) \cite{airoldi2008mixed}. Using the inherent geometry of this model, we link the inference of overlapping communities to the problem of finding corners in a noisy rotated and scaled simplex, for which consistent algorithms exist \citep{gillis2014fast}. We use this as a building block for our algorithm to infer the community memberships of each node, and prove its consistency. As a byproduct of our analysis, we derive sharp row-wise eigenvector deviation bounds, and provide a cleaning step that improves the performance drastically for sparse networks. We also propose both necessary and sufficient conditions for identifiability of the model, while existing methods typically present sufficient conditions for identifiability of the model involved. The empirical performance of our method is shown using simulated and real datasets scaling up to 100,000 nodes. version:1
arxiv-1704-08822 | A new image compression by gradient Haar wavelet | http://arxiv.org/abs/1704.08822 | id:1704.08822 author:Yaser Sadra category:cs.CV cs.MM  published:2017-04-28 summary:With the development of human communications the usage of Visual Communications has also increased. The advancement of image compression methods is one of the main reasons for the enhancement. This paper first presents main modes of image compression methods such as JPEG and JPEG2000 without mathematical details. Also, the paper describes gradient Haar wavelet transforms in order to construct a preliminary image compression algorithm. Then, a new image compression method is proposed based on the preliminary image compression algorithm that can improve standards of image compression. The new method is compared with original modes of JPEG and JPEG2000 (based on Haar wavelet) by image quality measures such as MAE, PSNAR, and SSIM. The image quality and statistical results confirm that can boost image compression standards. It is suggested that the new method is used in a part or all of an image compression standard. version:2
arxiv-1709-00382 | Automatic Brain Tumor Segmentation using Cascaded Anisotropic Convolutional Neural Networks | http://arxiv.org/abs/1709.00382 | id:1709.00382 author:Guotai Wang, Wenqi Li, Sebastien Ourselin, Tom Vercauteren category:cs.CV  published:2017-09-01 summary:A cascade of fully convolutional neural networks is proposed to segment multi-modality MR images with brain tumor into background and three subregions: enhanced tumor core, whole tumor and tumor core. The cascade is designed to decompose the multi-class segmentation into a sequence of three binary segmentations according to the subregion hierarchy. Segmentation of the first (second) step is used as a crisp binary mask for the second (third) step. Each network consists of multiple layers of anisotropic and dilated convolution filters that were obtained by training each network end-to-end. Residual connections and multi-scale predictions were employed in these networks to boost the segmentation performance. Experiments with BraTS 2017 validation set shows the proposed method achieved average Dice scores of 0.7859, 0.9050, 0.8378 for enhanced tumor core, whole tumor and tumor core respectively. version:1
arxiv-1709-00379 | Sparse Regularization in Marketing and Economics | http://arxiv.org/abs/1709.00379 | id:1709.00379 author:Guanhao Feng, Nicholas Polson, Yuexi Wang, Jianeng Xu category:stat.ML  published:2017-09-01 summary:Sparse alpha-norm regularization has many data-rich applications in marketing and economics. In contrast to traditional lasso and ridge regularization, the alpha-norm penalty has the property of jumping to a sparse solution. This is an attractive feature for ultra high-dimensional problems that occur in market demand estimation and forecasting. The underlying nonconvex regularization problem is solved via coordinate descent, and a proximal operator. To illustrate our methodology, we study a classic demand forecasting problem of Bajari, Nekipelov, Ryan, and Yang (2015a). On the empirical side, we find many strong sparse predictors, including price, equivalized volume, promotion, flavor scent, and brand effects. Benchmark methods including linear regression, ridge, lasso and elastic net, are used in an out-of-sample forecasting study. In particular, alpha-norm regularization provides accurate estimates for the promotion effects. Finally, we conclude with directions for future research. version:1
arxiv-1709-00354 | Query-by-example Spoken Term Detection using Attention-based Multi-hop Networks | http://arxiv.org/abs/1709.00354 | id:1709.00354 author:Chia-Wei Ao, Hung-yi Lee category:cs.CL cs.MM  published:2017-09-01 summary:Retrieving spoken content with spoken queries, or query-by- example spoken term detection (STD), is attractive because it makes possible the matching of signals directly on the acoustic level without transcribing them into text. Here, we propose an end-to-end query-by-example STD model based on an attention-based multi-hop network, whose input is a spoken query and an audio segment containing several utterances; the output states whether the audio segment includes the query. The model can be trained in either a supervised scenario using labeled data, or in an unsupervised fashion. In the supervised scenario, we find that the attention mechanism and multiple hops improve performance, and that the attention weights indicate the time span of the detected terms. In the unsupervised setting, the model mimics the behavior of the existing query-by-example STD system, yielding performance comparable to the existing system but with a lower search time complexity. version:1
arxiv-1704-06761 | Content-Based Video-Music Retrieval Using Soft Intra-Modal Structure Constraint | http://arxiv.org/abs/1704.06761 | id:1704.06761 author:Sungeun Hong, Woobin Im, Hyun S. Yang category:cs.CV  published:2017-04-22 summary:Up to now, only limited research has been conducted on cross-modal retrieval of suitable music for a specified video or vice versa. Moreover, much of the existing research relies on metadata such as keywords, tags, or associated description that must be individually produced and attached posterior. This paper introduces a new content-based, cross-modal retrieval method for video and music that is implemented through deep neural networks. We train the network via inter-modal ranking loss such that videos and music with similar semantics end up close together in the embedding space. However, if only the inter-modal ranking constraint is used for embedding, modality-specific characteristics can be lost. To address this problem, we propose a novel soft intra-modal structure loss that leverages the relative distance relationship between intra-modal samples before embedding. We also introduce reasonable quantitative and qualitative experimental protocols to solve the lack of standard protocols for less-mature video-music related tasks. Finally, we construct a large-scale 200K video-music pair benchmark. All the datasets and source code can be found in our online repository (https://github.com/csehong/VM-NET). version:2
arxiv-1709-00265 | Adversarial Networks for Spatial Context-Aware Spectral Image Reconstruction from RGB | http://arxiv.org/abs/1709.00265 | id:1709.00265 author:Aitor Alvarez-Gila, Joost van de Weijer, Estibaliz Garrote category:cs.CV  published:2017-09-01 summary:Hyperspectral signal reconstruction aims at recovering the original spectral input that produced a certain trichromatic (RGB) response from a capturing device or observer. Given the heavily underconstrained, non-linear nature of the problem, traditional techniques leverage different statistical properties of the spectral signal in order to build informative priors from real world object reflectances for constructing such RGB to spectral signal mapping. However, most of them treat each sample independently, and thus do not benefit from the contextual information that the spatial dimensions can provide. We pose hyperspectral natural image reconstruction as an image to image mapping learning problem, and apply a conditional generative adversarial framework to help capture spatial semantics. This is the first time Convolutional Neural Networks -and, particularly, Generative Adversarial Networks- are used to solve this task. Quantitative evaluation shows a Root Mean Squared Error (RMSE) drop of 44.7% and a Relative RMSE drop of 47.0% on the ICVL natural hyperspectral image dataset. version:1
arxiv-1709-00235 | Too Far to See? Not Really! --- Pedestrian Detection with Scale-aware Localization Policy | http://arxiv.org/abs/1709.00235 | id:1709.00235 author:Xiaowei Zhang, Li Cheng, Bo Li, Hai-Miao Hu category:cs.CV  published:2017-09-01 summary:A major bottleneck of pedestrian detection lies on the sharp performance deterioration in the presence of small-size pedestrians that are relatively far from the camera. Motivated by the observation that pedestrians of disparate spatial scales exhibit distinct visual appearances, we propose in this paper an active pedestrian detector that explicitly operates over multiple-layer neuronal representations of the input still image. More specifically, convolutional neural nets such as ResNet and faster R-CNNs are exploited to provide a rich and discriminative hierarchy of feature representations as well as initial pedestrian proposals. Here each pedestrian observation of distinct size could be best characterized in terms of the ResNet feature representation at a certain layer of the hierarchy; Meanwhile, initial pedestrian proposals are attained by faster R-CNNs techniques, i.e. region proposal network and follow-up region of interesting pooling layer employed right after the specific ResNet convolutional layer of interest, to produce joint predictions on the bounding-box proposals' locations and categories (i.e. pedestrian or not). This is engaged as input to our active detector where for each initial pedestrian proposal, a sequence of coordinate transformation actions is carried out to determine its proper x-y 2D location and layer of feature representation, or eventually terminated as being background. Empirically our approach is demonstrated to produce overall lower detection errors on widely-used benchmarks, and it works particularly well with far-scale pedestrians. For example, compared with 60.51% log-average miss rate of the state-of-the-art MS-CNN for far-scale pedestrians (those below 80 pixels in bounding-box height) of the Caltech benchmark, the miss rate of our approach is 41.85%, with a notable reduction of 18.68%. version:1
arxiv-1709-00228 | Learning Multi-item Auctions with (or without) Samples | http://arxiv.org/abs/1709.00228 | id:1709.00228 author:Yang Cai, Constantinos Daskalakis category:cs.GT cs.DS cs.LG  published:2017-09-01 summary:We provide algorithms that learn simple auctions whose revenue is approximately optimal in multi-item multi-bidder settings, for a wide range of valuations including unit-demand, additive, constrained additive, XOS, and subadditive. We obtain our learning results in two settings. The first is the commonly studied setting where sample access to the bidders' distributions over valuations is given, for both regular distributions and arbitrary distributions with bounded support. Our algorithms require polynomially many samples in the number of items and bidders. The second is a more general max-min learning setting that we introduce, where we are given "approximate distributions," and we seek to compute an auction whose revenue is approximately optimal simultaneously for all "true distributions" that are close to the given ones. These results are more general in that they imply the sample-based results, and are also applicable in settings where we have no sample access to the underlying distributions but have estimated them indirectly via market research or by observation of previously run, potentially non-truthful auctions. Our results hold for valuation distributions satisfying the standard (and necessary) independence-across-items property. They also generalize and improve upon recent works, which have provided algorithms that learn approximately optimal auctions in more restricted settings with additive, subadditive and unit-demand valuations using sample access to distributions. We generalize these results to the complete unit-demand, additive, and XOS setting, to i.i.d. subadditive bidders, and to the max-min setting. Our results are enabled by new uniform convergence bounds for hypotheses classes under product measures. Our bounds result in exponential savings in sample complexity compared to bounds derived by bounding the VC dimension, and are of independent interest. version:1
arxiv-1709-00226 | Semantic Composition via Probabilistic Model Theory | http://arxiv.org/abs/1709.00226 | id:1709.00226 author:Guy Emerson, Ann Copestake category:cs.CL  published:2017-09-01 summary:Semantic composition remains an open problem for vector space models of semantics. In this paper, we explain how the probabilistic graphical model used in the framework of Functional Distributional Semantics can be interpreted as a probabilistic version of model theory. Building on this, we explain how various semantic phenomena can be recast in terms of conditional probabilities in the graphical model. This connection between formal semantics and machine learning is helpful in both directions: it gives us an explicit mechanism for modelling context-dependent meanings (a challenge for formal semantics), and also gives us well-motivated techniques for composing distributed representations (a challenge for distributional semantics). We present results on two datasets that go beyond word similarity, showing how these semantically-motivated techniques improve on the performance of vector models. version:1
arxiv-1709-00224 | Variational Inference for Logical Inference | http://arxiv.org/abs/1709.00224 | id:1709.00224 author:Guy Emerson, Ann Copestake category:cs.CL  published:2017-09-01 summary:Functional Distributional Semantics is a framework that aims to learn, from text, semantic representations which can be interpreted in terms of truth. Here we make two contributions to this framework. The first is to show how a type of logical inference can be performed by evaluating conditional probabilities. The second is to make these calculations tractable by means of a variational approximation. This approximation also enables faster convergence during training, allowing us to close the gap with state-of-the-art vector space models when evaluating on semantic similarity. We demonstrate promising performance on two tasks. version:1
arxiv-1708-08999 | NODDI-SH: a computational efficient NODDI extension for fODF estimation in diffusion MRI | http://arxiv.org/abs/1708.08999 | id:1708.08999 author:Mauro Zucchelli, Maxime Descoteaux, Gloria Menegaz category:cs.CV physics.med-ph  published:2017-08-28 summary:Diffusion Magnetic Resonance Imaging (DMRI) is the only non-invasive imaging technique which is able to detect the principal directions of water diffusion as well as neurites density in the human brain. Exploiting the ability of Spherical Harmonics (SH) to model spherical functions, we propose a new reconstruction model for DMRI data which is able to estimate both the fiber Orientation Distribution Function (fODF) and the relative volume fractions of the neurites in each voxel, which is robust to multiple fiber crossings. We consider a Neurite Orientation Dispersion and Density Imaging (NODDI) inspired single fiber diffusion signal to be derived from three compartments: intracellular, extracellular, and cerebrospinal fluid. The model, called NODDI-SH, is derived by convolving the single fiber response with the fODF in each voxel. NODDI-SH embeds the calculation of the fODF and the neurite density in a unified mathematical model providing efficient, robust and accurate results. Results were validated on simulated data and tested on \textit{in-vivo} data of human brain, and compared to and Constrained Spherical Deconvolution (CSD) for benchmarking. Results revealed competitive performance in all respects and inherent adaptivity to local microstructure, while sensibly reducing the computational cost. We also investigated NODDI-SH performance when only a limited number of samples are available for the fitting, demonstrating that 60 samples are enough to obtain reliable results. The fast computational time and the low number of signal samples required, make NODDI-SH feasible for clinical application. version:2
arxiv-1709-00201 | DeepUNet: A Deep Fully Convolutional Network for Pixel-level Sea-Land Segmentation | http://arxiv.org/abs/1709.00201 | id:1709.00201 author:Ruirui Li, Wenjie Liu, Lei Yang, Shihao Sun, Wei Hu, Fan Zhang, Wei Li category:cs.CV  published:2017-09-01 summary:Semantic segmentation is a fundamental research in remote sensing image processing. Because of the complex maritime environment, the sea-land segmentation is a challenging task. Although the neural network has achieved excellent performance in semantic segmentation in the last years, there are a few of works using CNN for sea-land segmentation and the results could be further improved. This paper proposes a novel deep convolution neural network named DeepUNet. Like the U-Net, its structure has a contracting path and an expansive path to get high resolution output. But differently, the DeepUNet uses DownBlocks instead of convolution layers in the contracting path and uses UpBlock in the expansive path. The two novel blocks bring two new connections that are U-connection and Plus connection. They are promoted to get more precise segmentation results. To verify our network architecture, we made a new challenging sea-land dataset and compare the DeepUNet on it with the SegNet and the U-Net. Experimental results show that DeepUNet achieved good performance compared with other architectures, especially in high-resolution remote sensing imagery. version:1
arxiv-1709-00199 | Two-Step Disentanglement for Financial Data | http://arxiv.org/abs/1709.00199 | id:1709.00199 author:Naama Hadad, Lior Wolf, Moni Shahar category:cs.LG stat.ML  published:2017-09-01 summary:In this work, we address the problem of disentanglement of factors that generate a given data into those that are correlated with the labeling and those that are not. Our solution is simpler than previous solutions and employs adversarial training in a straightforward manner. We demonstrate the new method on visual datasets as well as on financial data. In order to evaluate the latter, we developed a hypothetical trading strategy whose performance is affected by the performance of the disentanglement, namely, it trades better when the factors are better separated. version:1
arxiv-1709-00192 | Weighted Low-rank Tensor Recovery for Hyperspectral Image Restoration | http://arxiv.org/abs/1709.00192 | id:1709.00192 author:Yi Chang, Luxin Yan, Houzhang Fang, Sheng Zhong, Zhijun Zhang category:cs.CV  published:2017-09-01 summary:Hyperspectral imaging, providing abundant spatial and spectral information simultaneously, has attracted a lot of interest in recent years. Unfortunately, due to the hardware limitations, the hyperspectral image (HSI) is vulnerable to various degradations, such noises (random noise, HSI denoising), blurs (Gaussian and uniform blur, HSI deblurring), and down-sampled (both spectral and spatial downsample, HSI super-resolution). Previous HSI restoration methods are designed for one specific task only. Besides, most of them start from the 1-D vector or 2-D matrix models and cannot fully exploit the structurally spectral-spatial correlation in 3-D HSI. To overcome these limitations, in this work, we propose a unified low-rank tensor recovery model for comprehensive HSI restoration tasks, in which non-local similarity between spectral-spatial cubic and spectral correlation are simultaneously captured by 3-order tensors. Further, to improve the capability and flexibility, we formulate it as a weighted low-rank tensor recovery (WLRTR) model by treating the singular values differently, and study its analytical solution. We also consider the exclusive stripe noise in HSI as the gross error by extending WLRTR to robust principal component analysis (WLRTR-RPCA). Extensive experiments demonstrate the proposed WLRTR models consistently outperform state-of-the-arts in typical low level vision HSI tasks, including denoising, destriping, deblurring and super-resolution. version:1
arxiv-1709-00179 | Effective Use of Dilated Convolutions for Segmenting Small Object Instances in Remote Sensing Imagery | http://arxiv.org/abs/1709.00179 | id:1709.00179 author:Ryuhei Hamaguchi, Aito Fujita, Keisuke Nemoto, Tomoyuki Imaizumi, Shuhei Hikosaka category:cs.CV  published:2017-09-01 summary:Thanks to recent advances in CNNs, solid improvements have been made in semantic segmentation of high resolution remote sensing imagery. However, most of the previous works have not fully taken into account the specific difficulties that exist in remote sensing tasks. One of such difficulties is that objects are small and crowded in remote sensing imagery. To tackle with this challenging task we have proposed a novel architecture called local feature extraction (LFE) module attached on top of dilated front-end module. The LFE module is based on our findings that aggressively increasing dilation factors fails to aggregate local features due to sparsity of the kernel, and detrimental to small objects. The proposed LFE module solves this problem by aggregating local features with decreasing dilation factor. We tested our network on three remote sensing datasets and acquired remarkably good results for all datasets especially for small objects. version:1
arxiv-1708-00257 | Robust PCA by Manifold Optimization | http://arxiv.org/abs/1708.00257 | id:1708.00257 author:Teng Zhang, Yi Yang category:stat.ML stat.CO  published:2017-08-01 summary:Robust PCA is a widely used statistical procedure to recover a underlying low-rank matrix with grossly corrupted observations. This work considers the problem of robust PCA as a nonconvex optimization problem on the manifold of low-rank matrices, and proposes two algorithms (for two versions of retractions) based on manifold optimization. It is shown that, with a proper designed initialization, the proposed algorithms are guaranteed to converge to the underlying low-rank matrix linearly. Compared with a previous work based on the Burer-Monterio decomposition of low-rank matrices, the proposed algorithms reduce the dependence on the conditional number of the underlying low-rank matrix theoretically. Simulations and real data examples confirm the competitive performance of our method. version:3
arxiv-1709-00158 | Reasoning with shapes: profiting cognitive susceptibilities to infer linear mapping transformations between shapes | http://arxiv.org/abs/1709.00158 | id:1709.00158 author:Vahid Jalili category:cs.CV  published:2017-09-01 summary:Visual information plays an indispensable role in our daily interactions with environment. Such information is manipulated for a wide range of purposes spanning from basic object and material perception to complex gesture interpretations. There have been novel studies in cognitive science for in-depth understanding of visual information manipulation, which lead to answer questions such as: how we infer 2D/3D motion from a sequence of 2D images? how we understand a motion from a single image frame? how we see forest avoiding trees? Leveraging on congruence, linear mapping transformation determination between a set of shapes facilitate motion perception. Present study methodizes recent discoveries of human cognitive ability for scene understanding. The proposed method processes images hierarchically, that is an iterative analysis of scene abstractions using a rapidly converging heuristic iterative method. The method hierarchically abstracts images; the abstractions are represented in polar coordinate system, and any two consecutive abstractions have incremental level of details. The method then creates a graph of approximated linear mapping transformations based on circular shift permutations of hierarchical abstractions. The graph is then traversed in best-first fashion to find best linear mapping transformation. The accuracy of the proposed method is assessed using normal, noisy, and deformed images. Additionally, the present study deduces (i) the possibility of determining optimal mapping linear transformations in logarithmic iterations with respect to the precision of results, and (ii) computational cost is independent from the resolution of input shapes. version:1
arxiv-1709-00147 | Convergence Analysis of Deterministic Kernel-Based Quadrature Rules in Misspecified Settings | http://arxiv.org/abs/1709.00147 | id:1709.00147 author:Motonobu Kanagawa, Bharath K. Sriperumbudur, Kenji Fukumizu category:math.NA cs.NA stat.ML  published:2017-09-01 summary:This paper presents convergence analysis of kernel-based quadrature rules in misspecified settings, focusing on deterministic quadrature in Sobolev spaces. In particular, we deal with misspecified settings where a test integrand is less smooth than a Sobolev RKHS based on which a quadrature rule is constructed. We provide convergence guarantees based on two different assumptions on a quadrature rule: one on quadrature weights, and the other on design points. More precisely, we show that convergence rates can be derived (i) if the sum of absolute weights remains constant (or does not increase quickly), or (ii) if the minimum distance between distance design points does not decrease very quickly. As a consequence of the latter result, we derive a rate of convergence for Bayesian quadrature in misspecified settings. We reveal a condition on design points to make Bayesian quadrature robust to misspecification, and show that, under this condition, it may adaptively achieve the optimal rate of convergence in the Sobolev space of a lesser order (i.e., of the unknown smoothness of a test integrand), under a slightly stronger regularity condition on the integrand. version:1
arxiv-1709-02243 | Towards a Dedicated Computer Vision Tool set for Crowd Simulation Models | http://arxiv.org/abs/1709.02243 | id:1709.02243 author:Sultan Daud Khan, Muhammad Saqib, Michael Blumenstein category:cs.CV  published:2017-09-01 summary:As the population of world is increasing, and even more concentrated in urban areas, ensuring public safety is becoming a taunting job for security personnel and crowd managers. Mass events like sports, festivals, concerts, political gatherings attract thousand of people in a constraint environment,therefore adequate safety measures should be adopted. Despite safety measures, crowd disasters still occur frequently. Understanding underlying dynamics and behavior of crowd is becoming areas of interest for most of computer scientists. In recent years, researchers developed several models for understanding crowd dynamics. These models should be properly calibrated and validated by means of data acquired in the field. In this paper, we developed a computer vision tool set that can be helpful not only in initializing the crowd simulation models but can also validate the simulation results. The main features of proposed tool set are: (1) Crowd flow segmentation and crowd counting, (2) Identifying source/sink location for understanding crowd behavior, (3) Group detection and tracking in crowds. version:1
arxiv-1704-07049 | Probabilistic Vehicle Trajectory Prediction over Occupancy Grid Map via Recurrent Neural Network | http://arxiv.org/abs/1704.07049 | id:1704.07049 author:ByeoungDo Kim, Chang Mook Kang, Seung Hi Lee, Hyunmin Chae, Jaekyum Kim, Chung Choo Chung, Jun Won Choi category:cs.LG  published:2017-04-24 summary:In this paper, we propose an efficient vehicle trajectory prediction framework based on recurrent neural network. Basically, the characteristic of the vehicle's trajectory is different from that of regular moving objects since it is affected by various latent factors including road structure, traffic rules, and driver's intention. Previous state of the art approaches use sophisticated vehicle behavior model describing these factors and derive the complex trajectory prediction algorithm, which requires a system designer to conduct intensive model optimization for practical use. Our approach is data-driven and simple to use in that it learns complex behavior of the vehicles from the massive amount of trajectory data through deep neural network model. The proposed trajectory prediction method employs the recurrent neural network called long short-term memory (LSTM) to analyze the temporal behavior and predict the future coordinate of the surrounding vehicles. The proposed scheme feeds the sequence of vehicles' coordinates obtained from sensor measurements to the LSTM and produces the probabilistic information on the future location of the vehicles over occupancy grid map. The experiments conducted using the data collected from highway driving show that the proposed method can produce reasonably good estimate of future trajectory. version:2
arxiv-1709-00141 | Context Based Visual Content Verification | http://arxiv.org/abs/1709.00141 | id:1709.00141 author:Martin Lukac, Aigerim Bazarbayeva, Michitaka Kameyama category:cs.CV  published:2017-09-01 summary:In this paper the intermediary visual content verification method based on multi-level co-occurrences is studied. The co-occurrence statistics are in general used to determine relational properties between objects based on information collected from data. As such these measures are heavily subject to relative number of occurrences and give only limited amount of accuracy when predicting objects in real world. In order to improve the accuracy of this method in the verification task, we include the context information such as location, type of environment etc. In order to train our model we provide new annotated dataset the Advanced Attribute VOC (AAVOC) that contains additional properties of the image. We show that the usage of context greatly improve the accuracy of verification with up to 16% improvement. version:1
arxiv-1709-00139 | Fast Incremental SVDD Learning Algorithm with the Gaussian Kernel | http://arxiv.org/abs/1709.00139 | id:1709.00139 author:Hansi Jiang, Haoyu Wang, Wenhao Hu, Deovrat Kakde, Arin Chaudhuri category:stat.ML cs.LG  published:2017-09-01 summary:Support vector data description (SVDD) is a machine learning technique that is used for single-class classification and outlier detection. The idea of SVDD is to find a set of support vectors that defines a boundary around data. When dealing with online or large data, existing batch SVDD methods have to be rerun in each iteration. We propose an incremental learning algorithm for SVDD that uses the Gaussian kernel. This algorithm builds on the observation that all support vectors on the boundary have the same distance to the center of sphere in a higher-dimensional feature space as mapped by the Gaussian kernel function. Each iteration only involves the existing support vectors and the new data point. The algorithm is based solely on matrix manipulations; the support vectors and their corresponding Lagrange multiplier $\alpha_i$'s are automatically selected and determined in each iteration. It can be seen that the complexity of our algorithm in each iteration is only $O(k^2)$, where $k$ is the number of support vectors. version:1
arxiv-1709-00138 | Single Shot Text Detector with Regional Attention | http://arxiv.org/abs/1709.00138 | id:1709.00138 author:Pan He, Weilin Huang, Tong He, Qile Zhu, Yu Qiao, Xiaolin Li category:cs.CV  published:2017-09-01 summary:We present a novel single-shot text detector that directly outputs word-level bounding boxes in a natural image. We propose an attention mechanism which roughly identifies text regions via an automatically learned attentional map. This substantially suppresses background interference in the convolutional features, which is the key to producing accurate inference of words, particularly at extremely small sizes. This results in a single model that essentially works in a coarse-to-fine manner. It departs from recent FCN- based text detectors which cascade multiple FCN models to achieve an accurate prediction. Furthermore, we develop a hierarchical inception module which efficiently aggregates multi-scale inception features. This enhances local details, and also encodes strong context information, allow- ing the detector to work reliably on multi-scale and multi- orientation text with single-scale images. Our text detector achieves an F-measure of 77% on the ICDAR 2015 bench- mark, advancing the state-of-the-art results in [18, 28]. Demo is available at: http://sstd.whuang.org/. version:1
arxiv-1709-00127 | Low Permutation-rank Matrices: Structural Properties and Noisy Completion | http://arxiv.org/abs/1709.00127 | id:1709.00127 author:Nihar B. Shah, Sivaraman Balakrishnan, Martin J. Wainwright category:stat.ML cs.IT cs.LG math.IT  published:2017-09-01 summary:We consider the problem of noisy matrix completion, in which the goal is to reconstruct a structured matrix whose entries are partially observed in noise. Standard approaches to this underdetermined inverse problem are based on assuming that the underlying matrix has low rank, or is well-approximated by a low rank matrix. In this paper, we propose a richer model based on what we term the "permutation-rank" of a matrix. We first describe how the classical non-negative rank model enforces restrictions that may be undesirable in practice, and how and these restrictions can be avoided by using the richer permutation-rank model. Second, we establish the minimax rates of estimation under the new permutation-based model, and prove that surprisingly, the minimax rates are equivalent up to logarithmic factors to those for estimation under the typical low rank model. Third, we analyze a computationally efficient singular-value-thresholding algorithm, known to be optimal for the low-rank setting, and show that it also simultaneously yields a consistent estimator for the low-permutation rank setting. Finally, we present various structural results characterizing the uniqueness of the permutation-rank decomposition, and characterizing convex approximations of the permutation-rank polytope. version:1
arxiv-1705-06995 | On near optimality of one-sample update for joint detection and estimation | http://arxiv.org/abs/1705.06995 | id:1705.06995 author:Yang Cao, Liyan Xie, Yao Xie, Huan Xu category:math.ST cs.LG stat.TH  published:2017-05-19 summary:Sequential hypothesis test and change-point detection when the distribution parameters are unknown is a fundamental problem in statistics and machine learning. We show that for such problems, detection procedures based on sequential likelihood ratios with simple one-sample update estimates such as online mirror descent are nearly second-order optimal. This means that the upper bound for the algorithm performance meets the lower bound asymptotically up to a log-log factor in the false-alarm rate when it tends to zero. This is a blessing, since although the generalized likelihood ratio(GLR) statistics are optimal theoretically, but they cannot be computed recursively, and their exact computation usually requires infinite memory of historical data. We prove the nearly second-order optimality by making a connection between sequential analysis and online convex optimization and leveraging the logarithmic regret bound property of online mirror descent algorithm. Numerical examples validate our theory. version:2
arxiv-1709-00106 | Online Convolutional Dictionary Learning | http://arxiv.org/abs/1709.00106 | id:1709.00106 author:Jialin Liu, Cristina Garcia-Cardona, Brendt Wohlberg, Wotao Yin category:cs.LG cs.CV math.OC stat.ML  published:2017-08-31 summary:Convolutional sparse representations are a form of sparse representation with a structured, translation invariant dictionary. Most convolutional dictionary learning algorithms to date operate in batch mode, requiring simultaneous access to all training images during the learning process, which results in very high memory usage and severely limits the training data that can be used. Very recently, however, a number of authors have considered the design of online convolutional dictionary learning algorithms that offer far better scaling of memory and computational cost with training set size than batch methods. This paper extends our prior work, improving a number of aspects of our previous algorithm; proposing an entirely new one, with better performance, and that supports the inclusion of a spatial mask for learning from incomplete data; and providing a rigorous theoretical analysis of these methods. version:1
arxiv-1708-07517 | FacePoseNet: Making a Case for Landmark-Free Face Alignment | http://arxiv.org/abs/1708.07517 | id:1708.07517 author:Fengju Chang, Anh Tuan Tran, Tal Hassner, Iacopo Masi, Ram Nevatia, Gerard Medioni category:cs.CV  published:2017-08-24 summary:We show how a simple convolutional neural network (CNN) can be trained to accurately and robustly regress 6 degrees of freedom (6DoF) 3D head pose, directly from image intensities. We further explain how this FacePoseNet (FPN) can be used to align faces in 2D and 3D as an alternative to explicit facial landmark detection for these tasks. We claim that in many cases the standard means of measuring landmark detector accuracy can be misleading when comparing different face alignments. Instead, we compare our FPN with existing methods by evaluating how they affect face recognition accuracy on the IJB-A and IJB-B benchmarks: using the same recognition pipeline, but varying the face alignment method. Our results show that (a) better landmark detection accuracy measured on the 300W benchmark does not necessarily imply better face recognition accuracy. (b) Our FPN provides superior 2D and 3D face alignment on both benchmarks. Finally, (c), FPN aligns faces at a small fraction of the computational cost of comparably accurate landmark detectors. For many purposes, FPN is thus a far faster and far more accurate face alignment method than using facial landmark detectors. version:2
arxiv-1709-00094 | Linguistic Reflexes of Well-Being and Happiness in Echo | http://arxiv.org/abs/1709.00094 | id:1709.00094 author:Jiaqi Wu, Marilyn Walker, Pranav Anand, Steve Whittaker category:cs.CL  published:2017-08-31 summary:Different theories posit different sources for feelings of well-being and happiness. Appraisal theory grounds our emotional responses in our goals and desires and their fulfillment, or lack of fulfillment. Self Determination theory posits that the basis for well-being rests on our assessment of our competence, autonomy, and social connection. And surveys that measure happiness empirically note that people require their basic needs to be met for food and shelter, but beyond that tend to be happiest when socializing, eating or having sex. We analyze a corpus of private microblogs from a well-being application called ECHO, where users label each written post about daily events with a happiness score between 1 and 9. Our goal is to ground the linguistic descriptions of events that users experience in theories of well-being and happiness, and then examine the extent to which different theoretical accounts can explain the variance in the happiness scores. We show that recurrent event types, such as OBLIGATION and INCOMPETENCE, which affect people's feelings of well-being are not captured in current lexical or semantic resources. version:1
arxiv-1709-00092 | RANK: Large-Scale Inference with Graphical Nonlinear Knockoffs | http://arxiv.org/abs/1709.00092 | id:1709.00092 author:Yingying Fan, Emre Demirkaya, Gaorong Li, Jinchi Lv category:math.ST stat.ME stat.ML stat.TH  published:2017-08-31 summary:Power and reproducibility are key to enabling refined scientific discoveries in contemporary big data applications with general high-dimensional nonlinear models. In this paper, we provide theoretical foundations on the power and robustness for the model-free knockoffs procedure introduced recently in Cand\`{e}s, Fan, Janson and Lv (2016) in high-dimensional setting when the covariate distribution is characterized by Gaussian graphical model. We establish that under mild regularity conditions, the power of the oracle knockoffs procedure with known covariate distribution in high-dimensional linear models is asymptotically one as sample size goes to infinity. When moving away from the ideal case, we suggest the modified model-free knockoffs method called graphical nonlinear knockoffs (RANK) to accommodate the unknown covariate distribution. We provide theoretical justifications on the robustness of our modified procedure by showing that the false discovery rate (FDR) is asymptotically controlled at the target level and the power is asymptotically one with the estimated covariate distribution. To the best of our knowledge, this is the first formal theoretical result on the power for the knockoffs procedure. Simulation results demonstrate that compared to existing approaches, our method performs competitively in both FDR control and power. A real data set is analyzed to further assess the performance of the suggested knockoffs procedure. version:1
arxiv-1709-00074 | Unsupervised Learning of Semantic Mappings | http://arxiv.org/abs/1709.00074 | id:1709.00074 author:Tomer Galanti, Lior Wolf category:cs.LG  published:2017-08-31 summary:We discuss the feasibility of the following learning problem: given unmatched samples from two domains and nothing else, learn a mapping between the two, which preserves semantics. Due to the lack of paired samples and without any definition of the semantic information, the problem might seem ill-posed. Specifically, in typical cases, it seems possible to build infinitely many alternative mappings from every target mapping. This apparent ambiguity stands in sharp contrast to the recent empirical success in solving this problem. A theoretical framework for measuring the complexity of compositions of functions is developed in order to show that the target mapping is of lower complexity than all other mappings. The measured complexity is directly related to the depth of the neural networks being learned and the semantic mapping could be captured simply by learning using architectures that are not much bigger than the minimal architecture. version:1
arxiv-1709-00072 | Exact Blur Measure Outperforms Conventional Learned Features for Depth Finding | http://arxiv.org/abs/1709.00072 | id:1709.00072 author:Akbar Saadat category:cs.CV  published:2017-08-31 summary:Image analysis methods that are based on exact blur values are faced with the computational complexities due to blur measurement error. This atmosphere encourages scholars to look for handcrafted and learned features for finding depth from a single image. This paper introduces a novel exact realization for blur measures on digital images and implements it on a new measure of defocus Gaussian blur at edge points in Depth From Defocus (DFD) methods with the potential to change this atmosphere. The experiments on real images indicate superiority of the proposed measure in error performance over conventional learned features in the state-of the-art single image based depth estimation methods. version:1
arxiv-1709-00071 | Weather impacts expressed sentiment | http://arxiv.org/abs/1709.00071 | id:1709.00071 author:Patrick Baylis, Nick Obradovich, Yury Kryvasheyeu, Haohui Chen, Lorenzo Coviello, Esteban Moro, Manuel Cebrian, James H. Fowler category:stat.AP cs.CL  published:2017-08-31 summary:We conduct the largest ever investigation into the relationship between meteorological conditions and the sentiment of human expressions. To do this, we employ over three and a half billion social media posts from tens of millions of individuals from both Facebook and Twitter between 2009 and 2016. We find that cold temperatures, hot temperatures, precipitation, narrower daily temperature ranges, humidity, and cloud cover are all associated with worsened expressions of sentiment, even when excluding weather-related posts. We compare the magnitude of our estimates with the effect sizes associated with notable historical events occurring within our data. version:1
arxiv-1709-00069 | Learning Inference Models for Computer Vision | http://arxiv.org/abs/1709.00069 | id:1709.00069 author:Varun Jampani category:cs.CV  published:2017-08-31 summary:Computer vision can be understood as the ability to perform inference on image data. Breakthroughs in computer vision technology are often marked by advances in inference techniques. This thesis proposes novel inference schemes and demonstrates applications in computer vision. We propose inference techniques for both generative and discriminative vision models. The use of generative models in vision is often hampered by the difficulty of posterior inference. We propose techniques for improving inference in MCMC sampling and message-passing inference. Our inference strategy is to learn separate discriminative models that assist Bayesian inference in a generative model. Experiments on a range of generative models show that the proposed techniques accelerate the inference process and/or converge to better solutions. A main complication in the design of discriminative models is the inclusion of prior knowledge. We concentrate on CNN models and propose a generalization of standard spatial convolutions to bilateral convolutions. We generalize the existing use of bilateral filters and then propose new neural network architectures with learnable bilateral filters, which we call `Bilateral Neural Networks'. Experiments demonstrate the use of the bilateral networks on a wide range of image and video tasks and datasets. In summary, we propose techniques for better inference in several vision models ranging from inverse graphics to freely parameterized neural networks. In generative models, our inference techniques alleviate some of the crucial hurdles in Bayesian posterior inference, paving new ways for the use of model based machine learning in vision. In discriminative CNN models, the proposed filter generalizations aid in the design of new neural network architectures that can handle sparse high-dimensional data as well as provide a way to incorporate prior knowledge into CNNs. version:1
arxiv-1709-00045 | On Security and Sparsity of Linear Classifiers for Adversarial Settings | http://arxiv.org/abs/1709.00045 | id:1709.00045 author:Ambra Demontis, Paolo Russu, Battista Biggio, Giorgio Fumera, Fabio Roli category:cs.LG cs.CR  published:2017-08-31 summary:Machine-learning techniques are widely used in security-related applications, like spam and malware detection. However, in such settings, they have been shown to be vulnerable to adversarial attacks, including the deliberate manipulation of data at test time to evade detection. In this work, we focus on the vulnerability of linear classifiers to evasion attacks. This can be considered a relevant problem, as linear classifiers have been increasingly used in embedded systems and mobile devices for their low processing time and memory requirements. We exploit recent findings in robust optimization to investigate the link between regularization and security of linear classifiers, depending on the type of attack. We also analyze the relationship between the sparsity of feature weights, which is desirable for reducing processing cost, and the security of linear classifiers. We further propose a novel octagonal regularizer that allows us to achieve a proper trade-off between them. Finally, we empirically show how this regularizer can improve classifier security and sparsity in real-world application examples including spam and malware detection. version:1
arxiv-1709-00042 | Multi-task Dictionary Learning based Convolutional Neural Network for Computer aided Diagnosis with Longitudinal Images | http://arxiv.org/abs/1709.00042 | id:1709.00042 author:Jie Zhang, Qingyang Li, Richard J. Caselli, Jieping Ye, Yalin Wang category:cs.CV  published:2017-08-31 summary:Algorithmic image-based diagnosis and prognosis of neurodegenerative diseases on longitudinal data has drawn great interest from computer vision researchers. The current state-of-the-art models for many image classification tasks are based on the Convolutional Neural Networks (CNN). However, a key challenge in applying CNN to biological problems is that the available labeled training samples are very limited. Another issue for CNN to be applied in computer aided diagnosis applications is that to achieve better diagnosis and prognosis accuracy, one usually has to deal with the longitudinal dataset, i.e., the dataset of images scanned at different time points. Here we argue that an enhanced CNN model with transfer learning for the joint analysis of tasks from multiple time points or regions of interests may have a potential to improve the accuracy of computer aided diagnosis. To reach this goal, we innovate a CNN based deep learning multi-task dictionary learning framework to address the above challenges. Firstly, we pre-train CNN on the ImageNet dataset and transfer the knowledge from the pre-trained model to the medical imaging progression representation, generating the features for different tasks. Then, we propose a novel unsupervised learning method, termed Multi-task Stochastic Coordinate Coding (MSCC), for learning different tasks by using shared and individual dictionaries and generating the sparse features required to predict the future cognitive clinical scores. We apply our new model in a publicly available neuroimaging cohort to predict clinical measures with two different feature sets and compare them with seven other state-of-the-art methods. The experimental results show our proposed method achieved superior results. version:1
arxiv-1708-03020 | Non-stationary Stochastic Optimization with Local Spatial and Temporal Changes | http://arxiv.org/abs/1708.03020 | id:1708.03020 author:Xi Chen, Yining Wang, Yu-Xiang Wang category:stat.ML cs.LG  published:2017-08-09 summary:We consider a non-stationary sequential stochastic optimization problem, in which the underlying cost functions change over time under a variation budget constraint. We propose an $L_{p,q}$-variation functional to quantify the change, which captures local spatial and temporal variations of the sequence of functions. Under the $L_{p,q}$-variation functional constraint, we derive both upper and matching lower regret bounds for smooth and strongly convex function sequences, which generalize previous results in (Besbes et al., 2015). Our results reveal some surprising phenomena under this general variation functional, such as the curse of dimensionality of the function domain. The key technical novelties in our analysis include an affinity lemma that characterizes the distance of the minimizers of two convex functions with bounded $L_p$ difference, and a cubic spline based construction that attains matching lower bounds. version:2
arxiv-1709-00037 | Earth System Modeling 2.0: A Blueprint for Models That Learn From Observations and Targeted High-Resolution Simulations | http://arxiv.org/abs/1709.00037 | id:1709.00037 author:Tapio Schneider, Shiwei Lan, Andrew Stuart, João Teixeira category:stat.ML physics.ao-ph  published:2017-08-31 summary:Climate projections continue to be marred by large uncertainties, which originate in processes that need to be parameterized, such as clouds, convection, and ecosystems. But rapid progress is now within reach. New computational tools and methods from data assimilation and machine learning make it possible to integrate global observations and local high-resolution simulations in an Earth system model (ESM) that systematically learns from both. Here we propose a blueprint for such an ESM. We outline how parameterization schemes can learn from global observations and targeted high-resolution simulations, for example, of clouds and convection, through matching low-order statistics between ESMs, observations, and high-resolution simulations. We illustrate learning algorithms for ESMs with a simple dynamical system that shares characteristics of the climate system; and we discuss the opportunities the proposed framework presents and the challenges that remain to realize it. version:1
arxiv-1709-00029 | EuroSAT: A Novel Dataset and Deep Learning Benchmark for Land Use and Land Cover Classification | http://arxiv.org/abs/1709.00029 | id:1709.00029 author:Patrick Helber, Benjamin Bischke, Andreas Dengel, Damian Borth category:cs.CV cs.LG  published:2017-08-31 summary:In this paper, we address the challenge of land use and land cover classification using remote sensing satellite images. For this challenging task, we use the openly and freely accessible Sentinel-2 satellite images provided within the scope of the Earth observation program Copernicus. The key contributions are as follows. We present a novel dataset based on satellite images covering 13 different spectral bands and consisting of 10 classes with in total 27,000 labeled images. We evaluate state-of-the-art deep Convolutional Neural Network (CNNs) on this novel dataset with its different spectral bands. We also evaluate deep CNNs on existing remote sensing datasets and compare the obtained results. With the proposed novel dataset, we achieved an overall classification accuracy of 98.57%. The classification system resulting from the proposed research opens a gate towards a number of Earth observation applications. We demonstrate how the classification system can be used for detecting land use or land cover changes and how it can assist in improving geographical maps. version:1
arxiv-1709-00028 | Glyph-aware Embedding of Chinese Characters | http://arxiv.org/abs/1709.00028 | id:1709.00028 author:Falcon Z. Dai, Zheng Cai category:cs.CL  published:2017-08-31 summary:Given the advantage and recent success of English character-level and subword-unit models in several NLP tasks, we consider the equivalent modeling problem for Chinese. Chinese script is logographic and many Chinese logograms are composed of common substructures that provide semantic, phonetic and syntactic hints. In this work, we propose to explicitly incorporate the visual appearance of a character's glyph in its representation, resulting in a novel glyph-aware embedding of Chinese characters. Being inspired by the success of convolutional neural networks in computer vision, we use them to incorporate the spatio-structural patterns of Chinese glyphs as rendered in raw pixels. In the context of two basic Chinese NLP tasks of language modeling and word segmentation, the model learns to represent each character's task-relevant semantic and syntactic information in the character-level embedding. version:1
arxiv-1709-00025 | A State-Space Approach to Dynamic Nonnegative Matrix Factorization | http://arxiv.org/abs/1709.00025 | id:1709.00025 author:Nasser Mohammadiha, Paris Smaragdis, Ghazaleh Panahandeh, Simon Doclo category:cs.LG stat.ML  published:2017-08-31 summary:Nonnegative matrix factorization (NMF) has been actively investigated and used in a wide range of problems in the past decade. A significant amount of attention has been given to develop NMF algorithms that are suitable to model time series with strong temporal dependencies. In this paper, we propose a novel state-space approach to perform dynamic NMF (D-NMF). In the proposed probabilistic framework, the NMF coefficients act as the state variables and their dynamics are modeled using a multi-lag nonnegative vector autoregressive (N-VAR) model within the process equation. We use expectation maximization and propose a maximum-likelihood estimation framework to estimate the basis matrix and the N-VAR model parameters. Interestingly, the N-VAR model parameters are obtained by simply applying NMF. Moreover, we derive a maximum a posteriori estimate of the state variables (i.e., the NMF coefficients) that is based on a prediction step and an update step, similarly to the Kalman filter. We illustrate the benefits of the proposed approach using different numerical simulations where D-NMF significantly outperforms its static counterpart. Experimental results for three different applications show that the proposed approach outperforms two state-of-the-art NMF approaches that exploit temporal dependencies, namely a nonnegative hidden Markov model and a frame stacking approach, while it requires less memory and computational power. version:1
arxiv-1708-09839 | 3D Visual Perception for Self-Driving Cars using a Multi-Camera System: Calibration, Mapping, Localization, and Obstacle Detection | http://arxiv.org/abs/1708.09839 | id:1708.09839 author:Christian Häne, Lionel Heng, Gim Hee Lee, Friedrich Fraundorfer, Paul Furgale, Torsten Sattler, Marc Pollefeys category:cs.CV  published:2017-08-31 summary:Cameras are a crucial exteroceptive sensor for self-driving cars as they are low-cost and small, provide appearance information about the environment, and work in various weather conditions. They can be used for multiple purposes such as visual navigation and obstacle detection. We can use a surround multi-camera system to cover the full 360-degree field-of-view around the car. In this way, we avoid blind spots which can otherwise lead to accidents. To minimize the number of cameras needed for surround perception, we utilize fisheye cameras. Consequently, standard vision pipelines for 3D mapping, visual localization, obstacle detection, etc. need to be adapted to take full advantage of the availability of multiple cameras rather than treat each camera individually. In addition, processing of fisheye images has to be supported. In this paper, we describe the camera calibration and subsequent processing pipeline for multi-fisheye-camera systems developed as part of the V-Charge project. This project seeks to enable automated valet parking for self-driving cars. Our pipeline is able to precisely calibrate multi-camera systems, build sparse 3D maps for visual navigation, visually localize the car with respect to these maps, generate accurate dense maps, as well as detect obstacles based on real-time depth map extraction. version:1
arxiv-1708-00523 | Gradient Descent using Duality Structures | http://arxiv.org/abs/1708.00523 | id:1708.00523 author:Thomas Flynn category:cs.LG math.OC  published:2017-08-01 summary:In most applications of gradient-based optimization to complex problems the choice of step size is based on trial-and-error and other heuristics. A case when it is easy to choose the step sizes is when the function has a Lipschitz continuous gradient. Many functions of interest do not appear at first sight to have this property, but often it can be established with the right choice of underlying metric. We find a simple recipe for choosing step sizes when a function has a Lipschitz gradient with respect to any Finsler structure that verifies an exponential bound. These step sizes are guaranteed to give convergence, but they may be conservative since they rely on an exponential bound. However, when relevant problem structure can be encoded in the metric to yield a significantly tighter bound while keeping optimization tractable, this may lead to rigorous and efficient algorithms. In particular, our general result can be applied to yield an optimization algorithm with non-asymptotic performance guarantees for batch optimization of multilayer neural networks. version:4
arxiv-1708-09832 | Model based learning for accelerated, limited-view 3D photoacoustic tomography | http://arxiv.org/abs/1708.09832 | id:1708.09832 author:Andreas Hauptmann, Felix Lucka, Marta Betcke, Nam Huynh, Ben Cox, Paul Beard, Sebastien Ourselin, Simon Arridge category:cs.CV cs.NE math.OC  published:2017-08-31 summary:Recent advances in deep learning for tomographic reconstructions have shown great potential to create accurate and high quality images with a considerable speed-up. In this work we present a deep neural network that is specifically designed to provide high resolution 3D images from restricted photoacoustic measurements. The network is designed to represent an iterative scheme and incorporates gradient information of the data fit to compensate for limited view artefacts. Due to the high complexity of the photoacoustic forward operator, we separate training and computation of the gradient information. A suitable prior for the desired image structures is learned as part of the training. The resulting network is trained and tested on a set of segmented vessels from lung CT scans and then applied to in-vivo photoacoustic measurement data. version:1
arxiv-1708-09825 | Inferring Human Activities Using Robust Privileged Probabilistic Learning | http://arxiv.org/abs/1708.09825 | id:1708.09825 author:Michalis Vrigkas, Evangelos Kazakos, Christophoros Nikou, Ioannis A. Kakadiaris category:cs.CV  published:2017-08-31 summary:Classification models may often suffer from "structure imbalance" between training and testing data that may occur due to the deficient data collection process. This imbalance can be represented by the learning using privileged information (LUPI) paradigm. In this paper, we present a supervised probabilistic classification approach that integrates LUPI into a hidden conditional random field (HCRF) model. The proposed model is called LUPI-HCRF and is able to cope with additional information that is only available during training. Moreover, the proposed method employes Student's t-distribution to provide robustness to outliers by modeling the conditional distribution of the privileged information. Experimental results in three publicly available datasets demonstrate the effectiveness of the proposed approach and improve the state-of-the-art in the LUPI framework for recognizing human activities. version:1
arxiv-1708-09811 | Efficient tracking of a growing number of experts | http://arxiv.org/abs/1708.09811 | id:1708.09811 author:Jaouad Mourtada, Odalric-Ambrym Maillard category:stat.ML cs.LG  published:2017-08-31 summary:We consider a variation on the problem of prediction with expert advice, where new forecasters that were unknown until then may appear at each round. As often in prediction with expert advice, designing an algorithm that achieves near-optimal regret guarantees is straightforward, using aggregation of experts. However, when the comparison class is sufficiently rich, for instance when the best expert and the set of experts itself changes over time, such strategies naively require to maintain a prohibitive number of weights (typically exponential with the time horizon). By contrast, designing strategies that both achieve a near-optimal regret and maintain a reasonable number of weights is highly non-trivial. We consider three increasingly challenging objectives (simple regret, shifting regret and sparse shifting regret) that extend existing notions defined for a fixed expert ensemble; in each case, we design strategies that achieve tight regret bounds, adaptive to the parameters of the comparison class, while being computationally inexpensive. Moreover, our algorithms are anytime, agnostic to the number of incoming experts and completely parameter-free. Such remarkable results are made possible thanks to two simple but highly effective recipes: first the "abstention trick" that comes from the specialist framework and enables to handle the least challenging notions of regret, but is limited when addressing more sophisticated objectives. Second, the "muting trick" that we introduce to give more flexibility. We show how to combine these two tricks in order to handle the most challenging class of comparison strategies. version:1
arxiv-1708-09794 | Design and Analysis of the NIPS 2016 Review Process | http://arxiv.org/abs/1708.09794 | id:1708.09794 author:Nihar B. Shah, Behzad Tabibian, Krikamol Muandet, Isabelle Guyon, Ulrike von Luxburg category:cs.DL cs.LG cs.SI stat.ML  published:2017-08-31 summary:Neural Information Processing Systems (NIPS) is a top-tier annual conference in machine learning. The 2016 edition of the conference comprised more than 2,400 paper submissions, 3,000 reviewers, and 8,000 attendees, representing a growth of nearly 40% in terms of submissions, 96% in terms of reviewers, and over 100% in terms of attendees as compared to the previous year. In this report, we analyze several aspects of the data collected during the review process, including an experiment investigating the efficacy of collecting ordinal rankings from reviewers (vs. usual scores aka cardinal rankings). Our goal is to check the soundness of the review process we implemented and, in going so, provide insights that may be useful in the design of the review process of subsequent conferences. We introduce a number of metrics that could be used for monitoring improvements when new ideas are introduced. version:1
arxiv-1708-09789 | Learning Lexico-Functional Patterns for First-Person Affect | http://arxiv.org/abs/1708.09789 | id:1708.09789 author:Lena Reed, Jiaqi Wu, Shereen Oraby, Pranav Anand, Marilyn Walker category:cs.CL  published:2017-08-31 summary:Informal first-person narratives are a unique resource for computational models of everyday events and people's affective reactions to them. People blogging about their day tend not to explicitly say I am happy. Instead they describe situations from which other humans can readily infer their affective reactions. However current sentiment dictionaries are missing much of the information needed to make similar inferences. We build on recent work that models affect in terms of lexical predicate functions and affect on the predicate's arguments. We present a method to learn proxies for these functions from first-person narratives. We construct a novel fine-grained test set, and show that the patterns we learn improve our ability to predict first-person affective reactions to everyday events, from a Stanford sentiment baseline of .67F to .75F. version:1
arxiv-1708-06590 | Automatic detection and decoding of honey bee waggle dances | http://arxiv.org/abs/1708.06590 | id:1708.06590 author:Fernando Wario, Benjamin Wild, Raúl Rojas, Tim Landgraf category:cs.CV q-bio.QM  published:2017-08-22 summary:The waggle dance is one of the most popular examples of animal communication. Forager bees direct their nestmates to profitable resources via a complex motor display. Essentially, the dance encodes the polar coordinates to the resource in the field. Unemployed foragers follow the dancer's movements and then search for the advertised spots in the field. Throughout the last decades, biologists have employed different techniques to measure key characteristics of the waggle dance and decode the information that it conveys. Early techniques involved the use of protractors and stopwatches to measure the dance orientation and duration directly from the observation hive. Recent approaches employ digital video recordings from which dance characteristics are extracted using digital protractors on screen. However, manual approaches are very time-consuming. Most studies, therefore, regard only small numbers of animals in short periods of time. We have developed a system capable of automatically detecting, decoding and mapping communication dances in real-time. In this paper, we describe our recording setup, the image processing steps performed for dance detection and decoding and an algorithm to map dances to the field. The proposed system performs with an accuracy of 90.07%. The decoded waggle orientation has an average error of -2.92{\deg} (SD = 7.37{\deg}), well within the range of human error. To evaluate and exemplify the system's performance, a group of bees was trained to an artificial feeder, and all dances in the colony were automatically detected, decoded and mapped. The system presented here is the first of this kind made publicly available, including source code and hardware specifications. We hope this will foster quantitative analyses of the honey bee waggle dance. version:2
arxiv-1708-09708 | Sketching the order of events | http://arxiv.org/abs/1708.09708 | id:1708.09708 author:Terry Lyons, Harald Oberhauser category:stat.ML cs.DS math.ST stat.TH  published:2017-08-31 summary:We introduce features for massive data streams. These stream features can be thought of as "ordered moments" and generalize stream sketches from "moments of order one" to "ordered moments of arbitrary order". In analogy to classic moments, they have theoretical guarantees such as universality that are important for learning algorithms. version:1
arxiv-1708-09702 | Human and Machine Judgements for Russian Semantic Relatedness | http://arxiv.org/abs/1708.09702 | id:1708.09702 author:Alexander Panchenko, Dmitry Ustalov, Nikolay Arefyev, Denis Paperno, Natalia Konstantinova, Natalia Loukachevitch, Chris Biemann category:cs.CL  published:2017-08-31 summary:Semantic relatedness of terms represents similarity of meaning by a numerical score. On the one hand, humans easily make judgments about semantic relatedness. On the other hand, this kind of information is useful in language processing systems. While semantic relatedness has been extensively studied for English using numerous language resources, such as associative norms, human judgments, and datasets generated from lexical databases, no evaluation resources of this kind have been available for Russian to date. Our contribution addresses this problem. We present five language resources of different scale and purpose for Russian semantic relatedness, each being a list of triples (word_i, word_j, relatedness_ij). Four of them are designed for evaluation of systems for computing semantic relatedness, complementing each other in terms of the semantic relation type they represent. These benchmarks were used to organize a shared task on Russian semantic relatedness, which attracted 19 teams. We use one of the best approaches identified in this competition to generate the fifth high-coverage resource, the first open distributional thesaurus of Russian. Multiple evaluations of this thesaurus, including a large-scale crowdsourcing study involving native speakers, indicate its high accuracy. version:1
arxiv-1709-00340 | Visual-textual Attention Driven Fine-grained Representation Learning | http://arxiv.org/abs/1709.00340 | id:1709.00340 author:Xiangteng He, Yuxin Peng category:cs.CV  published:2017-08-31 summary:Fine-grained image classification is to recognize hundreds of subcategories belonging to the same basic-level category, which is a highly challenging task due to the quite subtle visual distinctions among similar subcategories. Most existing methods generally learn part detectors to discover discriminative regions for better performance. However, not all localized parts are beneficial and indispensable for classification, and the setting for number of part detectors relies heavily on prior knowledge as well as experimental results. As is known to all, when we describe the object of an image into text via natural language, we only focus on the pivotal characteristics, and rarely pay attention to common characteristics as well as the background areas. This is an involuntary transfer from human visual attention to textual attention, which leads to the fact that textual attention tells us how many and which parts are discriminative and significant. So textual attention of natural language descriptions could help us to discover visual attention in image. Inspired by this, we propose a visual-textual attention driven fine-grained representation learning (VTA) approach, and its main contributions are: (1) Fine-grained visual-textual pattern mining devotes to discovering discriminative visual-textual pairwise information for boosting classification through jointly modeling vision and text with generative adversarial networks (GANs), which automatically and adaptively discovers discriminative parts. (2) Visual-textual representation learning jointly combine visual and textual information, which preserves the intra-modality and inter-modality information to generate complementary fine-grained representation, and further improve classification performance. Experiments on the two widely-used datasets demonstrate the effectiveness of our VTA approach, which achieves the best classification accuracy. version:1
arxiv-1708-09684 | On Boosting, Tug of War, and Lexicographic Programming | http://arxiv.org/abs/1708.09684 | id:1708.09684 author:Shounak Datta, Sayak Nag, Swagatam Das category:cs.CV  published:2017-08-31 summary:Despite the large amount of research effort dedicated to adapting boosting for imbalanced classification, boosting methods are yet to be satisfactorily immune to class imbalance, especially for multi-class problems, due to the long-standing reliance on expensive cost set tuning. We show that the assignment of weights to the component classifiers of a boosted ensemble can be thought of as a game of Tug of War between the classes in the margin space. We then demonstrate how this insight can be used to attain a good compromise between the rare and abundant classes without having to resort to cost set tuning, which has long been the norm for imbalanced classification. The solution is based on a lexicographic linear programming framework which requires two stages. Initially, class-specific component weight combinations are found so as to minimize a hinge loss individually for each of the classes. Subsequently, the final component weights are assigned so that the maximum deviation from the class-specific minimum loss values (obtained in the previous stage) is minimized. Hence, the proposal is not only restricted to two-class situations, but is also readily applicable to multi-class problems. We also derive the dual formulation corresponding to the proposed framework. Experiments conducted on artificial and real-world imbalanced datasets as well as challenging applications such as hyperspectral image classification and ImageNet classification establish the efficacy of the proposal. version:1
arxiv-1708-09644 | Abnormal Event Detection in Videos using Generative Adversarial Nets | http://arxiv.org/abs/1708.09644 | id:1708.09644 author:Mahdyar Ravanbakhsh, Moin Nabi, Enver Sangineto, Lucio Marcenaro, Carlo Regazzoni, Nicu Sebe category:cs.CV cs.MM  published:2017-08-31 summary:In this paper we address the abnormality detection problem in crowded scenes. We propose to use Generative Adversarial Nets (GANs), which are trained using normal frames and corresponding optical-flow images in order to learn an internal representation of the scene normality. Since our GANs are trained with only normal data, they are not able to generate abnormal events. At testing time the real data are compared with both the appearance and the motion representations reconstructed by our GANs and abnormal areas are detected by computing local differences. Experimental results on challenging abnormality detection datasets show the superiority of the proposed method compared to the state of the art in both frame-level and pixel-level abnormality detection tasks. version:1
arxiv-1708-09642 | Neural Class-Specific Regression for face verification | http://arxiv.org/abs/1708.09642 | id:1708.09642 author:Guanqun Cao, Alexandros Iosifidis, Moncef Gabbouj category:cs.CV  published:2017-08-31 summary:Face verification is a problem approached in the literature mainly using nonlinear class-specific subspace learning techniques. While it has been shown that kernel-based Class-Specific Discriminant Analysis is able to provide excellent performance in small- and medium-scale face verification problems, its application in today's large-scale problems is difficult due to its training space and computational requirements. In this paper, generalizing our previous work on kernel-based class-specific discriminant analysis, we show that class-specific subspace learning can be cast as a regression problem. This allows us to derive linear, (reduced) kernel and neural network-based class-specific discriminant analysis methods using efficient batch and/or iterative training schemes, suited for large-scale learning problems. We test the performance of these methods in two datasets describing medium- and large-scale face verification problems. version:1
arxiv-1708-09641 | Automatic Semantic Style Transfer using Deep Convolutional Neural Networks and Soft Masks | http://arxiv.org/abs/1708.09641 | id:1708.09641 author:Huihuang Zhao, Paul L. Rosin, Yu-Kun Lai category:cs.CV  published:2017-08-31 summary:This paper presents an automatic image synthesis method to transfer the style of an example image to a content image. When standard neural style transfer approaches are used, the textures and colours in different semantic regions of the style image are often applied inappropriately to the content image, ignoring its semantic layout, and ruining the transfer result. In order to reduce or avoid such effects, we propose a novel method based on automatically segmenting the objects and extracting their soft semantic masks from the style and content images, in order to preserve the structure of the content image while having the style transferred. Each soft mask of the style image represents a specific part of the style image, corresponding to the soft mask of the content image with the same semantics. Both the soft masks and source images are provided as multichannel input to an augmented deep CNN framework for style transfer which incorporates a generative Markov random field (MRF) model. Results on various images show that our method outperforms the most recent techniques. version:1
arxiv-1708-09633 | ALCN: Meta-Learning for Contrast Normalization Applied to Robust 3D Pose Estimation | http://arxiv.org/abs/1708.09633 | id:1708.09633 author:Mahdi Rad, Peter M. Roth, Vincent Lepetit category:cs.CV  published:2017-08-31 summary:To be robust to illumination changes when detecting objects in images, the current trend is to train a Deep Network with training images captured under many different lighting conditions. Unfortunately, creating such a training set is very cumbersome, or sometimes even impossible, for some applications such as 3D pose estimation of specific objects, which is the application we focus on in this paper. We therefore propose a novel illumination normalization method that lets us learn to detect objects and estimate their 3D pose under challenging illumination conditions from very few training samples. Our key insight is that normalization parameters should adapt to the input image. In particular, we realized this via a Convolutional Neural Network trained to predict the parameters of a generalization of the Difference-of-Gaussians method. We show that our method significantly outperforms standard normalization methods and demonstrate it on two challenging 3D detection and pose estimation problems. version:1
arxiv-1708-09609 | Identifying Products in Online Cybercrime Marketplaces: A Dataset for Fine-grained Domain Adaptation | http://arxiv.org/abs/1708.09609 | id:1708.09609 author:Greg Durrett, Jonathan K. Kummerfeld, Taylor Berg-Kirkpatrick, Rebecca S. Portnoff, Sadia Afroz, Damon McCoy, Kirill Levchenko, Vern Paxson category:cs.CL I.2.7  published:2017-08-31 summary:One weakness of machine-learned NLP models is that they typically perform poorly on out-of-domain data. In this work, we study the task of identifying products being bought and sold in online cybercrime forums, which exhibits particularly challenging cross-domain effects. We formulate a task that represents a hybrid of slot-filling information extraction and named entity recognition and annotate data from four different forums. Each of these forums constitutes its own "fine-grained domain" in that the forums cover different market sectors with different properties, even though all forums are in the broad domain of cybercrime. We characterize these domain differences in the context of a learning-based system: supervised models see decreased accuracy when applied to new forums, and standard techniques for semi-supervised learning and domain adaptation have limited effectiveness on this data, which suggests the need to improve these techniques. We release a dataset of 1,938 annotated posts from across the four forums. version:1
arxiv-1708-09585 | ICDAR2017 Competition on Reading Chinese Text in the Wild (RCTW-17) | http://arxiv.org/abs/1708.09585 | id:1708.09585 author:Baoguang Shi, Cong Yao, Minghui Liao, Mingkun Yang, Pei Xu, Linyan Cui, Serge Belongie, Shijian Lu, Xiang Bai category:cs.CV  published:2017-08-31 summary:Chinese is the most widely used language in the world. Algorithms that read Chinese text in natural images facilitate applications of various kinds. Despite the large potential value, datasets and competitions in the past primarily focus on English, which bares very different characteristics than Chinese. This report introduces RCTW, a new competition that focuses on Chinese text reading. The competition features a large-scale dataset with over 12,000 annotated images. Two tasks, namely text localization and end-to-end recognition, are set up. The competition took place from January 20 to May 31, 2017. 23 valid submissions were received from 19 teams. This report includes dataset description, task definitions, evaluation protocols, and results summaries and analysis. Through this competition, we call for more future research on the Chinese text reading problem. version:1
arxiv-1708-04673 | Acoustic Feature Learning via Deep Variational Canonical Correlation Analysis | http://arxiv.org/abs/1708.04673 | id:1708.04673 author:Qingming Tang, Weiran Wang, Karen Livescu category:cs.CV  published:2017-08-11 summary:We study the problem of acoustic feature learning in the setting where we have access to another (non-acoustic) modality for feature learning but not at test time. We use deep variational canonical correlation analysis (VCCA), a recently proposed deep generative method for multi-view representation learning. We also extend VCCA with improved latent variable priors and with adversarial learning. Compared to other techniques for multi-view feature learning, VCCA's advantages include an intuitive latent variable interpretation and a variational lower bound objective that can be trained end-to-end efficiently. We compare VCCA and its extensions with previous feature learning methods on the University of Wisconsin X-ray Microbeam Database, and show that VCCA-based feature learning improves over previous methods for speaker-independent phonetic recognition. version:2
arxiv-1708-09580 | Fast Landmark Localization with 3D Component Reconstruction and CNN for Cross-Pose Recognition | http://arxiv.org/abs/1708.09580 | id:1708.09580 author:Gee-Sern, Hsu, Hung-Cheng Shie, Cheng-Hua Hsieh category:cs.CV  published:2017-08-31 summary:Two approaches are proposed for cross-pose face recognition, one is based on the 3D reconstruction of facial components and the other is based on the deep Convolutional Neural Network (CNN). Unlike most 3D approaches that consider holistic faces, the proposed approach considers 3D facial components. It segments a 2D gallery face into components, reconstructs the 3D surface for each component, and recognizes a probe face by component features. The segmentation is based on the landmarks located by a hierarchical algorithm that combines the Faster R-CNN for face detection and the Reduced Tree Structured Model for landmark localization. The core part of the CNN-based approach is a revised VGG network. We study the performances with different settings on the training set, including the synthesized data from 3D reconstruction, the real-life data from an in-the-wild database, and both types of data combined. We investigate the performances of the network when it is employed as a classifier or designed as a feature extractor. The two recognition approaches and the fast landmark localization are evaluated in extensive experiments, and compared to stateof-the-art methods to demonstrate their efficacy. version:1
arxiv-1708-09545 | Video Summarization with Attention-Based Encoder-Decoder Networks | http://arxiv.org/abs/1708.09545 | id:1708.09545 author:Zhong Ji, Kailin Xiong, Yanwei Pang, Xuelong Li category:cs.CV  published:2017-08-31 summary:This paper addresses the problem of supervised video summarization by formulating it as a sequence-to-sequence learning problem, where the input is a sequence of original video frames, the output is a keyshot sequence. Our key idea is to learn a deep summarization network with attention mechanism to mimic the way of selecting the keyshots of human. To this end, we propose a novel video summarization framework named Attentive encoder-decoder networks for Video Summarization (AVS), in which the encoder uses a Bidirectional Long Short-Term Memory (BiLSTM) to encode the contextual information among the input video frames. As for the decoder, two attention-based LSTM networks are explored by using additive and multiplicative objective functions, respectively. Extensive experiments are conducted on three video summarization benchmark datasets, i.e., SumMe, TVSum, and YouTube. The results demonstrate the superiority of the proposed AVS-based approaches against the state-of-the-art approaches, with remarkable improvements from 3% to 11% on the three datasets, respectively. version:1
arxiv-1708-09533 | Learning a Generative Adversarial Network for High Resolution Artwork Synthesis | http://arxiv.org/abs/1708.09533 | id:1708.09533 author:Wei Ren Tan, Chee Seng Chan, Hernan Aguirre, Kiyoshi Tanaka category:cs.CV  published:2017-08-31 summary:Artwork is a mode of creative expression and this paper is particularly interested in investigating if machine can learn and synthetically create artwork that are usually non- figurative and structured abstract. To this end, we propose an extension to the Generative Adversarial Network (GAN), namely as the ArtGAN to synthetically generate high quality artwork. This is in contrast to most of the current solutions that focused on generating structural images such as birds, flowers and faces. The key innovation of our work is to allow back-propagation of the loss function w.r.t. the labels (randomly assigned to each generated images) to the generator from the categorical autoencoder-based discriminator that incorporates an autoencoder into the categorical discriminator for additional complementary information. In order to synthesize a high reso- lution artwork, we include a novel magnified learning strategy to improve the correlations between neighbouring pixels. Based on visual inspection and Inception scores, we demonstrate that ArtGAN is able to draw high resolution and realistic artwork, as well as generate images of much higher quality in four other datasets (i.e. CIFAR-10, STL-10, Oxford-102 and CUB-200). version:1
arxiv-1708-09522 | Action Classification and Highlighting in Videos | http://arxiv.org/abs/1708.09522 | id:1708.09522 author:Atousa Torabi, Leonid Sigal category:cs.CV  published:2017-08-31 summary:Inspired by recent advances in neural machine translation, that jointly align and translate using encoder-decoder networks equipped with attention, we propose an attentionbased LSTM model for human activity recognition. Our model jointly learns to classify actions and highlight frames associated with the action, by attending to salient visual information through a jointly learned soft-attention networks. We explore attention informed by various forms of visual semantic features, including those encoding actions, objects and scenes. We qualitatively show that soft-attention can learn to effectively attend to important objects and scene information correlated with specific human actions. Further, we show that, quantitatively, our attention-based LSTM outperforms the vanilla LSTM and CNN models used by stateof-the-art methods. On a large-scale youtube video dataset, ActivityNet, our model outperforms competing methods in action classification. version:1
arxiv-1708-09516 | Leveraging Deep Neural Network Activation Entropy to cope with Unseen Data in Speech Recognition | http://arxiv.org/abs/1708.09516 | id:1708.09516 author:Vikramjit Mitra, Horacio Franco category:cs.LG cs.CL stat.ML  published:2017-08-31 summary:Unseen data conditions can inflict serious performance degradation on systems relying on supervised machine learning algorithms. Because data can often be unseen, and because traditional machine learning algorithms are trained in a supervised manner, unsupervised adaptation techniques must be used to adapt the model to the unseen data conditions. However, unsupervised adaptation is often challenging, as one must generate some hypothesis given a model and then use that hypothesis to bootstrap the model to the unseen data conditions. Unfortunately, reliability of such hypotheses is often poor, given the mismatch between the training and testing datasets. In such cases, a model hypothesis confidence measure enables performing data selection for the model adaptation. Underlying this approach is the fact that for unseen data conditions, data variability is introduced to the model, which the model propagates to its output decision, impacting decision reliability. In a fully connected network, this data variability is propagated as distortions from one layer to the next. This work aims to estimate the propagation of such distortion in the form of network activation entropy, which is measured over a short- time running window on the activation from each neuron of a given hidden layer, and these measurements are then used to compute summary entropy. This work demonstrates that such an entropy measure can help to select data for unsupervised model adaptation, resulting in performance gains in speech recognition tasks. Results from standard benchmark speech recognition tasks show that the proposed approach can alleviate the performance degradation experienced under unseen data conditions by iteratively adapting the model to the unseen datas acoustic condition. version:1
arxiv-1708-09497 | Unsupervised Induction of Contingent Event Pairs from Film Scenes | http://arxiv.org/abs/1708.09497 | id:1708.09497 author:Zhichao Hu, Elahe Rahimtoroghi, Larissa Munishkina, Reid Swanson, Marilyn A. Walker category:cs.CL  published:2017-08-30 summary:Human engagement in narrative is partially driven by reasoning about discourse relations between narrative events, and the expectations about what is likely to happen next that results from such reasoning. Researchers in NLP have tackled modeling such expectations from a range of perspectives, including treating it as the inference of the contingent discourse relation, or as a type of common-sense causal reasoning. Our approach is to model likelihood between events by drawing on several of these lines of previous work. We implement and evaluate different unsupervised methods for learning event pairs that are likely to be contingent on one another. We refine event pairs that we learn from a corpus of film scene descriptions utilizing web search counts, and evaluate our results by collecting human judgments of contingency. Our results indicate that the use of web search counts increases the average accuracy of our best method to 85.64% over a baseline of 50%, as compared to an average accuracy of 75.15% without web search. version:1
arxiv-1708-09496 | Inferring Narrative Causality between Event Pairs in Films | http://arxiv.org/abs/1708.09496 | id:1708.09496 author:Zhichao Hu, Marilyn A. Walker category:cs.CL  published:2017-08-30 summary:To understand narrative, humans draw inferences about the underlying relations between narrative events. Cognitive theories of narrative understanding define these inferences as four different types of causality, that include pairs of events A, B where A physically causes B (X drop, X break), to pairs of events where A causes emotional state B (Y saw X, Y felt fear). Previous work on learning narrative relations from text has either focused on "strict" physical causality, or has been vague about what relation is being learned. This paper learns pairs of causal events from a corpus of film scene descriptions which are action rich and tend to be told in chronological order. We show that event pairs induced using our methods are of high quality and are judged to have a stronger causal relation than event pairs from Rel-grams. version:1
arxiv-1708-09492 | Automatically Generating Commit Messages from Diffs using Neural Machine Translation | http://arxiv.org/abs/1708.09492 | id:1708.09492 author:Siyuan Jiang, Ameer Armaly, Collin McMillan category:cs.SE cs.CL  published:2017-08-30 summary:Commit messages are a valuable resource in comprehension of software evolution, since they provide a record of changes such as feature additions and bug repairs. Unfortunately, programmers often neglect to write good commit messages. Different techniques have been proposed to help programmers by automatically writing these messages. These techniques are effective at describing what changed, but are often verbose and lack context for understanding the rationale behind a change. In contrast, humans write messages that are short and summarize the high level rationale. In this paper, we adapt Neural Machine Translation (NMT) to automatically "translate" diffs into commit messages. We trained an NMT algorithm using a corpus of diffs and human-written commit messages from the top 1k Github projects. We designed a filter to help ensure that we only trained the algorithm on higher-quality commit messages. Our evaluation uncovered a pattern in which the messages we generate tend to be either very high or very low quality. Therefore, we created a quality-assurance filter to detect cases in which we are unable to produce good messages, and return a warning instead. version:1
arxiv-1708-09479 | Graphical Lasso and Thresholding: Equivalence and Closed-form Solutions | http://arxiv.org/abs/1708.09479 | id:1708.09479 author:Salar Fattahi, Somayeh Sojoudi category:stat.ML  published:2017-08-30 summary:Graphical Lasso (GL) is a popular method for learning the structure of an undirected graphical model, which is based on an $l_1$ regularization technique. The first goal of this work is to study the behavior of the optimal solution of GL as a function of its regularization coefficient. We show that if the number of samples is not too small compared to the number of parameters, the sparsity pattern of the optimal solution of GL changes gradually when the regularization coefficient increases from 0 to infinity. The second objective of this paper is to compare the computationally-heavy GL technique with a numerically-cheap heuristic method for learning graphical models that is based on simply thresholding the sample correlation matrix. To this end, two notions of sign-consistent and inverse-consistent matrices are developed, and then it is shown that the thresholding and GL methods are equivalent if: (i) the thresholded sample correlation matrix is both sign-consistent and inverse-consistent, and (ii) the gap between the largest thresholded and the smallest un-thresholded entries of the sample correlation matrix is not too small. By building upon this result, it is proved that the GL method--as a conic optimization problem--has an explicit closed-form solution if the thresholded sample correlation matrix has an acyclic structure. This result is then generalized to arbitrary sparse support graphs, where a formula is found to obtain an approximate solution of GL. The closed-form solution approximately satisfies the KKT conditions for the GL problem and, more importantly, the approximation error decreases exponentially fast with respect to the length of the minimum-length cycle of the sparsity graph. The developed results are demonstrated on synthetic data, electrical circuits, functional MRI data, and traffic flows for transportation networks. version:1
arxiv-1706-09563 | Online Convolutional Dictionary Learning | http://arxiv.org/abs/1706.09563 | id:1706.09563 author:Jialin Liu, Cristina Garcia-Cardona, Brendt Wohlberg, Wotao Yin category:cs.LG cs.CV  published:2017-06-29 summary:While a number of different algorithms have recently been proposed for convolutional dictionary learning, this remains an expensive problem. The single biggest impediment to learning from large training sets is the memory requirements, which grow at least linearly with the size of the training set since all existing methods are batch algorithms. The work reported here addresses this limitation by extending online dictionary learning ideas to the convolutional context. version:2
arxiv-1709-00291 | Asymptotic Bias of Stochastic Gradient Search | http://arxiv.org/abs/1709.00291 | id:1709.00291 author:Vladislav B. Tadic, Arnaud Doucet category:math.ST math.OC stat.ML stat.TH  published:2017-08-30 summary:The asymptotic behavior of the stochastic gradient algorithm with a biased gradient estimator is analyzed. Relying on arguments based on the dynamic system theory (chain-recurrence) and the differential geometry (Yomdin theorem and Lojasiewicz inequality), tight bounds on the asymptotic bias of the iterates generated by such an algorithm are derived. The obtained results hold under mild conditions and cover a broad class of high-dimensional nonlinear algorithms. Using these results, the asymptotic properties of the policy-gradient (reinforcement) learning and adaptive population Monte Carlo sampling are studied. Relying on the same results, the asymptotic behavior of the recursive maximum split-likelihood estimation in hidden Markov models is analyzed, too. version:1
arxiv-1708-09417 | LangPro: Natural Language Theorem Prover | http://arxiv.org/abs/1708.09417 | id:1708.09417 author:Lasha Abzianidze category:cs.CL 68T50 I.2.7  published:2017-08-30 summary:LangPro is an automated theorem prover for natural language (https://github.com/kovvalsky/LangPro). Given a set of premises and a hypothesis, it is able to prove semantic relations between them. The prover is based on a version of analytic tableau method specially designed for natural logic. The proof procedure operates on logical forms that preserve linguistic expressions to a large extent. %This property makes the logical forms easily obtainable from syntactic trees. %, in particular, Combinatory Categorial Grammar derivation trees. The nature of proofs is deductive and transparent. On the FraCaS and SICK textual entailment datasets, the prover achieves high results comparable to state-of-the-art. version:1
arxiv-1708-06500 | Sparsity Invariant CNNs | http://arxiv.org/abs/1708.06500 | id:1708.06500 author:Jonas Uhrig, Nick Schneider, Lukas Schneider, Uwe Franke, Thomas Brox, Andreas Geiger category:cs.CV  published:2017-08-22 summary:In this paper, we consider convolutional neural networks operating on sparse inputs with an application to depth upsampling from sparse laser scan data. First, we show that traditional convolutional networks perform poorly when applied to sparse data even when the location of missing data is provided to the network. To overcome this problem, we propose a simple yet effective sparse convolution layer which explicitly considers the location of missing data during the convolution operation. We demonstrate the benefits of the proposed network architecture in synthetic and real experiments with respect to various baseline approaches. Compared to dense baselines, the proposed sparse convolution network generalizes well to novel datasets and is invariant to the level of sparsity in the data. For our evaluation, we derive a novel dataset from the KITTI benchmark, comprising 93k depth annotated RGB images. Our dataset allows for training and evaluating depth upsampling and depth prediction techniques in challenging real-world settings and will be made available upon publication. version:2
arxiv-1708-09403 | Fast(er) Exact Decoding and Global Training for Transition-Based Dependency Parsing via a Minimal Feature Set | http://arxiv.org/abs/1708.09403 | id:1708.09403 author:Tianze Shi, Liang Huang, Lillian Lee category:cs.CL I.2.7  published:2017-08-30 summary:We first present a minimal feature set for transition-based dependency parsing, continuing a recent trend started by Kiperwasser and Goldberg (2016a) and Cross and Huang (2016a) of using bi-directional LSTM features. We plug our minimal feature set into the dynamic-programming framework of Huang and Sagae (2010) and Kuhlmann et al. (2011) to produce the first implementation of worst-case O(n^3) exact decoders for arc-hybrid and arc-eager transition systems. With our minimal features, we also present O(n^3) global training methods. Finally, using ensembles including our new parsers, we achieve the best unlabeled attachment score reported (to our knowledge) on the Chinese Treebank and the "second-best-in-class" result on the English Penn Treebank. version:1
arxiv-1708-05529 | Word Searching in Scene Image and Video Frame in Multi-Script Scenario using Dynamic Shape Coding | http://arxiv.org/abs/1708.05529 | id:1708.05529 author:Partha Pratim Roy, Ayan Kumar Bhunia, Avirup Bhattacharyya, Umapada Pal category:cs.CV cs.IR  published:2017-08-18 summary:Retrieval of text information from natural scene images and video frames is a challenging task due to its inherent problems like complex character shapes, low resolution, background noise, etc. Available OCR systems often fail to retrieve such information in scene/video frames. Keyword spotting, an alternative way to retrieve information, performs efficient text searching in such scenarios. However, current word spotting techniques in scene/video images are script-specific and they are mainly developed for Latin script. This paper presents a novel word spotting framework using dynamic shape coding for text retrieval in natural scene image and video frames. The framework is designed to search query keyword from multiple scripts with the help of on-the-fly script-wise keyword generation for the corresponding script. We have used a two-stage word spotting approach using Hidden Markov Model (HMM) to detect the translated keyword in a given text line by identifying the script of the line. A novel unsupervised dynamic shape coding based scheme has been used to group similar shape characters to avoid confusion and to improve text alignment. Next, the hypotheses locations are verified to improve retrieval performance. To evaluate the proposed system for searching keyword from natural scene image and video frames, we have considered two popular Indic scripts such as Bangla (Bengali) and Devanagari along with English. Inspired by the zone-wise recognition approach in Indic scripts[1], zone-wise text information has been used to improve the traditional word spotting performance in Indic scripts. For our experiment, a dataset consisting of images of different scenes and video frames of English, Bangla and Devanagari scripts were considered. The results obtained showed the effectiveness of our proposed word spotting approach. version:2
arxiv-1708-05279 | Designing and building the mlpack open-source machine learning library | http://arxiv.org/abs/1708.05279 | id:1708.05279 author:Ryan R. Curtin, Marcus Edel category:cs.MS cs.LG cs.SE  published:2017-08-17 summary:mlpack is an open-source C++ machine learning library with an emphasis on speed and flexibility. Since its original inception in 2007, it has grown to be a large project implementing a wide variety of machine learning algorithms, from standard techniques such as decision trees and logistic regression to modern techniques such as deep neural networks as well as other recently-published cutting-edge techniques not found in any other library. mlpack is quite fast, with benchmarks showing mlpack outperforming other libraries' implementations of the same methods. mlpack has an active community, with contributors from around the world---including some from PUST. This short paper describes the goals and design of mlpack, discusses how the open-source community functions, and shows an example usage of mlpack for a simple data science problem. version:2
arxiv-1708-09321 | Adversarial nets with perceptual losses for text-to-image synthesis | http://arxiv.org/abs/1708.09321 | id:1708.09321 author:Miriam Cha, Youngjune Gwon, H. T. Kung category:cs.CV  published:2017-08-30 summary:Recent approaches in generative adversarial networks (GANs) can automatically synthesize realistic images from descriptive text. Despite the overall fair quality, the generated images often expose visible flaws that lack structural definition for an object of interest. In this paper, we aim to extend state of the art for GAN-based text-to-image synthesis by improving perceptual quality of generated images. Differentiated from previous work, our synthetic image generator optimizes on perceptual loss functions that measure pixel, feature activation, and texture differences against a natural image. We present visually more compelling synthetic images of birds and flowers generated from text descriptions in comparison to some of the most prominent existing work. version:1
arxiv-1708-09317 | Disguised Face Identification (DFI) with Facial KeyPoints using Spatial Fusion Convolutional Network | http://arxiv.org/abs/1708.09317 | id:1708.09317 author:Amarjot Singh, Devendra Patil, G Meghana Reddy, SN Omkar category:cs.CV  published:2017-08-30 summary:Disguised face identification (DFI) is an extremely challenging problem due to the numerous variations that can be introduced using different disguises. This paper introduces a deep learning framework to first detect 14 facial key-points which are then utilized to perform disguised face identification. Since the training of deep learning architectures relies on large annotated datasets, two annotated facial key-points datasets are introduced. The effectiveness of the facial keypoint detection framework is presented for each keypoint. The superiority of the key-point detection framework is also demonstrated by a comparison with other deep networks. The effectiveness of classification performance is also demonstrated by comparison with the state-of-the-art face disguise classification methods. version:1
arxiv-1708-09300 | Texture and Structure Incorporated ScatterNet Hybrid Deep Learning Network (TS-SHDL) For Brain Matter Segmentation | http://arxiv.org/abs/1708.09300 | id:1708.09300 author:Amarjot Singh, Devamanyu Hazarika, Aniruddha Bhattacharya category:cs.CV  published:2017-08-30 summary:Automation of brain matter segmentation from MR images is a challenging task due to the irregular boundaries between the grey and white matter regions. In addition, the presence of intensity inhomogeneity in the MR images further complicates the problem. In this paper, we propose a texture and vesselness incorporated version of the ScatterNet Hybrid Deep Learning Network (TS-SHDL) that extracts hierarchical invariant mid-level features, used by fisher vector encoding and a conditional random field (CRF) to perform the desired segmentation. The performance of the proposed network is evaluated by extensive experimentation and comparison with the state-of-the-art methods on several 2D MRI scans taken from the synthetic McGill Brain Web as well as on the MRBrainS dataset of real 3D MRI scans. The advantages of the TS-SHDL network over supervised deep learning networks is also presented in addition to its superior performance over the state-of-the-art. version:1
arxiv-1708-09268 | Two-stream Flow-guided Convolutional Attention Networks for Action Recognition | http://arxiv.org/abs/1708.09268 | id:1708.09268 author:An Tran, Loong-Fah Cheong category:cs.CV  published:2017-08-30 summary:This paper proposes a two-stream flow-guided convolutional attention networks for action recognition in videos. The central idea is that optical flows, when properly compensated for the camera motion, can be used to guide attention to the human foreground. We thus develop cross-link layers from the temporal network (trained on flows) to the spatial network (trained on RGB frames). These cross-link layers guide the spatial-stream to pay more attention to the human foreground areas and be less affected by background clutter. We obtain promising performances with our approach on the UCF101, HMDB51 and Hollywood2 datasets. version:1
arxiv-1708-09259 | Efficient Convolutional Network Learning using Parametric Log based Dual-Tree Wavelet ScatterNet | http://arxiv.org/abs/1708.09259 | id:1708.09259 author:Amarjot Singh, Nick Kingsbury category:cs.LG stat.ML  published:2017-08-30 summary:We propose a DTCWT ScatterNet Convolutional Neural Network (DTSCNN) formed by replacing the first few layers of a CNN network with a parametric log based DTCWT ScatterNet. The ScatterNet extracts edge based invariant representations that are used by the later layers of the CNN to learn high-level features. This improves the training of the network as the later layers can learn more complex patterns from the start of learning because the edge representations are already present. The efficient learning of the DTSCNN network is demonstrated on CIFAR-10 and Caltech-101 datasets. The generic nature of the ScatterNet front-end is shown by an equivalent performance to pre-trained CNN front-ends. A comparison with the state-of-the-art on CIFAR-10 and Caltech-101 datasets is also presented. version:1
arxiv-1708-05401 | Deformable Modeling for Human Body Acquired from Depth Sensors | http://arxiv.org/abs/1708.05401 | id:1708.05401 author:Vamshhi Pavan Kumar Varma Vegeshna category:cs.CV  published:2017-08-17 summary:This paper presents a novel approach to reconstruct complete 3D deformable models over time by a single depth camera. These are the steps employed for deforming objects from single depth camera. The partial surfaces reconstructed from various times of capture are assembled together to form a complete 3D surface. A mesh warping algorithm is used to align different partial surfaces based on linear mesh deformation. A volumetric method is then applied to combine partial surfaces, fix missing holes and smooth alignment errors. version:2
arxiv-1708-07987 | Stereo Matching With Color-Weighted Correlation, Hierarchical Belief Propagation And Occlusion Handling | http://arxiv.org/abs/1708.07987 | id:1708.07987 author:Vamshhi Pavan Kumar Varma Vegeshna category:cs.CV  published:2017-08-26 summary:In this paper, we contrive a stereo matching algorithm with careful handling of disparity, discontinuity and occlusion. This algorithm works a worldwide matching stereo model which is based on minimization of energy. The global energy comprises two terms, firstly the data term and secondly the smoothness term. The data term is approximated by a color-weighted correlation, then refined in obstruct and low-texture areas in many applications of hierarchical loopy belief propagation algorithm. The results during the experiment are evaluated on the Middlebury data sets, showing that out algorithm is the top performer among all the algorithms listed there version:2
arxiv-1708-09234 | Fighting with the Sparsity of Synonymy Dictionaries | http://arxiv.org/abs/1708.09234 | id:1708.09234 author:Dmitry Ustalov, Mikhail Chernoskutov, Chris Biemann, Alexander Panchenko category:cs.CL I.2.6; I.5.3; I.2.4  published:2017-08-30 summary:Graph-based synset induction methods, such as MaxMax and Watset, induce synsets by performing a global clustering of a synonymy graph. However, such methods are sensitive to the structure of the input synonymy graph: sparseness of the input dictionary can substantially reduce the quality of the extracted synsets. In this paper, we propose two different approaches designed to alleviate the incompleteness of the input dictionaries. The first one performs a pre-processing of the graph by adding missing edges, while the second one performs a post-processing by merging similar synset clusters. We evaluate these approaches on two datasets for the Russian language and discuss their impact on the performance of synset induction methods. Finally, we perform an extensive error analysis of each approach and discuss prominent alternative methods for coping with the problem of the sparsity of the synonymy dictionaries. version:1
arxiv-1708-01902 | Universally consistent predictive distributions | http://arxiv.org/abs/1708.01902 | id:1708.01902 author:Vladimir Vovk category:cs.LG  published:2017-08-06 summary:This paper describes simple universally consistent procedures of probability forecasting that satisfy a natural property of small-sample validity, under the assumption that the observations are produced independently in the IID fashion. version:2
arxiv-1708-09217 | Look-ahead Attention for Generation in Neural Machine Translation | http://arxiv.org/abs/1708.09217 | id:1708.09217 author:Long Zhou, Jiajun Zhang, Chengqing Zong category:cs.CL  published:2017-08-30 summary:The attention model has become a standard component in neural machine translation (NMT) and it guides translation process by selectively focusing on parts of the source sentence when predicting each target word. However, we find that the generation of a target word does not only depend on the source sentence, but also rely heavily on the previous generated target words, especially the distant words which are difficult to model by using recurrent neural networks. To solve this problem, we propose in this paper a novel look-ahead attention mechanism for generation in NMT, which aims at directly capturing the dependency relationship between target words. We further design three patterns to integrate our look-ahead attention into the conventional attention model. Experiments on NIST Chinese-to-English and WMT English-to-German translation tasks show that our proposed look-ahead attention mechanism achieves substantial improvements over state-of-the-art baselines. version:1
arxiv-1708-09212 | ScatterNet Hybrid Deep Learning (SHDL) Network For Object Classification | http://arxiv.org/abs/1708.09212 | id:1708.09212 author:Amarjot Singh, Nick Kingsbury category:cs.CV  published:2017-08-30 summary:The paper proposes the ScatterNet Hybrid Deep Learning (SHDL) network that extracts invariant and discriminative image representations for object recognition. SHDL framework is constructed with a multi-layer ScatterNet front-end, an unsupervised learning middle, and a supervised learning back-end module. Each layer of the SHDL network is automatically designed as an explicit optimization problem leading to an optimal deep learning architecture with improved computational performance as compared to the more usual deep network architectures. SHDL network produces the state-of-the-art classification performance against unsupervised and semi-supervised learning (GANs) on two image datasets. Advantages of the SHDL network over supervised methods (NIN, VGG) are also demonstrated with experiments performed on training datasets of reduced size. version:1
arxiv-1708-09204 | Cascade Residual Learning: A Two-stage Convolutional Neural Network for Stereo Matching | http://arxiv.org/abs/1708.09204 | id:1708.09204 author:Jiahao Pang, Wenxiu Sun, Jimmy SJ. Ren, Chengxi Yang, Qiong Yan category:cs.CV  published:2017-08-30 summary:Leveraging on the recent developments in convolutional neural networks (CNNs), matching dense correspondence from a stereo pair has been cast as a learning problem, with performance exceeding traditional approaches. However, it remains challenging to generate high-quality disparities for the inherently ill-posed regions. To tackle this problem, we propose a novel cascade CNN architecture composing of two stages. The first stage advances the recently proposed DispNet by equipping it with extra up-convolution modules, leading to disparity images with more details. The second stage explicitly rectifies the disparity initialized by the first stage; it couples with the first-stage and generates residual signals across multiple scales. The summation of the outputs from the two stages gives the final disparity. As opposed to directly learning the disparity at the second stage, we show that residual learning provides more effective refinement. Moreover, it also benefits the training of the overall cascade network. Experimentation shows that our cascade residual learning scheme provides state-of-the-art performance for matching stereo correspondence. By the time of the submission of this paper, our method ranks first in the KITTI 2015 stereo benchmark, surpassing the prior works by a noteworthy margin. version:1
arxiv-1708-09200 | Joint Maximum Purity Forest with Application to Image Super-Resolution | http://arxiv.org/abs/1708.09200 | id:1708.09200 author:Hailiang Li, Kin-Man Lam, Dong Li category:cs.CV  published:2017-08-30 summary:In this paper, we propose a novel random-forest scheme, namely Joint Maximum Purity Forest (JMPF), for classification, clustering, and regression tasks. In the JMPF scheme, the original feature space is transformed into a compactly pre-clustered feature space, via a trained rotation matrix. The rotation matrix is obtained through an iterative quantization process, where the input data belonging to different classes are clustered to the respective vertices of the new feature space with maximum purity. In the new feature space, orthogonal hyperplanes, which are employed at the split-nodes of decision trees in random forests, can tackle the clustering problems effectively. We evaluated our proposed method on public benchmark datasets for regression and classification tasks, and experiments showed that JMPF remarkably outperforms other state-of-the-art random-forest-based approaches. Furthermore, we applied JMPF to image super-resolution, because the transformed, compact features are more discriminative to the clustering-regression scheme. Experiment results on several public benchmark datasets also showed that the JMPF-based image super-resolution scheme is consistently superior to recent state-of-the-art image super-resolution algorithms. version:1
arxiv-1708-09182 | A Greedy Part Assignment Algorithm for Real-time Multi-person 2D Pose Estimation | http://arxiv.org/abs/1708.09182 | id:1708.09182 author:Srenivas Varadarajan, Parual Datta, Omesh Tickoo category:cs.CV  published:2017-08-30 summary:Human pose-estimation in a multi-person image involves detection of various body parts and grouping them into individual person clusters. While the former task is challenging due to mutual occlusions, the combinatorial complexity of the latter task is very high. We propose a greedy part assignment algorithm that exploits the inherent structure of the human body to achieve a lower complexity, compared to any of the prior published works. This is accomplished by (i) reducing the number of part-candidates using the estimated number of people in the image, (ii) doing a greedy sequential assignment of part-classes, following the kinematic chain from head to ankle (iii) doing a greedy assignment of parts in each part-class set, to person-clusters (iv) limiting the candidate person clusters to the most proximal clusters using human anthropometric data and (v) using only a specific subset of pre-assigned parts for establishing pairwise structural constraints. We show that, these steps result in a sparse body parts relationship graph and reduces the complexity. We also propose methods for improving the accuracy of pose-estimation by (i) spawning person-clusters from any unassigned significant body part and (ii) suppressing hallucinated parts. On the MPII multi-person pose database, pose-estimation using the proposed method takes only 0.14 seconds per image. We show that, our proposed algorithm, by using a large spatial and structural context, achieves the state-of-the-art accuracy on both MPII and WAF multi-person pose datasets, demonstrating the robustness of our approach. version:1
arxiv-1708-09165 | Tensor Networks for Dimensionality Reduction and Large-Scale Optimizations. Part 2 Applications and Future Perspectives | http://arxiv.org/abs/1708.09165 | id:1708.09165 author:A. Cichocki, A-H. Phan, Q. Zhao, N. Lee, I. V. Oseledets, M. Sugiyama, D. Mandic category:cs.NA cs.LG  published:2017-08-30 summary:Part 2 of this monograph builds on the introduction to tensor networks and their operations presented in Part 1. It focuses on tensor network models for super-compressed higher-order representation of data/parameters and related cost functions, while providing an outline of their applications in machine learning and data analytics. A particular emphasis is on the tensor train (TT) and Hierarchical Tucker (HT) decompositions, and their physically meaningful interpretations which reflect the scalability of the tensor network approach. Through a graphical approach, we also elucidate how, by virtue of the underlying low-rank tensor approximations and sophisticated contractions of core tensors, tensor networks have the ability to perform distributed computations on otherwise prohibitively large volumes of data/parameters, thereby alleviating or even eliminating the curse of dimensionality. The usefulness of this concept is illustrated over a number of applied areas, including generalized regression and classification (support tensor machines, canonical correlation analysis, higher order partial least squares), generalized eigenvalue decomposition, Riemannian optimization, and in the optimization of deep neural networks. Part 1 and Part 2 of this work can be used either as stand-alone separate texts, or indeed as a conjoint comprehensive review of the exciting field of low-rank tensor networks and tensor decompositions. version:1
arxiv-1708-09163 | An Empirical Study of Discriminative Sequence Labeling Models for Vietnamese Text Processing | http://arxiv.org/abs/1708.09163 | id:1708.09163 author:Phuong Le-Hong, Minh Pham Quang Nhat, Thai-Hoang Pham, Tuan-Anh Tran, Dang-Minh Nguyen category:cs.CL  published:2017-08-30 summary:This paper presents an empirical study of two widely-used sequence prediction models, Conditional Random Fields (CRFs) and Long Short-Term Memory Networks (LSTMs), on two fundamental tasks for Vietnamese text processing, including part-of-speech tagging and named entity recognition. We show that a strong lower bound for labeling accuracy can be obtained by relying only on simple word-based features with minimal hand-crafted feature engineering, of 90.65\% and 86.03\% performance scores on the standard test sets for the two tasks respectively. In particular, we demonstrate empirically the surprising efficiency of word embeddings in both of the two tasks, with both of the two models. We point out that the state-of-the-art LSTMs model does not always outperform significantly the traditional CRFs model, especially on moderate-sized data sets. Finally, we give some suggestions and discussions for efficient use of sequence labeling models in practical applications. version:1
arxiv-1708-09157 | Cross-lingual, Character-Level Neural Morphological Tagging | http://arxiv.org/abs/1708.09157 | id:1708.09157 author:Ryan Cotterell, Georg Heigold category:cs.CL  published:2017-08-30 summary:Even for common NLP tasks, sufficient supervision is not available in many languages -- morphological tagging is no exception. In the work presented here, we explore a transfer learning scheme, whereby we train character-level recurrent neural taggers to predict morphological taggings for high-resource languages and low-resource languages together. Learning joint character representations among multiple related languages successfully enables knowledge transfer from the high-resource languages to the low-resource ones, improving accuracy by up to 30% version:1
arxiv-1708-09151 | Paradigm Completion for Derivational Morphology | http://arxiv.org/abs/1708.09151 | id:1708.09151 author:Ryan Cotterell, Ekaterina Vylomova, Huda Khayrallah, Christo Kirov, David Yarowsky category:cs.CL  published:2017-08-30 summary:The generation of complex derived word forms has been an overlooked problem in NLP; we fill this gap by applying neural sequence-to-sequence models to the task. We overview the theoretical motivation for a paradigmatic treatment of derivational morphology, and introduce the task of derivational paradigm completion as a parallel to inflectional paradigm completion. State-of-the-art neural models, adapted from the inflection task, are able to learn a range of derivation patterns, and outperform a non-neural baseline by 16.4%. However, due to semantic, historical, and lexical considerations involved in derivational morphology, future work will be needed to achieve performance parity with inflection-generating systems. version:1
arxiv-1708-09126 | Photorealistic Facial Expression Synthesis by the Conditional Difference Adversarial Autoencoder | http://arxiv.org/abs/1708.09126 | id:1708.09126 author:Yuqian Zhou, Bertram Emil Shi category:cs.CV  published:2017-08-30 summary:Photorealistic facial expression synthesis from single face image can be widely applied to face recognition, data augmentation for emotion recognition or entertainment. This problem is challenging, in part due to a paucity of labeled facial expression data, making it difficult for algorithms to disambiguate changes due to identity and changes due to expression. In this paper, we propose the conditional difference adversarial autoencoder, CDAAE, for facial expression synthesis. The CDAAE takes a facial image of a previously unseen person and generates an image of that human face with a target emotion or facial action unit label. The CDAAE adds a feedforward path to an autoencoder structure connecting low level features at the encoder to features at the corresponding level at the decoder. It handles the problem of disambiguating changes due to identity and changes due to facial expression by learning to generate the difference between low-level features of images of the same person but with different facial expressions. The CDAAE structure can be used to generate novel expressions by combining and interpolating between facial expressions/action units within the training set. Our experimental results demonstrate that the CDAAE can preserve identity information when generating facial expression for unseen subjects more faithfully than previous approaches. This is especially advantageous when training with small databases. version:1
arxiv-1708-09121 | Interpretable Categorization of Heterogeneous Time Series Data | http://arxiv.org/abs/1708.09121 | id:1708.09121 author:Ritchie Lee, Mykel J. Kochenderfer, Ole J. Mengshoel, Joshua Silbermann category:cs.LG  published:2017-08-30 summary:The explanation of heterogeneous multivariate time series data is a central problem in many applications. The problem requires two major data mining challenges to be addressed simultaneously: Learning models that are human-interpretable and mining of heterogeneous multivariate time series data. The intersection of these two areas is not adequately explored in the existing literature. To address this gap, we propose grammar-based decision trees and an algorithm for learning them. Grammar-based decision tree extends decision trees with a grammar framework. Logical expressions, derived from context-free grammar, are used for branching in place of simple thresholds on attributes. The added expressivity enables support for a wide range of data types while retaining the interpretability of decision trees. By choosing a grammar based on temporal logic, we show that grammar-based decision trees can be used for the interpretable classification of high-dimensional and heterogeneous time series data. In addition to classification, we show how grammar-based decision trees can also be used for categorization, which is a combination of clustering and generating interpretable explanations for each cluster. We apply grammar-based decision trees to analyze the classic Australian Sign Language dataset as well as categorize and explain near mid-air collisions to support the development of a prototype aircraft collision avoidance system. version:1
arxiv-1708-09116 | Slope Stability Analysis with Geometric Semantic Genetic Programming | http://arxiv.org/abs/1708.09116 | id:1708.09116 author:Juncai Xu, Zhenzhong Shen, Qingwen Ren, Xin Xie, Zhengyu Yang category:cs.NE  published:2017-08-30 summary:Genetic programming has been widely used in the engineering field. Compared with the conventional genetic programming and artificial neural network, geometric semantic genetic programming (GSGP) is superior in astringency and computing efficiency. In this paper, GSGP is adopted for the classification and regression analysis of a sample dataset. Furthermore, a model for slope stability analysis is established on the basis of geometric semantics. According to the results of the study based on GSGP, the method can analyze slope stability objectively and is highly precise in predicting slope stability and safety factors. Hence, the predicted results can be used as a reference for slope safety design. version:1
arxiv-1709-00389 | End-to-end Learning for Short Text Expansion | http://arxiv.org/abs/1709.00389 | id:1709.00389 author:Jian Tang, Yue Wang, Kai Zheng, Qiaozhu Mei category:cs.CL cs.IR  published:2017-08-30 summary:Effectively making sense of short texts is a critical task for many real world applications such as search engines, social media services, and recommender systems. The task is particularly challenging as a short text contains very sparse information, often too sparse for a machine learning algorithm to pick up useful signals. A common practice for analyzing short text is to first expand it with external information, which is usually harvested from a large collection of longer texts. In literature, short text expansion has been done with all kinds of heuristics. We propose an end-to-end solution that automatically learns how to expand short text to optimize a given learning task. A novel deep memory network is proposed to automatically find relevant information from a collection of longer documents and reformulate the short text through a gating mechanism. Using short text classification as a demonstrating task, we show that the deep memory network significantly outperforms classical text expansion methods with comprehensive experiments on real world data sets. version:1
