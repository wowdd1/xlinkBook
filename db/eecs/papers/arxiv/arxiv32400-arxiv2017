arxiv-1709-06662 | Verifying Properties of Binarized Deep Neural Networks | http://arxiv.org/abs/1709.06662 | id:1709.06662 author:Nina Narodytska, Shiva Prasad Kasiviswanathan, Leonid Ryzhyk, Mooly Sagiv, Toby Walsh category:stat.ML cs.AI cs.CR cs.LG  published:2017-09-19 summary:Understanding properties of deep neural networks is an important challenge in deep learning. In this paper, we take a step in this direction by proposing a rigorous way of verifying properties of a popular class of neural networks, Binarized Neural Networks, using the well-developed means of Boolean satisfiability. Our main contribution is a construction that creates a representation of a binarized neural network as a Boolean formula. Our encoding is the first exact Boolean representation of a deep neural network. Using this encoding, we leverage the power of modern SAT solvers along with a proposed counterexample-guided search procedure to verify various properties of these networks. A particular focus will be on the critical property of robustness to adversarial perturbations. For this property, our experimental results demonstrate that our approach scales to medium-size deep neural networks used in image classification tasks. To the best of our knowledge, this is the first work on verifying properties of deep neural networks using an exact Boolean encoding of the network. version:1
arxiv-1709-06656 | Deep Reinforcement Learning for Event-Driven Multi-Agent Decision Processes | http://arxiv.org/abs/1709.06656 | id:1709.06656 author:Kunal Menda, Yi-Chun Chen, Justin Grana, James W. Bono, Brendan D. Tracey, Mykel J. Kochenderfer, David Wolpert category:cs.AI cs.MA  published:2017-09-19 summary:The incorporation of macro-actions (temporally extended actions) into multi-agent decision problems has the potential to address the curse of dimensionality associated with such decision problems. Since macro-actions last for stochastic durations, multiple agents executing decentralized policies in cooperative environments must act asynchronously. We present an algorithm that modifies Generalized Advantage Estimation for temporally extended actions, allowing a state-of-the-art policy optimization algorithm to optimize policies in Dec-POMDPs in which agents act asynchronously. We show that our algorithm is capable of learning optimal policies in two cooperative domains, one involving real-time bus holding control and one involving wildfire fighting with unmanned aircraft. Our algorithm works by framing problems as "event-driven decision processes," which are scenarios where the sequence and timing of actions and events are random and governed by an underlying stochastic process. In addition to optimizing policies with continuous state and action spaces, our algorithm also facilitates the use of event-driven simulators, which do not require time to be discretized into time-steps. We demonstrate the benefit of using event-driven simulation in the context of multiple agents taking asynchronous actions. We show that fixed time-step simulation risks obfuscating the sequence in which closely-separated events occur, adversely affecting the policies learned. Additionally, we show that arbitrarily shrinking the time-step scales poorly with the number of agents. version:1
arxiv-1709-06620 | Learning of Coordination Policies for Robotic Swarms | http://arxiv.org/abs/1709.06620 | id:1709.06620 author:Qiyang Li, Xintong Du, Yizhou Huang, Quinlan Sykora, Angela P. Schoellig category:cs.RO cs.AI cs.LG cs.MA cs.NE  published:2017-09-19 summary:Inspired by biological swarms, robotic swarms are envisioned to solve real-world problems that are difficult for individual agents. Biological swarms can achieve collective intelligence based on local interactions and simple rules; however, designing effective distributed policies for large-scale robotic swarms to achieve a global objective can be challenging. Although it is often possible to design an optimal centralized strategy for smaller numbers of agents, those methods can fail as the number of agents increases. Motivated by the growing success of machine learning, we develop a deep learning approach that learns distributed coordination policies from centralized policies. In contrast to traditional distributed control approaches, which are usually based on human-designed policies for relatively simple tasks, this learning-based approach can be adapted to more difficult tasks. We demonstrate the efficacy of our proposed approach on two different tasks, the well-known rendezvous problem and a more difficult particle assignment problem. For the latter, no known distributed policy exists. From extensive simulations, it is shown that the performance of the learned coordination policies is comparable to the centralized policies, surpassing state-of-the-art distributed policies. Thereby, our proposed approach provides a promising alternative for real-world coordination problems that would be otherwise computationally expensive to solve or intangible to explore. version:1
arxiv-1709-06614 | A Memristive Neural Network Computing Engine using CMOS-Compatible Charge-Trap-Transistor (CTT) | http://arxiv.org/abs/1709.06614 | id:1709.06614 author:Yuan Du, Li Du, Xuefeng Gu, Xiao Wang, Mau-Chung Frank Chang category:cs.ET cs.AR cs.LG  published:2017-09-19 summary:A memristive neural network computing engine based on CMOS-compatible charge-trap transistor (CTT) is proposed in this paper. CTT devices are used as analog multipliers. Compared to digital multipliers, CTT-based analog multipliers show dramatic area and power reduction (>100x). The proposed memristive computing engine is composed of a scalable CTT multiplier array and energy efficient analog-digital interfaces. Through implementing the sequential analog fabric (SAF), the mixed-signal of the engine interfaces are simplified and hardware overhead remains constant regardless of the size of the array. A proof-of-concept 784 by 784 CTT computing engine is implemented using TSMC 28nm CMOS technology and occupied 0.68mm2. It achieves 69.9 TOPS with 500 MHz clock frequency and consumes 14.8 mW. As an example, we utilize this computing engine to address a classic pattern recognition problem-classifying handwritten digits on MNIST database - and obtained a performance comparable to state-of-the-art fully connected neural networks using 8-bit fixed-point resolution. version:1
arxiv-1709-06613 | A Server-based Approach for Predictable GPU Access with Improved Analysis | http://arxiv.org/abs/1709.06613 | id:1709.06613 author:Hyoseung Kim, Pratyush Patel, Shige Wang, Ragunathan, Rajkumar category:cs.DC  published:2017-09-19 summary:We propose a server-based approach to manage a general-purpose graphics processing unit (GPU) in a predictable and efficient manner. Our proposed approach introduces a GPU server that is a dedicated task to handle GPU requests from other tasks on their behalf. The GPU server ensures bounded time to access the GPU, and allows other tasks to suspend during their GPU computation to save CPU cycles. By doing so, we address the two major limitations of the existing real-time synchronization-based GPU management approach: busy waiting and long priority inversion. We have implemented a prototype of the server-based approach on a real embedded platform. This case study demonstrates the practicality and effectiveness of the server-based approach. Experimental results indicate that the server-based approach yields significant improvements in task schedulability over the existing synchronization-based approach in most practical settings. Although we focus on a GPU in this paper, the server-based approach can also be used for other types of computational accelerators. version:1
arxiv-1709-06604 | Derivation of Network Reprogramming Protocol with Z3 | http://arxiv.org/abs/1709.06604 | id:1709.06604 author:Vidhya Tekken-Valapil, Sandeep S. Kulkarni category:cs.DC  published:2017-09-19 summary:Networks protocols are the heart of communication networks. An efficient network protocol does maximum utilization of the underlying network capabilities. Network Protocol synthesis is the process of synthesizing or deriving network specific protocols from the requirements of a given specific network. In this report, we present a step-by-step approach for the automated synthesis of network protocols from the network specifications. Using SMT solvers to automate the protocol generation is the key idea behind the presented synthesis approach. The protocols generated using this approach followed the most optimal way of data transmission for the given network requirements. version:1
arxiv-1709-06601 | Parameterization of configuration space obstacles in three-dimensional rotational motion planning | http://arxiv.org/abs/1709.06601 | id:1709.06601 author:Przemysław Dobrowolski category:cs.CG cs.RO  published:2017-09-19 summary:This study investigates the exact geometry of the configuration space in three-dimensional rotational motion planning. A parameterization of configuration space obstacles is derived for a given triangulated or ball-approximated scene with an object rotating around a given point. The results obtained are an important step towards a complete description of the rich structure of a configuration space in three-dimensional rotational motion planning. version:1
arxiv-1709-06533 | Summable Reparameterizations of Wasserstein Critics in the One-Dimensional Setting | http://arxiv.org/abs/1709.06533 | id:1709.06533 author:Christopher Grimm, Yuhang Song, Michael L. Littman category:cs.LG cs.AI stat.ML  published:2017-09-19 summary:Generative adversarial networks (GANs) are an exciting alternative to algorithms for solving density estimation problems---using data to assess how likely samples are to be drawn from the same distribution. Instead of explicitly computing these probabilities, GANs learn a generator that can match the given probabilistic source. This paper looks particularly at this matching capability in the context of problems with one-dimensional outputs. We identify a class of function decompositions with properties that make them well suited to the critic role in a leading approach to GANs known as Wasserstein GANs. We show that Taylor and Fourier series decompositions belong to our class, provide examples of these critics outperforming standard GAN approaches, and suggest how they can be scaled to higher dimensional problems in the future. version:1
arxiv-1709-05948 | The shortest way to visit all metro lines in Paris | http://arxiv.org/abs/1709.05948 | id:1709.05948 author:Florian Sikora category:cs.AI math.OC  published:2017-09-13 summary:What if $\{$a tourist, a train addict, Dr. Sheldon Cooper, somebody who likes to waste time$\}$ wants to visit all metro lines or carriages in a given network in a minimum number of steps? We study this problem with an application to the Parisian metro network and propose optimal solutions thanks to mathematical programming tools. Quite surprisingly, it appears that you can visit all 16 Parisian metro lines in only 26 steps (we denote by a step the act of taking the metro from one station to an adjacent one). Perhaps even more surprisingly, adding the 5 RER lines to these 16 lines does not increase the size of the best solution. version:2
arxiv-1709-04305 | Automated Cloud Provisioning on AWS using Deep Reinforcement Learning | http://arxiv.org/abs/1709.04305 | id:1709.04305 author:Zhiguang Wang, Chul Gwon, Tim Oates, Adam Iezzi category:cs.DC cs.AI cs.LG  published:2017-09-13 summary:As the use of cloud computing continues to rise, controlling cost becomes increasingly important. Yet there is evidence that 30\% - 45\% of cloud spend is wasted. Existing tools for cloud provisioning typically rely on highly trained human experts to specify what to monitor, thresholds for triggering action, and actions. In this paper we explore the use of reinforcement learning (RL) to acquire policies to balance performance and spend, allowing humans to specify what they want as opposed to how to do it, minimizing the need for cloud expertise. Empirical results with tabular, deep, and dueling double deep Q-learning with the CloudSim simulator show the utility of RL and the relative merits of the approaches. We also demonstrate effective policy transfer learning from an extremely simple simulator to CloudSim, with the next step being transfer from CloudSim to an Amazon Web Services physical environment. version:2
arxiv-1506-02930 | Arguments for the Effectiveness of Human Problem Solving | http://arxiv.org/abs/1506.02930 | id:1506.02930 author:Frantisek Duris category:cs.AI 68T20 I.2.0; I.2.8  published:2015-06-09 summary:The question of how humans solve problem has been addressed extensively. However, the direct study of the effectiveness of this process seems to be overlooked. In this paper, we address the issue of the effectiveness of human problem solving: we analyze where this effectiveness comes from and what cognitive mechanisms or heuristics are involved. Our results are based on the optimal probabilistic problem solving strategy that appeared in Solomonoff paper on general problem solving system. We provide arguments that a certain set of cognitive mechanisms or heuristics drive human problem solving in the similar manner as the optimal Solomonoff strategy. The results presented in this paper can serve both cognitive psychology in better understanding of human problem solving processes as well as artificial intelligence in designing more human-like agents. version:2
arxiv-1709-06404 | Interactive Music Generation with Positional Constraints using Anticipation-RNNs | http://arxiv.org/abs/1709.06404 | id:1709.06404 author:Gaëtan Hadjeres, Frank Nielsen category:cs.AI cs.LG stat.ML  published:2017-09-19 summary:Recurrent Neural Networks (RNNS) are now widely used on sequence generation tasks due to their ability to learn long-range dependencies and to generate sequences of arbitrary length. However, their left-to-right generation procedure only allows a limited control from a potential user which makes them unsuitable for interactive and creative usages such as interactive music generation. This paper introduces a novel architecture called Anticipation-RNN which possesses the assets of the RNN-based generative models while allowing to enforce user-defined positional constraints. We demonstrate its efficiency on the task of generating melodies satisfying positional constraints in the style of the soprano parts of the J.S. Bach chorale harmonizations. Sampling using the Anticipation-RNN is of the same order of complexity than sampling from the traditional RNN model. This fast and interactive generation of musical sequences opens ways to devise real-time systems that could be used for creative purposes. version:1
arxiv-1708-03418 | Learning to Attend, Copy, and Generate for Session-Based Query Suggestion | http://arxiv.org/abs/1708.03418 | id:1708.03418 author:Mostafa Dehghani, Sascha Rothe, Enrique Alfonseca, Pascal Fleury category:cs.IR cs.AI cs.CL  published:2017-08-11 summary:Users try to articulate their complex information needs during search sessions by reformulating their queries. To make this process more effective, search engines provide related queries to help users in specifying the information need in their search process. In this paper, we propose a customized sequence-to-sequence model for session-based query suggestion. In our model, we employ a query-aware attention mechanism to capture the structure of the session context. is enables us to control the scope of the session from which we infer the suggested next query, which helps not only handle the noisy data but also automatically detect session boundaries. Furthermore, we observe that, based on the user query reformulation behavior, within a single session a large portion of query terms is retained from the previously submitted queries and consists of mostly infrequent or unseen terms that are usually not included in the vocabulary. We therefore empower the decoder of our model to access the source words from the session context during decoding by incorporating a copy mechanism. Moreover, we propose evaluation metrics to assess the quality of the generative models for query suggestion. We conduct an extensive set of experiments and analysis. e results suggest that our model outperforms the baselines both in terms of the generating queries and scoring candidate queries for the task of query suggestion. version:3
arxiv-1709-06314 | Rigid vs compliant contact: An experimental study on biped walking | http://arxiv.org/abs/1709.06314 | id:1709.06314 author:Majid Khadiv, S. Ali A. Moosvian, Aghil Yousefi-Koma, Majid Sadedel, Abbas Dashkhaneh, Saeed Mansouri category:cs.RO  published:2017-09-19 summary:In this paper, the main goal is to present an experimental comparison of the two prevailing contact modeling approaches of bipedal locomotion, i. e. rigid versus compliant contact model. To do this, first, an explicit dynamics model for the robot multibody with rigid model of contact for various phases of walking is developed. Then, in order to develop a model with compliant contact, a physically oriented software is exploited and using its tools the robot multibody is modeled. To model the unilateral contact in interaction points in this software, a nonlinear compliant contact model is proposed. Finally, the drive mechanism dynamics is modeled through a linear identification routine. By adding the drive system dynamics to both models, the procedure of modeling is completed. In order to compare the performance of the developed models, obtained results from these models are compared to the empirical measurements from bipedal walking of the human-size humanoid robot SURENA III, which has been designed and fabricated at CAST, university of Tehran. This comparison shows the merit of both models in estimating dynamic behavior, while the model with rigid contact with less complexity can be employed for model-based motion optimization, analysis as well as control, and the model with compliant contact with more complexity is suitable for more realistic simulation scenarios. version:1
arxiv-1709-06298 | MuseGAN: Symbolic-domain Music Generation and Accompaniment with Multi-track Sequential Generative Adversarial Networks | http://arxiv.org/abs/1709.06298 | id:1709.06298 author:Hao-Wen Dong, Wen-Yi Hsiao, Li-Chia Yang, Yi-Hsuan Yang category:eess.AS cs.AI cs.LG cs.SD  published:2017-09-19 summary:Generating music has a few notable differences from generating images and videos. First, music is an art of time, necessitating a temporal model. Second, music is usually composed of multiple instruments/tracks, with close interaction with one another. Each track has its own temporal dynamics, but collectively they unfold over time interdependently. Lastly, for symbolic domain music generation, the targeted output is sequences of discrete musical events, not continuous values. In this paper, we propose and study three generative adversarial networks (GANs) for symbolic-domain multi-track music generation, using a data set of 127,731 MIDI bars of pop/rock music. The three models, which differ in the underlying model assumption and accordingly the network architecture, are referred to as the jamming model, composer model, and hybrid model, respectively. We propose a few intra-track and inter-track objective metrics to examine and compare their generation result, in addition to a subjective evaluation. We show that our models can learn from the noisy MIDI files and generate coherent music of four bars right from scratch (i.e. without human inputs). We also propose extensions of our models to facilitate human-AI cooperative music creation: given the piano track composed by human we can generate four additional tracks in return to accompany it. version:1
arxiv-1709-06290 | The Critical Radius in Sampling-Based Motion Planning | http://arxiv.org/abs/1709.06290 | id:1709.06290 author:Kiril Solovey, Michal Kleinbort category:cs.RO math.PR  published:2017-09-19 summary:We develop a new analysis of sampling-based motion planning with uniform sampling, which significantly improves upon the celebrated result of Karaman and Frazzoli (2011) and subsequent work. Particularly, we prove the existence of a critical radius value proportional to $\Theta(n^{-1/d})$ for $n$ samples and $d$ dimensions: Below this value the planner is guaranteed to fail (similarly shown by the aforementioned work, ibid.). More importantly, for larger radius values the planner is asymptotically (near-)optimal (AO). A practical implication of our work is that AO is achieved when each sample is connected to only $\Theta(1)$ neighbors. This is in stark contrast to previous work which requires $O(\log n)$ connections, that are induced by a radius proportional to $\left(\frac{\log n}{n}\right)^{1/d}$. Our analysis is not restricted to PRM and is applicable to a variety of :PRM-based" planners, such as RRG, FMT* and BTT. Continuum percolation theory plays an important role in our proofs. version:1
arxiv-1709-06283 | Cartman: The low-cost Cartesian Manipulator that won the Amazon Robotics Challenge | http://arxiv.org/abs/1709.06283 | id:1709.06283 author:D. Morrison, A. W. Tow, M. McTaggart, R. Smith, N. Kelly-Boxall, S. Wade-McCue, J. Erskine, R. Grinover, A. Gurman, T. Hunn, D. Lee, A. Milan, T. Pham, G. Rallos, A. Razjigaev, T. Rowntree, K. Vijay, Z. Zhuang, C. Lehnert, I. Reid, P. Corke, J. Leitner category:cs.RO  published:2017-09-19 summary:The Amazon Robotics Challenge enlisted sixteen teams to each design a pick-and-place robot for autonomous warehousing, addressing development in robotic vision and manipulation. This paper presents the design of our custom-built. cost-effective robot system Cartman, which won first place in the competition finals by stowing 14 (out of 16) and picking all 9 items in 27 minutes, scoring a total of 272 points. We highlight our experience-centred design methodology and key aspects of our system that contributed to our competitiveness. We believe these aspects are crucial to building robust and effective robotic systems. version:1
arxiv-1709-06275 | Incorrigibility in the CIRL Framework | http://arxiv.org/abs/1709.06275 | id:1709.06275 author:Ryan Carey category:cs.AI  published:2017-09-19 summary:A value learning system has incentives to follow shutdown instructions, assuming the shutdown instruction provides information (in the technical sense) about which actions lead to valuable outcomes. However, this assumption is not robust to model mis-specification (e.g., in the case of programmer errors). We demonstrate this by presenting some Supervised POMDP scenarios in which errors in the parameterized reward function remove the incentive to follow shutdown commands. These difficulties parallel those discussed by Soares et al. (2015) in their paper on corrigibility. We argue that it is important to consider systems that follow shutdown commands under some weaker set of assumptions (e.g., that one small verified module is correctly implemented; as opposed to an entire prior probability distribution and/or parameterized reward function). We discuss some difficulties with simple ways to attempt to attain these sorts of guarantees in a value learning framework. version:1
arxiv-1709-05365 | Understanding System Characteristics of Online Erasure Coding on Scalable, Distributed and Large-Scale SSD Array Systems | http://arxiv.org/abs/1709.05365 | id:1709.05365 author:Sungjoon Koh, Jie Zhang, Miryeong Kwon, Jungyeon Yoon, David Donofrio, Namsung Kim, Myoungsoo Jung category:cs.DC cs.AR  published:2017-09-14 summary:Large-scale systems with arrays of solid state disks (SSDs) have become increasingly common in many computing segments. To make such systems resilient, we can adopt erasure coding such as Reed-Solomon (RS) code as an alternative to replication because erasure coding can offer a significantly lower storage cost than replication. To understand the impact of using erasure coding on system performance and other system aspects such as CPU utilization and network traffic, we build a storage cluster consisting of approximately one hundred processor cores with more than fifty high-performance SSDs, and evaluate the cluster with a popular open-source distributed parallel file system, Ceph. Then we analyze behaviors of systems adopting erasure coding from the following five viewpoints, compared with those of systems using replication: (1) storage system I/O performance; (2) computing and software overheads; (3) I/O amplification; (4) network traffic among storage nodes; (5) the impact of physical data layout on performance of RS-coded SSD arrays. For all these analyses, we examine two representative RS configurations, which are used by Google and Facebook file systems, and compare them with triple replication that a typical parallel file system employs as a default fault tolerance mechanism. Lastly, we collect 54 block-level traces from the cluster and make them available for other researchers. version:2
arxiv-1708-02556 | Multi-Generator Generative Adversarial Nets | http://arxiv.org/abs/1708.02556 | id:1708.02556 author:Quan Hoang, Tu Dinh Nguyen, Trung Le, Dinh Phung category:cs.LG cs.AI stat.ML  published:2017-08-08 summary:We propose in this paper a novel approach to address the mode collapse problem in Generative Adversarial Nets (GANs) by training many generators. The training procedure is formulated as a minimax game among many generators, a classifier, and a discriminator. Generators produce data to fool the discriminator while staying within the decision boundary defined by the classifier as much as possible; classifier estimates the probability that a sample came from each of the generators; and discriminator estimates the probability that a sample came from the training data rather than from all generators. We develop theoretical analysis to show that at equilibrium of this system, the Jensen-Shannon divergence between the equally weighted mixture of all generators' distributions and the real data distribution is minimal while the Jensen-Shannon divergence among generators' distributions is maximal. Generators can be trained efficiently by utilizing parameter sharing, thus adding minimal cost to the basic GAN model. We conduct extensive experiments on synthetic and real-world large scale data sets (CIFAR-10 and STL-10) to evaluate the effectiveness of our proposed method. Experimental results demonstrate the superior performance of our approach in generating diverse and visually appealing samples over the latest state-of-the-art GAN's variants. version:3
arxiv-1709-05586 | Generalized PMC model for the hybrid diagnosis of multiprocessor systems | http://arxiv.org/abs/1709.05586 | id:1709.05586 author:Qiang Zhu category:cs.DC  published:2017-09-17 summary:Fault diagnosis is important to the design and maintenance of large multiprocessor systems. PMC model is the most famous diagnosis model in the system level diagnosis of multiprocessor systems. Under the PMC model, only node faults are allowed. But in real circumstances, link faults may occur. So based on the PMC model, we propose in this paper a diagnosis model called the generalized PMC(GPMC) model to adapt to the real circumstances. The foundation of GPMC model has been established. And to measure the fault diagnosis capability of multiprocessor systems under the GPMC model, the fault diagnosis capability measuring parameters: $h$-edge restricted diagnosability and $h$-vertex restricted edge diagnosability have been introduced. As an application, the $h$-edge restricted diagnosability and $h$-vertex restricted edge diagnosability of hypercubes are explored. version:2
arxiv-1709-06217 | Deterministic meeting of sniffing agents in the plane | http://arxiv.org/abs/1709.06217 | id:1709.06217 author:Samir Elouasbi, Andrzej Pelc category:cs.DC  published:2017-09-19 summary:Two mobile agents, starting at arbitrary, possibly different times from arbitrary locations in the plane, have to meet. Agents are modeled as discs of diameter 1, and meeting occurs when these discs touch. Agents have different labels which are integers from the set of 0 to L-1. Each agent knows L and knows its own label, but not the label of the other agent. Agents are equipped with compasses and have synchronized clocks. They make a series of moves. Each move specifies the direction and the duration of moving. This includes a null move which consists in staying inert for some time, or forever. In a non-null move agents travel at the same constant speed, normalized to 1. We assume that agents have sensors enabling them to estimate the distance from the other agent (defined as the distance between centers of discs), but not the direction towards it. We consider two models of estimation. In both models an agent reads its sensor at the moment of its appearance in the plane and then at the end of each move. This reading (together with the previous ones) determines the decision concerning the next move. In both models the reading of the sensor tells the agent if the other agent is already present. Moreover, in the monotone model, each agent can find out, for any two readings in moments t1 and t2, whether the distance from the other agent at time t1 was smaller, equal or larger than at time t2. In the weaker binary model, each agent can find out, at any reading, whether it is at distance less than \r{ho} or at distance at least \r{ho} from the other agent, for some real \r{ho} > 1 unknown to them. Such distance estimation mechanism can be implemented, e.g., using chemical sensors. Each agent emits some chemical substance (scent), and the sensor of the other agent detects it, i.e., sniffs. The intensity of the scent decreases with the distance. version:1
arxiv-1709-06214 | Deterministic rendezvous with detection using beeps | http://arxiv.org/abs/1709.06214 | id:1709.06214 author:Samir Elouasbi, Andrzej Pelc category:cs.DC  published:2017-09-19 summary:Two mobile agents, starting at arbitrary, possibly different times from arbitrary nodes of an unknown network, have to meet at some node. Agents move in synchronous rounds: in each round an agent can either stay at the current node or move to one of its neighbors. Agents have different labels which are positive integers. Each agent knows its own label, but not the label of the other agent. In traditional formulations of the rendezvous problem, meeting is accomplished when the agents get to the same node in the same round. We want to achieve a more demanding goal, called rendezvous with detection: agents must become aware that the meeting is accomplished, simultaneously declare this and stop. This awareness depends on how an agent can communicate to the other agent its presence at a node. We use two variations of the arguably weakest model of communication, called the beeping model, introduced in [8]. In each round an agent can either listen or beep. In the local beeping model, an agent hears a beep in a round if it listens in this round and if the other agent is at the same node and beeps. In the global beeping model, an agent hears a loud beep in a round if it listens in this round and if the other agent is at the same node and beeps, and it hears a soft beep in a round if it listens in this round and if the other agent is at some other node and beeps. We first present a deterministic algorithm of rendezvous with detection working, even for the local beeping model, in an arbitrary unknown network in time polynomial in the size of the network and in the length of the smaller label (i.e., in the logarithm of this label). However, in this algorithm, agents spend a lot of energy: the number of moves that an agent must make, is proportional to the time of rendezvous. It is thus natural to ask if bounded-energy agents can always achieve rendezvous with detection as well... version:1
arxiv-1709-06202 | A Comparative Quantitative Analysis of Contemporary Big Data Clustering Algorithms for Market Segmentation in Hospitality Industry | http://arxiv.org/abs/1709.06202 | id:1709.06202 author:Avishek Bose, Arslan Munir, Neda Shabani category:cs.DB cs.AI  published:2017-09-18 summary:The hospitality industry is one of the data-rich industries that receives huge Volumes of data streaming at high Velocity with considerably Variety, Veracity, and Variability. These properties make the data analysis in the hospitality industry a big data problem. Meeting the customers' expectations is a key factor in the hospitality industry to grasp the customers' loyalty. To achieve this goal, marketing professionals in this industry actively look for ways to utilize their data in the best possible manner and advance their data analytic solutions, such as identifying a unique market segmentation clustering and developing a recommendation system. In this paper, we present a comprehensive literature review of existing big data clustering algorithms and their advantages and disadvantages for various use cases. We implement the existing big data clustering algorithms and provide a quantitative comparison of the performance of different clustering algorithms for different scenarios. We also present our insights and recommendations regarding the suitability of different big data clustering algorithms for different use cases. These recommendations will be helpful for hoteliers in selecting the appropriate market segmentation clustering algorithm for different clustering datasets to improve the customer experience and maximize the hotel revenue. version:1
arxiv-1709-06201 | Human Understandable Explanation Extraction for Black-box Classification Models Based on Matrix Factorization | http://arxiv.org/abs/1709.06201 | id:1709.06201 author:Jaedeok Kim, Jingoo Seo category:cs.AI cs.LG stat.ML  published:2017-09-18 summary:In recent years, a number of artificial intelligent services have been developed such as defect detection system or diagnosis system for customer services. Unfortunately, the core in these services is a black-box in which human cannot understand the underlying decision making logic, even though the inspection of the logic is crucial before launching a commercial service. Our goal in this paper is to propose an analytic method of a model explanation that is applicable to general classification models. To this end, we introduce the concept of a contribution matrix and an explanation embedding in a constraint space by using a matrix factorization. We extract a rule-like model explanation from the contribution matrix with the help of the nonnegative matrix factorization. To validate our method, the experiment results provide with open datasets as well as an industry dataset of a LTE network diagnosis and the results show our method extracts reasonable explanations. version:1
arxiv-1709-06196 | POMCPOW: An online algorithm for POMDPs with continuous state, action, and observation spaces | http://arxiv.org/abs/1709.06196 | id:1709.06196 author:Zachary Sunberg, Mykel Kochenderfer category:cs.AI cs.RO cs.SY  published:2017-09-18 summary:Online solvers for partially observable Markov decision processes have been applied to problems with large discrete state spaces, but continuous state, action, and observation spaces remain a challenge. This paper begins by investigating double progressive widening (DPW) as a solution to this challenge. However, we prove that this modification alone is not sufficient because the belief representations in the search tree collapse to a single particle causing the algorithm to converge to a policy that is suboptimal regardless of the computation time. The main contribution of the paper is to propose a new algorithm, POMCPOW, that incorporates DPW and weighted particle filtering to overcome this deficiency and attack continuous problems. Simulation results show that these modifications allow the algorithm to be successful where previous approaches fail. version:1
arxiv-1709-06555 | Trading Computation for Communication: A Taxonomy | http://arxiv.org/abs/1709.06555 | id:1709.06555 author:Ismail Akturk, Ulya R. Karpuzcu category:cs.DC  published:2017-09-18 summary:A critical challenge for modern system design is meeting the overwhelming performance, storage, and communication bandwidth demand of emerging applications within a tightly bound power budget. As both the time and power, hence the energy, spent in data communication by far exceeds the energy spent in actual data generation (i.e., computation), (re)computing data can easily become cheaper than storing and retrieving (pre)computed data. Therefore, trading computation for communication can improve energy efficiency by minimizing the energy overhead incurred by data storage, retrieval, and communication. This paper hence provides a taxonomy for the computation vs. communication trade-off along with quantitative characterization. version:1
arxiv-1709-06175 | Blocking Versus Non-Blocking Halo Exchange | http://arxiv.org/abs/1709.06175 | id:1709.06175 author:Anthony Bourached category:cs.DC  published:2017-09-18 summary:This report describes the design, implementation and analysis of a non-blocking halo exchange routine as an alternative to the blocking halo exchange routine in the lattice Boltzmann code Ludwig. The alternative, non-blocking, routine is implemented in such a way to allow work-communication overlap. Detailed benchmarks in this report show that the non-blocking version is a good alternative even without any work-communication overlap. Work-Communication overlap can be used to improve the performance of the non-blocking routine. Development and benchmarking were conducted on the UK national supercomputer, ARCHER. version:1
arxiv-1710-04685 | Recomputation Enabled Efficient Checkpointing | http://arxiv.org/abs/1710.04685 | id:1710.04685 author:Ismail Akturk, Ulya R. Karpuzcu category:cs.DC  published:2017-09-18 summary:Systematic checkpointing of the machine state makes roll-back and restart of execution from a safe state possible upon detection of an error. The energy overhead of checkpointing, however, as incurred by storage and communication of the machine state, grows with the frequency of checkpointing. Amortizing this overhead becomes especially challenging, considering the growth of expected error rates as an artifact of contemporary technology scaling, as checkpointing frequency tends to increase with increasing error rates. At the same time, due to imbalances in technology scaling, recomputing data can become more energy efficient than storing and retrieving precomputed data. Recomputation of data (which otherwise would be read from a checkpoint) can reduce the frequency of checkpointing along with the data size to be checkpointed, and thereby mitigate checkpointing overhead. This paper quantitatively characterizes a recomputation-enabled checkpointing framework which can reduce the storage overhead of checkpointing by up to 23.91%; the performance overhead by up to 11.92%, and the energy overhead by up to 12.53%, respectively. version:1
arxiv-1709-06172 | On the Complexity of Robust Stable Marriage | http://arxiv.org/abs/1709.06172 | id:1709.06172 author:Begum Genc, Mohamed Siala, Gilles Simonin, Barry O'Sullivan category:cs.CC cs.AI  published:2017-09-18 summary:Robust Stable Marriage (RSM) is a variant of the classical Stable Marriage problem, where the robustness of a given stable matching is measured by the number of modifications required for repairing it in case an unforeseen event occurs. We focus on the complexity of finding an (a,b)-supermatch. An (a,b)-supermatch is defined as a stable matching in which if any 'a' (non-fixed) men/women break up it is possible to find another stable matching by changing the partners of those 'a' men/women and also the partners of at most 'b' other couples. In order to show deciding if there exists an (a,b)-supermatch is NP-Complete, we first introduce a SAT formulation that is NP-Complete by using Schaefer's Dichotomy Theorem. Then, we show the equivalence between the SAT formulation and finding a (1,1)-supermatch on a specific family of instances. version:1
arxiv-1709-06166 | DropoutDAgger: A Bayesian Approach to Safe Imitation Learning | http://arxiv.org/abs/1709.06166 | id:1709.06166 author:Kunal Menda, Katherine Driggs-Campbell, Mykel J. Kochenderfer category:cs.AI cs.RO  published:2017-09-18 summary:While imitation learning is becoming common practice in robotics, this approach often suffers from data mismatch and compounding errors. DAgger is an iterative algorithm that addresses these issues by continually aggregating training data from both the expert and novice policies, but does not consider the impact of safety. We present a probabilistic extension to DAgger, which uses the distribution over actions provided by the novice policy, for a given observation. Our method, which we call DropoutDAgger, uses dropout to train the novice as a Bayesian neural network that provides insight to its confidence. Using the distribution over the novice's actions, we estimate a probabilistic measure of safety with respect to the expert action, tuned to balance exploration and exploitation. The utility of this approach is evaluated on the MuJoCo HalfCheetah and in a simple driving experiment, demonstrating improved performance and safety compared to other DAgger variants and classic imitation learning. version:1
arxiv-1709-06160 | On Dynamic Precision Scaling | http://arxiv.org/abs/1709.06160 | id:1709.06160 author:Serif Yesil, Ismail Akturk, Ulya R. Karpuzcu category:cs.DC  published:2017-09-18 summary:Based on the observation that application phases exhibit varying degrees of sensitivity to noise (i.e., accuracy loss) in computation during execution, this paper explores how Dynamic Precision Scaling (DPS) can maximize power efficiency by tailoring the precision of computation adaptively to temporal changes in algorithmic noise tolerance. DPS can decrease the arithmetic precision of noise-tolerant phases to result in power savings at the same operating speed (or faster execution within the same power budget), while keeping the overall loss in accuracy due to precision reduction bounded. version:1
arxiv-1709-06138 | Model-Powered Conditional Independence Test | http://arxiv.org/abs/1709.06138 | id:1709.06138 author:Rajat Sen, Ananda Theertha Suresh, Karthikeyan Shanmugam, Alexandros G. Dimakis, Sanjay Shakkottai category:stat.ML cs.AI cs.IT cs.LG math.IT  published:2017-09-18 summary:We consider the problem of non-parametric Conditional Independence testing (CI testing) for continuous random variables. Given i.i.d samples from the joint distribution $f(x,y,z)$ of continuous random vectors $X,Y$ and $Z,$ we determine whether $X \perp Y Z$. We approach this by converting the conditional independence test into a classification problem. This allows us to harness very powerful classifiers like gradient-boosted trees and deep neural networks. These models can handle complex probability distributions and allow us to perform significantly better compared to the prior state of the art, for high-dimensional CI testing. The main technical challenge in the classification problem is the need for samples from the conditional product distribution $f^{CI}(x,y,z) = f(x z)f(y z)f(z)$ -- the joint distribution if and only if $X \perp Y Z.$ -- when given access only to i.i.d. samples from the true joint distribution $f(x,y,z)$. To tackle this problem we propose a novel nearest neighbor bootstrap procedure and theoretically show that our generated samples are indeed close to $f^{CI}$ in terms of total variational distance. We then develop theoretical results regarding the generalization bounds for classification for our problem, which translate into error bounds for CI testing. We provide a novel analysis of Rademacher type classification bounds in the presence of non-i.i.d near-independent samples. We empirically validate the performance of our algorithm on simulated and real datasets and show performance gains over previous methods. version:1
arxiv-1709-06129 | When is a Convolutional Filter Easy To Learn? | http://arxiv.org/abs/1709.06129 | id:1709.06129 author:Simon S. Du, Jason D. Lee, Yuandong Tian category:cs.LG cs.AI cs.CV math.OC stat.ML  published:2017-09-18 summary:We analyze the convergence of (stochastic) gradient descent algorithm for learning a convolutional filter with Rectified Linear Unit (ReLU) activation function. Our analysis does not rely on any specific form of the input distribution and our proofs only use the definition of ReLU, in contrast with previous works that are restricted to standard Gaussian input. We show that (stochastic) gradient descent with random initialization can learn the convolutional filter in polynomial time and the convergence rate depends on the smoothness of the input distribution and the closeness of patches. To the best of our knowledge, this is the first recovery guarantee of gradient-based algorithms for convolutional filter on non-Gaussian input distributions. Our theory also justifies the two-stage learning rate strategy in deep neural networks. While our focus is theoretical, we also present experiments that illustrate our theoretical findings. version:1
arxiv-1709-06127 | Diluting the Scalability Boundaries: Exploring the Use of Disaggregated Architectures for High-Level Network Data Analysis | http://arxiv.org/abs/1709.06127 | id:1709.06127 author:Carlos Vega, Jose Fernando Zazo, Hugo Meyer, Ferad Zyulkyarov, Sergio Lopez Buedo, Javier Aracil category:cs.DC  published:2017-09-18 summary:Traditional data centers are designed with a rigid architecture of fit-for-purpose servers that provision resources beyond the average workload in order to deal with occasional peaks of data. Heterogeneous data centers are pushing towards more cost-efficient architectures with better resource provisioning. In this paper we study the feasibility of using disaggregated architectures for intensive data applications, in contrast to the monolithic approach of server-oriented architectures. Particularly, we have tested a proactive network analysis system in which the workload demands are highly variable. In the context of the dReDBox disaggregated architecture, the results show that the overhead caused by using remote memory resources is significant, between 66\% and 80\%, but we have also observed that the memory usage is one order of magnitude higher for the stress case with respect to average workloads. Therefore, dimensioning memory for the worst case in conventional systems will result in a notable waste of resources. Finally, we found that, for the selected use case, parallelism is limited by memory. Therefore, using a disaggregated architecture will allow for increased parallelism, which, at the same time, will mitigate the overhead caused by remote memory. version:1
arxiv-1709-06049 | A novel Skill-based Programming Paradigm based on Autonomous Playing and Skill-centric Testing | http://arxiv.org/abs/1709.06049 | id:1709.06049 author:Simon Hangl, Andreas Mennel, Justus Piater category:cs.RO  published:2017-09-18 summary:We introduce a novel paradigm for robot pro- gramming with which we aim to make robot programming more accessible for unexperienced users. In order to do so we incorporate two major components in one single framework: autonomous skill acquisition by robotic playing and visual programming. Simple robot program skeletons solving a task for one specific situation, so-called basic behaviours, are provided by the user. The robot then learns how to solve the same task in many different situations by autonomous playing which reduces the barrier for unexperienced robot programmers. Programmers can use a mix of visual programming and kinesthetic teaching in order to provide these simple program skeletons. The robot program can be implemented interactively by programming parts with visual programming and kinesthetic teaching. We further integrate work on experience-based skill-centric robot software testing which enables the user to continuously test implemented skills without having to deal with the details of specific components. version:1
arxiv-1709-06047 | Bayesian Optimization Using Domain Knowledge on the ATRIAS Biped | http://arxiv.org/abs/1709.06047 | id:1709.06047 author:Akshara Rai, Rika Antonova, Seungmoon Song, William Martin, Hartmut Geyer, Christopher G. Atkeson category:cs.RO  published:2017-09-18 summary:Controllers in robotics often consist of expert-designed heuristics, which can be hard to tune in higher dimensions. It is typical to use simulation to learn these parameters, but controllers learned in simulation often don't transfer to hardware. This necessitates optimization directly on hardware. However, collecting data on hardware can be expensive. This has led to a recent interest in adapting data-efficient learning techniques to robotics. One popular method is Bayesian Optimization (BO), a sample-efficient black-box optimization scheme, but its performance typically degrades in higher dimensions. We aim to overcome this problem by incorporating domain knowledge to reduce dimensionality in a meaningful way, with a focus on bipedal locomotion. In previous work, we proposed a transformation based on knowledge of human walking that projected a 16-dimensional controller to a 1-dimensional space. In simulation, this showed enhanced sample efficiency when optimizing human-inspired neuromuscular walking controllers on a humanoid model. In this paper, we present a generalized feature transform applicable to non-humanoid robot morphologies and evaluate it on the ATRIAS bipedal robot -- in simulation and on hardware. We present three different walking controllers; two are evaluated on the real robot. Our results show that this feature transform captures important aspects of walking and accelerates learning on hardware and simulation, as compared to traditional BO. version:1
arxiv-1709-06039 | Why did the Robot Cross the Road? - Learning from Multi-Modal Sensor Data for Autonomous Road Crossing | http://arxiv.org/abs/1709.06039 | id:1709.06039 author:Noha Radwan, Wera Winterhalter, Christian Dornhege, Wolfram Burgard category:cs.RO  published:2017-09-18 summary:We consider the problem of developing robots that navigate like pedestrians on sidewalks through city centers for performing various tasks including delivery and surveillance. One particular challenge for such robots is crossing streets without pedestrian traffic lights. To solve this task the robot has to decide based on its sensory input if the road is clear. In this work, we propose a novel multi-modal learning approach for the problem of autonomous street crossing. Our approach solely relies on laser and radar data and learns a classifier based on Random Forests to predict when it is safe to cross the road. We present extensive experimental evaluations using real-world data collected from multiple street crossing situations which demonstrate that our approach yields a safe and accurate street crossing behavior and generalizes well over different types of situations. A comparison to alternative methods demonstrates the advantages of our approach. version:1
arxiv-1709-06019 | LS-VO: Learning Dense Optical Subspace for Robust Visual Odometry Estimation | http://arxiv.org/abs/1709.06019 | id:1709.06019 author:Gabriele Costante, Thomas A. Ciarfuglia category:cs.CV cs.RO  published:2017-09-18 summary:This work proposes a novel deep network architecture to solve the camera Ego-Motion estimation problem. A motion estimation network generally learns features similar to Optical Flow (OF) fields starting from sequences of images. This OF can be described by a lower dimensional latent space. Previous research has shown how to find linear approximations of this space. We propose to use an Auto-Encoder network to find a non-linear representation of the OF manifold. In addition, we propose to learn the latent space jointly with the estimation task, so that the learned OF features become a more robust description of the OF input. We call this novel architecture LS-VO. The experiments show that LS-VO achieves a considerable increase in performances in respect to baselines, while the number of parameters of the estimation network only slightly increases. version:1
arxiv-1709-06011 | Guided Deep Reinforcement Learning for Swarm Systems | http://arxiv.org/abs/1709.06011 | id:1709.06011 author:Maximilian Hüttenrauch, Adrian Šošić, Gerhard Neumann category:cs.MA cs.AI cs.LG cs.SY stat.ML  published:2017-09-18 summary:In this paper, we investigate how to learn to control a group of cooperative agents with limited sensing capabilities such as robot swarms. The agents have only very basic sensor capabilities, yet in a group they can accomplish sophisticated tasks, such as distributed assembly or search and rescue tasks. Learning a policy for a group of agents is difficult due to distributed partial observability of the state. Here, we follow a guided approach where a critic has central access to the global state during learning, which simplifies the policy evaluation problem from a reinforcement learning point of view. For example, we can get the positions of all robots of the swarm using a camera image of a scene. This camera image is only available to the critic and not to the control policies of the robots. We follow an actor-critic approach, where the actors base their decisions only on locally sensed information. In contrast, the critic is learned based on the true global state. Our algorithm uses deep reinforcement learning to approximate both the Q-function and the policy. The performance of the algorithm is evaluated on two tasks with simple simulated 2D agents: 1) finding and maintaining a certain distance to each others and 2) locating a target. version:1
arxiv-1709-05976 | Leveraging Distributional Semantics for Multi-Label Learning | http://arxiv.org/abs/1709.05976 | id:1709.05976 author:Rahul Wadbude, Vivek Gupta, Piyush Rai, Nagarajan Natarajan, Harish Karnick category:cs.LG cs.AI  published:2017-09-18 summary:We present a novel and scalable label embedding framework for large-scale multi-label learning a.k.a ExMLDS (Extreme Multi-Label Learning using Distributional Semantics). Our approach draws inspiration from ideas rooted in distributional semantics, specifically the Skip Gram Negative Sampling (SGNS) approach, widely used to learn word embeddings for natural language processing tasks. Learning such embeddings can be reduced to a certain matrix factorization. Our approach is novel in that it highlights interesting connections between label embedding methods used for multi-label learning and paragraph/document embedding methods commonly used for learning representations of text data. The framework can also be easily extended to incorporate auxiliary information such as label-label correlations; this is crucial especially when there are a lot of missing labels in the training data. We demonstrate the effectiveness of our approach through an extensive set of experiments on a variety of benchmark datasets, and show that the proposed learning methods perform favorably compared to several baselines and state-of-the-art methods for large-scale multi-label learning. version:1
arxiv-1709-05943 | Fast YOLO: A Fast You Only Look Once System for Real-time Embedded Object Detection in Video | http://arxiv.org/abs/1709.05943 | id:1709.05943 author:Mohammad Javad Shafiee, Brendan Chywl, Francis Li, Alexander Wong category:cs.CV cs.AI cs.NE  published:2017-09-18 summary:Object detection is considered one of the most challenging problems in this field of computer vision, as it involves the combination of object classification and object localization within a scene. Recently, deep neural networks (DNNs) have been demonstrated to achieve superior object detection performance compared to other approaches, with YOLOv2 (an improved You Only Look Once model) being one of the state-of-the-art in DNN-based object detection methods in terms of both speed and accuracy. Although YOLOv2 can achieve real-time performance on a powerful GPU, it still remains very challenging for leveraging this approach for real-time object detection in video on embedded computing devices with limited computational power and limited memory. In this paper, we propose a new framework called Fast YOLO, a fast You Only Look Once framework which accelerates YOLOv2 to be able to perform object detection in video on embedded devices in a real-time manner. First, we leverage the evolutionary deep intelligence framework to evolve the YOLOv2 network architecture and produce an optimized architecture (referred to as O-YOLOv2 here) that has 2.8X fewer parameters with just a ~2% IOU drop. To further reduce power consumption on embedded devices while maintaining performance, a motion-adaptive inference method is introduced into the proposed Fast YOLO framework to reduce the frequency of deep inference with O-YOLOv2 based on temporal motion characteristics. Experimental results show that the proposed Fast YOLO framework can reduce the number of deep inferences by an average of 38.13%, and an average speedup of ~3.3X for objection detection in video compared to the original YOLOv2, leading Fast YOLO to run an average of ~18FPS on a Nvidia Jetson TX1 embedded system. version:1
arxiv-1709-05910 | Learning a Fully Convolutional Network for Object Recognition using very few Data | http://arxiv.org/abs/1709.05910 | id:1709.05910 author:Christoph Reinders, Hanno Ackermann, Michael Ying Yang, Bodo Rosenhahn category:cs.CV cs.RO  published:2017-09-18 summary:In recent years, data-driven methods have shown great success for extracting information about the infrastruc- ture in urban areas. These algorithms are usually trained on large datasets consisting of thousands or millions of labeled training examples. While large datasets have been published regarding cars, for cyclists very few labeled data is available although appearance, point of view, and positioning of even relevant objects differ. Unfortunately, labeling data is costly and requires a huge amount of work. In this paper, we thus address the problem of learning with very few labels. The aim is to recognize particular traffic signs in crowdsourced data to collect information which is of interest to cyclists. We propose a system for object recognition that is trained with only 15 examples per class on average. To achieve this, we combine the advantages of convolutional neural networks and random forests to learn a patch-wise classifier. In the next step, we map the random forest to a neural network and transform the classifier to a fully convolutional network. Thereby, the processing of full images is significantly accelerated and bounding boxes can be predicted. Finally, we integrate data of the Global Positioning System (GPS) to localize the predictions on the map. In comparison to Faster R-CNN and other networks for object recognition or algorithms for transfer learning, we considerably reduce the required amount of labeled data. We demonstrate good performance on the recognition of traffic signs for cyclists as well as their localization in maps. version:1
arxiv-1709-05871 | IBM Deep Learning Service | http://arxiv.org/abs/1709.05871 | id:1709.05871 author:Bishwaranjan Bhattacharjee, Scott Boag, Chandani Doshi, Parijat Dube, Ben Herta, Vatche Ishakian, K. R. Jayaram, Rania Khalaf, Avesh Krishna, Yu Bo Li, Vinod Muthusamy, Ruchir Puri, Yufei Ren, Florian Rosenberg, Seetharami R. Seelam, Yandong Wang, Jian Ming Zhang, Li Zhang category:cs.DC  published:2017-09-18 summary:Deep learning driven by large neural network models is overtaking traditional machine learning methods for understanding unstructured and perceptual data domains such as speech, text, and vision. At the same time, the "as-a-Service"-based business model on the cloud is fundamentally transforming the information technology industry. These two trends: deep learning, and "as-a-service" are colliding to give rise to a new business model for cognitive application delivery: deep learning as a service in the cloud. In this paper, we will discuss the details of the software architecture behind IBM's deep learning as a service (DLaaS). DLaaS provides developers the flexibility to use popular deep learning libraries such as Caffe, Torch and TensorFlow, in the cloud in a scalable and resilient manner with minimal effort. The platform uses a distribution and orchestration layer that facilitates learning from a large amount of data in a reasonable amount of time across compute nodes. A resource provisioning layer enables flexible job management on heterogeneous resources, such as graphics processing units (GPUs) and central processing units (CPUs), in an infrastructure as a service (IaaS) cloud. version:1
arxiv-1709-05870 | ZhuSuan: A Library for Bayesian Deep Learning | http://arxiv.org/abs/1709.05870 | id:1709.05870 author:Jiaxin Shi, Jianfei Chen, Jun Zhu, Shengyang Sun, Yucen Luo, Yihong Gu, Yuhao Zhou category:stat.ML cs.AI cs.LG cs.NE stat.CO  published:2017-09-18 summary:In this paper we introduce ZhuSuan, a python probabilistic programming library for Bayesian deep learning, which conjoins the complimentary advantages of Bayesian methods and deep learning. ZhuSuan is built upon Tensorflow. Unlike existing deep learning libraries, which are mainly designed for deterministic neural networks and supervised tasks, ZhuSuan is featured for its deep root into Bayesian inference, thus supporting various kinds of probabilistic models, including both the traditional hierarchical Bayesian models and recent deep generative models. We use running examples to illustrate the probabilistic programming on ZhuSuan, including Bayesian logistic regression, variational auto-encoders, deep sigmoid belief networks and Bayesian recurrent neural networks. version:1
arxiv-1709-05869 | Use of Information, Memory and Randomization in Asynchronous Gathering | http://arxiv.org/abs/1709.05869 | id:1709.05869 author:Andrzej Pelc category:cs.DC  published:2017-09-18 summary:We investigate initial information, unbounded memory and randomization in gathering mobile agents on a grid. We construct a state machine, such that it is possible to gather, with probability 1, all configurations of its copies. This machine has initial input, unbounded memory, and is randomized. We show that no machine having any two of these capabilities but not the third, can be used to gather, with high probability, all configurations. We construct deterministic Turing Machines that are used to gather all connected configurations, and we construct deterministic finite automata that are used to gather all contractible connected configurations. version:1
arxiv-1709-02618 | The Shape of a Benedictine Monastery: The SaintGall Ontology | http://arxiv.org/abs/1709.02618 | id:1709.02618 author:Claudia Cantale, Domenico Cantone, Manuela Lupica Rinato, Marianna Nicolosi-Asmundo, Daniele Francesco Santamaria category:cs.AI cs.LO  published:2017-09-08 summary:We present an OWL 2 ontology representing the Saint Gall plan, one of the most ancient documents arrived intact to us, which describes the ideal model of a Benedictine monastic complex that inspired the design of many European monasteries. version:4
arxiv-1709-05862 | Recognizing Objects In-the-wild: Where Do We Stand? | http://arxiv.org/abs/1709.05862 | id:1709.05862 author:Mohammad Reza Loghmani, Barbara Caputo, Markus Vincze category:cs.RO cs.CV  published:2017-09-18 summary:The ability to recognize objects is an essential skill for a robotic system acting in human-populated environments. Despite decades of effort from the robotic and vision research communities, robots are still missing good visual perceptual systems, preventing the use of autonomous agents for real-world applications. The progress is slowed down by the lack of a testbed able to accurately represent the world perceived by the robot in-the-wild. In order to fill this gap, we introduce a large-scale, multi-view object dataset collected with an RGB-D camera mounted on a mobile robot. The dataset embeds the challenges faced by a robot in a real-life application and provides a useful tool for validating object recognition algorithms. Besides describing the characteristics of the dataset, the paper evaluates the performance of a collection of well-established deep convolutional networks on the new dataset and analyzes the transferability of deep representations from Web images to robotic data. Despite the promising results obtained with such representations, the experiments demonstrate that object classification with real-life robotic data is far from being solved. Finally, we provide a comparative study to analyze and highlight the open challenges in robot vision, explaining the discrepancies in the performance. version:1
arxiv-1709-05843 | Decentralized Collision-Free Control of Multiple Robots in 2D and 3D Spaces | http://arxiv.org/abs/1709.05843 | id:1709.05843 author:Xiaotian Yang category:cs.RO cs.MA cs.SY I.2.9; I.2.11  published:2017-09-18 summary:Decentralized control of robots has attracted huge research interests. However, some of the research used unrealistic assumptions without collision avoidance. This report focuses on the collision-free control for multiple robots in both complete coverage and search tasks in 2D and 3D areas which are arbitrary unknown. All algorithms are decentralized as robots have limited abilities and they are mathematically proved. The report starts with the grid selection in the two tasks. Grid patterns simplify the representation of the area and robots only need to move straightly between neighbor vertices. For the 100% complete 2D coverage, the equilateral triangular grid is proposed. For the complete coverage ignoring the boundary effect, the grid with the fewest vertices is calculated in every situation for both 2D and 3D areas. The second part is for the complete coverage in 2D and 3D areas. A decentralized collision-free algorithm with the above selected grid is presented driving robots to sections which are furthest from the reference point. The area can be static or expanding, and the algorithm is simulated in MATLAB. Thirdly, three grid-based decentralized random algorithms with collision avoidance are provided to search targets in 2D or 3D areas. The number of targets can be known or unknown. In the first algorithm, robots choose vacant neighbors randomly with priorities on unvisited ones while the second one adds the repulsive force to disperse robots if they are close. In the third algorithm, if surrounded by visited vertices, the robot will use the breadth-first search algorithm to go to one of the nearest unvisited vertices via the grid. The second search algorithm is verified on Pioneer 3-DX robots. The general way to generate the formula to estimate the search time is demonstrated. Algorithms are compared with five other algorithms in MATLAB to show their effectiveness. version:1
arxiv-1709-05825 | Relational Marginal Problems: Theory and Estimation | http://arxiv.org/abs/1709.05825 | id:1709.05825 author:Ondrej Kuzelka, Yuyi Wang, Jesse Davis, Steven Schockaert category:cs.AI  published:2017-09-18 summary:In the propositional setting, the marginal problem is to find a (maximum-entropy) distribution that has some given marginals. We study this problem in a relational setting and make the following contributions. First, we compare two different notions of relational marginals. Second, we show a duality between the resulting relational marginal problems and the maximum likelihood estimation of the parameters of relational models, which generalizes a well-known duality from the propositional setting. Third, by exploiting the relational marginal formulation, we present a statistically sound method to learn the parameters of relational models that will be applied in settings where the number of constants differs between the training and test data. Furthermore, based on a relational generalization of marginal polytopes, we characterize cases where the standard estimators based on feature's number of true groundings needs to be adjusted and we quantitatively characterize the consequences of these adjustments. Fourth, we prove bounds on expected errors of the estimated parameters, which allows us to lower-bound, among other things, the effective sample size of relational training data. version:1
arxiv-1709-05774 | Direction-Aware Semi-Dense SLAM | http://arxiv.org/abs/1709.05774 | id:1709.05774 author:Julian Straub, Randi Cabezas, John Leonard, John W. Fisher III category:cs.CV cs.AI  published:2017-09-18 summary:To aide simultaneous localization and mapping (SLAM), future perception systems will incorporate forms of scene understanding. In a step towards fully integrated probabilistic geometric scene understanding, localization and mapping we propose the first direction-aware semi-dense SLAM system. It jointly infers the directional Stata Center World (SCW) segmentation and a surfel-based semi-dense map while performing real-time camera tracking. The joint SCW map model connects a scene-wide Bayesian nonparametric Dirichlet Process von-Mises-Fisher mixture model (DP-vMF) prior on surfel orientations with the local surfel locations via a conditional random field (CRF). Camera tracking leverages the SCW segmentation to improve efficiency via guided observation selection. Results demonstrate improved SLAM accuracy and tracking efficiency at state of the art performance. version:1
arxiv-1709-05748 | Settling Payments Fast and Private: Efficient Decentralized Routing for Path-Based Transactions | http://arxiv.org/abs/1709.05748 | id:1709.05748 author:Stefanie Roos, Pedro Moreno-Sanchez, Aniket Kate, Ian Goldberg category:cs.CR cs.DC  published:2017-09-18 summary:Path-based transaction (PBT) networks, which settle payments from one user to another via a path of intermediaries, are a growing area of research. They overcome the scalability and privacy issues in cryptocurrencies like Bitcoin and Ethereum by replacing expensive and slow on-chain blockchain operations with inexpensive and fast off-chain transfers. In the form of credit networks such as Ripple and Stellar, they also enable low-price real-time gross settlements across different currencies. For example, SilentWhsipers is a recently proposed fully distributed credit network relying on path-based transactions for secure and in particular private payments without a public ledger. At the core of a decentralized PBT network is a routing algorithm that discovers transaction paths between payer and payee. During the last year, a number of routing algorithms have been proposed. However, the existing ad hoc efforts lack either efficiency or privacy. In this work, we first identify several efficiency concerns in SilentWhsipers. Armed with this knowledge, we design and evaluate SpeedyMurmurs, a novel routing algorithm for decentralized PBT networks using efficient and flexible embedding-based path discovery and on-demand efficient stabilization to handle the dynamics of a PBT network. Our simulation study, based on real-world data from the currently deployed Ripple credit network, indicates that SpeedyMurmurs reduces the overhead of stabilization by up to two orders of magnitude and the overhead of routing a transaction by more than a factor of two. Furthermore, using SpeedyMurmurs maintains at least the same success ratio as decentralized landmark routing, while providing lower delays. Finally, SpeedyMurmurs achieves key privacy goals for routing in PBT networks. version:1
arxiv-1709-05746 | Sim-to-real Transfer of Visuo-motor Policies for Reaching in Clutter: Domain Randomization and Adaptation with Modular Networks | http://arxiv.org/abs/1709.05746 | id:1709.05746 author:Fangyi Zhang, Jürgen Leitner, Michael Milford, Peter Corke category:cs.RO cs.AI cs.CV cs.LG cs.SY  published:2017-09-18 summary:A modular method is proposed to learn and transfer visuo-motor policies from simulation to the real world in an efficient manner by combining domain randomization and adaptation. The feasibility of the approach is demonstrated in a table-top object reaching task where a 7 DoF arm is controlled in velocity mode to reach a blue cuboid in clutter through visual observations. The learned visuo-motor policies are robust to novel (not seen in training) objects in clutter and even a moving target, achieving a 93.3% success rate and 2.2 cm control accuracy. version:1
arxiv-1709-05708 | Cost-Based Assessment of Partitioning Algorithms of Agent-Based Systems on Hybrid Cloud Environments | http://arxiv.org/abs/1709.05708 | id:1709.05708 author:Chahrazed Labba, Narjès Bellamine Ben Saoud category:cs.DC  published:2017-09-17 summary:Distributing agent-based simulators reveals many challenges while deploying them on a hybrid cloud infrastructure. In fact, a researcher's main motivations by running simulations on hybrid clouds, are reaching more scalable systems as well as reducing monetary costs. Indeed, hybrid cloud environment, despite providing scalability and effective control over proper data, requires an efficient deployment strategy combining both an efficient partitioning mechanism and cost savings. In this paper, we propose a cost deployment model dedicated to distributed agent-based simulation systems. This cost model, combining general performance partitioning criteria as well as monetary costs, is used to evaluate cluster and grid based partitioning algorithms on hybrid cloud environments. The first experimental results show that, for a given agent-based model, a good partitioning method used with the suitable hybrid cloud environment lead to an efficient and economic deployment. version:1
arxiv-1709-05703 | AI Programmer: Autonomously Creating Software Programs Using Genetic Algorithms | http://arxiv.org/abs/1709.05703 | id:1709.05703 author:Kory Becker, Justin Gottschlich category:cs.AI cs.NE  published:2017-09-17 summary:In this paper, we present the first-of-its-kind machine learning (ML) system, called AI Programmer, that can automatically generate full software programs requiring only minimal human guidance. At its core, AI Programmer uses genetic algorithms (GA) coupled with a tightly constrained programming language that minimizes the overhead of its ML search space. Part of AI Programmer's novelty stems from (i) its unique system design, including an embedded, hand-crafted interpreter for efficiency and security and (ii) its augmentation of GAs to include instruction-gene randomization bindings and programming language-specific genome construction and elimination techniques. We provide a detailed examination of AI Programmer's system design, several examples detailing how the system works, and experimental data demonstrating its software generation capabilities and performance using only mainstream CPUs. version:1
arxiv-1709-05684 | A Categorical Approach for Recognizing Emotional Effects of Music | http://arxiv.org/abs/1709.05684 | id:1709.05684 author:Mohsen Sahraei Ardakani, Ehsan Arbabi category:cs.AI cs.SD stat.ML  published:2017-09-17 summary:Recently, digital music libraries have been developed and can be plainly accessed. Latest research showed that current organization and retrieval of music tracks based on album information are inefficient. Moreover, they demonstrated that people use emotion tags for music tracks in order to search and retrieve them. In this paper, we discuss separability of a set of emotional labels, proposed in the categorical emotion expression, using Fisher's separation theorem. We determine a set of adjectives to tag music parts: happy, sad, relaxing, exciting, epic and thriller. Temporal, frequency and energy features have been extracted from the music parts. It could be seen that the maximum separability within the extracted features occurs between relaxing and epic music parts. Finally, we have trained a classifier using Support Vector Machines to automatically recognize and generate emotional labels for a music part. Accuracy for recognizing each label has been calculated; where the results show that epic music can be recognized more accurately (77.4%), comparing to the other types of music. version:1
arxiv-1709-05666 | On Inductive Abilities of Latent Factor Models for Relational Learning | http://arxiv.org/abs/1709.05666 | id:1709.05666 author:Théo Trouillon, Éric Gaussier, Christopher R. Dance, Guillaume Bouchard category:cs.LG cs.AI stat.ML  published:2017-09-17 summary:Latent factor models are increasingly popular for modeling multi-relational knowledge graphs. By their vectorial nature, it is not only hard to interpret why this class of models works so well, but also to understand where they fail and how they might be improved. We conduct an experimental survey of state-of-the-art models, not towards a purely comparative end, but as a means to get insight about their inductive abilities. To assess the strengths and weaknesses of each model, we create simple tasks that exhibit first, atomic properties of binary relations, and then, common inter-relational inference through synthetic genealogies. Based on these experimental results, we propose new research directions to improve on existing models. version:1
arxiv-1708-08377 | Two-Dimensional Indirect Binary Search for the Positive One-in-Three Satisfiability Problem | http://arxiv.org/abs/1708.08377 | id:1708.08377 author:Shunichi Matsubara category:cs.DS cs.AI cs.CC cs.DM math.CO  published:2017-08-28 summary:In this paper, we propose an algorithm for the positive one-in-three satisfiability problem (Pos1in3SAT). The proposed algorithm can efficiently decide the existence of a satisfying assignment in all assignments for a given formula by using a 2-dimensional binary search method without constructing an exponential number of assignments. version:2
arxiv-1709-05638 | Reinforcement Learning Based Conversational Search Assistant | http://arxiv.org/abs/1709.05638 | id:1709.05638 author:Milan Aggarwal, Aarushi Arora, Shagun Sodhani, Balaji Krishnamurthy category:cs.AI  published:2017-09-17 summary:In this work, we develop an end-to-end Reinforcement Learning based architecture for a conversational search agent to assist users in searching on an e-commerce marketplace for digital assets. Our approach caters to a search task fundamentally different from the ones which have limited search modalities where the user can express his preferences objectively. The system interacts with the users to display search results to the queries, and gauges user's intent and context of the conversation to choose the next action and reply. To train the agent in the absence of true conversation data, a virtual user is constructed to model a human user using the query and session logs from a major stock photography and digital assets marketplace. The system provides an alternative that is more engaging than the traditional search while maintaining similar effectiveness. This work provides a mechanism to build and deploy bootstrapped version of an effective conversational agent from readily available query log data. The system can then be used to acquire true conversational data and be fine-tuned further. The methodology discussed in this paper can be extended to e-commerce domains in general. version:1
arxiv-1709-05635 | Joining Jolie to Docker - Orchestration of Microservices on a Containers-as-a-Service Layer | http://arxiv.org/abs/1709.05635 | id:1709.05635 author:Alberto Giaretta, Nicola Dragoni, Manuel Mazzara category:cs.SE cs.DC  published:2017-09-17 summary:Cloud computing is steadily growing and, as IaaS vendors have started to offer pay-as-you-go billing policies, it is fundamental to achieve as much elasticity as possible, avoiding over-provisioning that would imply higher costs. In this paper, we briefly analyse the orchestration characteristics of PaaSSOA, a proposed architecture already implemented for Jolie microservices, and Kubernetes, one of the various orchestration plugins for Docker; then, we outline similarities and differences of the two approaches, with respect to their own domain of application. Furthermore, we investigate some ideas to achieve a federation of the two technologies, proposing an architectural composition of Jolie microservices on Docker Container-as-a-Service layer. version:1
arxiv-1709-05628 | Design, Development and Evaluation of a UAV to Study Air Quality in Qatar | http://arxiv.org/abs/1709.05628 | id:1709.05628 author:Khalid Al-Hajjaji, Mouadh Ezzin, Husain Khamdan, Abdelhakim El Hassani, Nizar Zorba category:cs.RO cs.CY  published:2017-09-17 summary:Measuring gases for air quality monitoring is a challenging task that claims a lot of time of observation and large numbers of sensors. The aim of this project is to develop a partially autonomous unmanned aerial vehicle (UAV) equipped with sensors, in order to monitor and collect air quality real time data in designated areas and send it to the ground base. This project is designed and implemented by a multidisciplinary team from electrical and computer engineering departments. The electrical engineering team responsible for implementing air quality sensors for detecting real time data and transmit it from the plane to the ground. On the other hand, the computer engineering team is in charge of Interface sensors and provide platform to view and visualize air quality data and live video streaming. The proposed project contains several sensors to measure Temperature, Humidity, Dust, CO, CO2 and O3. The collected data is transmitted to a server over a wireless internet connection and the server will store, and supply these data to any party who has permission to access it through android phone or website in semi-real time. The developed UAV has carried several field tests in Al Shamal airport in Qatar, with interesting results and proof of concept outcomes. version:1
arxiv-1709-01265 | Probabilistic Surfel Fusion for Dense LiDAR Mapping | http://arxiv.org/abs/1709.01265 | id:1709.01265 author:Chanoh Park, Soohwan Kim, Peyman Moghadam, Clinton Fookes, Sridha Sridharan category:cs.RO  published:2017-09-05 summary:With the recent development of high-end LiDARs, more and more systems are able to continuously map the environment while moving and producing spatially redundant information. However, none of the previous approaches were able to effectively exploit this redundancy in a dense LiDAR mapping problem. In this paper, we present a new approach for dense LiDAR mapping using probabilistic surfel fusion. The proposed system is capable of reconstructing a high-quality dense surface element (surfel) map from spatially redundant multiple views. This is achieved by a proposed probabilistic surfel fusion along with a geometry considered data association. The proposed surfel data association method considers surface resolution as well as high measurement uncertainty along its beam direction which enables the mapping system to be able to control surface resolution without introducing spatial digitization. The proposed fusion method successfully suppresses the map noise level by considering measurement noise caused by laser beam incident angle and depth distance in a Bayesian filtering framework. Experimental results with simulated and real data for the dense surfel mapping prove the ability of the proposed method to accurately find the canonical form of the environment without further post-processing. version:2
arxiv-1709-05601 | Markov Brains: A Technical Introduction | http://arxiv.org/abs/1709.05601 | id:1709.05601 author:Arend Hintze, Jeffrey A. Edlund, Randal S. Olson, David B. Knoester, Jory Schossau, Larissa Albantakis, Ali Tehrani-Saleh, Peter Kvam, Leigh Sheneman, Heather Goldsby, Clifford Bohm, Christoph Adami category:cs.AI  published:2017-09-17 summary:Markov Brains are a class of evolvable artificial neural networks (ANN). They differ from conventional ANNs in many aspects, but the key difference is that instead of a layered architecture, with each node performing the same function, Markov Brains are networks built from individual computational components. These computational components interact with each other, receive inputs from sensors, and control motor outputs. The function of the computational components, their connections to each other, as well as connections to sensors and motors are all subject to evolutionary optimization. Here we describe in detail how a Markov Brain works, what techniques can be used to study them, and how they can be evolved. version:1
arxiv-1709-05588 | Hybrid Fault diagnosis capability analysis of Hypercubes under the PMC model and MM* model | http://arxiv.org/abs/1709.05588 | id:1709.05588 author:Qiang Zhu, Lili Li, Sanyang Liu, Xing Zhang category:cs.DC  published:2017-09-17 summary:System level diagnosis is an important approach for the fault diagnosis of multiprocessor systems. In system level diagnosis, diagnosability is an important measure of the diagnosis capability of interconnection networks. But as a measure, diagnosability can not reflect the diagnosis capability of multiprocessor systems to link faults which may occur in real circumstances. In this paper, we propose the definition of $h$-edge tolerable diagnosability to better measure the diagnosis capability of interconnection networks under hybrid fault circumstances. The $h$-edge tolerable diagnosability of a multiprocessor system $G$ is the maximum number of faulty nodes that the system can guarantee to locate when the number of faulty edges does not exceed $h$,denoted by $t_h^{e}(G)$. The PMC model and MM model are the two most widely studied diagnosis models for the system level diagnosis of multiprocessor systems. The hypercubes are the most well-known interconnection networks. In this paper, the $h$-edge tolerable diagnosability of $n$-dimensional hypercube under the PMC model and MM$^{*}$ is determined as follows: $t_h^{e}(Q_n)= n-h$, where $1\leq h<n$, $n\geq3$. version:1
arxiv-1709-05581 | Multi-Modal Multi-Task Deep Learning for Autonomous Driving | http://arxiv.org/abs/1709.05581 | id:1709.05581 author:Sauhaarda Chowdhuri, Tushar Pankaj, Karl Zipser category:cs.LG cs.RO  published:2017-09-16 summary:Several deep learning approaches have been applied to the autonomous driving task, many employing end-to-end deep neural networks. Autonomous driving is complex, utilizing multiple behavioral modalities ranging from lane changing to turning and stopping. However, most existing approaches do not factor in the different behavioral modalities of the driving task into the training strategy. This paper describes a technique for using Multi-Modal Multi-Task Learning that considers multiple behavioral modalities as distinct modes of operation for an end-to-end autonomous deep neural network utilizing the insertion of modal information as secondary input data. Using labeled data from hours of driving our fleet of 1/10th scale model cars, we trained multiple neural networks to imitate the steering angle and driving speed of human control of a car. We show that in each case, our models trained with MTL can match or outperform multiple networks trained on individual tasks, while using a fraction of the parameters and having more distinct modes of operation than a network trained without MTL on the same multi-modal data. These results should encourage Multi-Modal MTL-style training with the insertion of Modal Information for tasks with related behaviors. version:1
arxiv-1709-05576 | SKOS Concepts and Natural Language Concepts: an Analysis of Latent Relationships in KOSs | http://arxiv.org/abs/1709.05576 | id:1709.05576 author:Anna Mastora, Manolis Peponakis, Sarantos Kapidakis category:cs.DL cs.AI cs.CL  published:2017-09-16 summary:The vehicle to represent Knowledge Organization Systems (KOSs) in the environment of the Semantic Web and linked data is the Simple Knowledge Organization System (SKOS). SKOS provides a way to assign a URI to each concept, and this URI functions as a surrogate for the concept. This fact makes of main concern the need to clarify the URIs' ontological meaning. The aim of this study is to investigate the relation between the ontological substance of KOS concepts and concepts revealed through the grammatical and syntactic formalisms of natural language. For this purpose, we examined the dividableness of concepts in specific KOSs (i.e. a thesaurus, a subject headings system and a classification scheme) by applying Natural Language Processing (NLP) techniques (i.e. morphosyntactic analysis) to the lexical representations (i.e. RDF literals) of SKOS concepts. The results of the comparative analysis reveal that, despite the use of multi-word units, thesauri tend to represent concepts in a way that can hardly be further divided conceptually, while Subject Headings and Classification Schemes - to a certain extent - comprise terms that can be decomposed into more conceptual constituents. Consequently, SKOS concepts deriving from thesauri are more likely to represent atomic conceptual units and thus be more appropriate tools for inference and reasoning. Since identifiers represent the meaning of a concept, complex concepts are neither the most appropriate nor the most efficient way of modelling a KOS for the Semantic Web. version:1
arxiv-1709-06080 | Feedforward and Recurrent Neural Networks Backward Propagation and Hessian in Matrix Form | http://arxiv.org/abs/1709.06080 | id:1709.06080 author:Maxim Naumov category:cs.LG cs.AI math.NA I.2.6; I.5.0  published:2017-09-16 summary:In this paper we focus on the linear algebra theory behind feedforward (FNN) and recurrent (RNN) neural networks. We review backward propagation, including backward propagation through time (BPTT). Also, we obtain a new exact expression for Hessian, which represents second order effects. We show that for $t$ time steps the weight gradient can be expressed as a rank-$t$ matrix, while the weight Hessian is as a sum of $t^{2}$ Kronecker products of rank-$1$ and $W^{T}AW$ matrices, for some matrix $A$ and weight matrix $W$. Also, we show that for a mini-batch of size $r$, the weight update can be expressed as a rank-$rt$ matrix. Finally, we briefly comment on the eigenvalues of the Hessian matrix. version:1
arxiv-1709-04240 | A Comparison of Public Causal Search Packages on Linear, Gaussian Data with No Latent Variables | http://arxiv.org/abs/1709.04240 | id:1709.04240 author:Joseph D. Ramsey, Bryan Andrews category:cs.AI  published:2017-09-13 summary:We compare Tetrad (Java) algorithms to the other public software packages BNT (Bayes Net Toolbox, Matlab), pcalg (R), bnlearn (R) on the \vanilla" task of recovering DAG structure to the extent possible from data generated recursively from linear, Gaussian structure equation models (SEMs) with no latent variables, for random graphs, with no additional knowledge of variable order or adjacency structure, and without additional specification of intervention information. Each one of the above packages offers at least one implementation suitable to this purpose. We compare them on adjacency and orientation accuracy as well as time performance, for fixed datasets. We vary the number of variables, the number of samples, and the density of graph, for a total of 27 combinations, averaging all statistics over 10 runs, for a total of 270 datasets. All runs are carried out on the same machine and on their native platforms. An interactive visualization tool is provided for the reader who wishes to know more than can be documented explicitly in this report. version:2
arxiv-1709-05533 | Topomap: Topological Mapping and Navigation Based on Visual SLAM Maps | http://arxiv.org/abs/1709.05533 | id:1709.05533 author:Fabian Blöchliger, Marius Fehr, Marcin Dymczyk, Thomas Schneider, Roland Siegwart category:cs.RO  published:2017-09-16 summary:Visual robot navigation within large-scale, semistructured environments deals with various challenges such as computation intensive path planning algorithms or insufficient knowledge about traversable spaces. Moreover, many stateof-the-art navigation approaches only operate locally instead of gaining a more conceptual understanding of the planning objective. This limits the complexity of tasks a robot can accomplish and makes it harder to deal with uncertainties that are present in the context of real-time robotics applications. In this work, we present Topomap, a framework which simplifies the navigation task by providing a map to the robot which is tailored for path planning use. This novel approach transforms a sparse feature-based map from a visual Simultaneous Localization And Mapping (SLAM) system into a three-dimensional topological map. This is done in two steps. First, we extract occupancy information directly from the noisy sparse point cloud. Then, we create a set of convex free-space clusters, which are the vertices of the topological map. We show that this representation improves the efficiency of global planning, and we provide a complete derivation of our algorithm. Planning experiments on real world datasets demonstrate that we achieve similar performance as RRT* with significantly lower computation times and storage requirements. Finally, we test our algorithm on a mobile robotic platform to prove its advantages. version:1
arxiv-1709-05483 | sPIN: High-performance streaming Processing in the Network | http://arxiv.org/abs/1709.05483 | id:1709.05483 author:Torsten Hoefler, Salvatore Di Girolamo, Konstantin Taranov, Ryan E. Grant, Ron Brightwell category:cs.DC  published:2017-09-16 summary:Optimizing communication performance is imperative for large-scale computing because communication overheads limit the strong scalability of parallel applications. Today's network cards contain rather powerful processors optimized for data movement. However, these devices are limited to fixed functions, such as remote direct memory access. We develop sPIN, a portable programming model to offload simple packet processing functions to the network card. To demonstrate the potential of the model, we design a cycle-accurate simulation environment by combining the network simulator LogGOPSim and the CPU simulator gem5. We implement offloaded message matching, datatype processing, and collective communications and demonstrate transparent full-application speedups. Furthermore, we show how sPIN can be used to accelerate redundant in-memory filesystems and several other use cases. Our work investigates a portable packet-processing network acceleration model similar to compute acceleration with CUDA or OpenCL. We show how such network acceleration enables an eco-system that can significantly speed up applications and system services. version:1
arxiv-1709-05479 | AA-ICP: Iterative Closest Point with Anderson Acceleration | http://arxiv.org/abs/1709.05479 | id:1709.05479 author:A. L. Pavlov, G. V. Ovchinnikov, D. Yu. Derbyshev, D. Tsetserukou, I. V. Oseledets category:cs.RO  published:2017-09-16 summary:Iterative Closest Point (ICP) is a widely used method for performing scan-matching and registration. Being simple and robust method, it is still computationally expensive and may be challenging to use in real-time applications with limited resources on mobile platforms. In this paper we propose novel effective method for acceleration of ICP which does not require substantial modifications to the existing code. This method is based on an idea of Anderson acceleration which is an iterative procedure for finding a fixed point of contractive mapping. The latter is often faster than a standard Picard iteration, usually used in ICP implementations. We show that ICP, being a fixed point problem, can be significantly accelerated by this method enhanced by heuristics to improve overall robustness. We implement proposed approach into Point Cloud Library (PCL) and make it available online. Benchmarking on real-world data fully supports our claims. version:1
arxiv-1709-05474 | Sensor-Based Reactive Symbolic Planning in Partially Known Environments | http://arxiv.org/abs/1709.05474 | id:1709.05474 author:Vasileios Vasilopoulos, William Vega-Brown, Omur Arslan, Nicholas Roy, Daniel E. Koditschek category:cs.RO  published:2017-09-16 summary:This paper considers the problem of completing assemblies of passive objects in nonconvex environments, cluttered with convex obstacles of unknown position, shape and size that satisfy a specific separation assumption. A differential drive robot equipped with a gripper and a LIDAR sensor, capable of perceiving its environment only locally, is used to position the passive objects in a desired configuration. The method combines the virtues of a deliberative planner generating high-level, symbolic commands, with the formal guarantees of convergence and obstacle avoidance of a reactive planner that requires little onboard computation and is used online. The validity of the proposed method is verified both with formal proofs and numerical simulations. version:1
arxiv-1709-05453 | Augmenting End-to-End Dialog Systems with Commonsense Knowledge | http://arxiv.org/abs/1709.05453 | id:1709.05453 author:Tom Young, Erik Cambria, Iti Chaturvedi, Minlie Huang, Hao Zhou, Subham Biswas category:cs.AI cs.CL  published:2017-09-16 summary:Building dialog agents that can converse naturally with humans is a challenging yet intriguing problem of artificial intelligence. In open-domain human-computer conversation, where the conversational agent is expected to respond to human responses in an interesting and engaging way, commonsense knowledge has to be integrated into the model effectively. In this paper, we investigate the impact of providing commonsense knowledge about the concepts covered in the dialog. Our model represents the first attempt to integrating a large commonsense knowledge base into end-to-end conversational models. In the retrieval-based scenario, we propose the Tri-LSTM model to jointly take into account message and commonsense for selecting an appropriate response. Our experiments suggest that the knowledge-augmented models are superior to their knowledge-free counterparts in automatic evaluation. version:1
arxiv-1708-06303 | Network Model Selection for Task-Focused Attributed Network Inference | http://arxiv.org/abs/1708.06303 | id:1708.06303 author:Ivan Brugere, Chris Kanich, Tanya Y. Berger-Wolf category:cs.SI cs.AI  published:2017-08-21 summary:Networks are models representing relationships between entities. Often these relationships are explicitly given, or we must learn a representation which generalizes and predicts observed behavior in underlying individual data (e.g. attributes or labels). Whether given or inferred, choosing the best representation affects subsequent tasks and questions on the network. This work focuses on model selection to evaluate network representations from data, focusing on fundamental predictive tasks on networks. We present a modular methodology using general, interpretable network models, task neighborhood functions found across domains, and several criteria for robust model selection. We demonstrate our methodology on three online user activity datasets and show that network model selection for the appropriate network task vs. an alternate task increases performance by an order of magnitude in our experiments. version:2
arxiv-1709-05448 | Learning Sampling Distributions for Robot Motion Planning | http://arxiv.org/abs/1709.05448 | id:1709.05448 author:Brian Ichter, James Harrison, Marco Pavone category:cs.RO cs.LG  published:2017-09-16 summary:A defining feature of sampling-based motion planning is the reliance on an implicit representation of the state space, which is enabled by a set of probing samples. Traditionally, these samples are drawn either probabilistically or deterministically to uniformly cover the state space. Yet, the motion of many robotic systems is often restricted to "small" regions of the state space, due to e.g. differential constraints or collision-avoidance constraints. To accelerate the planning process, it is thus desirable to devise non-uniform sampling strategies that favor sampling in those regions where an optimal solution might lie. This paper proposes a methodology for non-uniform sampling, whereby a sampling distribution is learnt from demonstrations, and then used to bias sampling. The sampling distribution is computed through a conditional variational autoencoder, allowing sample generation from the latent space conditioned on the specific planning problem. This methodology is general, can be used in combination with any sampling-based planner, and can effectively exploit the underlying structure of a planning problem while maintaining the theoretical guarantees of sampling-based approaches. Specifically, on several planning problems, the proposed methodology is shown to effectively learn representations for the relevant regions of the state space, resulting in an order of magnitude improvement in terms of success rate and convergence to the optimal cost. version:1
arxiv-1709-04696 | DiSAN: Directional Self-Attention Network for RNN/CNN-free Language Understanding | http://arxiv.org/abs/1709.04696 | id:1709.04696 author:Tao Shen, Tianyi Zhou, Guodong Long, Jing Jiang, Shirui Pan, Chengqi Zhang category:cs.CL cs.AI  published:2017-09-14 summary:Recurrent neural nets (RNN) and convolutional neural nets (CNN) are widely used in NLP tasks to capture the long-term and local dependencies respectively. Attention mechanisms have recently attracted enormous interest due to their highly parallelizable computation, significantly less training time, and flexibility in modeling dependencies. We propose a novel attention mechanism in which the attention between elements from input sequence(s) is directional and multi-dimensional, i.e., feature-wise. A light-weight neural net, "Directional Self-Attention Network (DiSAN)", is then proposed to learn sentence embedding, based solely on the proposed attention without any RNN/CNN structure. DiSAN is only composed of a directional self-attention block with temporal order encoded, followed by a multi-dimensional attention that compresses the sequence into a vector representation. Despite this simple form, DiSAN outperforms complicated RNN/CNN models on both prediction quality and efficiency. It achieves the best test accuracy among all sentence encoding methods and improves the most recent best result by about 1.0% on the Stanford Natural Language Inference (SNLI) dataset, and shows the state-of-the-art test accuracy on the Stanford Sentiment Treebank (SST), Sentences Involving Compositional Knowledge (SICK), TREC Question-type Classification and Multi-Genre Natural Language Inference (MultiNLI) datasets. version:2
arxiv-1709-05446 | Offline reconstruction of missing vehicle trajectory data from 3D LIDAR | http://arxiv.org/abs/1709.05446 | id:1709.05446 author:Cem Sazara, Reza Vatani Nezafat, Mecit Cetin category:cs.RO  published:2017-09-16 summary:LIDAR has become an important part of many autonomous vehicles with its advantages on distance measurement and obstacle detection. LIDAR produces point clouds which have important information about surrounding environment. In this paper, we collected trajectory data on a two lane urban road using a Velodyne VLP-16 Lidar. Due to dynamic nature of data collection and limited range of the sensor, some of these trajectories have missing points or gaps. In this paper, we propose a novel method for recovery of missing vehicle trajectory data points using microscopic traffic flow models. While short gaps (less than 5 seconds) can be recovered with simple linear regression, and longer gaps are recovered with the proposed method that makes use of car following models calibrated by assigning weights to known points based on proximity to the gaps. Newell's, Pipes, IDM and Gipps' car following models are calibrated and tested with the ground truth trajectory data from LIDAR and NGSIM I-80 dataset. Gipps' calibrated model yielded the best result. version:1
arxiv-1709-05440 | Process-oriented Iterative Multiple Alignment for Medical Process Mining | http://arxiv.org/abs/1709.05440 | id:1709.05440 author:Shuhong Chen, Sen Yang, Moliang Zhou, Randall S. Burd, Ivan Marsic category:cs.DS cs.AI  published:2017-09-16 summary:Adapted from biological sequence alignment, trace alignment is a process mining technique used to visualize and analyze workflow data. Any analysis done with this method, however, is affected by the alignment quality. The best existing trace alignment techniques use progressive guide-trees to heuristically approximate the optimal alignment in O(N2L2) time. These algorithms are heavily dependent on the selected guide-tree metric, often return sum-of-pairs-score-reducing errors that interfere with interpretation, and are computationally intensive for large datasets. To alleviate these issues, we propose process-oriented iterative multiple alignment (PIMA), which contains specialized optimizations to better handle workflow data. We demonstrate that PIMA is a flexible framework capable of achieving better sum-of-pairs score than existing trace alignment algorithms in only O(NL2) time. We applied PIMA to analyzing medical workflow data, showing how iterative alignment can better represent the data and facilitate the extraction of insights from data visualization. version:1
arxiv-1709-05439 | To Go or Not To Go? A Near Unsupervised Learning Approach For Robot Navigation | http://arxiv.org/abs/1709.05439 | id:1709.05439 author:Noriaki Hirose, Amir Sadeghian, Patrick Goebel, Silvio Savarese category:cs.CV cs.RO  published:2017-09-16 summary:It is important for robots to be able to decide whether they can go through a space or not, as they navigate through a dynamic environment. This capability can help them avoid injury or serious damage, e.g., as a result of running into people and obstacles, getting stuck, or falling off an edge. To this end, we propose an unsupervised and a near-unsupervised method based on Generative Adversarial Networks (GAN) to classify scenarios as traversable or not based on visual data. Our method is inspired by the recent success of data-driven approaches on computer vision problems and anomaly detection, and reduces the need for vast amounts of negative examples at training time. Collecting negative data indicating that a robot should not go through a space is typically hard and dangerous because of collisions, whereas collecting positive data can be automated and done safely based on the robot's own traveling experience. We verify the generality and effectiveness of the proposed approach on a test dataset collected in a previously unseen environment with a mobile robot. Furthermore, we show that our method can be used to build costmaps (we call as "GoNoGo" costmaps) for robot path planning using visual data only. version:1
arxiv-1709-05437 | A Causal And-Or Graph Model for Visibility Fluent Reasoning in Human-Object Interactions | http://arxiv.org/abs/1709.05437 | id:1709.05437 author:Lei Qin, Yuanlu Xu, Xiaobai Liu, Song-Chun Zhu category:cs.CV cs.AI  published:2017-09-16 summary:Tracking humans that are interacting with the other subjects or environment remains unsolved in visual tracking, because the visibility of the human of interests in videos is unknown and might vary over times. In particular, it is still difficult for state-of-the-art human trackers to recover complete human trajectories in crowded scenes with frequent human interactions. In this work, we consider the visibility status of a subject as a fluent variable, whose changes are mostly attributed to the subject's interactions with the surrounding, e.g., crossing behind another objects, entering a building, or getting into a vehicle, etc. We introduce a Causal And-Or Graph (C-AOG) to represent the causal-effect relations between an object's visibility fluents and its activities, and develop a probabilistic graph model to jointly reason the visibility fluent change (e.g., from visible to invisible) and track humans in videos. We formulate the above joint task as an iterative search of feasible causal graph structure that enables fast search algorithm, e.g., dynamic programming method. We apply the proposed method on challenging video sequences to evaluate its capabilities of estimating visibility fluent changes of subjects and tracking subjects of interests over time. Results with comparisons demonstrated that our method clearly outperforms the alternative trackers and can recover complete trajectories of humans in complicated scenarios with frequent human interactions. version:1
arxiv-1709-05436 | Joint Parsing of Cross-view Scenes with Spatio-temporal Semantic Parse Graphs | http://arxiv.org/abs/1709.05436 | id:1709.05436 author:Hang Qi, Yuanlu Xu, Tao Yuan, Tianfu Wu, Song-Chun Zhu category:cs.CV cs.AI  published:2017-09-16 summary:Cross-view video understanding is an important yet under-explored area in computer vision. In this paper, we introduce a joint parsing method that takes view-centric proposals from pre-trained computer vision models and produces spatio-temporal parse graphs that represents a coherent scene-centric understanding of cross-view scenes. Our key observations are that overlapping fields of views embed rich appearance and geometry correlations and that knowledge segments corresponding to individual vision tasks are governed by consistency constraints available in commonsense knowledge. The proposed joint parsing framework models such correlations and constraints explicitly and generates semantic parse graphs about the scene. Quantitative experiments show that scene-centric predictions in the parse graph outperform view-centric predictions. version:1
arxiv-1709-05435 | An Integrated System for Perception-Driven Autonomy with Modular Robots | http://arxiv.org/abs/1709.05435 | id:1709.05435 author:Jonathan Daudelin, Gangyuan Jing, Tarik Tosun, Mark Yim, Hadas Kress-Gazit, Mark Campbell category:cs.RO  published:2017-09-15 summary:The theoretical ability of modular robots to reconfigure in response to complex tasks in a priori unknown environments has frequently been cited as an advantage, but has never been experimentally demonstrated. For the first time, we present a system that integrates perception, high-level mission planning, and modular robot hardware, allowing a modular robot to autonomously reconfigure in response to an a priori unknown environment in order to complete high-level tasks. Three hardware experiments validate the system, and demonstrate a modular robot autonomously exploring, reconfiguring, and manipulating objects to complete high-level tasks in unknown environments. We present system architecture, software and hardware in a general framework that enables modular robots to solve tasks in unknown environments using autonomous, reactive reconfiguration. The physical robot is composed of modules that support multiple robot configurations. An onboard 3D sensor provides information about the environment and informs exploration, reconfiguration decision making and feedback control. A centralized high-level mission planner uses information from the environment and the user-specified task description to autonomously compose low-level controllers to perform locomotion, reconfiguration, and other behaviors. A novel, centralized self-reconfiguration method is used to change robot configurations as needed. version:1
arxiv-1708-07575 | Generalized Paxos Made Byzantine (and Less Complex) | http://arxiv.org/abs/1708.07575 | id:1708.07575 author:Miguel Pires, Srivatsan Ravi, Rodrigo Rodrigues category:cs.DC  published:2017-08-24 summary:One of the most recent members of the Paxos family of protocols is Generalized Paxos. This variant of Paxos has the characteristic that it departs from the original specification of consensus, allowing for a weaker safety condition where different processes can have a different views on a sequence being agreed upon. However, much like the original Paxos counterpart, Generalized Paxos does not have a simple implementation. Furthermore, with the recent practical adoption of Byzantine fault tolerant protocols, it is timely and important to understand how Generalized Paxos can be implemented in the Byzantine model. In this paper, we make two main contributions. First, we provide a description of Generalized Paxos that is easier to understand, based on a simpler specification and the pseudocode for a solution that can be readily implemented. Second, we extend the protocol to the Byzantine fault model. version:2
arxiv-1709-05401 | Search-based Motion Planning for Quadrotors using Linear Quadratic Minimum Time Control | http://arxiv.org/abs/1709.05401 | id:1709.05401 author:Sikang Liu, Nikolay Atanasov, Kartik Mohta, Vijay Kumar category:cs.RO  published:2017-09-15 summary:In this work, we propose a search-based planning method to compute dynamically feasible trajectories for a quadrotor flying in an obstacle-cluttered environment. Our approach searches for smooth, minimum-time trajectories by exploring the map using a set of short-duration motion primitives. The primitives are generated by solving an optimal control problem and induce a finite lattice discretization on the state space which can be explored using a graph-search algorithm. The proposed approach is able to generate resolution-complete (i.e., optimal in the discretized space), safe, dynamically feasibility trajectories efficiently by exploiting the explicit solution of a Linear Quadratic Minimum Time problem. It does not assume a hovering initial condition and, hence, is suitable for fast online re-planning while the robot is moving. Quadrotor navigation with online re-planning is demonstrated using the proposed approach in simulation and physical experiments and comparisons with trajectory generation based on state-of-art quadratic programming are presented. version:1
arxiv-1709-05380 | The Uncertainty Bellman Equation and Exploration | http://arxiv.org/abs/1709.05380 | id:1709.05380 author:Brendan O'Donoghue, Ian Osband, Remi Munos, Volodymyr Mnih category:cs.AI cs.LG math.OC stat.ML  published:2017-09-15 summary:We consider the exploration/exploitation problem in reinforcement learning. For exploitation, it is well known that the Bellman equation connects the value at any time-step to the expected value at subsequent time-steps. In this paper we consider a similar uncertainty Bellman equation (UBE), which connects the uncertainty at any time-step to the expected uncertainties at subsequent time-steps, thereby extending the potential exploratory benefit of a policy beyond individual time-steps. We prove that the unique fixed point of the UBE yields an upper bound on the variance of the estimated value of any fixed policy. This bound can be much tighter than traditional count-based bonuses that compound standard deviation rather than variance. Importantly, and unlike several existing approaches to optimism, this method scales naturally to large systems with complex generalization. Substituting our UBE-exploration strategy for $\epsilon$-greedy improves DQN performance on 51 out of 57 games in the Atari suite. version:1
arxiv-1709-06076 | Modelling Energy Consumption based on Resource Utilization | http://arxiv.org/abs/1709.06076 | id:1709.06076 author:Lucas Venezian Povoa, Cesar Marcondes, Hermes Senger category:cs.LG cs.DC  published:2017-09-15 summary:Power management is an expensive and important issue for large computational infrastructures such as datacenters, large clusters, and computational grids. However, measuring energy consumption of scalable systems may be impractical due to both cost and complexity for deploying power metering devices on a large number of machines. In this paper, we propose the use of information about resource utilization (e.g. processor, memory, disk operations, and network traffic) as proxies for estimating power consumption. We employ machine learning techniques to estimate power consumption using such information which are provided by common operating systems. Experiments with linear regression, regression tree, and multilayer perceptron on data from different hardware resulted into a model with 99.94\% of accuracy and 6.32 watts of error in the best case. version:1
arxiv-1709-06075 | Deep Graph Attention Model | http://arxiv.org/abs/1709.06075 | id:1709.06075 author:John Boaz Lee, Ryan Rossi, Xiangnan Kong category:cs.LG cs.AI  published:2017-09-15 summary:Graph classification is a problem with practical applications in many different domains. Most of the existing methods take the entire graph into account when calculating graph features. In a graphlet-based approach, for instance, the entire graph is processed to get the total count of different graphlets or sub-graphs. In the real-world, however, graphs can be both large and noisy with discriminative patterns confined to certain regions in the graph only. In this work, we study the problem of attentional processing for graph classification. The use of attention allows us to focus on small but informative parts of the graph, avoiding noise in the rest of the graph. We present a novel RNN model, called the Graph Attention Model (GAM), that processes only a portion of the graph by adaptively selecting a sequence of "interesting" nodes. The model is equipped with an external memory component which allows it to integrate information gathered from different parts of the graph. We demonstrate the effectiveness of the model through various experiments. version:1
arxiv-1709-05368 | Learning Ground Traversability from Simulations | http://arxiv.org/abs/1709.05368 | id:1709.05368 author:R. Omar Chavez-Garcia, Jerome Guzzi, Luca M. Gambardella, Alessandro Giusti category:cs.RO  published:2017-09-15 summary:Mobile robots operating on unstructured terrain must predict which areas of the environment they are able to pass in order to plan feasible paths and to react to unforeseen terrain patterns. We address traversability estimation as a heightmap classification problem: we build a convolutional neural network that, given an image representing the heightmap of a terrain patch, predicts whether the robot will be able to traverse such patch from left to right. The classifier is trained for a specific wheeled robot model (but may implement any other locomotion type such as tracked, legged, snake-like), using simulation data on a variety of procedurally generated training terrains; once trained, the classifier can quickly be applied to patches extracted from unseen large heightmaps, in multiple orientations, thus building oriented traversability maps. We quantitatively validate the approach on real-elevation datasets and implement a path planning approach that employs our traversability estimation. version:1
arxiv-1709-05363 | Synthesis of surveillance strategies via belief abstraction | http://arxiv.org/abs/1709.05363 | id:1709.05363 author:Suda Bharadwaj, Rayna Dimitrova, Ufuk Topcu category:cs.RO cs.GT cs.SY I.2.4  published:2017-09-15 summary:We study the problem of synthesizing a controller for a robot with a surveillance objective, that is, the robot is required to maintain knowledge of the location of a moving, possibly adversarial target. We formulate this problem as a one-sided partial-information game in which the winning condition for the agent is specified as a temporal logic formula. The specification formalizes the surveillance requirement given by the user, including additional non-surveillance tasks. In order to synthesize a surveillance strategy that meets the specification, we transform the partial-information game into a perfect-information one, using abstraction to mitigate the exponential blow-up typically incurred by such transformations. This enables the use of off-the-shelf tools for reactive synthesis. We use counterexample-guided refinement to automatically achieve abstraction precision that is sufficient to synthesize a surveillance strategy. We evaluate the proposed method on two case-studies, demonstrating its applicability to large state-spaces and diverse requirements. version:1
arxiv-1709-05360 | Embedding Deep Networks into Visual Explanations | http://arxiv.org/abs/1709.05360 | id:1709.05360 author:Zhongang Qi, Fuxin Li category:cs.CV cs.AI  published:2017-09-15 summary:In this paper, we propose a novel explanation module to explain the predictions made by deep learning. Explanation modules work by embedding a high-dimensional deep network layer nonlinearly into a low-dimensional explanation space, while retaining faithfulness in that the original deep learning predictions can be constructed from the few concepts extracted by the explanation module. We then visualize such concepts so that human can learn about the high-level concepts deep learning is using to make decisions. We propose an algorithm called Sparse Reconstruction Autoencoder (SRAE) for learning the embedding to the explanation space, SRAE aims to reconstruct part of the original feature space while retaining faithfulness. A visualization system is then introduced for human understanding of features in the explanation space. The proposed method is applied to explain CNN models in image classification tasks, and several novel metrics are introduced to evaluate the performance of explanations quantitatively without human involvement. Experiments show that the proposed approach could generate better explanations of the mechanisms CNN use for making predictions in the task. version:1
arxiv-1709-05341 | LoIDE: a web-based IDE for Logic Programming - Preliminary Technical Report | http://arxiv.org/abs/1709.05341 | id:1709.05341 author:Stefano Germano, Francesco Calimeri, Eliana Palermiti category:cs.SE cs.AI 68T27  68N17  published:2017-09-15 summary:Logic-based paradigms are nowadays widely used in many different fields, also thank to the availability of robust tools and systems that allow the development of real-world and industrial applications. In this work we present LoIDE, an advanced and modular web-editor for logic-based languages that also integrates with state-of-the-art solvers. version:1
arxiv-1709-05293 | Commonsense Scene Semantics for Cognitive Robotics: Towards Grounding Embodied Visuo-Locomotive Interactions | http://arxiv.org/abs/1709.05293 | id:1709.05293 author:Jakob Suchan, Mehul Bhatt category:cs.RO cs.AI cs.CV  published:2017-09-15 summary:We present a commonsense, qualitative model for the semantic grounding of embodied visuo-spatial and locomotive interactions. The key contribution is an integrative methodology combining low-level visual processing with high-level, human-centred representations of space and motion rooted in artificial intelligence. We demonstrate practical applicability with examples involving object interactions, and indoor movement. version:1
arxiv-1709-04579 | Autonomous Extracting a Hierarchical Structure of Tasks in Reinforcement Learning and Multi-task Reinforcement Learning | http://arxiv.org/abs/1709.04579 | id:1709.04579 author:Behzad Ghazanfari, Matthew E. Taylor category:cs.AI  published:2017-09-14 summary:Reinforcement learning (RL), while often powerful, can suffer from slow learning speeds, particularly in high dimensional spaces. The autonomous decomposition of tasks and use of hierarchical methods hold the potential to significantly speed up learning in such domains. This paper proposes a novel practical method that can autonomously decompose tasks, by leveraging association rule mining, which discovers hidden relationship among entities in data mining. We introduce a novel method called ARM-HSTRL (Association Rule Mining to extract Hierarchical Structure of Tasks in Reinforcement Learning). It extracts temporal and structural relationships of sub-goals in RL, and multi-task RL. In particular,it finds sub-goals and relationship among them. It is shown the significant efficiency and performance of the proposed method in two main topics of RL. version:2
arxiv-1709-05278 | Algorithms and Architecture for Real-time Recommendations at News UK | http://arxiv.org/abs/1709.05278 | id:1709.05278 author:Dion Bailey, Tom Pajak, Daoud Clarke, Carlos Rodriguez category:cs.IR cs.AI cs.CL  published:2017-09-15 summary:Recommendation systems are recognised as being hugely important in industry, and the area is now well understood. At News UK, there is a requirement to be able to quickly generate recommendations for users on news items as they are published. However, little has been published about systems that can generate recommendations in response to changes in recommendable items and user behaviour in a very short space of time. In this paper we describe a new algorithm for updating collaborative filtering models incrementally, and demonstrate its effectiveness on clickstream data from The Times. We also describe the architecture that allows recommendations to be generated on the fly, and how we have made each component scalable. The system is currently being used in production at News UK. version:1
arxiv-1709-05273 | Cooperative Motion Planning for Non-Holonomic Agents with Value Iteration Networks | http://arxiv.org/abs/1709.05273 | id:1709.05273 author:Eike Rehder, Maximilian Naumann, Niels Ole Salscheider, Christoph Stiller category:cs.RO cs.MA  published:2017-09-15 summary:Cooperative motion planning is still a challenging task for robots. Recently, Value Iteration Networks (VINs) were proposed to model motion planning tasks as Neural Networks. In this work, we extend VINs to solve cooperative planning tasks under non-holonomic constraints. For this, we interconnect multiple VINs to pay respect to each other's outputs. Policies for cooperation are generated via iterative gradient descend. Validation in simulation shows that the resulting networks can resolve non-holonomic motion planning problems that require cooperation. version:1
arxiv-1709-05246 | A Generic Framework for Interesting Subspace Cluster Detection in Multi-attributed Networks | http://arxiv.org/abs/1709.05246 | id:1709.05246 author:Feng Chen, Baojian Zhou, Adil Alim, Liang Zhao category:cs.LG cs.AI  published:2017-09-15 summary:Detection of interesting (e.g., coherent or anomalous) clusters has been studied extensively on plain or univariate networks, with various applications. Recently, algorithms have been extended to networks with multiple attributes for each node in the real-world. In a multi-attributed network, often, a cluster of nodes is only interesting for a subset (subspace) of attributes, and this type of clusters is called subspace clusters. However, in the current literature, few methods are capable of detecting subspace clusters, which involves concurrent feature selection and network cluster detection. These relevant methods are mostly heuristic-driven and customized for specific application scenarios. In this work, we present a generic and theoretical framework for detection of interesting subspace clusters in large multi-attributed networks. Specifically, we propose a subspace graph-structured matching pursuit algorithm, namely, SG-Pursuit, to address a broad class of such problems for different score functions (e.g., coherence or anomalous functions) and topology constraints (e.g., connected subgraphs and dense subgraphs). We prove that our algorithm 1) runs in nearly-linear time on the network size and the total number of attributes and 2) enjoys rigorous guarantees (geometrical convergence rate and tight error bound) analogous to those of the state-of-the-art algorithms for sparse feature selection problems and subgraph detection problems. As a case study, we specialize SG-Pursuit to optimize a number of well-known score functions for two typical tasks, including detection of coherent dense and anomalous connected subspace clusters in real-world networks. Empirical evidence demonstrates that our proposed generic algorithm SG-Pursuit performs superior over state-of-the-art methods that are designed specifically for these two tasks. version:1
arxiv-1709-05231 | A Spectral Method for Activity Shaping in Continuous-Time Information Cascades | http://arxiv.org/abs/1709.05231 | id:1709.05231 author:Kevin Scaman, Argyris Kalogeratos, Luca Corinzia, Nicolas Vayatis category:stat.ML cs.AI cs.LG cs.SI math.OC 93E20  91D30 I.2.6  published:2017-09-15 summary:Information Cascades Model captures dynamical properties of user activity in a social network. In this work, we develop a novel framework for activity shaping under the Continuous-Time Information Cascades Model which allows the administrator for local control actions by allocating targeted resources that can alter the spread of the process. Our framework employs the optimization of the spectral radius of the Hazard matrix, a quantity that has been shown to drive the maximum influence in a network, while enjoying a simple convex relaxation when used to minimize the influence of the cascade. In addition, use-cases such as quarantine and node immunization are discussed to highlight the generality of the proposed activity shaping framework. Finally, we present the NetShape influence minimization method which is compared favorably to baseline and state-of-the-art approaches through simulations on real social networks. version:1
arxiv-1709-05915 | Push and Pull Search for Solving Constrained Multi-objective Optimization Problems | http://arxiv.org/abs/1709.05915 | id:1709.05915 author:Zhun Fan, Wenji Li, Xinye Cai, Hui Li, Caimin Wei, Qingfu Zhang, Kalyanmoy Deb, Erik D. Goodman category:cs.NE cs.AI  published:2017-09-15 summary:This paper proposes a push and pull search (PPS) framework for solving constrained multi-objective optimization problems (CMOPs). To be more specific, the proposed PPS divides the search process into two different stages, including the push and pull search stages. In the push stage, a multi-objective evolutionary algorithm (MOEA) is adopted to explore the search space without considering any constraints, which can help to get across infeasible regions very fast and approach the unconstrained Pareto front. Furthermore, the landscape of CMOPs with constraints can be probed and estimated in the push stage, which can be utilized to conduct the parameters setting for constraint-handling approaches applied in the pull stage. Then, a constrained multi-objective evolutionary algorithm (CMOEA) equipped with an improved epsilon constraint-handling is applied to pull the infeasible individuals achieved in the push stage to the feasible and non-dominated regions. Compared with other CMOEAs, the proposed PPS method can more efficiently get across infeasible regions and converge to the feasible and non-dominated regions by applying push and pull search strategies at different stages. To evaluate the performance regarding convergence and diversity, a set of benchmark CMOPs is used to test the proposed PPS and compare with other five CMOEAs, including MOEA/D-CDP, MOEA/D-SR, C-MOEA/D, MOEA/D-Epsilon and MOEA/D-IEpsilon. The comprehensive experimental results demonstrate that the proposed PPS achieves significantly better or competitive performance than the other five CMOEAs on most of the benchmark set. version:1
arxiv-1709-05185 | Unsupervised state representation learning with robotic priors: a robustness benchmark | http://arxiv.org/abs/1709.05185 | id:1709.05185 author:Timothée Lesort, Mathieu Seurin, Xinrui Li, Natalia Díaz Rodríguez, David Filliat category:cs.AI cs.CV cs.RO  published:2017-09-15 summary:Our understanding of the world depends highly on our capacity to produce intuitive and simplified representations which can be easily used to solve problems. We reproduce this simplification process using a neural network to build a low dimensional state representation of the world from images acquired by a robot. As in Jonschkowski et al. 2015, we learn in an unsupervised way using prior knowledge about the world as loss functions called robotic priors and extend this approach to high dimension richer images to learn a 3D representation of the hand position of a robot from RGB images. We propose a quantitative evaluation of the learned representation using nearest neighbors in the state space that allows to assess its quality and show both the potential and limitations of robotic priors in realistic environments. We augment image size, add distractors and domain randomization, all crucial components to achieve transfer learning to real robots. Finally, we also contribute a new prior to improve the robustness of the representation. The applications of such low dimensional state representation range from easing reinforcement learning (RL) and knowledge transfer across tasks, to facilitating learning from raw data with more efficient and compact high level representations. The results show that the robotic prior approach is able to extract high level representation as the 3D position of an arm and organize it into a compact and coherent space of states in a challenging dataset. version:1
arxiv-1709-05183 | Fast OLAP Query Execution in Main Memory on Large Data in a Cluster | http://arxiv.org/abs/1709.05183 | id:1709.05183 author:Demian Hespe, Martin Weidner, Jonathan Dees, Peter Sanders category:cs.DB cs.DC  published:2017-09-15 summary:Main memory column-stores have proven to be efficient for processing analytical queries. Still, there has been much less work in the context of clusters. Using only a single machine poses several restrictions: Processing power and data volume are bounded to the number of cores and main memory fitting on one tightly coupled system. To enable the processing of larger data sets, switching to a cluster becomes necessary. In this work, we explore techniques for efficient execution of analytical SQL queries on large amounts of data in a parallel database cluster while making maximal use of the available hardware. This includes precompiled query plans for efficient CPU utilization, full parallelization on single nodes and across the cluster, and efficient inter-node communication. We implement all features in a prototype for running a subset of TPC-H benchmark queries. We evaluate our implementation using a 128 node cluster running TPC-H queries with 30 000 gigabyte of uncompressed data. version:1
arxiv-1709-05972 | Towards CNN map representation and compression for camera relocalisation | http://arxiv.org/abs/1709.05972 | id:1709.05972 author:Luis Contreras, Walterio Mayol-Cuevas category:cs.CV cs.RO  published:2017-09-15 summary:This paper presents a study on the use of Convolutional Neural Networks for camera relocalisation and its application to map compression. We follow state of the art visual relocalisation results and evaluate response to different data inputs -- namely, depth, grayscale, RGB, spatial position and combinations of these. We use a CNN map representation and introduce the notion of map compression under this paradigm by using smaller CNN architectures without sacrificing relocalisation performance. We evaluate our proposal in a series of publicly available datasets over a number of CNN architectures with different sizes, both in complexity and number of layers. This formulation allows us to improve relocalisation accuracy by increasing the number of training trajectories while maintaining a constant-size CNN. version:1
arxiv-1709-05122 | Distributed Random Process for a Large-Scale Peer-to-Peer Lottery | http://arxiv.org/abs/1709.05122 | id:1709.05122 author:Stéphane Grumbach, Robert Riemann category:cs.DC cs.CR  published:2017-09-15 summary:Most online lotteries today fail to ensure the verifiability of the random process and rely on a trusted third party. This issue has received little attention since the emergence of distributed protocols like Bitcoin that demonstrated the potential of protocols with no trusted third party. We argue that the security requirements of online lotteries are similar to those of online voting, and propose a novel distributed online lottery protocol that applies techniques developed for voting applications to an existing lottery protocol. As a result, the protocol is scalable, provides efficient verification of the random process and does not rely on a trusted third party nor on assumptions of bounded computational resources. An early prototype confirms the feasibility of our approach. version:1
arxiv-1709-05116 | A Streaming Accelerator for Deep Convolutional Neural Networks with Image and Feature Decomposition for Resource-limited System Applications | http://arxiv.org/abs/1709.05116 | id:1709.05116 author:Yuan Du, Li Du, Yilei Li, Junjie Su, Mau-Chung Frank Chang category:cs.AR cs.AI  published:2017-09-15 summary:Deep convolutional neural networks (CNN) are widely used in modern artificial intelligence (AI) and smart vision systems but also limited by computation latency, throughput, and energy efficiency on a resource-limited scenario, such as mobile devices, internet of things (IoT), unmanned aerial vehicles (UAV), and so on. A hardware streaming architecture is proposed to accelerate convolution and pooling computations for state-of-the-art deep CNNs. It is optimized for energy efficiency by maximizing local data reuse to reduce off-chip DRAM data access. In addition, image and feature decomposition techniques are introduced to optimize memory access pattern for an arbitrary size of image and number of features within limited on-chip SRAM capacity. A prototype accelerator was implemented in TSMC 65 nm CMOS technology with 2.3 mm x 0.8 mm core area, which achieves 144 GOPS peak throughput and 0.8 TOPS/W peak energy efficiency. version:1
arxiv-1709-05107 | Multi-Label Zero-Shot Human Action Recognition via Joint Latent Embedding | http://arxiv.org/abs/1709.05107 | id:1709.05107 author:Qian Wang, Ke Chen category:cs.CV cs.AI cs.LG  published:2017-09-15 summary:Human action recognition refers to automatic recognizing human actions from a video clip, which is one of the most challenging tasks in computer vision. In reality, a video stream is often weakly-annotated with a set of relevant human action labels at a global level rather than assigning each label to a specific video episode corresponding to a single action, which leads to a multi-label learning problem. Furthermore, there are a great number of meaningful human actions in reality but it would be extremely difficult, if not impossible, to collect/annotate video clips regarding all of various human actions, which leads to a zero-shot learning scenario. To the best of our knowledge, there is no work that has addressed all the above issues together in human action recognition. In this paper, we formulate a real-world human action recognition task as a multi-label zero-shot learning problem and propose a framework to tackle this problem. Our framework simultaneously tackles the issue of unknown temporal boundaries between different actions for multi-label learning and exploits the side information regarding the semantic relationship between different human actions for zero-shot learning. As a result, our framework leads to a joint latent embedding representation for multi-label zero-shot human action recognition. The joint latent embedding is learned with two component models by exploring temporal coherence underlying video data and the intrinsic relationship between visual and semantic domain. We evaluate our framework with different settings, including a novel data split scheme designed especially for evaluating multi-label zero-shot learning, on two weakly annotated multi-label human action datasets: Breakfast and Charades. The experimental results demonstrate the effectiveness of our framework in multi-label zero-shot human action recognition. version:1
arxiv-1709-05101 | Time-Optimal Path Tracking: Online Scaling with Guarantees | http://arxiv.org/abs/1709.05101 | id:1709.05101 author:Hung Pham, Quang-Cuong Pham category:cs.RO I.2.8; I.2.9  published:2017-09-15 summary:Given a geometric path, the Time-Optimal Path Tracking problem consists in finding the control strategy to traverse the path time-optimally while regulating tracking errors caused by model inaccuracies and online perturbations. Online Scaling (OS) is a simple yet effective approach to this problem. The overall OS controller is composed of two components: (i) a path controller, which modulates the parameterization of the desired path in an online manner, yielding a reference trajectory; and (ii) a torque controller, which takes the reference trajectory and outputs torque commands for tracking. However, OS has one major drawback: the path controller might not find any feasible reference trajectory that can be tracked by the torque controller because of torque constraints. In turn, this results in degraded tracking performances. Here, we propose a new controller, termed Online Scaling with Guarantees (OSG), which is guaranteed to find a feasible reference trajectory by accounting for all possible future perturbations. Our approach is based on Robust Reachability Analysis. Simulations show that the OSG controller outperforms existing methods. version:1
arxiv-1709-05077 | Transforming Cooling Optimization for Green Data Center via Deep Reinforcement Learning | http://arxiv.org/abs/1709.05077 | id:1709.05077 author:Yuanlong Li, Yonggang Wen, Kyle Guan, Dacheng Tao category:cs.AI cs.SY  published:2017-09-15 summary:Cooling system plays a key role in modern data center. Developing an optimal control policy for data center cooling system is a challenging task. The prevailing approaches often rely on approximated system models that are built upon the knowledge of mechanical cooling, electrical and thermal management, which is difficult to design and may lead to sub-optimal or unstable performances. In this paper we propose to utilize the large amount of monitoring data in data center to optimize the control policy. To do so, we cast the cooling control policy design into an energy cost minimization problem with temperature constraints, and tab it into the emerging deep reinforcement learning (DRL) framework. Specifically, we propose an end-to-end neural control algorithm that is based on the actor-critic framework and the deep deterministic policy gradient (DDPG) technique. To improve the robustness of the control algorithm, we test various DRL related optimization techniques, such as recurrent decision making, discounted return, different neural network architectures, and different stochastic gradient descent algorithms, and adding additional constraints on the output of the policy network. We evaluate the proposed algorithms on the EnergyPlus simulation platform and on a real data trace collected from the National Super Computing Centre (NSCC) of Singapore. Our results show that the proposed end-to-end cooling control algorithm can achieve about 10% cooling cost saving on the simulation platform compared with a canonical two stage optimization algorithm; and it can achieve about 13.6% cooling energy saving on the NSCC data trace. Furthermore, it shows high accuracy in predicting the temperature of the racks (with mean absolute error 0.1 degree) and can control the temperature of the data center zone close to the predefined threshold with variation lower to 0.2 degree. version:1
arxiv-1709-05070 | Shapechanger: Environments for Transfer Learning | http://arxiv.org/abs/1709.05070 | id:1709.05070 author:Sébastien M. R. Arnold, Tsam Kiu Pun, Théo-Tim J. Denisart, Francisco J. Valero-Cuevas category:cs.LG cs.RO  published:2017-09-15 summary:We present Shapechanger, a library for transfer reinforcement learning specifically designed for robotic tasks. We consider three types of knowledge transfer---from simulation to simulation, from simulation to real, and from real to real---and a wide range of tasks with continuous states and actions. Shapechanger is under active development and open-sourced at: https://github.com/seba-1511/shapechanger/. version:1
arxiv-1709-05067 | Deep Reinforcement Learning for Conversational AI | http://arxiv.org/abs/1709.05067 | id:1709.05067 author:Mahipal Jadeja, Neelanshi Varia, Agam Shah category:cs.AI  published:2017-09-15 summary:Deep reinforcement learning is revolutionizing the artificial intelligence field. Currently, it serves as a good starting point for constructing intelligent autonomous systems which offer a better knowledge of the visual world. It is possible to scale deep reinforcement learning with the use of deep learning and do amazing tasks such as use of pixels in playing video games. In this paper, key concepts of deep reinforcement learning including reward function, differences between reinforcement learning and supervised learning and models for implementation of reinforcement are discussed. Key challenges related to the implementation of reinforcement learning in conversational AI domain are identified as well as discussed in detail. Various conversational models which are based on deep reinforcement learning (as well as deep learning) are also discussed. In summary, this paper discusses key aspects of deep reinforcement learning which are crucial for designing an efficient conversational AI. version:1
arxiv-1709-05061 | Technical Report: Accelerating Dynamic Graph Analytics on GPUs | http://arxiv.org/abs/1709.05061 | id:1709.05061 author:Mo Sha, Yuchen Li, Bingsheng He, Kian-Lee Tan category:cs.DS cs.DC H.2.4; E.1  published:2017-09-15 summary:As graph analytics often involves compute-intensive operations, GPUs have been extensively used to accelerate the processing. However, in many applications such as social networks, cyber security, and fraud detection, their representative graphs evolve frequently and one has to perform a rebuild of the graph structure on GPUs to incorporate the updates. Hence, rebuilding the graphs becomes the bottleneck of processing high-speed graph streams. In this paper, we propose a GPU-based dynamic graph storage scheme to support existing graph algorithms easily. Furthermore, we propose parallel update algorithms to support efficient stream updates so that the maintained graph is immediately available for high-speed analytic processing on GPUs. Our extensive experiments with three streaming applications on large-scale real and synthetic datasets demonstrate the superior performance of our proposed approach. version:1
arxiv-1709-05047 | Disentangled Variational Auto-Encoder for Semi-supervised Learning | http://arxiv.org/abs/1709.05047 | id:1709.05047 author:Yang Li, Quan Pan, Suhang Wang, Haiyun Peng, Tao Yang, Erik Cambria category:cs.LG cs.AI  published:2017-09-15 summary:In this paper, we develop a novel approach for semi-supervised VAE without classifier. Specifically, we propose a new model called SDVAE, which encodes the input data into disentangled representation and non-interpretable representation, then the category information is directly utilized to regularize the disentangled representation via equation constraint. To further enhance the feature learning ability of the proposed VAE, we incorporate reinforcement learning to relieve the lack of data. The dynamic framework is capable of dealing with both image and text data with its corresponding encoder and decoder networks. Extensive experiments on image and text datasets demonstrate the effectiveness of the proposed framework. version:1
arxiv-1709-05021 | ClickBAIT: Click-based Accelerated Incremental Training of Convolutional Neural Networks | http://arxiv.org/abs/1709.05021 | id:1709.05021 author:Ervin Teng, João Diogo Falcão, Bob Iannucci category:cs.CV cs.AI cs.HC C.1.3  published:2017-09-15 summary:Today's general-purpose deep convolutional neural networks (CNN) for image classification and object detection are trained offline on large static datasets. Some applications, however, will require training in real-time on live video streams with a human-in-the-loop. We refer to this class of problem as Time-ordered Online Training (ToOT) - these problems will require a consideration of not only the quantity of incoming training data, but the human effort required to tag and use it. In this paper, we define training benefit as a metric to measure the effectiveness of a sequence in using each user interaction. We demonstrate and evaluate a system tailored to performing ToOT in the field, capable of training an image classifier on a live video stream through minimal input from a human operator. We show that by exploiting the time-ordered nature of the video stream through optical flow-based object tracking, we can increase the effectiveness of human actions by about 8 times. version:1
arxiv-1709-02023 | CausalGAN: Learning Causal Implicit Generative Models with Adversarial Training | http://arxiv.org/abs/1709.02023 | id:1709.02023 author:Murat Kocaoglu, Christopher Snyder, Alexandros G. Dimakis, Sriram Vishwanath category:cs.LG cs.AI cs.IT math.IT stat.ML  published:2017-09-06 summary:We propose an adversarial training procedure for learning a causal implicit generative model for a given causal graph. We show that adversarial training can be used to learn a generative model with true observational and interventional distributions if the generator architecture is consistent with the given causal graph. We consider the application of generating faces based on given binary labels where the dependency structure between the labels is preserved with a causal graph. This problem can be seen as learning a causal implicit generative model for the image and labels. We devise a two-stage procedure for this problem. First we train a causal implicit generative model over binary labels using a neural network consistent with a causal graph as the generator. We empirically show that WassersteinGAN can be used to output discrete labels. Later, we propose two new conditional GAN architectures, which we call CausalGAN and CausalBEGAN. We show that the optimal generator of the CausalGAN, given the labels, samples from the image distributions conditioned on these labels. The conditional GAN combined with a trained causal implicit generative model for the labels is then a causal implicit generative model over the labels and the generated image. We show that the proposed architectures can be used to sample from observational and interventional image distributions, even for interventions which do not naturally occur in the dataset. version:2
arxiv-1709-04991 | Abstractions for AI-Based User Interfaces and Systems | http://arxiv.org/abs/1709.04991 | id:1709.04991 author:Alex Renda, Harrison Goldstein, Sarah Bird, Chris Quirk, Adrian Sampson category:cs.PL cs.AI  published:2017-09-14 summary:Novel user interfaces based on artificial intelligence, such as natural-language agents, present new categories of engineering challenges. These systems need to cope with uncertainty and ambiguity, interface with machine learning algorithms, and compose information from multiple users to make decisions. We propose to treat these challenges as language-design problems. We describe three programming language abstractions for three core problems in intelligent system design. First, hypothetical worlds support nondeterministic search over spaces of alternative actions. Second, a feature type system abstracts the interaction between applications and learning algorithms. Finally, constructs for collaborative execution extend hypothetical worlds across multiple machines while controlling access to private data. We envision these features as first steps toward a complete language for implementing AI-based interfaces and applications. version:1
arxiv-1709-05958 | Towards Cognitive-and-Immersive Systems: Experiments in a Shared (or common) Blockworld Framework | http://arxiv.org/abs/1709.05958 | id:1709.05958 author:Matthew Peveler, Biplav Srivastava, Kartik Talamadupula, Naveen Sundar G., Selmer Bringsjord, Hui Su category:cs.AI  published:2017-09-14 summary:As computational power has continued to increase, and sensors have become more accurate, the corresponding advent of systems that are cognitive-and-immersive (CAI) has come to pass. CAI systems fall squarely into the intersection of AI with HCI/HRI: such systems interact with and assist the human agents that enter them, in no small part because such systems are infused with AI able to understand and reason about these humans and their beliefs, goals, and plans. We herein explain our approach to engineering CAI systems. We emphasize the capacity of a CAI system to develop and reason over a "theory of the mind" of its humans partners. This capacity means that the AI in question has a sophisticated model of the beliefs, knowledge, goals, desires, emotions, etc. of these humans. To accomplish this engineering, a formal framework of very high expressivity is needed. In our case, this framework is a \textit{cognitive event calculus}, a partciular kind of quantified multi-modal logic, and a matching high-expressivity planner. To explain, advance, and to a degree validate our approach, we show that a calculus of this type can enable a CAI system to understand a psychologically tricky scenario couched in what we call the \textit{cognitive blockworld framework} (CBF). CBF includes machinery able to represent and plan over not merely blocks and actions, but also agents and their mental attitudes about other agents. version:1
arxiv-1709-04981 | Dynamic Markers: UAV landing proof of concept | http://arxiv.org/abs/1709.04981 | id:1709.04981 author:Raul Acuna, Rosa Maria Carpio, Volker Willert category:cs.RO  published:2017-09-14 summary:In this paper, we introduce a dynamic fiducial marker which can change its appearance according to the spatio-temporal requirements of the visual perception task of a mobile robot using a camera as sensor. We present a control scheme to dynamically change the appearance of the marker such that the pose of the robot can be optimally estimated from the camera image. The appearance control takes into account the dependency of the estimation quality on the current pose of the camera in relation to the marker.Hence, we realize a tight coupling between the visual pose control of the mobile robot and the appearance control of the dynamic fiducial marker. Further on, we discuss the implications of time delays because of processing time and communication delays between the robot and the marker. Finally, we propose a real time dynamic marker visual servoing control scheme for quadcopter landing and evaluate the performance on a real world example. version:1
arxiv-1709-04940 | A Robust Model Predictive Control Approach for Underwater Robotic Vehicles Operating in a Constrained workspace | http://arxiv.org/abs/1709.04940 | id:1709.04940 author:Shahab Heshmati-alamdari, George C. Karras, Panos Marantos, Kostas J. Kyriakopoulos category:cs.RO cs.SY  published:2017-09-14 summary:This paper presents a novel Nonlinear Model Predictive Control (NMPC) scheme for underwater robotic vehicles operating in a constrained workspace including static obstacles. The purpose of the controller is to guide the vehicle towards specific way points with guaranteed input and state constraints (i.e obstacle avoidance, workspace boundaries). The proposed scheme incorporates the full dynamics of the vehicle in which the ocean currents are also involved. Hence, the control inputs calculated by the proposed scheme are formulated in a way that the vehicle will exploit the ocean currents, when these are in favor of the way-point tracking mission which results in reduced energy consumption by the thrusters. The closed-loop system has analytically guaranteed stability and convergence properties. The performance of the proposed control strategy is experimentally verified using a $4$ Degrees of Freedom (DoF) underwater robotic vehicle inside a constrained test tank with obstacles. version:1
arxiv-1709-04931 | 5-DoF Monocular Visual Localization Over Grid Based Floor | http://arxiv.org/abs/1709.04931 | id:1709.04931 author:Manash Pratim Das, Gaurav Gardi, Jayanta Mukhopadhyay category:cs.RO 68T40  published:2017-09-14 summary:Reliable localization is one of the most important parts of an MAV system. Localization in an indoor GPS-denied environment is a relatively difficult problem. Current vision based algorithms track optical features to calculate odometry. We present a novel localization method which can be applied in an environment having orthogonal sets of equally spaced lines to form a grid. With the help of a monocular camera and using the properties of the grid-lines below, the MAV is localized inside each sub-cell of the grid and consequently over the entire grid for a relative localization over the grid. We demonstrate the effectiveness of our system onboard a customized MAV platform. The experimental results show that our method provides accurate 5-DoF localization over grid lines and it can be performed in real-time. version:1
arxiv-1709-04909 | Shared Learning : Enhancing Reinforcement in $Q$-Ensembles | http://arxiv.org/abs/1709.04909 | id:1709.04909 author:Rakesh R Menon, Balaraman Ravindran category:cs.LG cs.AI  published:2017-09-14 summary:Deep Reinforcement Learning has been able to achieve amazing successes in a variety of domains from video games to continuous control by trying to maximize the cumulative reward. However, most of these successes rely on algorithms that require a large amount of data to train in order to obtain results on par with human-level performance. This is not feasible if we are to deploy these systems on real world tasks and hence there has been an increased thrust in exploring data efficient algorithms. To this end, we propose the Shared Learning framework aimed at making $Q$-ensemble algorithms data-efficient. For achieving this, we look into some principles of transfer learning which aim to study the benefits of information exchange across tasks in reinforcement learning and adapt transfer to learning our value function estimates in a novel manner. In this paper, we consider the special case of transfer between the value function estimates in the $Q$-ensemble architecture of BootstrappedDQN. We further empirically demonstrate how our proposed framework can help in speeding up the learning process in $Q$-ensembles with minimum computational overhead on a suite of Atari 2600 Games. version:1
arxiv-1709-04905 | One-Shot Visual Imitation Learning via Meta-Learning | http://arxiv.org/abs/1709.04905 | id:1709.04905 author:Chelsea Finn, Tianhe Yu, Tianhao Zhang, Pieter Abbeel, Sergey Levine category:cs.LG cs.AI cs.CV cs.RO  published:2017-09-14 summary:In order for a robot to be a generalist that can perform a wide range of jobs, it must be able to acquire a wide variety of skills quickly and efficiently in complex unstructured environments. High-capacity models such as deep neural networks can enable a robot to represent complex skills, but learning each skill from scratch then becomes infeasible. In this work, we present a meta-imitation learning method that enables a robot to learn how to learn more efficiently, allowing it to acquire new skills from just a single demonstration. Unlike prior methods for one-shot imitation, our method can scale to raw pixel inputs and requires data from significantly fewer prior tasks for effective learning of new skills. Our experiments on both simulated and real robot platforms demonstrate the ability to learn new tasks, end-to-end, from a single visual demonstration. version:1
arxiv-1709-04885 | Optimal broadcasting in networks with faulty nodes | http://arxiv.org/abs/1709.04885 | id:1709.04885 author:Yoel Grinshpon, Ori Gurel-Gurevich category:cs.DS cs.DC 60C05  68W15  68W20 C.2.1  published:2017-09-14 summary:Large computer networks are an essential part of modern technology, and quite often information needs to be broadcast to all the computers in the network. If all computers work perfectly all the time, this is simple. Suppose, however, that some of the computers fail occasionally. What is the fastest way to ensure that with high probability all working computers get the information? In this paper, we analyze three algorithms to do so. All algorithms terminate in logarithmic time, assuming computers fail with probability $1-p$ independently of each other. We prove that the third algorithm, which runs in time $(1+o(1))(\frac{\log N}{\log(1+p)})$, is asymptotically optimal. version:1
arxiv-1710-04049 | About Microservices, Containers and their Underestimated Impact on Network Performance | http://arxiv.org/abs/1710.04049 | id:1710.04049 author:Nane Kratzke category:cs.DC  published:2017-09-14 summary:Microservices are used to build complex applications composed of small, independent and highly decoupled processes. Recently, microservices are often mentioned in one breath with container technologies like Docker. That is why operating system virtualization experiences a renaissance in cloud computing. These approaches shall provide horizontally scalable, easily deployable systems and a high-performance alternative to hypervisors. Nevertheless, performance impacts of containers on top of hypervisors are hardly investigated. Furthermore, microservice frameworks often come along with software defined networks. This contribution presents benchmark results to quantify the impacts of container, software defined networking and encryption on network performance. Even containers, although postulated to be lightweight, show a noteworthy impact to network performance. These impacts can be minimized on several system layers. Some design recommendations for cloud deployed systems following the microservice architecture pattern are derived. version:1
arxiv-1709-04859 | Power Regulation in High Performance Multicore Processors | http://arxiv.org/abs/1709.04859 | id:1709.04859 author:X. Chen, Y. Wardi, S. Yalamanchili category:cs.DC math.OC  published:2017-09-14 summary:This paper presents, implements, and evaluates a power-regulation technique for multicore processors, based on an integral controller with adjustable gain. The gain is designed for wide stability margins, and computed in real time as part of the control law. The tracking performance of the control system is robust with respect to modeling uncertainties and computational errors in the loop. The main challenge of designing such a controller is that the power dissipation of program-workloads varies widely and often cannot be measured accurately; hence extant controllers are either ad hoc or based on a-priori modeling characterizations of the processor and workloads. Our approach is different. Leveraging the aforementioned robustness it uses a simple textbook modeling framework, and adjusts its parameters in real time by a system-identification module. In this it trades modeling precision for fast computations in the loop making it suitable for on-line implementation in commodity data-center processors. Consequently, the proposed controller is agnostic in the sense that it does not require any a-priori system characterizations. We present an implementation of the controller on Intel's fourth-generation microarchitecture, Haswell, and test it on a number of industry benchmark programs which are used in scientific computing and datacenter applications. Results of these experiments are presented in detail exposing the practical challenges of implementing provably-convergent power regulation solutions in commodity multicore processors. version:1
arxiv-1709-04825 | General problem solving with category theory | http://arxiv.org/abs/1709.04825 | id:1709.04825 author:Francisco J. Arjonilla, Tetsuya Ogata category:cs.AI  published:2017-09-14 summary:This paper proposes a formal cognitive framework for problem solving based on category theory. We introduce cognitive categories, which are categories with exactly one morphism between any two objects. Objects in these categories are interpreted as states and morphisms as transformations between states. Moreover, cognitive problems are reduced to the specification of two objects in a cognitive category: an outset (i.e. the current state of the system) and a goal (i.e. the desired state). Cognitive systems transform the target system by means of generators and evaluators. Generators realize cognitive operations over a system by grouping morphisms, whilst evaluators group objects as a way to generalize outsets and goals to partially defined states. Meta-cognition emerges when the whole cognitive system is self-referenced as sub-states in the cognitive category, whilst learning must always be considered as a meta-cognitive process to maintain consistency. Several examples grounded in basic AI methods are provided as well. version:1
arxiv-1709-05262 | Supervising Unsupervised Learning | http://arxiv.org/abs/1709.05262 | id:1709.05262 author:Vikas K. Garg, Adam Kalai category:cs.AI cs.LG stat.ML  published:2017-09-14 summary:We introduce a framework to leverage knowledge acquired from a repository of (heterogeneous) supervised datasets to new unsupervised datasets. Our perspective avoids the subjectivity inherent in unsupervised learning by reducing it to supervised learning, and provides a principled way to evaluate unsupervised algorithms. We demonstrate the versatility of our framework via simple agnostic bounds on unsupervised problems. In the context of clustering, our approach can help choose the number of clusters, the clustering algorithm, and provably circumvents Kleinberg's impossibility result. Experimental results across hundreds of problems demonstrate improved performance on unsupervised data with simple algorithms, despite the fact problems come from different domains. Additionally, a deep learning algorithm learns common features from many small datasets across multiple domains. version:1
arxiv-1709-04811 | A self-stabilizing algorithm for maximal matching in link-register model in $O(nΔ^3)$ moves | http://arxiv.org/abs/1709.04811 | id:1709.04811 author:Johanne Cohen, Georges Manoussakis, Laurence Pilard, Devan Sohier category:cs.DC  published:2017-09-14 summary:In the matching problem, each node maintains a pointer to one of its neighbor or to $null$, and a maximal matching is computed when each node points either to a neighbor that itself points to it (they are then called married), or to $null$, in which case no neighbor can also point to $null$. This paper presents a self-stabilizing distributed algorithm to compute a maximal matching in the link-register model under read/write atomicity, with complexity {$O(n\Delta^3)$} moves under the adversarial distributed daemon, where $\Delta$ is the maximum degree of the graph. version:1
arxiv-1709-04806 | TraceTracker: Hardware/Software Co-Evaluation for Large-Scale I/O Workload Reconstruction | http://arxiv.org/abs/1709.04806 | id:1709.04806 author:Miryeong Kwon, Jie Zhang, Gyuyoung Park, Wonil Choi, David Donofrio, John Shalf, Mahmut Kandemir, Myoungsoo Jung category:cs.DC cs.AR  published:2017-09-14 summary:Block traces are widely used for system studies, model verifications, and design analyses in both industry and academia. While such traces include detailed block access patterns, existing trace-driven research unfortunately often fails to find true-north due to a lack of runtime contexts such as user idle periods and system delays, which are fundamentally linked to the characteristics of target storage hardware. In this work, we propose TraceTracker, a novel hardware/software co-evaluation method that allows users to reuse a broad range of the existing block traces by keeping most their execution contexts and user scenarios while adjusting them with new system information. Specifically, our TraceTracker's software evaluation model can infer CPU burst times and user idle periods from old storage traces, whereas its hardware evaluation method remasters the storage traces by interoperating the inferred time information, and updates all inter-arrival times by making them aware of the target storage system. We apply the proposed co-evaluation model to 577 traces, which were collected by servers from different institutions and locations a decade ago, and revive the traces on a high-performance flash-based storage array. The evaluation results reveal that the accuracy of the execution contexts reconstructed by TraceTracker is on average 99% and 96% with regard to the frequency of idle operations and the total idle periods, respectively. version:1
arxiv-1709-04794 | Fast semi-supervised discriminant analysis for binary classification of large data-sets | http://arxiv.org/abs/1709.04794 | id:1709.04794 author:Joris Tavernier, Jaak Simm, Karl Meerbergen, Joerg Kurt Wegner, Hugo Ceulemans, Yves Moreau category:cs.AI cs.NA cs.PF 65F15  65F50  68T10  published:2017-09-14 summary:High-dimensional data requires scalable algorithms. We propose and analyze three scalable and related algorithms for semi-supervised discriminant analysis (SDA). These methods are based on Krylov subspace methods which exploit the data sparsity and the shift-invariance of Krylov subspaces. In addition, the problem definition was improved by adding centralization to the semi-supervised setting. The proposed methods are evaluated on a industry-scale data set from a pharmaceutical company to predict compound activity on target proteins. The results show that SDA achieves good predictive performance and our methods only require a few seconds, significantly improving computation time on previous state of the art. version:1
arxiv-1709-04762 | Denoising Autoencoders for Overgeneralization in Neural Networks | http://arxiv.org/abs/1709.04762 | id:1709.04762 author:Giacomo Spigler category:cs.AI cs.CV cs.LG  published:2017-09-14 summary:Despite the recent developments that allowed neural networks to achieve impressive performance on a variety of applications, these models are intrinsically affected by the problem of overgeneralization, due to their partitioning of the full input space into the fixed set of target classes used during training. Thus it is possible for novel inputs belonging to categories unknown during training or even completely unrecognizable to humans to fool the system into classifying them as one of the known classes, even with a high degree of confidence. Solving this problem may help improve the security of such systems in critical applications, and may further lead to applications in the context of open set recognition and 1-class recognition. This paper presents a novel way to compute a confidence score using denoising autoencoders and shows that such confidence score can correctly identify the regions of the input space close to the training distribution by approximately identifying its local maxima. version:1
arxiv-1709-04751 | From Plants to Landmarks: Time-invariant Plant Localization that uses Deep Pose Regression in Agricultural Fields | http://arxiv.org/abs/1709.04751 | id:1709.04751 author:Florian Kraemer, Alexander Schaefer, Andreas Eitel, Johan Vertens, Wolfram Burgard category:cs.RO cs.CV cs.LG  published:2017-09-14 summary:Agricultural robots are expected to increase yields in a sustainable way and automate precision tasks, such as weeding and plant monitoring. At the same time, they move in a continuously changing, semi-structured field environment, in which features can hardly be found and reproduced at a later time. Challenges for Lidar and visual detection systems stem from the fact that plants can be very small, overlapping and have a steadily changing appearance. Therefore, a popular way to localize vehicles with high accuracy is based on ex- pensive global navigation satellite systems and not on natural landmarks. The contribution of this work is a novel image- based plant localization technique that uses the time-invariant stem emerging point as a reference. Our approach is based on a fully convolutional neural network that learns landmark localization from RGB and NIR image input in an end-to-end manner. The network performs pose regression to generate a plant location likelihood map. Our approach allows us to cope with visual variances of plants both for different species and different growth stages. We achieve high localization accuracies as shown in detailed evaluations of a sugar beet cultivation phase. In experiments with our BoniRob we demonstrate that detections can be robustly reproduced with centimeter accuracy. version:1
arxiv-1709-04734 | Perspectives for Evaluating Conversational AI | http://arxiv.org/abs/1709.04734 | id:1709.04734 author:Mahipal Jadeja, Neelanshi Varia category:cs.AI  published:2017-09-14 summary:Conversational AI systems are becoming famous in day to day lives. In this paper, we are trying to address the following key question: To identify whether design, as well as development efforts for search oriented conversational AI are successful or not.It is tricky to define 'success' in the case of conversational AI and equally tricky part is to use appropriate metrics for the evaluation of conversational AI. We propose four different perspectives namely user experience, information retrieval, linguistic and artificial intelligence for the evaluation of conversational AI systems. Additionally, background details of conversational AI systems are provided including desirable characteristics of personal assistants, differences between chatbot and an AI based personal assistant. An importance of personalization and how it can be achieved is explained in detail. Current challenges in the development of an ideal conversational AI (personal assistant) are also highlighted along with guidelines for achieving personalized experience for users. version:1
arxiv-1709-04714 | Trace and Stable Failures Semantics for CSP-Agda | http://arxiv.org/abs/1709.04714 | id:1709.04714 author:Bashar Igried, Anton Setzer category:cs.PL cs.DC cs.LO  published:2017-09-14 summary:CSP-Agda is a library, which formalises the process algebra CSP in the interactive theorem prover Agda using coinductive data types. In CSP-Agda, CSP processes are in monadic form, which sup- ports a modular development of processes. In this paper, we implement two main models of CSP, trace and stable failures semantics, in CSP-Agda, and define the corresponding refinement and equal- ity relations. Because of the monadic setting, some adjustments need to be made. As an example, we prove commutativity of the external choice operator w.r.t. the trace semantics in CSP-Agda, and that refinement w.r.t. stable failures semantics is a partial order. All proofs and definitions have been type checked in Agda. Further proofs of algebraic laws will be available in the CSP-Agda repository. version:1
arxiv-1709-04708 | A Randomly Expandable Method for Data Layout of RAID Storage Systems | http://arxiv.org/abs/1709.04708 | id:1709.04708 author:De-zhai Yuan, Xing-yi Peng, Ting Liu, Zhe Cui category:cs.DC  published:2017-09-14 summary:With the increase of huge amounts of data in volume, velocity, and variety, the need for capacity of Redundant Arrays of Inexpensive Disks (RAID) storage systems is dramatically growing. However, the probability of disk failures in RAID storage systems is sharply high with the increase of program/erase cycles, read cycles, and retention time. Furthermore, they are faced with more challenges in fault tolerance, storage efficiency, computational complexity, and expandability. This article presents a novel data layout scheme for RAID storage System using Random Binary Extensive Code (RBEC), which are designed to ensure random expandability, high reliability, and availability of data in RAID storage systems. RBEC is a family of systematic code, in which the generator matrix consists of two submatrices with entries over GF(2), an identity matrix on the top, and another submatrix on the bottom. Compared with the existed approaches, the attractive advantages of our schemes include 1) they are completely implemented based on only simple eXclusive OR (XOR) operations and have systematic code property, 2) they can provide arbitrary fault tolerance, 3) their storage efficiency is quasi-optimal, and 4) data and parity disks of RAID storage systems can be randomly expanded according to practical requirements. Thus, our scheme is particularly suitable for RAID storage systems that need higher reliability, availability, and expandability. version:1
arxiv-1709-05197 | Scalable real-time processing with Spark Streaming: implementation and design of a Car Information System | http://arxiv.org/abs/1709.05197 | id:1709.05197 author:Philipp M. Grulich category:cs.DB cs.DC  published:2017-09-14 summary:Streaming data processing is a hot topic in big data these days, because it made it possible to process a huge amount of events within a low latency. One of the most common used open-source stream processing platforms is Spark Streaming, which is demonstrated and discussed based on a real-world use-case in this paper. The use-case is about a Car Information System, which is an example for a classic stream processing system. First the System is de- signed and engineered, whereby the application architecture is created carefully, because it should be adaptable for similar use-cases. At the end of this paper the CIS and Spark Streaming is evaluated by the use of the Goal Question Metric model. The evaluation proves that Spark Streaming is capable to create stream processing in a scalable and fault tolerant manner. But it also shows that Spark is a very fast moving project, which could cause problems during the development and maintenance of a software project. version:1
arxiv-1709-04697 | GREENER: A Tool for Improving Energy Efficiency of Register Files | http://arxiv.org/abs/1709.04697 | id:1709.04697 author:Vishwesh Jatala, Jayvant Anantpur, Amey Karkare category:cs.AR  published:2017-09-14 summary:Graphics Processing Units (GPUs) maintain a large register file to increase thread block occupancy, hence to improve the thread level parallelism (TLP). However, register files in the GPU dissipate a significant portion of the total leakage power. Leakage power of the register file can be reduced by putting the registers into low power (SLEEP or OFF) state. However, one challenge in doing so is the lack of precise register access information for each instruction at run-time. This paper proposes GREENER (GPU REgister file ENErgy Reducer): a tool for minimizing leakage energy of the register file of GPUs. GREENER employs a compile-time analysis to estimate the run-time register access information. The result of the analysis is used to determine the power state of the registers (ON, SLEEP, or OFF) after each instruction. We propose a new power optimized assembly instruction format that allows GREENER to encode the power state of the registers with its instruction. Further, GREENER transforms a given input assembly language to a power optimized assembly. The optimized assembly, along with a run-time optimization to update the power state of a register during execution, results in significant power reduction. We implemented GREENER in GPGPU-Sim simulator and used GPUWattch framework to measure the leakage power of register file. We evaluated the effectiveness of GREENER on 21 kernels from CUDASDK, GPGPU-SIM, Parboil, and Rodinia benchmarks suites. We observe an average reduction of register leakage energy by 69.2% and maximum reduction of 88.41% with a negligible performance overhead (0.05% slowdown on average). version:1
arxiv-1709-04695 | The Conditional Analogy GAN: Swapping Fashion Articles on People Images | http://arxiv.org/abs/1709.04695 | id:1709.04695 author:Nikolay Jetchev, Urs Bergmann category:stat.ML cs.AI cs.CV  published:2017-09-14 summary:We present a novel method to solve image analogy problems : it allows to learn the relation between paired images present in training data, and then generalize and generate images that correspond to the relation, but were never seen in the training set. Therefore, we call the method Conditional Analogy Generative Adversarial Network (CAGAN), as it is based on adversarial training and employs deep convolutional neural networks. An especially interesting application of that technique is automatic swapping of clothing on fashion model photos. Our work has the following contributions. First, the definition of the end-to-end trainable CAGAN architecture, which implicitly learns segmentation masks without expensive supervised labeling data. Second, experimental results show plausible segmentation masks and often convincing swapped images, given the target article. Finally, we discuss the next steps for that technique: neural network architecture improvements and more advanced applications. version:1
arxiv-1704-01074 | Emotional Chatting Machine: Emotional Conversation Generation with Internal and External Memory | http://arxiv.org/abs/1704.01074 | id:1704.01074 author:Hao Zhou, Minlie Huang, Tianyang Zhang, Xiaoyan Zhu, Bing Liu category:cs.CL cs.AI  published:2017-04-04 summary:Perception and expression of emotion are key factors to the success of dialogue systems or conversational agents. However, this problem has not been studied in large-scale conversation generation so far. In this paper, we propose Emotional Chatting Machine (ECM) that can generate appropriate responses not only in content (relevant and grammatical) but also in emotion (emotionally consistent). To the best of our knowledge, this is the first work that addresses the emotion factor in large-scale conversation generation. ECM addresses the factor using three new mechanisms that respectively (1) models the high-level abstraction of emotion expressions by embedding emotion categories, (2) captures the change of implicit internal emotion states, and (3) uses explicit emotion expressions with an external emotion vocabulary. Experiments show that the proposed model can generate responses appropriate not only in content but also in emotion. version:3
arxiv-1709-04385 | The Power of Synchronisation: Formal Analysis of Power Consumption in Networks of Pulse-Coupled Oscillators | http://arxiv.org/abs/1709.04385 | id:1709.04385 author:Paul Gainer, Sven Linker, Clare Dixon, Ullrich Hustadt, Michael Fisher category:cs.DC cs.NI  published:2017-09-13 summary:We assess the power consumption of network synchronisation protocols, particularly the energy required to synchronise all nodes across a network. We use the widely adopted approach of bio-inspired, pulse-coupled oscillators to achieve network-wide synchronisation and provide an extended formal model of just such a protocol, enhanced with structures for recording energy usage. Exhaustive analysis is then carried out through formal verification, utilising the PRISM model checker to calculate the resources consumed on each possible system execution. This allows us to assess a range of parameter instantiations and to explore trade-offs between power consumption and time to synchronise. This provides a principled basis for the formal analysis of a much broader range of large-scale network protocols. version:2
arxiv-1709-03300 | SO-MRS: a multi-robot system architecture based on the SOA paradigm and ontology | http://arxiv.org/abs/1709.03300 | id:1709.03300 author:Kamil Skarzynski, Marcin Stepniak, Waldemar Bartyna, Stanislaw Ambroszkiewicz category:cs.RO cs.MA cs.SE 68T40 I.2.9  published:2017-09-11 summary:A generic architecture for a class of distributed robotic systems is presented. The architecture supports openness and heterogeneity, i.e. heterogeneous components may be joined and removed from the systems without affecting its basic functionality. The architecture is based on the paradigm of Service Oriented Architecture (SOA), and a generic representation (ontology) of the environment. A device (e.g. robot) is seen as a collection of its capabilities exposed as services. Generic protocols for publishing, discovering, arranging services are proposed for creating composite services that can accomplish complex tasks in an automatic way. Also generic protocols for execution of composite services are proposed along with simple protocols for monitoring the executions, and for recovery from failures. A software platform built on a multi-robot system (according to the proposed architecture) is a multi-agent system. version:2
arxiv-1709-04687 | Feature Based Potential Field for Low-level Active Visual Navigation | http://arxiv.org/abs/1709.04687 | id:1709.04687 author:Rômulo T. Rodrigues, Meysam Basiri, A. Pedro Aguiar, Pedro Miraldo category:cs.RO  published:2017-09-14 summary:This paper proposes a novel solution for improving visual localization in an active fashion. The solution, based on artificial potential field, associates each feature in the current image frame with an attractive or neutral potential energy. The resultant action drives the vehicle towards the goal, while still favoring feature rich areas. Experimental results with a mini quadrotor equipped with a downward looking camera assess the performance of the proposed method. version:1
arxiv-1709-04676 | KBLRN : End-to-End Learning of Knowledge Base Representations with Latent, Relational, and Numerical Features | http://arxiv.org/abs/1709.04676 | id:1709.04676 author:Alberto Garcia-Duran, Mathias Niepert category:cs.AI  published:2017-09-14 summary:We present KBLRN, a novel framework for end-to-end learning of knowledge base representations from latent, relational, and numerical features. We discuss the advantages of each of the three feature types and the benefits of their combination. To the best of our knowledge, KBLRN is the first machine learning approach that learns representations of knowledge bases by integrating latent, relational, and numerical features. We show that instances of KBLRN outperform existing methods on a range of knowledge base completion tasks. For the experiments, we created novel data sets by enriching commonly used knowledge base completion benchmarks with numerical features. We also investigate in more detail the impact numerical features have on the link prediction performance. version:1
arxiv-1709-04640 | Scalability Evaluation of NSLP Algorithm for Solving Non-Stationary Linear Programming Problems on Cluster Computing Systems | http://arxiv.org/abs/1709.04640 | id:1709.04640 author:Irina Sokolinskaya, Leonid B. Sokolinsky category:cs.DC math.OC  published:2017-09-14 summary:The paper is devoted to a scalability study of the NSLP algorithm for solving non-stationary high-dimension linear programming problem on the cluster computing systems. The analysis is based on the BSF model of parallel computations. The BSF model is a new parallel computation model designed on the basis of BSP and SPMD models. The brief descriptions of the NSLP algorithm and the BSF model are given. The NSLP algorithm implementation in the form of a BSF program is considered. On the basis of the BSF cost metric, the upper bound of the NSLP algorithm scalability is derived and its parallel efficiency is estimated. NSLP algorithm implementation using BSF skeleton is described. A comparison of scalability estimations obtained analytically and experimentally is provided. version:1
arxiv-1709-04636 | Warmstarting of Model-based Algorithm Configuration | http://arxiv.org/abs/1709.04636 | id:1709.04636 author:Marius Lindauer, Frank Hutter category:cs.AI  published:2017-09-14 summary:The performance of many hard combinatorial problem solvers depends strongly on their parameter settings, and since manual parameter tuning is both tedious and suboptimal the AI community has recently developed several algorithm configuration (AC) methods to automatically address this problem. While all existing AC methods start the configuration process of an algorithm A from scratch for each new type of benchmark instances, here we propose to exploit information about A's performance on previous benchmarks in order to warmstart its configuration on new types of benchmarks. We introduce two complementary ways in which we can exploit this information to warmstart AC methods based on a predictive model. Experiments for optimizing a very flexible modern SAT solver on twelve different instance sets show that our methods often yield substantial speedups over existing AC methods (up to 165-fold) and can also find substantially better configurations given the same compute budget. version:1
arxiv-1610-09950 | From Node Embedding To Community Embedding | http://arxiv.org/abs/1610.09950 | id:1610.09950 author:Vincent W. Zheng, Sandro Cavallari, Hongyun Cai, Kevin Chen-Chuan Chang, Erik Cambria category:cs.SI cs.AI  published:2016-10-31 summary:Most of the existing graph embedding methods focus on nodes, which aim to output a vector representation for each node in the graph such that two nodes being "close" on the graph are close too in the low-dimensional space. Despite the success of embedding individual nodes for graph analytics, we notice that an important concept of embedding communities (i.e., groups of nodes) is missing. Embedding communities is useful, not only for supporting various community-level applications, but also to help preserve community structure in graph embedding. In fact, we see community embedding as providing a higher-order proximity to define the node closeness, whereas most of the popular graph embedding methods focus on first-order and/or second-order proximities. To learn the community embedding, we hinge upon the insight that community embedding and node embedding reinforce with each other. As a result, we propose ComEmbed, the first community embedding method, which jointly optimizes the community embedding and node embedding together. We evaluate ComEmbed on real-world data sets. We show it outperforms the state-of-the-art baselines in both tasks of node classification and community prediction. version:2
arxiv-1709-04622 | Agent-based Learning for Driving Policy Learning in Connected and Autonomous Vehicles | http://arxiv.org/abs/1709.04622 | id:1709.04622 author:Xiongzhao Wang, Varuna De Silva, Ahmet Kondoz category:cs.MA cs.RO  published:2017-09-14 summary:Due to the complexity of the natural world, a programmer cannot foresee all possible situations a connected and autonomous vehicle (CAV) will face during its operation, and hence, CAVs will need to learn to make decisions autonomously. Due to the sensing of its surroundings and information exchanged with other vehicles and road infrastructure a CAV will have access to large amounts of useful data. This paper investigates a data driven driving policy learning framework through an agent based learning. A reinforcement learning framework is presented in the paper, which simulates the self-evolution of a CAV over its lifetime. The results indicated that overtime the CAVs are able to learn useful policies to avoid crashes and achieve its objectives in more efficient ways. Vehicle to vehicle communication in particular, enables additional useful information to be acquired by CAVs, which in turn enables CAVs to learn driving policies more efficiently. The simulation results indicate that while a CAV can learn to make autonomous decision V2V communication of information improves this capability. The future work will investigate complex driving policies such as roundabout negotiations, cooperative learning between CAVs and deep reinforcement learning to traverse larger state spaces. version:1
arxiv-1709-06416 | Weld: Rethinking the Interface Between Data-Intensive Applications | http://arxiv.org/abs/1709.06416 | id:1709.06416 author:Shoumik Palkar, James Thomas, Deepak Narayanan, Anil Shanbhag, Rahul Palamuttam, Holger Pirk, Malte Schwarzkopf, Saman Amarasinghe, Samuel Madden, Matei Zaharia category:cs.DC cs.DB cs.PF  published:2017-09-14 summary:Data analytics applications combine multiple functions from different libraries and frameworks. Even when each function is optimized in isolation, the performance of the combined application can be an order of magnitude below hardware limits due to extensive data movement across these functions. To address this problem, we propose Weld, a new interface between data-intensive libraries that can optimize across disjoint libraries and functions. Weld exposes a lazily-evaluated API where diverse functions can submit their computations in a simple but general intermediate representation that captures their data-parallel structure. It then optimizes data movement across these functions and emits efficient code for diverse hardware. Weld can be integrated into existing frameworks such as Spark, TensorFlow, Pandas and NumPy without changing their user-facing APIs. We demonstrate that Weld can speed up applications using these frameworks by up to 29x. version:1
arxiv-1709-04617 | An Information Theoretic Approach to Sample Acquisition and Perception in Planetary Robotics | http://arxiv.org/abs/1709.04617 | id:1709.04617 author:Garrett Fleetwood, Jekan Thangavelautham category:cs.RO astro-ph.IM  published:2017-09-14 summary:An important and emerging component of planetary exploration is sample retrieval and return to Earth. Obtaining and analyzing rock samples can provide unprecedented insight into the geology, geo-history and prospects for finding past life and water. Current methods of exploration rely on mission scientists to identify objects of interests and this presents major operational challenges. Finding objects of interests will require systematic and efficient methods to quickly and correctly evaluate the importance of hundreds if not thousands of samples so that the most interesting are saved for further analysis by the mission scientists. In this paper, we propose an automated information theoretic approach to identify shapes of interests using a library of predefined interesting shapes. These predefined shapes maybe human input or samples that are then extrapolated by the shape matching system using the Superformula to judge the importance of newly obtained objects. Shape samples are matched to a library of shapes using the eigenfaces approach enabling categorization and prioritization of the sample. The approach shows robustness to simulated sensor noise of up to 20%. The effect of shape parameters and rotational angle on shape matching accuracy has been analyzed. The approach shows significant promise and efforts are underway in testing the algorithm with real rock samples. version:1
arxiv-1709-04599 | Simple Round Compression for Parallel Vertex Cover | http://arxiv.org/abs/1709.04599 | id:1709.04599 author:Sepehr Assadi category:cs.DS cs.DC  published:2017-09-14 summary:Recently, Czumaj et.al. (arXiv 2017) presented a parallel (almost) $2$-approximation algorithm for the maximum matching problem in only $O({(\log\log{n})^2})$ rounds of the massive parallel computation (MPC) framework, when the memory per machine is $O(n)$. The main approach in their work is a way of compressing $O(\log{n})$ rounds of a distributed algorithm for maximum matching into only $O({(\log\log{n})^2})$ MPC rounds. In this note, we present a similar algorithm for the closely related problem of approximating the minimum vertex cover in the MPC framework. We show that one can achieve an $O(\log{n})$ approximation to minimum vertex cover in only $O(\log\log{n})$ MPC rounds when the memory per machine is $O(n)$. Our algorithm for vertex cover is similar to the maximum matching algorithm of Czumaj et.al. but avoids many of the intricacies in their approach and as a result admits a considerably simpler analysis (at a cost of a worse approximation guarantee). We obtain this result by modifying a previous parallel algorithm by Khanna and the author (SPAA 2017) for vertex cover that allowed for compressing $O(\log{n})$ rounds of a distributed algorithm into constant MPC rounds when the memory allowed per machine is $O(n\sqrt{n})$. version:1
arxiv-1710-00778 | Proactive Doppler Shift Compensation in Vehicular Cyber-Physical Systems | http://arxiv.org/abs/1710.00778 | id:1710.00778 author:Jian Du, Xue Liu, Lei Rao category:eess.SP cs.DC  published:2017-09-14 summary:In vehicular cyber-physical systems (CPS), safety information, including vehicular speed and location information, is shared among vehicles via wireless waves at specific frequency. This helps control vehicle to alleviate traffic congestion and road accidents. However, Doppler shift existing between vehicles with high relative speed causes an apparent frequency shift for the received wireless wave, which consequently decreases the reliability of the recovered safety information and jeopardizes the safety of vehicular CPS. Passive confrontation of Doppler shift at the receiver side is not applicable due to multiple Doppler shifts at each receiver. In this paper, we provide a proactive Doppler shift compensation algorithm based on the probabilistic graphical model. Each vehicle pre-compensates its carrier frequency individually so that there is no frequency shift from the desired carrier frequency between each pair of transceiver. The pre-compensated offset for each vehicle is computed in a distributed fashion in order to be adaptive to the distributed and dynamic topology of vehicular CPS. Besides, the updating procedure is designed in a broadcasting fashion to reduce communication burden. It is rigorously proved that the proposed algorithm is convergence guaranteed even for systems with packet drops and random communication delays. Simulations based on real map and transportation data verify the accuracy and convergence property of the proposed algorithm. It is shown that this method achieves almost the optimal frequency compensation accuracy with an error approaching the Cram\'{e}r-Rao lower bound. version:1
arxiv-1709-04596 | A Framework for Generalizing Graph-based Representation Learning Methods | http://arxiv.org/abs/1709.04596 | id:1709.04596 author:Nesreen K. Ahmed, Ryan A. Rossi, Rong Zhou, John Boaz Lee, Xiangnan Kong, Theodore L. Willke, Hoda Eldardiry category:stat.ML cs.AI cs.LG cs.SI  published:2017-09-14 summary:Random walks are at the heart of many existing deep learning algorithms for graph data. However, such algorithms have many limitations that arise from the use of random walks, e.g., the features resulting from these methods are unable to transfer to new nodes and graphs as they are tied to node identity. In this work, we introduce the notion of attributed random walks which serves as a basis for generalizing existing methods such as DeepWalk, node2vec, and many others that leverage random walks. Our proposed framework enables these methods to be more widely applicable for both transductive and inductive learning as well as for use on graphs with attributes (if available). This is achieved by learning functions that generalize to new nodes and graphs. We show that our proposed framework is effective with an average AUC improvement of 16.1% while requiring on average 853 times less space than existing methods on a variety of graphs from several domains. version:1
arxiv-1709-04574 | Towards personalized human AI interaction - adapting the behavior of AI agents using neural signatures of subjective interest | http://arxiv.org/abs/1709.04574 | id:1709.04574 author:Victor Shih, David C Jangraw, Paul Sajda, Sameer Saproo category:cs.HC cs.AI cs.SY stat.ML  published:2017-09-14 summary:Reinforcement Learning AI commonly uses reward/penalty signals that are objective and explicit in an environment -- e.g. game score, completion time, etc. -- in order to learn the optimal strategy for task performance. However, Human-AI interaction for such AI agents should include additional reinforcement that is implicit and subjective -- e.g. human preferences for certain AI behavior -- in order to adapt the AI behavior to idiosyncratic human preferences. Such adaptations would mirror naturally occurring processes that increase trust and comfort during social interactions. Here, we show how a hybrid brain-computer-interface (hBCI), which detects an individual's level of interest in objects/events in a virtual environment, can be used to adapt the behavior of a Deep Reinforcement Learning AI agent that is controlling a virtual autonomous vehicle. Specifically, we show that the AI learns a driving strategy that maintains a safe distance from a lead vehicle, and most novelly, preferentially slows the vehicle when the human passengers of the vehicle encounter objects of interest. This adaptation affords an additional 20\% viewing time for subjectively interesting objects. This is the first demonstration of how an hBCI can be used to provide implicit reinforcement to an AI agent in a way that incorporates user preferences into the control system. version:1
arxiv-1709-04571 | When Waiting is not an Option : Learning Options with a Deliberation Cost | http://arxiv.org/abs/1709.04571 | id:1709.04571 author:Jean Harb, Pierre-Luc Bacon, Martin Klissarov, Doina Precup category:cs.AI  published:2017-09-14 summary:Recent work has shown that temporally extended actions (options) can be learned fully end-to-end as opposed to being specified in advance. While the problem of "how" to learn options is increasingly well understood, the question of "what" good options should be has remained elusive. We formulate our answer to what "good" options should be in the bounded rationality framework (Simon, 1957) through the notion of deliberation cost. We then derive practical gradient-based learning algorithms to implement this objective. Our results in the Arcade Learning Environment (ALE) show increased performance and interpretability. version:1
arxiv-1709-04569 | REMOTEGATE: Incentive-Compatible Remote Configuration of Security Gateways | http://arxiv.org/abs/1709.04569 | id:1709.04569 author:Abhinav Aggarwal, Mahdi Zamani, Mihai Christodorescu category:cs.CR cs.DC cs.GT  published:2017-09-14 summary:Imagine that a malicious hacker is trying to attack a server over the Internet and the server wants to block the attack packets as close to their point of origin as possible. However, the security gateway ahead of the source of attack is untrusted. How can the server block the attack packets through this gateway? In this paper, we introduce REMOTEGATE, a trustworthy mechanism for allowing any party (server) on the Internet to configure a security gateway owned by a second party, at a certain agreed upon reward that the former pays to the latter for its service. We take an interactive incentive-compatible approach, for the case when both the server and the gateway are rational, to devise a protocol that will allow the server to help the security gateway generate and deploy a policy rule that filters the attack packets before they reach the server. The server will reward the gateway only when the latter can successfully verify that it has generated and deployed the correct rule for the issue. This mechanism will enable an Internet-scale approach to improving security and privacy, backed by digital payment incentives. version:1
arxiv-1709-04555 | Predicting Organic Reaction Outcomes with Weisfeiler-Lehman Network | http://arxiv.org/abs/1709.04555 | id:1709.04555 author:Wengong Jin, Connor W. Coley, Regina Barzilay, Tommi Jaakkola category:cs.LG cs.AI stat.ML  published:2017-09-13 summary:The prediction of organic reaction outcomes is a fundamental problem in computational chemistry. Since a reaction may involve hundreds of atoms, fully exploring the space of possible transformations is intractable. The current solution utilizes reaction templates to limit the space, but it suffers from coverage and efficiency issues. In this paper, we propose a template-free approach to efficiently explore the space of product molecules by first pinpointing the reaction center -- the set of nodes and edges where graph edits occur. Since only a small number of atoms contribute to reaction center, we can directly enumerate candidate products. The generated candidates are scored by a Weisfeiler-Lehman Difference Network that models high-order interactions between changes occurring at nodes across the molecule. Our framework outperforms the top-performing template-based approach with a 10\% margin, while running orders of magnitude faster. Finally, we demonstrate that the model accuracy rivals the performance of domain experts. version:1
arxiv-1709-04551 | An Operational Semantic Basis for OpenMP Race Analysis | http://arxiv.org/abs/1709.04551 | id:1709.04551 author:Simone Atzeni, Ganesh Gopalakrishnan category:cs.DC  published:2017-09-13 summary:OpenMP is the de facto standard to exploit the on-node parallelism in new generation supercomputers.Despite its overall ease of use, even expert users are known to create OpenMP programs that harbor concurrency errors, of which one of the most insidious of errors are {\em data races}.OpenMP is also a rapidly evolving standard, which means that future data races may be introduced within unfamiliar contexts.A simple and rigorous operational semantics for OpenMP can help build reliable race checkers and ward off future errors through programmer education and better tooling.This paper's key contribution is a simple operational semantics for OpenMP, with primitive events matching those generated by today's popular OpenMP runtimes and tracing methods such as OMPT.This makes our operational semantics more than a theoretical document for intellectual edification; it can serve as a blueprint for OpenMP event capture and tool building.We back this statement by summarizing the workings of a new data race checker for OpenMP being built based on this semantics.The larger purpose served by our semantics is to serve the needs of the OpenMP community with regard to their contemplated extensions to OpenMP, as well as future tooling efforts. version:1
arxiv-1709-04543 | Efficient Multi-Task and Multi-Robot Transfer with Continued Learning | http://arxiv.org/abs/1709.04543 | id:1709.04543 author:Karime Pereida, Mohamed K. Helwa, Angela P. Schoellig category:cs.RO  published:2017-09-13 summary:Ideally, robots should learn from a few demonstrations of a given task, and generalize knowledge to new, unseen tasks, and to different robots. In this paper, we focus on trajectory tracking and introduce a multi-robot, multi-task transfer learning framework that allows a target system to complete a target task by learning from a few demonstrations of a source task on a source system. The proposed multi-robot transfer learning framework is based on a combined L1 adaptive control and iterative learning control approach. The key idea is that the adaptive controller forces dynamically different systems to behave as the specified reference model. The proposed multi-task transfer learning framework uses theoretical control results (e.g. the concept of vector relative degree) to learn a map from desired trajectories to the inputs that make the system track these trajectories. The learned map is then used to calculate the inputs for a new, unseen trajectory. Experimental results using two different quadrotors show that, using the proposed framework, it is possible to significantly reduce the tracking error of a target trajectory on the target system when information from a single source trajectory learned on the source system is used. version:1
arxiv-1709-03767 | Parallel Work Inflation, Memory Effects, and their Empirical Analysis | http://arxiv.org/abs/1709.03767 | id:1709.03767 author:Umut A. Acar, Arthur Charguéraud, Mike Rainey category:cs.DC D.1.3  published:2017-09-12 summary:In this paper, we propose an empirical method for evaluating the performance of parallel code. Our method is based on a simple idea that is surprisingly effective in helping to identify causes of poor performance, such as high parallelization overheads, lack of adequate parallelism, and memory effects. Our method relies on only the measurement of the run time of a baseline sequential program, the run time of the parallel program, the single-processor run time of the parallel program, and the total amount of time processors spend idle, waiting for work. In our proposed approach, we establish an equality between the observed parallel speedups and three terms that we call parallel work, idle time, and work-inflation, where all terms except work inflation can be measured empirically, with precision. We then use the equality to calculate the difficult-to-measure work-inflation term, which includes increased communication costs and memory effects due to parallel execution. By isolating the main factors of poor performance, our method enables the programmer to assign blame to certain properties of the code, such as parallel grain size, amount of parallelism, and memory usage. We present a mathematical model, inspired by the work-span model, that enables us to justify the interpretation of our measurements. We also introduce a method to help the programmer to visualize both the relative impact of the various causes of poor performance and the scaling trends in the causes of poor performance. Our method fits in a sweet spot in between state-of-the-art profiling and visualization tools. We illustrate our method by several empirical studies and we describe a few experiments that emphasize the care that is required to accurately interpret speedup plots. version:2
arxiv-1709-04524 | Workflow Complexity for Collaborative Interactions: Where are the Metrics? -- A Challenge | http://arxiv.org/abs/1709.04524 | id:1709.04524 author:Kartik Talamadupula, Biplav Srivastava, Jeffrey O. Kephart category:cs.AI  published:2017-09-13 summary:In this paper, we introduce the problem of denoting and deriving the complexity of workflows (plans, schedules) in collaborative, planner-assisted settings where humans and agents are trying to jointly solve a task. The interactions -- and hence the workflows that connect the human and the agents -- may differ according to the domain and the kind of agents. We adapt insights from prior work in human-agent teaming and workflow analysis to suggest metrics for workflow complexity. The main motivation behind this work is to highlight metrics for human comprehensibility of plans and schedules. The planning community has seen its fair share of work on the synthesis of plans that take diversity into account -- what value do such plans hold if their generation is not guided at least in part by metrics that reflect the ease of engaging with and using those plans? version:1
arxiv-1709-04517 | Mr. Jones -- Towards a Proactive Smart Room Orchestrator | http://arxiv.org/abs/1709.04517 | id:1709.04517 author:Tathagata Chakraborti, Kartik Talamadupula, Mishal Dholakia, Biplav Srivastava, Jeffrey O. Kephart, Rachel K. E. Bellamy category:cs.AI cs.CY cs.HC  published:2017-09-13 summary:In this paper, we report work in progress on the development of Mr. Jones -- a proactive orchestrator and decision support agent for a collaborative decision making setting embodied by a smart room. The duties of such an agent may range across interactive problem solving with other agents in the environment, developing automated summaries of meetings, visualization of the internal decision making process, proactive data and resource management, and so on. Specifically, we highlight the importance of integrating higher level symbolic reasoning and intent recognition in the design of such an agent, and outline pathways towards the realization of these capabilities. We will demonstrate some of these functionalities here in the context of automated orchestration of a meeting in the CEL -- the Cognitive Environments Laboratory at IBM's T.J. Watson Research Center. version:1
arxiv-1709-03248 | Vector Field Guidance for Convoy Monitoring Using Elliptical Orbits | http://arxiv.org/abs/1709.03248 | id:1709.03248 author:Aseem V. Borkar, Vivek S. Borkar, Arpita Sinha category:cs.RO cs.SY  published:2017-09-11 summary:We propose a novel vector field based guidance scheme for tracking and surveillance of a convoy, moving along a possibly nonlinear trajectory on the ground, by an aerial agent. The scheme first computes a time varying ellipse that encompasses all the targets in the convoy using a simple regression based algorithm. It then ensures convergence of the agent to a trajectory that repeatedly traverses this moving ellipse. The scheme is analyzed using perturbation theory of nonlinear differential equations and supporting simulations are provided. Some related implementation issues are discussed and advantages of the scheme are highlighted. version:2
arxiv-1709-04407 | An Inversion-Based Learning Approach for Improving Impromptu Trajectory Tracking of Robots with Non-Minimum Phase Dynamics | http://arxiv.org/abs/1709.04407 | id:1709.04407 author:Siqi Zhou, Mohamed K. Helwa, Angela P. Schoellig category:cs.RO cs.LG cs.SY  published:2017-09-13 summary:This paper presents a learning-based approach for impromptu trajectory tracking of non-minimum phase systems -- systems with unstable inverse dynamics. In the control systems literature, inversion-based feedforward approaches are commonly used for improving the trajectory tracking performance; however, these approaches are not directly applicable to non-minimum phase systems due to the inherent instability. In order to resolve the instability issue, they assume that models of the systems are known and have dealt with the non-minimum phase systems by pre-actuation or inverse approximation techniques. In this work, we extend our deep-neural-network-enhanced impromptu trajectory tracking approach to the challenging case of non-minimum phase systems. Through theoretical discussions, simulations, and experiments, we show the stability and effectiveness of our proposed learning approach. In fact, for a known system, our approach performs equally well or better as a typical model-based approach but does not require a prior model of the system. Interestingly, our approach also shows that including more information in training (as is commonly assumed to be useful) does not lead to better performance but may trigger instability issues and impede the effectiveness of the overall approach. version:1
arxiv-1709-04380 | Neural Network Based Nonlinear Weighted Finite Automata | http://arxiv.org/abs/1709.04380 | id:1709.04380 author:Tianyu Li, Guillaume Rabusseau, Doina Precup category:cs.FL cs.AI cs.CL cs.LG  published:2017-09-13 summary:Weighted finite automata (WFA) can expressively model functions defined over strings. However, a WFA is inherently a linear model. In this paper, we propose a neural network based nonlinear WFA model along with a learning algorithm. Our learning algorithm performs a nonlinear decomposition of the so-called Hankel matrix (using an encode decoder neural network) from which the transition operators of the model are recovered. We assessed the performance of the proposed model in a simulation study. version:1
arxiv-1709-04377 | ProSLAM: Graph SLAM from a Programmer's Perspective | http://arxiv.org/abs/1709.04377 | id:1709.04377 author:Dominik Schlegel, Mirco Colosi, Giorgio Grisetti category:cs.RO  published:2017-09-13 summary:In this paper we present ProSLAM, a lightweight stereo visual SLAM system designed with simplicity in mind. Our work stems from the experience gathered by the authors while teaching SLAM to students and aims at providing a highly modular system that can be easily implemented and understood. Rather than focusing on the well known mathematical aspects of Stereo Visual SLAM, in this work we highlight the data structures and the algorithmic aspects that one needs to tackle during the design of such a system. We implemented ProSLAM using the C++ programming language in combination with a minimal set of well known used external libraries. In addition to an open source implementation, we provide several code snippets that address the core aspects of our approach directly in this paper. The results of a thorough validation performed on standard benchmark datasets show that our approach achieves accuracy comparable to state of the art methods, while requiring substantially less computational resources. version:1
arxiv-1709-04328 | Generating OWA weights using truncated distributions | http://arxiv.org/abs/1709.04328 | id:1709.04328 author:Maxime Lenormand category:cs.AI  published:2017-09-13 summary:Ordered weighted averaging (OWA) operators have been widely used in decision making these past few years. An important issue facing the OWA operators' users is the determination of the OWA weights. This paper introduces an OWA determination method based on truncated distributions that enables intuitive generation of OWA weights according to a certain level of risk and trade-off. These two dimensions are represented by the two first moments of the truncated distribution. We illustrate our approach with the well-know normal distribution and the definition of a continuous parabolic decision-strategy space. We finally study the impact of the number of criteria on the results. version:1
arxiv-1709-04326 | Learning with Opponent-Learning Awareness | http://arxiv.org/abs/1709.04326 | id:1709.04326 author:Jakob N. Foerster, Richard Y. Chen, Maruan Al-Shedivat, Shimon Whiteson, Pieter Abbeel, Igor Mordatch category:cs.AI cs.GT  published:2017-09-13 summary:Multi-agent settings are quickly gathering importance in machine learning. Beyond a plethora of recent work on deep multi-agent reinforcement learning, hierarchical reinforcement learning, generative adversarial networks and decentralized optimization can all be seen as instances of this setting. However, the presence of multiple learning agents in these settings renders the training problem non-stationary and often leads to unstable training or undesired final results. We present Learning with Opponent-Learning Awareness (LOLA), a method that reasons about the anticipated learning of the other agents. The LOLA learning rule includes an additional term that accounts for the impact of the agent's policy on the anticipated parameter update of the other agents. We show that the LOLA update rule can be efficiently calculated using an extension of the likelihood ratio policy gradient update, making the method suitable for model-free reinforcement learning. This method thus scales to large parameter and input spaces and nonlinear function approximators. Preliminary results show that the encounter of two LOLA agents leads to the emergence of tit-for-tat and therefore cooperation in the infinitely iterated prisoners' dilemma, while independent learning does not. In this domain, LOLA also receives higher payouts compared to a naive learner, and is robust against exploitation by higher order gradient-based methods. Applied to infinitely repeated matching pennies, only LOLA agents converge to the Nash equilibrium. We also apply LOLA to a grid world task with an embedded social dilemma using deep recurrent policies. Again, by considering the learning of the other agent, LOLA agents learn to cooperate out of selfish interests. version:1
arxiv-1709-04291 | Flora robotica -- An Architectural System Combining Living Natural Plants and Distributed Robots | http://arxiv.org/abs/1709.04291 | id:1709.04291 author:Heiko Hamann, Mohammad Divband Soorati, Mary Katherine Heinrich, Daniel Nicolas Hofstadler, Igor Kuksin, Frank Veenstra, Mostafa Wahby, Stig Anton Nielsen, Sebastian Risi, Tomasz Skrzypczak, Payam Zahadat, Przemyslaw Wojtaszek, Kasper Støy, Thomas Schmickl, Serge Kernbach, Phil Ayres category:cs.ET cs.RO  published:2017-09-13 summary:Key to our project flora robotica is the idea of creating a bio-hybrid system of tightly coupled natural plants and distributed robots to grow architectural artifacts and spaces. Our motivation with this ground research project is to lay a principled foundation towards the design and implementation of living architectural systems that provide functionalities beyond those of orthodox building practice, such as self-repair, material accumulation and self-organization. Plants and robots work together to create a living organism that is inhabited by human beings. User-defined design objectives help to steer the directional growth of the plants, but also the system's interactions with its inhabitants determine locations where growth is prohibited or desired (e.g., partitions, windows, occupiable space). We report our plant species selection process and aspects of living architecture. A leitmotif of our project is the rich concept of braiding: braids are produced by robots from continuous material and serve as both scaffolds and initial architectural artifacts before plants take over and grow the desired architecture. We use light and hormones as attraction stimuli and far-red light as repelling stimulus to influence the plants. Applied sensors range from simple proximity sensing to detect the presence of plants to sophisticated sensing technology, such as electrophysiology and measurements of sap flow. We conclude by discussing our anticipated final demonstrator that integrates key features of flora robotica, such as the continuous growth process of architectural artifacts and self-repair of living architecture. version:1
arxiv-1709-05945 | A General Framework for Flexible Multi-Cue Photometric Point Cloud Registration | http://arxiv.org/abs/1709.05945 | id:1709.05945 author:Bartolomeo Della Corte, Igor Bogoslavskyi, Cyrill Stachniss, Giorgio Grisetti category:cs.CV cs.RO  published:2017-09-13 summary:The ability to build maps is a key functionality for the majority of mobile robots. A central ingredient to most mapping systems is the registration or alignment of the recorded sensor data. In this paper, we present a general methodology for photometric registration that can deal with multiple different cues. We provide examples for registering RGBD as well as 3D LIDAR data. In contrast to popular point cloud registration approaches such as ICP our method does not rely on explicit data association and exploits multiple modalities such as raw range and image data streams. Color, depth, and normal information are handled in an uniform manner and the registration is obtained by minimizing the pixel-wise difference between two multi-channel images. We developed a flexible and general framework and implemented our approach inside that framework. We also released our implementation as open source C++ code. The experiments show that our approach allows for an accurate registration of the sensor data without requiring an explicit data association or model-specific adaptations to datasets or sensors. Our approach exploits the different cues in a natural and consistent way and the registration can be done at framerate for a typical range or imaging sensor. version:1
arxiv-1709-04271 | Action Schema Networks: Generalised Policies with Deep Learning | http://arxiv.org/abs/1709.04271 | id:1709.04271 author:Sam Toyer, Felipe Trevizan, Sylvie Thiebaux, Lexing Xie category:cs.AI cs.LG  published:2017-09-13 summary:In this paper, we introduce the Action Schema Network (ASNet): a neural network architecture for learning generalised policies for probabilistic planning problems. By mimicking the relational structure of planning problems, ASNets are able to adopt a weight-sharing scheme which allows the network to be applied to any problem from a given planning domain. This allows the cost of training the network to be amortised over all problems in that domain. Further, we propose a training method which balances exploration and supervised training on small problems to produce a policy which remains robust when evaluated on larger problems. In experiments, we show that ASNet's learning capability allows it to significantly outperform traditional non-learning planners in several challenging domains. version:1
arxiv-1707-03734 | A Decentralized Multi-Agent Unmanned Aerial System to Search, Pick Up, and Relocate Objects | http://arxiv.org/abs/1707.03734 | id:1707.03734 author:Rik Bähnemann, Dominik Schindler, Mina Kamel, Roland Siegwart, Juan Nieto category:cs.RO  published:2017-07-12 summary:We present a fully integrated autonomous multi- robot aerial system for finding and collecting moving and static objects with unknown locations. This task addresses multiple relevant problems in search and rescue (SAR) robotics such as multi-agent aerial exploration, object detection and tracking, and aerial gripping. Usually, the community tackles these problems individually but the integration into a working system generates extra complexity which is rarely addressed. We show that this task can be solved reliably using only simple components. Our decentralized system uses accurate global state estimation, reactive collision avoidance, and sweep planning for multi-agent exploration. Objects are detected, tracked, and picked up using blob detection, inverse 3D-projection, Kalman filtering, visual-servoing, and a magnetic gripper. We evaluate the individual components of our system on the real platform. The full system has been deployed successfully in various public demonstrations, field tests, and the Mohamed Bin Zayed International Robotics Challenge 2017 (MBZIRC). Among the contestants we showed reliable performances and reached second place out of 17 in the individual challenge. version:2
arxiv-1709-04255 | On the Generation of Initial Contexts for Effective Deadlock Detection | http://arxiv.org/abs/1709.04255 | id:1709.04255 author:Elvira Albert, Miguel Gómez-Zamalloa, Miguel Isabel category:cs.PL cs.DC cs.LO cs.SE  published:2017-09-13 summary:It has been recently proposed that testing based on symbolic execution can be used in conjunction with static deadlock analysis to define a deadlock detection framework that: (i) can show deadlock presence, in that case a concrete test-case and trace are obtained, and (ii) can also prove deadlock freedom. Such symbolic execution starts from an initial distributed context, i.e., a set of locations and their initial tasks. Considering all possibilities results in a combinatorial explosion on the different distributed contexts that must be considered. This paper proposes a technique to effectively generate initial contexts that can lead to deadlock, using the possible conflicting task interactions identified by static analysis, discarding other distributed contexts that cannot lead to deadlock. The proposed technique has been integrated in the above-mentioned deadlock detection framework hence enabling it to analyze systems without the need of any user supplied initial context. version:1
arxiv-1709-04219 | Assessing State-of-the-Art Sentiment Models on State-of-the-Art Sentiment Datasets | http://arxiv.org/abs/1709.04219 | id:1709.04219 author:Jeremy Barnes, Roman Klinger, Sabine Schulte im Walde category:cs.CL cs.AI  published:2017-09-13 summary:There has been a good amount of progress in sentiment analysis over the past 10 years, including the proposal of new methods and the creation of benchmark datasets. In some papers, however, there is a tendency to compare models only on one or two datasets, either because of time restraints or because the model is tailored to a specific task. Accordingly, it is hard to understand how well a certain model generalizes across different tasks and datasets. In this paper, we contribute to this situation by comparing several models on six different benchmarks, which belong to different domains and additionally have different levels of granularity (binary, 3-class, 4-class and 5-class). We show that Bi-LSTMs perform well across datasets and that both LSTMs and Bi-LSTMs are particularly good at fine-grained sentiment tasks (i. e., with more than two classes). Incorporating sentiment information into word embeddings during training gives good results for datasets that are lexically similar to the training data. With our experiments, we contribute to a better understanding of the performance of different model architectures on different data sets. Consequently, we detect novel state-of-the-art results on the SenTube datasets. version:1
arxiv-1709-04186 | On labeling Android malware signatures using minhashing and further classification with Structural Equation Models | http://arxiv.org/abs/1709.04186 | id:1709.04186 author:Ignacio Martín, José Alberto Hernández, Sergio de los Santos category:cs.CR cs.AI stat.ML  published:2017-09-13 summary:Multi-scanner Antivirus systems provide insightful information on the nature of a suspect application; however there is often a lack of consensus and consistency between different Anti-Virus engines. In this article, we analyze more than 250 thousand malware signatures generated by 61 different Anti-Virus engines after analyzing 82 thousand different Android malware applications. We identify 41 different malware classes grouped into three major categories, namely Adware, Harmful Threats and Unknown or Generic signatures. We further investigate the relationships between such 41 classes using community detection algorithms from graph theory to identify similarities between them; and we finally propose a Structure Equation Model to identify which Anti-Virus engines are more powerful at detecting each macro-category. As an application, we show how such models can help in identifying whether Unknown malware applications are more likely to be of Harmful or Adware type. version:1
arxiv-1709-04184 | Charge-based computing with analogue reconfigurable gates | http://arxiv.org/abs/1709.04184 | id:1709.04184 author:Alexantrou Serb, Ali Khiat, Themis Prodromakis category:cs.ET cs.AR  published:2017-09-13 summary:As the world enters the age of ubiquitous computing, the need for reconfigurable hardware operating close to the fundamental limits of energy consumption becomes increasingly pressing. Simultaneously, scaling-driven performance improvements within the framework of traditional analogue and digital design become progressively more restricted by fundamental physical constraints. Thus, a true paradigm shift in electronics design is required for fuelling the next big burst in technology. Here we lay the foundations of a new design paradigm that fuses analogue and digital thinking by combining digital electronics with memristive devices for achieving charge-based computation; information processing where every dissipated charge counts. This is realised by introducing memristive devices into standard logic gates, thus rendering them reconfigurable and able to perform analogue computation at a power cost close to digital. The power of this concept is then showcased by experimentally demonstrating a hardware data clusterer and a fuzzy NAND gate using this principle. version:1
arxiv-1709-04182 | Conflict management in information fusion with belief functions | http://arxiv.org/abs/1709.04182 | id:1709.04182 author:Arnaud Martin category:cs.AI  published:2017-09-13 summary:In Information fusion, the conflict is an important concept. Indeed, combining several imperfect experts or sources allows conflict. In the theory of belief functions, this notion has been discussed a lot. The mass appearing on the empty set during the conjunctive combination rule is generally considered as conflict, but that is not really a conflict. Some measures of conflict have been proposed and some approaches have been proposed in order to manage this conflict or to decide with conflicting mass functions. We recall in this chapter some of them and we propose a discussion to consider the conflict in information fusion with the theory of belief functions. version:1
arxiv-1709-04176 | Computing the Shapley Value in Allocation Problems: Approximations and Bounds, with an Application to the Italian VQR Research Assessment Program | http://arxiv.org/abs/1709.04176 | id:1709.04176 author:Francesco Lupia, Angelo Mendicelli, Andrea Ribichini, Francesco Scarcello, Marco Schaerf category:cs.GT cs.AI  published:2017-09-13 summary:In allocation problems, a given set of goods are assigned to agents in such a way that the social welfare is maximised, that is, the largest possible global worth is achieved. When goods are indivisible, it is possible to use money compensation to perform a fair allocation taking into account the actual contribution of all agents to the social welfare. Coalitional games provide a formal mathematical framework to model such problems, in particular the Shapley value is a solution concept widely used for assigning worths to agents in a fair way. Unfortunately, computing this value is a $\#{\rm P}$-hard problem, so that applying this good theoretical notion is often quite difficult in real-world problems. We describe useful properties that allow us to greatly simplify the instances of allocation problems, without affecting the Shapley value of any player. Moreover, we propose algorithms for computing lower bounds and upper bounds of the Shapley value, which in some cases provide the exact result and that can be combined with approximation algorithms. The proposed techniques have been implemented and tested on a real-world application of allocation problems, namely, the Italian research assessment program, known as VQR. For the large university considered in the experiments, the problem involves thousands of agents and goods (here, researchers and their research products). The algorithms described in the paper are able to compute the Shapley value for most of those agents, and to get a good approximation of the Shapley value for all of them. version:1
arxiv-1709-04145 | Articulated Body Dynamics Simulation using Optimization Integrator | http://arxiv.org/abs/1709.04145 | id:1709.04145 author:Zherong Pan, Dinesh Manocha category:cs.RO  published:2017-09-13 summary:We present a novel optimization-based algorithm for articulated body dynamics simulation. We formulate the governing equations of rigid body dynamics using only the position variables and recast the position-based articulated dynamics as an optimization problem. We also extend our framework to handle joint limits, control forces/torques, fluid drag forces, and frictional contact forces. Our reformulation allows us to use an off-the-shelf optimization algorithm to time integrate the articulated body with an arbitrarily large timestep size and analyze the stability. Our algorithm can efficiently perform each iteration of optimization within $\mathcal{O}(N)$ time using Quasi-Newton method and $\mathcal{O}(N^2)$ time using Newton's method, where $N$ is the number of links. We highlight the performance on different benchmarks and compare the performance with prior articulated body dynamics simulators. version:1
arxiv-1709-04137 | Models and Framework for Adversarial Attacks on Complex Adaptive Systems | http://arxiv.org/abs/1709.04137 | id:1709.04137 author:Vahid Behzadan, Arslan Munir category:cs.SY cs.CR cs.DC cs.GT  published:2017-09-13 summary:We introduce the paradigm of adversarial attacks that target the dynamics of Complex Adaptive Systems (CAS). To facilitate the analysis of such attacks, we present multiple approaches to the modeling of CAS as dynamical, data-driven, and game-theoretic systems, and develop quantitative definitions of attack, vulnerability, and resilience in the context of CAS security. Furthermore, we propose a comprehensive set of schemes for classification of attacks and attack surfaces in CAS, complemented with examples of practical attacks. Building on this foundation, we propose a framework based on reinforcement learning for simulation and analysis of attacks on CAS, and demonstrate its performance through three real-world case studies of targeting power grids, destabilization of terrorist organizations, and manipulation of machine learning agents. We also discuss potential mitigation techniques, and remark on future research directions in analysis and design of secure complex adaptive systems. version:1
arxiv-1503-03128 | Efficient Straggler Replication in Large-scale Parallel Computing | http://arxiv.org/abs/1503.03128 | id:1503.03128 author:Da Wang, Gauri Joshi, Gregory Wornell category:cs.DC C.4; F.2.2  published:2015-03-11 summary:In a cloud computing job with many parallel tasks, the tasks on the slowest machines (straggling tasks) become the bottleneck in the job completion. Computing frameworks such as MapReduce and Spark tackle this by replicating the straggling tasks and waiting for any one copy to finish. Despite being adopted in practice, there is little analysis of how replication affects the latency and the cost of additional computing resources. In this paper we provide a framework to analyze this latency-cost trade-off and find the best replication strategy by answering design questions such as: 1) when to replicate straggling tasks, 2) how many replicas to launch, and 3) whether to kill the original copy or not. Our analysis reveals that for certain execution time distributions, a small amount of task replication can drastically reduce both latency as well as the cost of computing resources. We also propose an algorithm to estimate the latency and cost based on the empirical distribution of task execution time. Evaluations using samples in the Google Cluster Trace suggest further latency and cost reduction compared to the existing replication strategy used in MapReduce. version:3
arxiv-1709-04083 | Pre-training Neural Networks with Human Demonstrations for Deep Reinforcement Learning | http://arxiv.org/abs/1709.04083 | id:1709.04083 author:Gabriel V. de la Cruz Jr, Yunshu Du, Matthew E. Taylor category:cs.LG cs.AI  published:2017-09-12 summary:Deep reinforcement learning (deep RL) has achieved superior performance in complex sequential tasks by using a deep neural network as its function approximator and by learning directly from raw images. A drawback of using raw images is that deep RL must learn the state feature representation from the raw images in addition to learning a policy. As a result, deep RL can require a prohibitively large amount of training time and data to reach reasonable performance, making it difficult to use deep RL in real-world applications, especially when data is expensive. In this work, we speed up training by addressing half of what deep RL is trying to solve --- learning features. Our approach is to learn some of the important features by pre-training deep RL network's hidden layers via supervised learning using a small set of human demonstrations. We empirically evaluate our approach using deep Q-network (DQN) and asynchronous advantage actor-critic (A3C) algorithms on the Atari 2600 games of Pong, Freeway, and Beamrider. Our results show that: 1) pre-training with human demonstrations in a supervised learning manner is better at discovering features relative to pre-training naively in DQN, and 2) initializing a deep RL network with a pre-trained model provides a significant improvement in training time even when pre-training from a small number of human demonstrations. version:1
arxiv-1709-04061 | ENORM: A Framework For Edge NOde Resource Management | http://arxiv.org/abs/1709.04061 | id:1709.04061 author:Nan Wang, Blesson Varghese, Michail Matthaiou, Dimitrios S. Nikolopoulos category:cs.DC  published:2017-09-12 summary:Current computing techniques using the cloud as a centralised server will become untenable as billions of devices get connected to the Internet. This raises the need for fog computing, which leverages computing at the edge of the network on nodes, such as routers, base stations and switches, along with the cloud. However, to realise fog computing the challenge of managing edge nodes will need to be addressed. This paper is motivated to address the resource management challenge. We develop the first framework to manage edge nodes, namely the Edge NOde Resource Management (ENORM) framework. Mechanisms for provisioning and auto-scaling edge node resources are proposed. The feasibility of the framework is demonstrated on a PokeMon Go-like online game use-case. The benefits of using ENORM are observed by reduced application latency between 20% - 80% and reduced data transfer and communication frequency between the edge node and the cloud by up to 95\%. These results highlight the potential of fog computing for improving the quality of service and experience. version:1
arxiv-1709-04057 | Parallelizing Linear Recurrent Neural Nets Over Sequence Length | http://arxiv.org/abs/1709.04057 | id:1709.04057 author:Eric Martin, Chris Cundy category:cs.NE cs.AI cs.LG  published:2017-09-12 summary:Recurrent neural networks (RNNs) are widely used to model sequential data but their non-linear dependencies between sequence elements prevent parallelizing training over sequence length. We show the training of RNNs with only linear sequential dependencies can be parallelized over the sequence length using the parallel scan algorithm, leading to rapid training on long sequences with small minibatch size. We abstract prior linear sequence models into a new framework of linear surrogate RNNs and develop a linear surrogate long short-term memory (LS-LSTM) powered by a parallel linear recurrence CUDA kernel we implemented. We evaluate the LS-LSTM on a long sequence noisy autoregressive task and find the LS-LSTM achieves slightly superior train and test performance to a similar sized LSTM in 4x less training time. We analyze latency and throughput of the LS-LSTM and find the LS-LSTM reaches up to 175x the throughput of the LSTM in the small minibatch long sequence regime. version:1
arxiv-1709-04049 | Information Design in Crowdfunding under Thresholding Policies | http://arxiv.org/abs/1709.04049 | id:1709.04049 author:Wen Shen, Jacob W. Crandall, Ke Yan, Cristina V. Lopes category:cs.AI cs.CY cs.MA  published:2017-09-12 summary:In crowdfunding, an entrepreneur often has to decide how to disclose the campaign status in order to collect as many contributions as possible. We propose information design as a tool to help the entrepreneur to improve revenue by influencing backers' beliefs. We introduce a heuristic algorithm to dynamically compute information-disclosure policies for the entrepreneur, followed by an empirical evaluation to demonstrate its competitiveness over the widely-adopted immediate-disclosure policy. Our work sheds light on information design in a dynamic setting where agents follow thresholding policies. version:1
arxiv-1709-04029 | Probability Reversal and the Disjunction Effect in Reasoning Systems | http://arxiv.org/abs/1709.04029 | id:1709.04029 author:Subhash Kak category:cs.AI  published:2017-09-12 summary:Data based judgments go into artificial intelligence applications but they undergo paradoxical reversal when seemingly unnecessary additional data is provided. Examples of this are Simpson's reversal and the disjunction effect where the beliefs about the data change once it is presented or aggregated differently. Sometimes the significance of the difference can be evaluated using statistical tests such as Pearson's chi-squared or Fisher's exact test, but this may not be helpful in threshold-based decision systems that operate with incomplete information. To mitigate risks in the use of algorithms in decision-making, we consider the question of modeling of beliefs. We argue that evidence supports that beliefs are not classical statistical variables and they should, in the general case, be considered as superposition states of disjoint or polar outcomes. We analyze the disjunction effect from the perspective of the belief as a quantum vector. version:1
arxiv-1709-03969 | Explore, Exploit or Listen: Combining Human Feedback and Policy Model to Speed up Deep Reinforcement Learning in 3D Worlds | http://arxiv.org/abs/1709.03969 | id:1709.03969 author:Zhiyu Lin, Brent Harrison, Aaron Keech, Mark O. Riedl category:cs.AI  published:2017-09-12 summary:We describe a method to use discrete human feedback to enhance the performance of deep learning agents in virtual three-dimensional environments by extending deep-reinforcement learning to model the confidence and consistency of human feedback. This enables deep reinforcement learning algorithms to determine the most appropriate time to listen to the human feedback, exploit the current policy model, or explore the agent's environment. Managing the trade-off between these three strategies allows DRL agents to be robust to inconsistent or intermittent human feedback. Through experimentation using a synthetic oracle, we show that our technique improves the training speed and overall performance of deep reinforcement learning in navigating three-dimensional environments using Minecraft. We further show that our technique is robust to highly innacurate human feedback and can also operate when no human feedback is given. version:1
arxiv-1709-03968 | Affective Neural Response Generation | http://arxiv.org/abs/1709.03968 | id:1709.03968 author:Nabiha Asghar, Pascal Poupart, Jesse Hoey, Xin Jiang, Lili Mou category:cs.CL cs.AI cs.CY cs.HC cs.IR 68T50 I.2.7  published:2017-09-12 summary:Existing neural conversational models process natural language primarily on a lexico-syntactic level, thereby ignoring one of the most crucial components of human-to-human dialogue: its affective content. We take a step in this direction by proposing three novel ways to incorporate affective/emotional aspects into long short term memory (LSTM) encoder-decoder neural conversation models: (1) affective word embeddings, which are cognitively engineered, (2) affect-based objective functions that augment the standard cross-entropy loss, and (3) affectively diverse beam search for decoding. Experiments show that these techniques improve the open-domain conversational prowess of encoder-decoder networks by enabling them to produce emotionally rich responses that are more interesting and natural. version:1
arxiv-1709-03981 | Aggregating incoherent agents who disagree | http://arxiv.org/abs/1709.03981 | id:1709.03981 author:Richard Pettigrew category:stat.OT cs.AI  published:2017-09-12 summary:In this paper, we explore how we should aggregate the degrees of belief of of a group of agents to give a single coherent set of degrees of belief, when at least some of those agents might be probabilistically incoherent. There are a number of way of aggregating degrees of belief, and there are a number of ways of fixing incoherent degrees of belief. When we have picked one of each, should we aggregate first and then fix, or fix first and then aggregate? Or should we try to do both at once? And when do these different procedures agree with one another? In this paper, we focus particularly on the final question. version:1
arxiv-1709-03947 | Constant Space Complexity Environment Representation for Vision-based Navigation | http://arxiv.org/abs/1709.03947 | id:1709.03947 author:Jeffrey Kane Johnson category:cs.RO  published:2017-09-12 summary:This paper presents a preliminary conceptual investigation into an environment representation that has constant space complexity with respect to the camera image space. This type of representation allows the planning algorithms of a mobile agent to bypass what are often complex and noisy transformations between camera image space and Euclidean space. The approach is to compute per-pixel potential values directly from processed camera data, which results in a discrete potential field that has constant space complexity with respect to the image plane. This can enable planning and control algorithms, whose complexity often depends on the size of the environment representation, to be defined with constant run-time. This type of approach can be particularly useful for platforms with strict resource constraints, such as embedded and real-time systems. version:1
arxiv-1709-03946 | Multimodal Content Analysis for Effective Advertisements on YouTube | http://arxiv.org/abs/1709.03946 | id:1709.03946 author:Nikhita Vedula, Wei Sun, Hyunhwan Lee, Harsh Gupta, Mitsunori Ogihara, Joseph Johnson, Gang Ren, Srinivasan Parthasarathy category:cs.AI cs.LG cs.MM cs.NE  published:2017-09-12 summary:The rapid advances in e-commerce and Web 2.0 technologies have greatly increased the impact of commercial advertisements on the general public. As a key enabling technology, a multitude of recommender systems exists which analyzes user features and browsing patterns to recommend appealing advertisements to users. In this work, we seek to study the characteristics or attributes that characterize an effective advertisement and recommend a useful set of features to aid the designing and production processes of commercial advertisements. We analyze the temporal patterns from multimedia content of advertisement videos including auditory, visual and textual components, and study their individual roles and synergies in the success of an advertisement. The objective of this work is then to measure the effectiveness of an advertisement, and to recommend a useful set of features to advertisement designers to make it more successful and approachable to users. Our proposed framework employs the signal processing technique of cross modality feature learning where data streams from different components are employed to train separate neural network models and are then fused together to learn a shared representation. Subsequently, a neural network model trained on this joint feature embedding representation is utilized as a classifier to predict advertisement effectiveness. We validate our approach using subjective ratings from a dedicated user study, the sentiment strength of online viewer comments, and a viewer opinion metric of the ratio of the Likes and Views received by each advertisement from an online platform. version:1
arxiv-1709-03919 | End-to-End United Video Dehazing and Detection | http://arxiv.org/abs/1709.03919 | id:1709.03919 author:Boyi Li, Xiulian Peng, Zhangyang Wang, Jizheng Xu, Dan Feng category:cs.CV cs.AI cs.LG  published:2017-09-12 summary:The recent development of CNN-based image dehazing has revealed the effectiveness of end-to-end modeling. However, extending the idea to end-to-end video dehazing has not been explored yet. In this paper, we propose an End-to-End Video Dehazing Network (EVD-Net), to exploit the temporal consistency between consecutive video frames. A thorough study has been conducted over a number of structure options, to identify the best temporal fusion strategy. Furthermore, we build an End-to-End United Video Dehazing and Detection Network(EVDD-Net), which concatenates and jointly trains EVD-Net with a video object detection model. The resulting augmented end-to-end pipeline has demonstrated much more stable and accurate detection results in hazy video. version:1
arxiv-1709-03915 | Specious rules: an efficient and effective unifying method for removing misleading and uninformative patterns in association rule mining | http://arxiv.org/abs/1709.03915 | id:1709.03915 author:Wilhelmiina Hämäläinen, Geoffrey I. Webb category:cs.AI  published:2017-09-12 summary:We present theoretical analysis and a suite of tests and procedures for addressing a broad class of redundant and misleading association rules we call \emph{specious rules}. Specious dependencies, also known as \emph{spurious}, \emph{apparent}, or \emph{illusory associations}, refer to a well-known phenomenon where marginal dependencies are merely products of interactions with other variables and disappear when conditioned on those variables. The most extreme example is Yule-Simpson's paradox where two variables present positive dependence in the marginal contingency table but negative in all partial tables defined by different levels of a confounding factor. It is accepted wisdom that in data of any nontrivial dimensionality it is infeasible to control for all of the exponentially many possible confounds of this nature. In this paper, we consider the problem of specious dependencies in the context of statistical association rule mining. We define specious rules and show they offer a unifying framework which covers many types of previously proposed redundant or misleading association rules. After theoretical analysis, we introduce practical algorithms for detecting and pruning out specious association rules efficiently under many key goodness measures, including mutual information and exact hypergeometric probabilities. We demonstrate that the procedure greatly reduces the number of associations discovered, providing an elegant and effective solution to the problem of association mining discovering large numbers of misleading and redundant rules. version:1
arxiv-1709-03854 | Meta-QSAR: a large-scale application of meta-learning to drug design and discovery | http://arxiv.org/abs/1709.03854 | id:1709.03854 author:Ivan Olier, Noureddin Sadawi, G. Richard Bickerton, Joaquin Vanschoren, Crina Grosan, Larisa Soldatova, Ross D. King category:cs.AI cs.LG I.2  published:2017-09-12 summary:We investigate the learning of quantitative structure activity relationships (QSARs) as a case-study of meta-learning. This application area is of the highest societal importance, as it is a key step in the development of new medicines. The standard QSAR learning problem is: given a target (usually a protein) and a set of chemical compounds (small molecules) with associated bioactivities (e.g. inhibition of the target), learn a predictive mapping from molecular representation to activity. Although almost every type of machine learning method has been applied to QSAR learning there is no agreed single best way of learning QSARs, and therefore the problem area is well-suited to meta-learning. We first carried out the most comprehensive ever comparison of machine learning methods for QSAR learning: 18 regression methods, 6 molecular representations, applied to more than 2,700 QSAR problems. (These results have been made publicly available on OpenML and represent a valuable resource for testing novel meta-learning methods.) We then investigated the utility of algorithm selection for QSAR problems. We found that this meta-learning approach outperformed the best individual QSAR learning method (random forests using a molecular fingerprint representation) by up to 13%, on average. We conclude that meta-learning outperforms base-learning methods for QSAR learning, and as this investigation is one of the most extensive ever comparisons of base and meta-learning methods ever made, it provides evidence for the general effectiveness of meta-learning over base-learning. version:1
arxiv-1709-02091 | Asynchronous COMID: the theoretic basis for transmitted data sparsification tricks on Parameter Server | http://arxiv.org/abs/1709.02091 | id:1709.02091 author:Daning Cheng, Shigang Li, Yunquan Zhang category:cs.DC  published:2017-09-07 summary:Asynchronous FTRL-proximal and L2 norm done at server are two widely used tricks in Parameters Server which is an implement of delayed SGD. Their commonness is leaving parts of updating computation on server which reduces the burden of network via making transmitted data sparse. But above tricks' convergences are not well-proved. In this paper, based on above commonness, we propose a more general algorithm named as asynchronous COMID and prove its convergence. We prove that asynchronous FTRL-proximal and L2 norm done at server are applications of asynchronous COMID, which demonstrates the convergences of above two tricks. Then, we conduct experiments to verify theoretical results. Experimental results show that compared with delayed SGD on Parameters Server, asynchronous COMID reduces the burden of the network without any harm on the mathematical convergence speed and final output. version:3
arxiv-1709-03980 | Refining Source Representations with Relation Networks for Neural Machine Translation | http://arxiv.org/abs/1709.03980 | id:1709.03980 author:Wen Zhang, Jiawei Hu, Yang Feng, Qun Liu category:cs.CL cs.AI cs.LG  published:2017-09-12 summary:Although neural machine translation (NMT) with the encoder-decoder framework has achieved great success in recent times, it still suffers from some drawbacks: RNNs tend to forget old information which is often useful and the encoder only operates through words without considering word relationship. To solve these problems, we introduce a relation networks (RN) into NMT to refine the encoding representations of the source. In our method, the RN first augments the representation of each source word with its neighbors and reasons all the possible pairwise relations between them. Then the source representations and all the relations are fed to the attention module and the decoder together, keeping the main encoder-decoder architecture unchanged. Experiments on two Chinese-to-English data sets in different scales both show that our method can outperform the competitive baselines significantly. version:1
arxiv-1709-03799 | Automatic Differentiation of Rigid Body Dynamics for Optimal Control and Estimation | http://arxiv.org/abs/1709.03799 | id:1709.03799 author:Markus Giftthaler, Michael Neunert, Markus Stäuble, Marco Frigerio, Claudio Semini, Jonas Buchli category:cs.RO  published:2017-09-12 summary:Many algorithms for control, optimization and estimation in robotics depend on derivatives of the underlying system dynamics, e.g. to compute linearizations, sensitivities or gradient directions. However, we show that when dealing with Rigid Body Dynamics, these derivatives are difficult to derive analytically and to implement efficiently. To overcome this issue, we extend the modelling tool `RobCoGen' to be compatible with Automatic Differentiation. Additionally, we propose how to automatically obtain the derivatives and generate highly efficient source code. We highlight the flexibility and performance of the approach in two application examples. First, we show a Trajectory Optimization example for the quadrupedal robot HyQ, which employs auto-differentiation on the dynamics including a contact model. Second, we present a hardware experiment in which a 6 DoF robotic arm avoids a randomly moving obstacle in a go-to task by fast, dynamic replanning. version:1
arxiv-1606-05597 | Adding Context to Concept Trees | http://arxiv.org/abs/1606.05597 | id:1606.05597 author:Kieran Greer category:cs.AI  published:2016-06-17 summary:Concept Trees are a type of database that can organise arbitrary textual information using a very simple rule. Each tree tries to represent a single cohesive concept and the trees can link with each other for navigation and semantic purposes. The trees are therefore a type of semantic network and would benefit from having a consistent level of context for each of the nodes. The Concept Tree nodes have a mathematical basis allowing for a consistent build process. These would represent nouns or verbs in a text sentence, for example. New to the design can then be lists of descriptive elements for each of the nodes. The descriptors can also be weighted, but do not have to follow the strict counting rule of the tree nodes. With the new descriptive layers, a much richer type of knowledge can be achieved and still reasoned over automatically. The linking structure of the licas network is very relevant to building the concept trees now and forms the basis for their construction. The concept tree - symbolic neural network relation is also extended further. version:2
arxiv-1708-06551 | Reinforcement Learning in POMDPs with Memoryless Options and Option-Observation Initiation Sets | http://arxiv.org/abs/1708.06551 | id:1708.06551 author:Denis Steckelmacher, Diederik M. Roijers, Anna Harutyunyan, Peter Vrancx, Hélène Plisnier, Ann Nowé category:cs.AI cs.LG  published:2017-08-22 summary:Many real-world reinforcement learning problems have a hierarchical nature, and often exhibit some degree of partial observability. While hierarchy and partial observability are usually tackled separately (for instance by combining recurrent neural networks and options), we show that addressing both problems simultaneously is simpler and more efficient in many cases. More specifically, we make the initiation set of options conditional on the previously-executed option, and show that options with such Option-Observation Initiation Sets (OOIs) are at least as expressive as Finite State Controllers (FSCs), a state-of-the-art approach for learning in POMDPs. OOIs are easy to design based on an intuitive description of the task, lead to explainable policies and keep the top-level and option policies memoryless. Our experiments show that OOIs allow agents to learn optimal policies in challenging POMDPs, while being much more sample-efficient than a recurrent neural network over options. version:2
arxiv-1709-03715 | OCCAM: a flexible, multi-purpose and extendable HPC cluster | http://arxiv.org/abs/1709.03715 | id:1709.03715 author:Marco Aldinucci, Stefano Bagnasco, Stefano Lusso, Paolo Pasteris, Sergio Rabellino, Sara Vallero category:cs.DC  published:2017-09-12 summary:The Open Computing Cluster for Advanced data Manipulation (OCCAM) is a multi-purpose flexible HPC cluster designed and operated by a collaboration between the University of Torino and the Sezione di Torino of the Istituto Nazionale di Fisica Nucleare. It is aimed at providing a flexible, reconfigurable and extendable infrastructure to cater to a wide range of different scientific computing use cases, including ones from solid-state chemistry, high-energy physics, computer science, big data analytics, computational biology, genomics and many others. Furthermore, it will serve as a platform for R&D activities on computational technologies themselves, with topics ranging from GPU acceleration to Cloud Computing technologies. A heterogeneous and reconfigurable system like this poses a number of challenges related to the frequency at which heterogeneous hardware resources might change their availability and shareability status, which in turn affect methods and means to allocate, manage, optimize, bill, monitor VMs, containers, virtual farms, jobs, interactive bare-metal sessions, etc. This work describes some of the use cases that prompted the design and construction of the HPC cluster, its architecture and resource provisioning model, along with a first characterization of its performance by some synthetic benchmark tools and a few realistic use-case tests. version:1
arxiv-1709-03714 | RRA: Recurrent Residual Attention for Sequence Learning | http://arxiv.org/abs/1709.03714 | id:1709.03714 author:Cheng Wang category:cs.LG cs.AI  published:2017-09-12 summary:In this paper, we propose a recurrent neural network (RNN) with residual attention (RRA) to learn long-range dependencies from sequential data. We propose to add residual connections across timesteps to RNN, which explicitly enhances the interaction between current state and hidden states that are several timesteps apart. This also allows training errors to be directly back-propagated through residual connections and effectively alleviates gradient vanishing problem. We further reformulate an attention mechanism over residual connections. An attention gate is defined to summarize the individual contribution from multiple previous hidden states in computing the current state. We evaluate RRA on three tasks: the adding problem, pixel-by-pixel MNIST classification and sentiment analysis on the IMDB dataset. Our experiments demonstrate that RRA yields better performance, faster convergence and more stable training compared to a standard LSTM network. Furthermore, RRA shows highly competitive performance to the state-of-the-art methods. version:1
arxiv-1708-06246 | Comparative Benchmarking of Causal Discovery Techniques | http://arxiv.org/abs/1708.06246 | id:1708.06246 author:Karamjit Singh, Garima Gupta, Vartika Tewari, Gautam Shroff category:cs.AI stat.ML  published:2017-08-18 summary:In this paper we present a comprehensive view of prominent causal discovery algorithms, categorized into two main categories (1) assuming acyclic and no latent variables, and (2) allowing both cycles and latent variables, along with experimental results comparing them from three perspectives: (a) structural accuracy, (b) standard predictive accuracy, and (c) accuracy of counterfactual inference. For (b) and (c) we train causal Bayesian networks with structures as predicted by each causal discovery technique to carry out counterfactual or standard predictive inference. We compare causal algorithms on two pub- licly available and one simulated datasets having different sample sizes: small, medium and large. Experiments show that structural accuracy of a technique does not necessarily correlate with higher accuracy of inferencing tasks. Fur- ther, surveyed structure learning algorithms do not perform well in terms of structural accuracy in case of datasets having large number of variables. version:2
arxiv-1709-03683 | A Practically Competitive and Provably Consistent Algorithm for Uplift Modeling | http://arxiv.org/abs/1709.03683 | id:1709.03683 author:Yan Zhao, Xiao Fang, David Simchi-Levi category:cs.LG cs.AI stat.ML  published:2017-09-12 summary:Randomized experiments have been critical tools of decision making for decades. However, subjects can show significant heterogeneity in response to treatments in many important applications. Therefore it is not enough to simply know which treatment is optimal for the entire population. What we need is a model that correctly customize treatment assignment base on subject characteristics. The problem of constructing such models from randomized experiments data is known as Uplift Modeling in the literature. Many algorithms have been proposed for uplift modeling and some have generated promising results on various data sets. Yet little is known about the theoretical properties of these algorithms. In this paper, we propose a new tree-based ensemble algorithm for uplift modeling. Experiments show that our algorithm can achieve competitive results on both synthetic and industry-provided data. In addition, by properly tuning the "node size" parameter, our algorithm is proved to be consistent under mild regularity conditions. This is the first consistent algorithm for uplift modeling that we are aware of. version:1
arxiv-1709-03669 | Capture Point Trajectories for Reduced Knee Bend using Step Time Optimization | http://arxiv.org/abs/1709.03669 | id:1709.03669 author:Robert J. Griffin, Sylvain Bertrand, Georg Wiedebach, Alexander Leonessa, Jerry Pratt category:cs.RO  published:2017-09-12 summary:Traditional force-controlled bipedal walking utilizes highly bent knees, resulting in high torques as well as inefficient, and unnatural motions. Even with advanced planning of center of mass height trajectories, significant amounts of knee-bend can be required due to arbitrarily chosen step timing. In this work, we present a method that examines the effects of adjusting the step timing to produce plans that only require a specified amount of knee bend to execute. We define a quadratic program that optimizes the step timings and is executed this using a simple iterative feedback approach to account for higher order terms. We then illustrate the effectiveness of this algorithm by comparing the walking gait of the simulated Atlas humanoid with and without the algorithm, showing that the algorithm significantly reduces the required knee bend for execution. We aim to later use this approach to achieve natural, efficient walking motions on humanoid robot platforms. version:1
arxiv-1709-03660 | Straight-Leg Walking Through Underconstrained Whole-Body Control | http://arxiv.org/abs/1709.03660 | id:1709.03660 author:Robert J. Griffin, Georg Wiedebach, Sylvain Bertrand, Alexander Leonessa, Jerry Pratt category:cs.RO  published:2017-09-12 summary:We present an approach for achieving a natural, efficient gait on bipedal robots using straightened legs and toe-off. Our algorithm avoids complex height planning by allowing a whole-body controller to determine the straightest possible leg configuration at run-time. The controller solutions are biased towards a straight leg configuration by projecting leg joint angle objectives into the null-space of the other quadratic program motion objectives. To allow the legs to remain straight throughout the gait, toe-off was utilized to increase the kinematic reachability of the legs. The toe-off motion is achieved through underconstraining the foot position, allowing it to emerge naturally. We applied this approach of under-specifying the motion objectives to the Atlas humanoid, allowing it to walk over a variety of terrain. We present both experimental and simulation results and discuss performance limitations and potential improvements. version:1
arxiv-1709-03641 | Semi-centralized control for multi-robot formation and theoretical lower bound | http://arxiv.org/abs/1709.03641 | id:1709.03641 author:Shuo Wan, Jiaxun Lu, Pingyi Fan, Khaled B. Letaief category:cs.RO  published:2017-09-12 summary:Multi-robot formation control enables robots to cooperate as a working group in completing complex tasks, which has been widely used in both civilian and military scenarios. Before moving to reach a given formation, each robot should choose a position from the formation so that the whole system cost is minimized. To solve the problem, we formulate an optimization problem in terms of the total moving distance and give a solution by the Hungarian method. To analyze the deviation of the achieved formation from the ideal one, we obtain the lower bound of formation bias with respect to system's parameters based on notions in information theory. As an extension, we discuss methods of transformation between different formations. Some theoretical results are obtained to give a guidance of the system design. version:1
arxiv-1709-03625 | Budgeted Experiment Design for Causal Structure Learning | http://arxiv.org/abs/1709.03625 | id:1709.03625 author:AmirEmad Ghassami, Saber Salehkaleybar, Negar Kiyavash, Elias Bareinboim category:cs.LG cs.AI stat.ML  published:2017-09-11 summary:We study the problem of causal structure learning when the experimenter is limited to perform at most $k$ non-adaptive experiments of size $1$. We formulate the problem of finding the best intervention target set as an optimization problem, which aims to maximize the average number of edges whose directions are resolved. We prove that the objective function is submodular and a greedy algorithm is a $(1-\frac{1}{e})$-approximation algorithm for the problem. We further present an accelerated variant of the greedy algorithm, which can lead to orders of magnitude performance speedup. We validate our proposed approach on synthetic and real graphs. The results show that compared to the purely observational setting, our algorithm orients majority of the edges through only a small number of interventions. version:1
arxiv-1709-03582 | Art of singular vectors and universal adversarial perturbations | http://arxiv.org/abs/1709.03582 | id:1709.03582 author:Valentin Khrulkov, Ivan Oseledets category:cs.CV cs.AI cs.LG  published:2017-09-11 summary:Vulnerability of state-of-the-art deep neural networks to adversarial attacks has been attracting a lot of attention recently. In this work we propose a new algorithm for constructing universal adversarial perturbations. Our approach is based on computing the so called $(p, q)$-singular vectors of the Jacobian matrices of hidden layers of a network. Resulting perturbations present interesting visual patterns and by using a batch of just $64$ images we can construct adversarial perturbations with relatively high fooling rate. We also investigate a correlation between the singular values of the Jacobian matrices and the fooling rate of a corresponding singular vector. version:1
arxiv-1709-03526 | FieldSAFE: Dataset for Obstacle Detection in Agriculture | http://arxiv.org/abs/1709.03526 | id:1709.03526 author:Mikkel Fly Kragh, Peter Christiansen, Morten Stigaard Laursen, Morten Larsen, Kim Arild Steen, Ole Green, Henrik Karstoft, Rasmus Nyholm Jørgensen category:cs.RO  published:2017-09-11 summary:In this paper, we present a novel multi-modal dataset for obstacle detection in agriculture. The dataset comprises approximately 2 hours of raw sensor data from a tractor-mounted sensor system in a grass mowing scenario in Denmark, October 2016. Sensing modalities include stereo camera, thermal camera, web camera, 360-degree camera, lidar, and radar, while precise localization is available from fused IMU and GNSS. Both static and moving obstacles are present including humans, mannequin dolls, rocks, barrels, buildings, vehicles, and vegetation. All obstacles have ground truth object labels and geographic coordinates. version:1
arxiv-1709-03486 | Robot Composite Learning and the Nunchaku Flipping Challenge | http://arxiv.org/abs/1709.03486 | id:1709.03486 author:Leidi Zhao, Yiwen Zhao, Siddharth Patil, Dylan Davies, Cong Wang, Lu Lu, Bo Ouyang category:cs.RO  published:2017-09-11 summary:Advanced motor skills are essential for robots to physically coexist with humans. Much research on robot dynamics and control has achieved success on hyper robot motor capabilities, but mostly through heavily case-specific engineering. Meanwhile, in terms of robot acquiring skills in a ubiquitous manner, robot learning from human demonstration (LfD) has achieved great progress, but still has limitations handling dynamic skills and compound actions. In this paper, we present a composite learning scheme which goes beyond LfD and integrates robot learning from human definition, demonstration, and evaluation. The method tackles advanced motor skills that require dynamic time-critical maneuver, complex contact control, and handling partly soft partly rigid objects. We also introduce the "nunchaku flipping challenge", an extreme test that puts hard requirements to all these three aspects. Continued from our previous presentations, this paper introduces the latest update of the composite learning scheme and the physical success of the nunchaku flipping challenge. version:1
arxiv-1709-03480 | Combining Strategic Learning and Tactical Search in Real-Time Strategy Games | http://arxiv.org/abs/1709.03480 | id:1709.03480 author:Nicolas A. Barriga, Marius Stanescu, Michael Buro category:cs.AI  published:2017-09-11 summary:A commonly used technique for managing AI complexity in real-time strategy (RTS) games is to use action and/or state abstractions. High-level abstractions can often lead to good strategic decision making, but tactical decision quality may suffer due to lost details. A competing method is to sample the search space which often leads to good tactical performance in simple scenarios, but poor high-level planning. We propose to use a deep convolutional neural network (CNN) to select among a limited set of abstract action choices, and to utilize the remaining computation time for game tree search to improve low level tactics. The CNN is trained by supervised learning on game states labelled by Puppet Search, a strategic search algorithm that uses action abstractions. The network is then used to select a script --- an abstract action --- to produce low level actions for all units. Subsequently, the game tree search algorithm improves the tactical actions of a subset of units using a limited view of the game state only considering units close to opponent units. Experiments in the microRTS game show that the combined algorithm results in higher win-rates than either of its two independent components and other state-of-the-art microRTS agents. To the best of our knowledge, this is the first successful application of a convolutional network to play a full RTS game on standard game maps, as previous work has focused on sub-problems, such as combat, or on very small maps. version:1
arxiv-1709-03474 | Dynamic Task Execution using Active Parameter Identification with the Baxter Research Robot | http://arxiv.org/abs/1709.03474 | id:1709.03474 author:Andrew D. Wilson, Jarvis A. Schultz, Alex R. Ansari, Todd D. Murphey category:cs.RO  published:2017-09-11 summary:This paper presents experimental results from real-time parameter estimation of a system model and subsequent trajectory optimization for a dynamic task using the Baxter Research Robot from Rethink Robotics. An active estimator maximizing Fisher information is used in real-time with a closed-loop, non-linear control technique known as Sequential Action Control. Baxter is tasked with estimating the length of a string connected to a load suspended from the gripper with a load cell providing the single source of feedback to the estimator. Following the active estimation, a trajectory is generated using the trep software package that controls Baxter to dynamically swing a suspended load into a box. Several trials are presented with varying initial estimates showing that estimation is required to obtain adequate open-loop trajectories to complete the prescribed task. The result of one trial with and without the active estimation is also shown in the accompanying video. version:1
arxiv-1708-02072 | Measuring Catastrophic Forgetting in Neural Networks | http://arxiv.org/abs/1708.02072 | id:1708.02072 author:Ronald Kemker, Marc McClure, Angelina Abitino, Tyler Hayes, Christopher Kanan category:cs.AI cs.CV cs.LG  published:2017-08-07 summary:Deep neural networks are used in many state-of-the-art systems for machine perception. Once a network is trained to do a specific task, e.g., bird classification, it cannot easily be trained to do new tasks, e.g., incrementally learning to recognize additional bird species or learning an entirely different task such as flower recognition. When new tasks are added, typical deep neural networks are prone to catastrophically forgetting previous tasks. Networks that are capable of assimilating new information incrementally, much like how humans form new memories over time, will be more efficient than re-training the model from scratch each time a new task needs to be learned. There have been multiple attempts to develop schemes that mitigate catastrophic forgetting, but these methods have not been directly compared, the tests used to evaluate them vary considerably, and these methods have only been evaluated on small-scale problems (e.g., MNIST). In this paper, we introduce new metrics and benchmarks for directly comparing five different mechanisms designed to mitigate catastrophic forgetting in neural networks: regularization, ensembling, rehearsal, dual-memory, and sparse-coding. Our experiments on real-world images and sounds show that the mechanism(s) that are critical for optimal performance vary based on the incremental training paradigm and type of data being used, but they all demonstrate that the catastrophic forgetting problem has yet to be solved. version:3
arxiv-1709-02314 | Representation Learning for Visual-Relational Knowledge Graphs | http://arxiv.org/abs/1709.02314 | id:1709.02314 author:Daniel Oñoro-Rubio, Mathias Niepert, Alberto García-Durán, Roberto González, Roberto J. López-Sastre category:cs.LG cs.AI  published:2017-09-07 summary:Much progress has been made towards the goal of developing ML systems that are able to recognize and interpret visual scenes. With this paper, we propose query answering in visual-relational knowledge graphs (KGs) as a novel and important reasoning problem. A visual-relational KG is a KG whose entities are associated with image data. We introduce ImageGraph, a publicly available KG with 1330 relation types, 14,870 entities, and 829,931 images. Visual-relational KGs naturally lead to several novel query types treating images as first-class citizens. We approach the query answering problems by combining ideas from the areas of KG embedding learning and deep learning for computer vision. The resulting ML models can answer queries such as "How are these two unseen images related to each other?" We also explore a novel zero-shot learning scenario where an image of an entirely new entity is linked to entities of an existing visual-relational KG. An extensive set of experiments shows that the proposed deep neural networks are able to answer the visual-relational queries efficiently and accurately. version:2
arxiv-1709-03450 | UI-Net: Interactive Artificial Neural Networks for Iterative Image Segmentation Based on a User Model | http://arxiv.org/abs/1709.03450 | id:1709.03450 author:Mario Amrehn, Sven Gaube, Mathias Unberath, Frank Schebesch, Tim Horz, Maddalena Strumia, Stefan Steidl, Markus Kowarschik, Andreas Maier category:cs.CV cs.AI cs.LG cs.NE 68T05  68T45 I.2.6; I.4.6; I.5.5  published:2017-09-11 summary:For complex segmentation tasks, fully automatic systems are inherently limited in their achievable accuracy for extracting relevant objects. Especially in cases where only few data sets need to be processed for a highly accurate result, semi-automatic segmentation techniques exhibit a clear benefit for the user. One area of application is medical image processing during an intervention for a single patient. We propose a learning-based cooperative segmentation approach which includes the computing entity as well as the user into the task. Our system builds upon a state-of-the-art fully convolutional artificial neural network (FCN) as well as an active user model for training. During the segmentation process, a user of the trained system can iteratively add additional hints in form of pictorial scribbles as seed points into the FCN system to achieve an interactive and precise segmentation result. The segmentation quality of interactive FCNs is evaluated. Iterative FCN approaches can yield superior results compared to networks without the user input channel component, due to a consistent improvement in segmentation quality after each interaction. version:1
arxiv-1709-03426 | Trajectory Synthesis for Fisher Information Maximization | http://arxiv.org/abs/1709.03426 | id:1709.03426 author:Andrew D. Wilson, Jarvis A. Schultz, Todd D. Murphey category:cs.RO cs.SY  published:2017-09-11 summary:Estimation of model parameters in a dynamic system can be significantly improved with the choice of experimental trajectory. For general, nonlinear dynamic systems, finding globally "best" trajectories is typically not feasible; however, given an initial estimate of the model parameters and an initial trajectory, we present a continuous-time optimization method that produces a locally optimal trajectory for parameter estimation in the presence of measurement noise. The optimization algorithm is formulated to find system trajectories that improve a norm on the Fisher information matrix. A double-pendulum cart apparatus is used to numerically and experimentally validate this technique. In simulation, the optimized trajectory increases the minimum eigenvalue of the Fisher information matrix by three orders of magnitude compared to the initial trajectory. Experimental results show that this optimized trajectory translates to an order of magnitude improvement in the parameter estimate error in practice. version:1
arxiv-1708-07579 | Hamiltonian Maker-Breaker games on small graphs | http://arxiv.org/abs/1708.07579 | id:1708.07579 author:Miloš Stojaković, Nikola Trkulja category:math.CO cs.AI cs.DM  published:2017-08-25 summary:We look at the unbiased Maker-Breaker Hamiltonicity game played on the edge set of a complete graph $K_n$, where Maker's goal is to claim a Hamiltonian cycle. First, we prove that, independent of who starts, Maker can win the game for $n = 8$ and $n = 9$. Then we use an inductive argument to show that, independent of who starts, Maker can win the game if and only if $n \geq 8$. This, in particular, resolves in the affirmative the long-standing conjecture of Papaioannou. We also study two standard positional games related to Hamiltonicity game. For Hamiltonian Path game, we show that Maker can claim a Hamiltonian path if and only if $n \geq 5$, independent of who starts. Next, we look at Fixed Hamiltonian Path game, where the goal of Maker is to claim a Hamiltonian path between two predetermined vertices. We prove that if Maker starts the game, he wins if and only if $n \geq 7$, and if Breaker starts, Maker wins if and only if $n \geq 8$. Using this result, we are able to improve the previously best upper bound on the smallest number of edges a graph on $n$ vertices can have, knowing that Maker can win the Maker-Breaker Hamiltonicity game played on its edges. To resolve the outcomes of the mentioned games on small (finite) boards, we devise algorithms for efficiently searching game trees and then obtain our results with the help of a computer. version:2
arxiv-1709-03404 | A Domain-specific Language for High-reliability Software used in the JUICE SWI Instrument - The hO Language Manual | http://arxiv.org/abs/1709.03404 | id:1709.03404 author:Felix Winkelmann, Oskar Schirmer category:cs.DC cs.PL  published:2017-09-11 summary:hO is a custom restricted dialect of Oberon, developed at the Max-Planck Institute for Solar System Research in G\"ottingen and used in the SWI flight software for the JUICE mission. hO is applied to reduce the possibility of syntactically valid but incorrect code, provide better means of statically analyzing source code, is more readable than C and gives syntactic support for the software architecture used in the SWI instrument software. By using a higher-level, application-specific notation a whole range of possible errors is eliminated and source code size is reduced, while making the code itself easier to understand, review and analyze. version:1
arxiv-1709-03363 | A Planning Approach to Monitoring Behavior of Computer Programs | http://arxiv.org/abs/1709.03363 | id:1709.03363 author:Alexandre Cukier, Ronen I. Brafman, Yotam Perkal, David Tolpin category:cs.AI cs.CR  published:2017-09-11 summary:We describe a novel approach to monitoring high level behaviors using concepts from AI planning. Our goal is to understand what a program is doing based on its system call trace. This ability is particularly important for detecting malware. We approach this problem by building an abstract model of the operating system using the STRIPS planning language, casting system calls as planning operators. Given a system call trace, we simulate the corresponding operators on our model and by observing the properties of the state reached, we learn about the nature of the original program and its behavior. Thus, unlike most statistical detection methods that focus on syntactic features, our approach is semantic in nature. Therefore, it is more robust against obfuscation techniques used by malware that change the outward appearance of the trace but not its effect. We demonstrate the efficacy of our approach by evaluating it on actual system call traces. version:1
arxiv-1709-03339 | Autonomous Quadrotor Landing using Deep Reinforcement Learning | http://arxiv.org/abs/1709.03339 | id:1709.03339 author:Riccardo Polvara, Massimiliano Patacchiola, Sanjay Sharma, Jian Wan, Andrew Manning, Robert Sutton, Angelo Cangelosi category:cs.AI cs.RO  published:2017-09-11 summary:Landing an unmanned aerial vehicle on a ground marker is an open problem despite the effort of the research community. Previous attempts mostly focused on the analysis of hand-crafted geometric features and the use of external sensors in order to allow the vehicle to approach the land-pad. In this article, we propose a method based on deep reinforcement learning which only requires low-resolution images taken from a down-looking camera in order to identify the position of the marker and land the quadrotor on it. The proposed approach is based on a hierarchy of Deep Q-Networks (DQNs) which are used as high-level control policy for the navigation toward the marker. We implemented different technical solutions, such as the combination of vanilla and double DQNs trained using a form of prioritized buffer replay which separates experiences in multiple containers. Learning is achieved without any human supervision, giving to the agent an high-level feedback. The results show that the quadrotor can autonomously accomplish landing on a large variety of simulated environments and with relevant noise. In some conditions the DQN outperformed human pilots tested in the same environment. version:1
arxiv-1709-03332 | Collaborative Reuse of Streaming Dataflows in IoT Applications | http://arxiv.org/abs/1709.03332 | id:1709.03332 author:Shilpa Chaturvedi, Sahil Tyagi, Yogesh Simmhan category:cs.DC  published:2017-09-11 summary:Distributed Stream Processing Systems (DSPS) like Apache Storm and Spark Streaming enable composition of continuous dataflows that execute persistently over data streams. They are used by Internet of Things (IoT) applications to analyze sensor data from Smart City cyber-infrastructure, and make active utility management decisions. As the ecosystem of such IoT applications that leverage shared urban sensor streams continue to grow, applications will perform duplicate pre-processing and analytics tasks. This offers the opportunity to collaboratively reuse the outputs of overlapping dataflows, thereby improving the resource efficiency. In this paper, we propose \emph{dataflow reuse algorithms} that given a submitted dataflow, identifies the intersection of reusable tasks and streams from a collection of running dataflows to form a \emph{merged dataflow}. Similar algorithms to unmerge dataflows when they are removed are also proposed. We implement these algorithms for the popular Apache Storm DSPS, and validate their performance and resource savings for 35 synthetic dataflows based on public OPMW workflows with diverse arrival and departure distributions, and on 21 real IoT dataflows from RIoTBench. version:1
arxiv-1709-03329 | weedNet: Dense Semantic Weed Classification Using Multispectral Images and MAV for Smart Farming | http://arxiv.org/abs/1709.03329 | id:1709.03329 author:Inkyu Sa, Zetao Chen, Marija Popovic, Raghav Khanna, Frank Liebisch, Juan Nieto, Roland Siegwart category:cs.CV cs.RO  published:2017-09-11 summary:Selective weed treatment is a critical step in autonomous crop management as related to crop health and yield. However, a key challenge is reliable, and accurate weed detection to minimize damage to surrounding plants. In this paper, we present an approach for dense semantic weed classification with multispectral images collected by a micro aerial vehicle (MAV). We use the recently developed encoder-decoder cascaded Convolutional Neural Network (CNN), Segnet, that infers dense semantic classes while allowing any number of input image channels and class balancing with our sugar beet and weed datasets. To obtain training datasets, we established an experimental field with varying herbicide levels resulting in field plots containing only either crop or weed, enabling us to use the Normalized Difference Vegetation Index (NDVI) as a distinguishable feature for automatic ground truth generation. We train 6 models with different numbers of input channels and condition (fine-tune) it to achieve about 0.8 F1-score and 0.78 Area Under the Curve (AUC) classification metrics. For model deployment, an embedded GPU system (Jetson TX2) is tested for MAV integration. Dataset used in this paper is released to support the community and future work. version:1
arxiv-1709-03316 | What does fault tolerant Deep Learning need from MPI? | http://arxiv.org/abs/1709.03316 | id:1709.03316 author:Vinay Amatya, Abhinav Vishnu, Charles Siegel, Jeff Daily category:cs.DC  published:2017-09-11 summary:Deep Learning (DL) algorithms have become the de facto Machine Learning (ML) algorithm for large scale data analysis. DL algorithms are computationally expensive - even distributed DL implementations which use MPI require days of training (model learning) time on commonly studied datasets. Long running DL applications become susceptible to faults - requiring development of a fault tolerant system infrastructure, in addition to fault tolerant DL algorithms. This raises an important question: What is needed from MPI for de- signing fault tolerant DL implementations? In this paper, we address this problem for permanent faults. We motivate the need for a fault tolerant MPI specification by an in-depth consideration of recent innovations in DL algorithms and their properties, which drive the need for specific fault tolerance features. We present an in-depth discussion on the suitability of different parallelism types (model, data and hybrid); a need (or lack thereof) for check-pointing of any critical data structures; and most importantly, consideration for several fault tolerance proposals (user-level fault mitigation (ULFM), Reinit) in MPI and their applicability to fault tolerant DL implementations. We leverage a distributed memory implementation of Caffe, currently available under the Machine Learning Toolkit for Extreme Scale (MaTEx). We implement our approaches by ex- tending MaTEx-Caffe for using ULFM-based implementation. Our evaluation using the ImageNet dataset and AlexNet, and GoogLeNet neural network topologies demonstrates the effectiveness of the proposed fault tolerant DL implementation using OpenMPI based ULFM. version:1
arxiv-1709-03309 | Discriminant chronicles mining: Application to care pathways analytics | http://arxiv.org/abs/1709.03309 | id:1709.03309 author:Yann Dauxais, Thomas Guyet, David Gross-Amblard, André Happe category:cs.AI cs.DS  published:2017-09-11 summary:Pharmaco-epidemiology (PE) is the study of uses and effects of drugs in well defined populations. As medico-administrative databases cover a large part of the population, they have become very interesting to carry PE studies. Such databases provide longitudinal care pathways in real condition containing timestamped care events, especially drug deliveries. Temporal pattern mining becomes a strategic choice to gain valuable insights about drug uses. In this paper we propose DCM, a new discriminant temporal pattern mining algorithm. It extracts chronicle patterns that occur more in a studied population than in a control population. We present results on the identification of possible associations between hospitalizations for seizure and anti-epileptic drug switches in care pathway of epileptic patients. version:1
arxiv-1709-03297 | Cellular Automaton Based Simulation of Large Pedestrian Facilities - A Case Study on the Staten Island Ferry Terminals | http://arxiv.org/abs/1709.03297 | id:1709.03297 author:Luca Crociani, Gregor Lämmel, H. Joon Park, Giuseppe Vizzari category:cs.MA cs.AI 68U20  published:2017-09-11 summary:Current metropolises largely depend on a functioning transport infrastructure and the increasing demand can only be satisfied by a well organized mass transit. One example for a crucial mass transit system is New York City's Staten Island Ferry, connecting the two boroughs of Staten Island and Manhattan with a regular passenger service. Today's demand already exceeds 2500 passengers for a single cycle during peek hours, and future projections suggest that it will further increase. One way to appraise how the system will cope with future demand is by simulation. This contribution proposes an integrated simulation approach to evaluate the system performance with respect to future demand. The simulation relies on a multiscale modeling approach where the terminal buildings are simulated by a microscopic and quantitatively valid cellular automata (CA) and the journeys of the ferries themselves are modeled by a mesoscopic queue simulation approach. Based on the simulation results recommendations with respect to the future demand are given. version:1
arxiv-1709-03270 | Expert Opinion Extraction from a Biomedical Database | http://arxiv.org/abs/1709.03270 | id:1709.03270 author:Ahmed Samet, Thomas Guyet, Benjamin Negrevergne, Tien-Tuan Dao, Tuan Nha Hoang, Marie-Christine Ho Ba Tho category:cs.AI cs.DB  published:2017-09-11 summary:In this paper, we tackle the problem of extracting frequent opinions from uncertain databases. We introduce the foundation of an opinion mining approach with the definition of pattern and support measure. The support measure is derived from the commitment definition. A new algorithm called OpMiner that extracts the set of frequent opinions modelled as a mass functions is detailed. Finally, we apply our approach on a real-world biomedical database that stores opinions of experts to evaluate the reliability level of biomedical data. Performance analysis showed a better quality patterns for our proposed model in comparison with literature-based methods. version:1
arxiv-1709-03267 | Mining relevant interval rules | http://arxiv.org/abs/1709.03267 | id:1709.03267 author:Thomas Guyet, René Quiniou, Véronique Masson category:cs.AI cs.DB  published:2017-09-11 summary:This article extends the method of Garriga et al. for mining relevant rules to numerical attributes by extracting interval-based pattern rules. We propose an algorithm that extracts such rules from numerical datasets using the interval-pattern approach from Kaytoue et al. This algorithm has been implemented and evaluated on real datasets. version:1
arxiv-1709-03265 | Secure and Trustable Distributed Aggregation based on Kademlia | http://arxiv.org/abs/1709.03265 | id:1709.03265 author:Stéphane Grumbach, Robert Riemann category:cs.CR cs.DC  published:2017-09-11 summary:Aggregation of values that need to be kept confidential while guaranteeing the robustness of the process and the correctness of the result is required in an increasing number of applications. We propose an aggregation algorithm, which supports a large spectrum of potential applications including complex voting protocols. It relies on the distributed hash table Kademlia, used in BitTorrent, for pseudonymous communication between randomly predetermined peers to ensure a high degree of confidentiality which does not solely relies on cryptography. The distribution of data and computation limits the potential for data breaches, and reduces the need for institutional trust. Experimental results confirm the complexity of O(n) for n peers allowing for large-scale applications. version:1
arxiv-1709-03264 | Report: Performance comparison between C2075 and P100 GPU cards using cosmological correlation functions | http://arxiv.org/abs/1709.03264 | id:1709.03264 author:Miguel Cárdenas-Montes, Iván Méndez-Jiménez, Juan José Rodríguez-Vázquez, José María Hernández Calama category:cs.PF astro-ph.IM cs.DC  published:2017-09-11 summary:In this report, some cosmological correlation functions are used to evaluate the differential performance between C2075 and P100 GPU cards. In the past, the correlation functions used in this work have been widely studied and exploited on some previous GPU architectures. The analysis of the performance indicates that a speedup in the range from 13 to 15 is achieved without any additional optimization process for the P100 card. version:1
arxiv-1709-03221 | Fairness Testing: Testing Software for Discrimination | http://arxiv.org/abs/1709.03221 | id:1709.03221 author:Sainyam Galhotra, Yuriy Brun, Alexandra Meliou category:cs.SE cs.AI cs.CY cs.DB cs.LG  published:2017-09-11 summary:This paper defines software fairness and discrimination and develops a testing-based method for measuring if and how much software discriminates, focusing on causality in discriminatory behavior. Evidence of software discrimination has been found in modern software systems that recommend criminal sentences, grant access to financial products, and determine who is allowed to participate in promotions. Our approach, Themis, generates efficient test suites to measure discrimination. Given a schema describing valid system inputs, Themis generates discrimination tests automatically and does not require an oracle. We evaluate Themis on 20 software systems, 12 of which come from prior work with explicit focus on avoiding discrimination. We find that (1) Themis is effective at discovering software discrimination, (2) state-of-the-art techniques for removing discrimination from algorithms fail in many situations, at times discriminating against as much as 98% of an input subdomain, (3) Themis optimizations are effective at producing efficient test suites for measuring discrimination, and (4) Themis is more efficient on systems that exhibit more discrimination. We thus demonstrate that fairness testing is a critical aspect of the software development cycle in domains with possible discrimination and provide initial tools for measuring software discrimination. version:1
arxiv-1709-03211 | A Nonparametric Motion Flow Model for Human Robot Cooperation | http://arxiv.org/abs/1709.03211 | id:1709.03211 author:Sungjoon Choi, Kyungjae Lee, H. Andy Park, Songhwai Oh category:cs.RO  published:2017-09-11 summary:In this paper, we present a novel nonparametric motion flow model that effectively describes a motion trajectory of a human and its application to human robot cooperation. To this end, motion flow similarity measure which considers both spatial and temporal properties of a trajectory is proposed by utilizing the mean and variance functions of a Gaussian process. We also present a human robot cooperation method using the proposed motion flow model. Given a set of interacting trajectories of two workers, the underlying reward function of cooperating behaviors is optimized by using the learned motion description as an input to the reward function where a stochastic trajectory optimization method is used to control a robot. The presented human robot cooperation method is compared with the state-of-the-art algorithm, which utilizes a mixture of interaction primitives (MIP), in terms of the RMS error between generated and target trajectories. While the proposed method shows comparable performance with the MIP when the full observation of human demonstrations is given, it shows superior performance with respect to given partial trajectory information. version:1
arxiv-1709-02500 | Super-speeds with Zero-RAM: Next Generation Large-Scale Optimization in Your Laptop! | http://arxiv.org/abs/1709.02500 | id:1709.02500 author:Mark Amo-Boateng category:cs.DC cs.CC cs.DS cs.PF math.OC  published:2017-09-08 summary:This article presents the novel breakthrough general purpose algorithm for large scale optimization problems. The novel algorithm is capable of achieving breakthrough speeds for very large-scale optimization on general purpose laptops and embedded systems. Application of the algorithm to the Griewank function was possible in up to 1 billion decision variables in double precision took only 64485 seconds (~18 hours) to solve, while consuming 7,630 MB (7.6 GB) or RAM on a single threaded laptop CPU. It shows that the algorithm is computationally and memory (space) linearly efficient, and can find the optimal or near-optimal solution in a fraction of the time and memory that many conventional algorithms require. It is envisaged that this will open up new possibilities of real-time large-scale problems on personal laptops and embedded systems. version:2
arxiv-1708-07290 | A Parallel Algorithm for Generating a Random Graph with a Prescribed Degree Sequence | http://arxiv.org/abs/1708.07290 | id:1708.07290 author:Hasanuzzaman Bhuiyan, Maleq Khan, Madhav Marathe category:cs.DC G.1.0; G.2.2; D.1.3  published:2017-08-24 summary:Random graphs (or networks) have gained a significant increase of interest due to its popularity in modeling and simulating many complex real-world systems. Degree sequence is one of the most important aspects of these systems. Random graphs with a given degree sequence can capture many characteristics like dependent edges and non-binomial degree distribution that are absent in many classical random graph models such as the Erd\H{o}s-R\'{e}nyi graph model. In addition, they have important applications in the uniform sampling of random graphs, counting the number of graphs having the same degree sequence, as well as in string theory, random matrix theory, and matching theory. In this paper, we present an OpenMP-based shared-memory parallel algorithm for generating a random graph with a prescribed degree sequence, which achieves a speedup of 20.5 with 32 cores. One of the steps in our parallel algorithm requires checking the Erd\H{o}s-Gallai characterization, i.e., whether there exists a graph obeying the given degree sequence, in parallel. This paper presents the first non-trivial parallel algorithm for checking the Erd\H{o}s-Gallai characterization, which achieves a speedup of 23 using 32 cores. version:2
arxiv-1709-03136 | Computational Machines in a Coexistence with Concrete Universals and Data Streams | http://arxiv.org/abs/1709.03136 | id:1709.03136 author:Vahid Moosavi category:cs.AI  published:2017-09-10 summary:We discuss that how the majority of traditional modeling approaches are following the idealism point of view in scientific modeling, which follow the set theoretical notions of models based on abstract universals. We show that while successful in many classical modeling domains, there are fundamental limits to the application of set theoretical models in dealing with complex systems with many potential aspects or properties depending on the perspectives. As an alternative to abstract universals, we propose a conceptual modeling framework based on concrete universals that can be interpreted as a category theoretical approach to modeling. We call this modeling framework pre-specific modeling. We further, discuss how a certain group of mathematical and computational methods, along with ever-growing data streams are able to operationalize the concept of pre-specific modeling. version:1
arxiv-1709-03133 | Location Privacy in Mobile Edge Clouds: A Chaff-based Approach | http://arxiv.org/abs/1709.03133 | id:1709.03133 author:Ting He, Ertugrul N. Ciftcioglu, Shiqiang Wang, Kevin S. Chan category:cs.DC  published:2017-09-10 summary:In this paper, we consider user location privacy in mobile edge clouds (MECs). MECs are small clouds deployed at the network edge to offer cloud services close to mobile users, and many solutions have been proposed to maximize service locality by migrating services to follow their users. Co-location of a user and his service, however, implies that a cyber eavesdropper observing service migrations between MECs can localize the user up to one MEC coverage area, which can be fairly small (e.g., a femtocell). We consider using chaff services to defend against such an eavesdropper, with focus on strategies to control the chaffs. Assuming the eavesdropper performs maximum likelihood (ML) detection, we consider both heuristic strategies that mimic the user's mobility and optimized strategies designed to minimize the detection or tracking accuracy. We show that a single chaff controlled by the optimal strategy or its online variation can drive the eavesdropper's tracking accuracy to zero when the user's mobility is sufficiently random. We further propose extended strategies that utilize randomization to defend against an advanced eavesdropper aware of the strategy. The efficacy of our solutions is verified through both synthetic and trace-driven simulations. version:1
arxiv-1709-03126 | Robust Emotion Recognition from Low Quality and Low Bit Rate Video: A Deep Learning Approach | http://arxiv.org/abs/1709.03126 | id:1709.03126 author:Bowen Cheng, Zhangyang Wang, Zhaobin Zhang, Zhu Li, Ding Liu, Jianchao Yang, Shuai Huang, Thomas S. Huang category:cs.CV cs.AI cs.LG  published:2017-09-10 summary:Emotion recognition from facial expressions is tremendously useful, especially when coupled with smart devices and wireless multimedia applications. However, the inadequate network bandwidth often limits the spatial resolution of the transmitted video, which will heavily degrade the recognition reliability. We develop a novel framework to achieve robust emotion recognition from low bit rate video. While video frames are downsampled at the encoder side, the decoder is embedded with a deep network model for joint super-resolution (SR) and recognition. Notably, we propose a novel max-mix training strategy, leading to a single "One-for-All" model that is remarkably robust to a vast range of downsampling factors. That makes our framework well adapted for the varied bandwidths in real transmission scenarios, without hampering scalability or efficiency. The proposed framework is evaluated on the AVEC 2016 benchmark, and demonstrates significantly improved stand-alone recognition performance, as well as rate-distortion (R-D) performance, than either directly recognizing from LR frames, or separating SR and recognition. version:1
arxiv-1709-03114 | Cognitive networks: brains, internet, and civilizations | http://arxiv.org/abs/1709.03114 | id:1709.03114 author:Dmitrii Yu. Manin, Yuri I. Manin category:cs.AI cs.SI physics.soc-ph q-bio.NC 68M10  62M45  97C30  published:2017-09-10 summary:In this short essay, we discuss some basic features of cognitive activity at several different space-time scales: from neural networks in the brain to civilizations. One motivation for such comparative study is its heuristic value. Attempts to better understand the functioning of "wetware" involved in cognitive activities of central nervous system by comparing it with a computing device have a long tradition. We suggest that comparison with Internet might be more adequate. We briefly touch upon such subjects as encoding, compression, and Saussurean trichotomy langue/langage/parole in various environments. version:1
arxiv-1709-03110 | G-thinker: Big Graph Mining Made Easier and Faster | http://arxiv.org/abs/1709.03110 | id:1709.03110 author:Da Yan, Hongzhi Chen, James Cheng, M. Tamer Özsu, Qizhen Zhang, John C. S. Lui category:cs.DC  published:2017-09-10 summary:This paper proposes a general system for compute-intensive graph mining tasks that find from a big graph all subgraphs that satisfy certain requirements (e.g., graph matching and community detection). Due to the broad range of applications of such tasks, many single-threaded algorithms have been proposed. However, graphs such as online social networks and knowledge graphs often have billions of vertices and edges, which require distributed processing in order to scale. Unfortunately, existing distributed graph processing systems such as Pregel and GraphLab are designed for data-intensive analytics, and are inefficient for compute-intensive graph mining tasks since computation over any data is coupled with the data's access that involves network transmission. We propose a distributed graph mining framework, called G-thinker, which is designed for compute-intensive graph mining workloads. G-thinker provides an intuitive graph-exploration API for the convenient implementation of various graph mining algorithms, and the runtime engine provides efficient execution with bounded memory consumption, light network communication, and parallelism between computation and communication. Extensive experiments were conducted, which demonstrate that G-thinker is orders of magnitude faster than existing solution, and can scale to graphs that are two orders of magnitude larger given the same hardware resources. version:1
arxiv-1709-03009 | How to Train a CAT: Learning Canonical Appearance Transformations for Robust Direct Localization Under Illumination Change | http://arxiv.org/abs/1709.03009 | id:1709.03009 author:Lee Clement, Jonathan Kelly category:cs.RO cs.CV  published:2017-09-09 summary:Direct visual localization has recently enjoyed a resurgence in popularity with the increasing availability of cheap mobile computing power. The competitive accuracy and robustness of these algorithms compared to state-of-the-art feature-based methods, as well as their natural ability to yield dense maps, makes them an appealing choice for a variety of mobile robotics applications. However, direct methods remain brittle in the face of appearance change due to their underlying assumption of photometric consistency, which is commonly violated in practice. In this paper, we propose to mitigate this problem by training deep convolutional encoder-decoder models to transform images of a scene such that they correspond to a chosen canonical appearance such as static diffuse illumination. We validate our method in multiple environments and illumination conditions using high-fidelity synthetic RGB-D datasets, and integrate the trained models into a direct visual localization pipeline, yielding improvements in visual odometry (VO) accuracy through time-varying illumination conditions, as well as improved relocalization performance under illumination change, where conventional methods normally fail. version:1
arxiv-1709-03008 | Identifying Irregular Power Usage by Turning Predictions into Holographic Spatial Visualizations | http://arxiv.org/abs/1709.03008 | id:1709.03008 author:Patrick Glauner, Niklas Dahringer, Oleksandr Puhachov, Jorge Augusto Meira, Petko Valtchev, Radu State, Diogo Duarte category:cs.LG cs.AI cs.HC  published:2017-09-09 summary:Power grids are critical infrastructure assets that face non-technical losses (NTL) such as electricity theft or faulty meters. NTL may range up to 40% of the total electricity distributed in emerging countries. Industrial NTL detection systems are still largely based on expert knowledge when deciding whether to carry out costly on-site inspections of customers. Electricity providers are reluctant to move to large-scale deployments of automated systems that learn NTL profiles from data due to the latter's propensity to suggest a large number of unnecessary inspections. In this paper, we propose a novel system that combines automated statistical decision making with expert knowledge. First, we propose a machine learning framework that classifies customers into NTL or non-NTL using a variety of features derived from the customers' consumption data. The methodology used is specifically tailored to the level of noise in the data. Second, in order to allow human experts to feed their knowledge in the decision loop, we propose a method for visualizing prediction results at various granularity levels in a spatial hologram. Our approach allows domain experts to put the classification results into the context of the data and to incorporate their knowledge for making the final decisions of which customers to inspect. This work has resulted in appreciable results on a real-world data set of 3.6M customers. Our system is being deployed in a commercial NTL detection software. version:1
arxiv-1709-02946 | Approximate Stream Analytics in Apache Flink and Apache Spark Streaming | http://arxiv.org/abs/1709.02946 | id:1709.02946 author:Do Le Quoc, Ruichuan Chen, Pramod Bhatotia, Christof Fetze, Volker Hilt, Thorsten Strufe category:cs.DC  published:2017-09-09 summary:Approximate computing aims for efficient execution of workflows where an approximate output is sufficient instead of the exact output. The idea behind approximate computing is to compute over a representative sample instead of the entire input dataset. Thus, approximate computing - based on the chosen sample size - can make a systematic trade-off between the output accuracy and computation efficiency. Unfortunately, the state-of-the-art systems for approximate computing primarily target batch analytics, where the input data remains unchanged during the course of sampling. Thus, they are not well-suited for stream analytics. This motivated the design of StreamApprox - a stream analytics system for approximate computing. To realize this idea, we designed an online stratified reservoir sampling algorithm to produce approximate output with rigorous error bounds. Importantly, our proposed algorithm is generic and can be applied to two prominent types of stream processing systems: (1) batched stream processing such as Apache Spark Streaming, and (2) pipelined stream processing such as Apache Flink. We evaluated StreamApprox using a set of microbenchmarks and real-world case studies. Our results show that Spark- and Flink-based StreamApprox systems achieve a speedup of $1.15\times$-$3\times$ compared to the respective native Spark Streaming and Flink executions, with varying sampling fraction of $80\%$ to $10\%$. Furthermore, we have also implemented an improved baseline in addition to the native execution baseline - a Spark-based approximate computing system leveraging the existing sampling modules in Apache Spark. Compared to the improved baseline, our results show that StreamApprox achieves a speedup $1.1\times$-$2.4\times$ while maintaining the same accuracy level. version:1
arxiv-1709-02938 | Hilbert's Space-filling Curve for Regions with Holes | http://arxiv.org/abs/1709.02938 | id:1709.02938 author:Siddharth H. Nair, Arpita Sinha, Leena Vachhani category:cs.RO  published:2017-09-09 summary:The paper presents a systematic strategy for implementing Hilbert's space filling curve for use in online exploration tasks and addresses its application in scenarios wherein the space to be searched obstacles (or holes) whose locations are not known a priori. Using the self-similarity and locality preserving properties of Hilbert's space filling curve, a set of evasive maneuvers are prescribed and characterized for online implementation. Application of these maneuvers in the case of non-uniform coverage of spaces and for obstacles of varying sizes is also presented. The results are validated with representative simulations demonstrating the deployment of the approach. version:1
arxiv-1709-02924 | Object Manipulation using Robotic Hands with Varying Degrees of Grasp Knowledge | http://arxiv.org/abs/1709.02924 | id:1709.02924 author:Wenceslao Shaw-Cortez, Denny Oetomo, Chris Manzie, Peter Choong category:cs.RO  published:2017-09-09 summary:In this paper, we propose a robust control framework for object manipulation for when the robotic hand has limited knowledge of the grasp scenario. The framework considers a hand-object system subject to disturbances resulting from uncertainties in the model of the hand-object system including object center of mass/inertia, hand kinematics, external wrenches, and contact locations. The proposed control provides semi-global asymptotic stability and exponential stability of the hand-object system with respect to object manipulation. The proposed framework is then applied to practical object manipulation scenarios with different levels of uncertainty related to the sensors available to the robotic hand. The analysis addresses the internal force control in relation to the various practical cases. Simulation and experimental results validate the effectiveness of the proposed approach. version:1
arxiv-1709-02885 | Network of Nano-Landers for In-Situ Characterization of Asteroid Impact Studies | http://arxiv.org/abs/1709.02885 | id:1709.02885 author:Himangshu Kalita, Erik Asphaug, Stephen Schwartz, Jekanthan Thangavelautham category:cs.RO  published:2017-09-09 summary:Exploration of asteroids and comets can give insight into the origins of the solar system and can be instrumental in planetary defence and in-situ resource utilization (ISRU). Asteroids, due to their low gravity are a challenging target for surface exploration. Current missions envision performing touch-and-go operations over an asteroid surface. In this work, we analyse the feasibility of sending scores of nano-landers, each 1 kg in mass and volume of 1U, or 1000 cm3. These landers would hop, roll and fly over the asteroid surface. The landers would include science instruments such as stereo cameras, hand-lens imagers and spectrometers to characterize rock composition. A network of nano-landers situated on the surface of an asteroid can provide unique and very detailed measurements of a spacecraft impacting onto an asteroid surface. A full-scale, artificial impact experiment onto an asteroid can help characterize its composition and geology and help in the development of asteroid deflection techniques intended for planetary defence. Scores of nano-landers could provide multiple complementary views of the impact, resultant seismic activity and trajectory of the ejecta. The nano-landers can analyse the pristine, unearthed regolith shielded from effects of UV and cosmic rays and that may be millions of years old. Our approach to formulating this mission concepts utilizes automated machine learning techniques in the planning and design of space systems. We use a form of Darwinian selection to select and identify suitable number of nano-landers, the on-board instruments and control system to explore and navigate the asteroid environment. Scenarios are generated in simulation and evaluated against quantifiable mission goals such as area explored on the asteroid and amount of data recorded from the impact event. version:1
arxiv-1709-02878 | TensorFlow Agents: Efficient Batched Reinforcement Learning in TensorFlow | http://arxiv.org/abs/1709.02878 | id:1709.02878 author:Danijar Hafner, James Davidson, Vincent Vanhoucke category:cs.LG cs.AI  published:2017-09-08 summary:We introduce TensorFlow Agents, an efficient infrastructure paradigm for building parallel reinforcement learning algorithms in TensorFlow. We simulate multiple environments in parallel, and group them to perform the neural network computation on a batch rather than individual observations. This allows the TensorFlow execution engine to parallelize computation, without the need for manual synchronization. Environments are stepped in separate Python processes to progress them in parallel without interference of the global interpreter lock. As part of this project, we introduce BatchPPO, an efficient implementation of the proximal policy optimization algorithm. By open sourcing TensorFlow Agents, we hope to provide a flexible starting point for future projects that accelerates future research in the field. version:1
arxiv-1709-02877 | Variable Annealing Length and Parallelism in Simulated Annealing | http://arxiv.org/abs/1709.02877 | id:1709.02877 author:Vincent A. Cicirello category:cs.NE cs.AI cs.DC  published:2017-09-08 summary:In this paper, we propose: (a) a restart schedule for an adaptive simulated annealer, and (b) parallel simulated annealing, with an adaptive and parameter-free annealing schedule. The foundation of our approach is the Modified Lam annealing schedule, which adaptively controls the temperature parameter to track a theoretically ideal rate of acceptance of neighboring states. A sequential implementation of Modified Lam simulated annealing is almost parameter-free. However, it requires prior knowledge of the annealing length. We eliminate this parameter using restarts, with an exponentially increasing schedule of annealing lengths. We then extend this restart schedule to parallel implementation, executing several Modified Lam simulated annealers in parallel, with varying initial annealing lengths, and our proposed parallel annealing length schedule. To validate our approach, we conduct experiments on an NP-Hard scheduling problem with sequence-dependent setup constraints. We compare our approach to fixed length restarts, both sequentially and in parallel. Our results show that our approach can achieve substantial performance gains, throughout the course of the run, demonstrating our approach to be an effective anytime algorithm. version:1
arxiv-1709-02865 | Prosocial learning agents solve generalized Stag Hunts better than selfish ones | http://arxiv.org/abs/1709.02865 | id:1709.02865 author:Alexander Peysakhovich, Adam Lerer category:cs.AI cs.GT  published:2017-09-08 summary:There is much interest in applying reinforcement learning methods to multi-agent systems. A popular way to do so is the method of reactive training -- ie. treating other agents as if they are a stationary part of the learner's environment. Dyads of such learners, if they converge, will converge to Nash equilibria of the game. However, there is an important game theoretic issue here: positive-sum games can have multiple equilibria which differ in their payoffs. We show that even in simple coordination games reactive reinforcement learning agents will often coordinate on equilibria with suboptimal payoffs for both agents. We also show that receiving utility from rewards other agents receive - ie. having prosocial preferences - leads agents to converging to better equilibria in a class of generalized Stag Hunt games. We show this analytically for matrix games and experimentally for more complex Markov versions. Importantly, this is true even if only one of the agents has social preferences. This implies that even if an agent designer only controls a single agent out of a dyad and only cares about their agent's payoff, it can still be better for the designer to make the agent prosocial rather than selfish. version:1
arxiv-1709-02844 | Uncertainty measurement with belief entropy on interference effect in Quantum-Like Bayesian Networks | http://arxiv.org/abs/1709.02844 | id:1709.02844 author:Zhiming Huang, Lin Yang, Wen Jiang category:cs.AI math.PR  published:2017-09-08 summary:Social dilemmas have been regarded as the essence of evolution game theory, in which the prisoner's dilemma game is the most famous metaphor for the problem of cooperation. Recent findings revealed people's behavior violated the Sure Thing Principle in such games. Classic probability methodologies have difficulty explaining the underlying mechanisms of people's behavior. In this paper, a novel quantum-like Bayesian Network was proposed to accommodate the paradoxical phenomenon. The special network can take interference into consideration, which is likely to be an efficient way to describe the underlying mechanism. With the assistance of belief entropy, named as Deng entropy, the paper proposes Belief Distance to render the model practical. Tested with empirical data, the proposed model is proved to be predictable and effective. version:1
arxiv-1709-02833 | Learning Robotic Manipulation of Granular Media | http://arxiv.org/abs/1709.02833 | id:1709.02833 author:Connor Schenck, Jonathan Tompson, Dieter Fox, Sergey Levine category:cs.RO  published:2017-09-08 summary:In this paper, we examine the problem of robotic manipulation of granular media. We evaluate multiple predictive models used to infer the dynamics of scooping and dumping actions. These models are evaluated on a task that involves manipulating the media in order to deform it into a desired shape. Our best performing model is based on a highly-tailored convolutional network architecture with domain-specific optimizations, which we show accurately models the physical interaction of the robotic scoop with the underlying media. We empirically demonstrate that explicitly predicting physical mechanics results in a policy that out-performs both a hand-crafted dynamics baseline, and a "value-network", which must otherwise implicitly predict the same mechanics in order to produce accurate value estimates. version:1
arxiv-1709-03879 | Ultimate Intelligence Part III: Measures of Intelligence, Perception and Intelligent Agents | http://arxiv.org/abs/1709.03879 | id:1709.03879 author:Eray Özkural category:cs.AI  published:2017-09-08 summary:We propose that operator induction serves as an adequate model of perception. We explain how to reduce universal agent models to operator induction. We propose a universal measure of operator induction fitness, and show how it can be used in a reinforcement learning model and a homeostasis (self-preserving) agent based on the free energy principle. We show that the action of the homeostasis agent can be explained by the operator induction model. version:1
arxiv-1709-03413 | Gigamachine: incremental machine learning on desktop computers | http://arxiv.org/abs/1709.03413 | id:1709.03413 author:Eray Özkural category:cs.AI cs.LG  published:2017-09-08 summary:We present a concrete design for Solomonoff's incremental machine learning system suitable for desktop computers. We use R5RS Scheme and its standard library with a few omissions as the reference machine. We introduce a Levin Search variant based on a stochastic Context Free Grammar together with new update algorithms that use the same grammar as a guiding probability distribution for incremental machine learning. The updates include adjusting production probabilities, re-using previous solutions, learning programming idioms and discovery of frequent subprograms. The issues of extending the a priori probability distribution and bootstrapping are discussed. We have implemented a good portion of the proposed algorithms. Experiments with toy problems show that the update algorithms work as expected. version:1
arxiv-1709-02779 | Machine learning \& artificial intelligence in the quantum domain | http://arxiv.org/abs/1709.02779 | id:1709.02779 author:Vedran Dunjko, Hans J. Briegel category:quant-ph cs.AI cs.CV  published:2017-09-08 summary:Quantum information technologies, and intelligent learning systems, are both emergent technologies that will likely have a transforming impact on our society. The respective underlying fields of research -- quantum information (QI) versus machine learning (ML) and artificial intelligence (AI) -- have their own specific challenges, which have hitherto been investigated largely independently. However, in a growing body of recent work, researchers have been probing the question to what extent these fields can learn and benefit from each other. QML explores the interaction between quantum computing and ML, investigating how results and techniques from one field can be used to solve the problems of the other. Recently, we have witnessed breakthroughs in both directions of influence. For instance, quantum computing is finding a vital application in providing speed-ups in ML, critical in our "big data" world. Conversely, ML already permeates cutting-edge technologies, and may become instrumental in advanced quantum technologies. Aside from quantum speed-up in data analysis, or classical ML optimization used in quantum experiments, quantum enhancements have also been demonstrated for interactive learning, highlighting the potential of quantum-enhanced learning agents. Finally, works exploring the use of AI for the very design of quantum experiments, and for performing parts of genuine research autonomously, have reported their first successes. Beyond the topics of mutual enhancement, researchers have also broached the fundamental issue of quantum generalizations of ML/AI concepts. This deals with questions of the very meaning of learning and intelligence in a world that is described by quantum mechanics. In this review, we describe the main ideas, recent developments, and progress in a broad spectrum of research investigating machine learning and artificial intelligence in the quantum domain. version:1
arxiv-1709-02758 | Autonomous Visual Rendering using Physical Motion | http://arxiv.org/abs/1709.02758 | id:1709.02758 author:Ahalya Prabhakar, Anastasia Mavrommati, Jarvis Schultz, Todd Murphey category:cs.RO  published:2017-09-08 summary:This paper addresses the problem of enabling a robot to represent and recreate visual information through physical motion, focusing on drawing using pens, brushes, or other tools. This work uses ergodicity as a control objective that translates planar visual input to physical motion without preprocessing (e.g., image processing, motion primitives). % or human-generated training data (i.e., machine learning). We achieve comparable results to existing drawing methods, while reducing the algorithmic complexity of the software. We demonstrate that optimal ergodic control algorithms with different time-horizon characteristics (infinitesimal, finite, and receding horizon) can generate qualitatively and stylistically different motions that render a wide range of visual information (e.g., letters, portraits, landscapes). In addition, we show that ergodic control enables the same software design to apply to multiple robotic systems by incorporating their particular dynamics, thereby reducing the dependence on task-specific robots. Finally, we demonstrate physical drawings with the Baxter robot. version:1
arxiv-1709-02718 | On-Disk Data Processing: Issues and Future Directions | http://arxiv.org/abs/1709.02718 | id:1709.02718 author:Mayank Mishra, Arun K. Somani category:cs.DC cs.PF  published:2017-09-08 summary:In this paper, we present a survey of "on-disk" data processing (ODDP). ODDP, which is a form of near-data processing, refers to the computing arrangement where the secondary storage drives have the data processing capability. Proposed ODDP schemes vary widely in terms of the data processing capability, target applications, architecture and the kind of storage drive employed. Some ODDP schemes provide only a specific but heavily used operation like sort whereas some provide a full range of operations. Recently, with the advent of Solid State Drives, powerful and extensive ODDP solutions have been proposed. In this paper, we present a thorough review of architectures developed for different on-disk processing approaches along with current and future challenges and also identify the future directions which ODDP can take. version:1
arxiv-1709-02642 | Object-Oriented Knowledge Extraction using Universal Exploiters | http://arxiv.org/abs/1709.02642 | id:1709.02642 author:Dmytro Terletskyi category:cs.AI F.4.1; D.1.5; D.3.3  published:2017-09-08 summary:This paper contains analysis and extension of exploiters-based knowledge extraction methods, which allow generation of new knowledge, based on the basic ones. The main achievement of the paper is useful features of some universal exploiters proof, which allow extending set of basic classes and set of basic relations by finite set of new classes of objects and relations among them, which allow creating of complete lattice. Proposed approach gives an opportunity to compute quantity of new classes, which can be generated using it, and quantity of different types, which each of obtained classes describes; constructing of defined hierarchy of classes with determined subsumption relation; avoidance of some problems of inheritance and more efficient restoring of basic knowledge within the database. version:1
arxiv-1709-02610 | Efficient Logging in Non-Volatile Memory by Exploiting Coherency Protocols | http://arxiv.org/abs/1709.02610 | id:1709.02610 author:Nachshon Cohen, Michal Friedman, James R. Larus category:cs.DC cs.DB cs.PL  published:2017-09-08 summary:Non-volatile memory (NVM) technologies such as PCM, ReRAM and STT-RAM allow processors to directly write values to persistent storage at speeds that are significantly faster than previous durable media such as hard drives or SSDs. Many applications of NVM are constructed on a logging subsystem, which enables operations to appear to execute atomically and facilitates recovery from failures. Writes to NVM, however, pass through a processor's memory system, which can delay and reorder them and can impair the correctness and cost of logging algorithms. Reordering arises because of out-of-order execution in a CPU and the inter-processor cache coherence protocol. By carefully considering the properties of these reorderings, this paper develops a logging protocol that requires only one round trip to non-volatile memory while avoiding expensive computations. We show how to extend the logging protocol to building a persistent set (hash map) that also requires only a single round trip to non-volatile memory for insertion, updating, or deletion. version:1
arxiv-1709-02600 | Objectness Scoring and Detection Proposals in Forward-Looking Sonar Images with Convolutional Neural Networks | http://arxiv.org/abs/1709.02600 | id:1709.02600 author:Matias Valdenegro-Toro category:cs.CV cs.RO  published:2017-09-08 summary:Forward-looking sonar can capture high resolution images of underwater scenes, but their interpretation is complex. Generic object detection in such images has not been solved, specially in cases of small and unknown objects. In comparison, detection proposal algorithms have produced top performing object detectors in real-world color images. In this work we develop a Convolutional Neural Network that can reliably score objectness of image windows in forward-looking sonar images and by thresholding objectness, we generate detection proposals. In our dataset of marine garbage objects, we obtain 94% recall, generating around 60 proposals per image. The biggest strength of our method is that it can generalize to previously unseen objects. We show this by detecting chain links, walls and a wrench without previous training in such objects. We strongly believe our method can be used for class-independent object detection, with many real-world applications such as chain following and mine detection. version:1
arxiv-1709-02599 | Fast Algorithm for Enumerating Diagonal Latin Squares of Small Order | http://arxiv.org/abs/1709.02599 | id:1709.02599 author:Stepan Kochemazov, Eduard Vatutin, Oleg Zaikin category:math.CO cs.DC cs.DM cs.DS  published:2017-09-08 summary:In this paper we propose an algorithm for enumerating diagonal Latin squares of small order. It relies on specific properties of diagonal Latin squares to employ symmetry breaking techniques, and on several heuristic optimizations and bit arithmetic techniques to make use of computational power of state-of-the-art CPUs. Using this approach we enumerated diagonal Latin squares of order at most 9, and vertically symmetric diagonal Latin squares of order at most 10. version:1
arxiv-1709-02589 | A geometric approach for learning compliant motions from demonstration | http://arxiv.org/abs/1709.02589 | id:1709.02589 author:Markku Suomalainen, Ville Kyrki category:cs.RO  published:2017-09-08 summary:This paper proposes a method to learn from human demonstration compliant contact motions, which take advantage of interaction forces between workpieces to align them, even when contact force may occur from different directions on different instances of reproduction. To manage the uncertainty in unstructured conditions, the motions learned with our method can be reproduced with an impedance controller. Learning from Demonstration is used because the planning of compliant motions in 3-D is computationally intractable. The proposed method will learn an individual compliant motion, many of which can be combined to solve more complex tasks. The method is based on measuring simultaneously the direction of motion and the forces acting on the end-effector. From these measurements we construct a set of constraints for motion directions which, with correct compliance, result in the observed motion. Constraints from multiple demonstrations are projected into a 2-D angular coordinate system where their intersection is determined to find a set of feasible desired directions, of which a single motion direction is chosen. The work is based on the assumption that movement in directions other than the desired direction is caused by interaction forces. Using this assumption, we infer the number of compliant axes and, if required, their directions. Experiments with a KUKA LWR4+ show that our method can successfully reproduce motions which require taking advantage of the environment. version:1
arxiv-1709-02561 | Formal Verification of Station Keeping Maneuvers for a Planar Autonomous Hybrid System | http://arxiv.org/abs/1709.02561 | id:1709.02561 author:Benjamin Martin, Khalil Ghorbal, Eric Goubault, Sylvie Putot category:cs.SY cs.RO  published:2017-09-08 summary:We formally verify a hybrid control law designed to perform a station keeping maneuver for a planar vehicle. Such maneuver requires that the vehicle reaches a neighborhood of its station in finite time and remains in it while waiting for further instructions. We model the dynamics as well as the control law as a hybrid program and formally verify both the reachability and safety properties involved. We highlight in particular the automated generation of invariant regions which turns out to be crucial in performing such verification. We use the theorem prover Keymaera X to discharge some of the generated proof obligations. version:1
arxiv-1709-02560 | Run-Time Risk Mitigation in Automated Vehicles: A Model for Studying Preparatory Steps | http://arxiv.org/abs/1709.02560 | id:1709.02560 author:Mario Gleirscher category:cs.SY cs.RO cs.SE  published:2017-09-08 summary:We assume that autonomous or highly automated driving (AD) will be accompanied by tough assurance obligations exceeding the requirements of even recent revisions of ISO 26262 or SOTIF. Hence, automotive control and safety engineers have to (i) comprehensively analyze the driving process and its control loop, (ii) identify relevant hazards stemming from this loop, (iii) establish feasible automated measures for the effective mitigation of these hazards or the alleviation of their consequences. By studying an example, this article investigates some achievements in the modeling for the steps (i), (ii), and (iii), amenable to formal verification of desired properties derived from potential assurance obligations such as the global existence of an effective mitigation strategy. In addition, the proposed approach is meant for step-wise refinement towards the automated synthesis of AD safety controllers implementing such properties. version:1
arxiv-1709-02555 | Causality-Aided Falsification | http://arxiv.org/abs/1709.02555 | id:1709.02555 author:Takumi Akazaki, Yoshihiro Kumazawa, Ichiro Hasuo category:cs.SY cs.AI cs.LG cs.LO  published:2017-09-08 summary:Falsification is drawing attention in quality assurance of heterogeneous systems whose complexities are beyond most verification techniques' scalability. In this paper we introduce the idea of causality aid in falsification: by providing a falsification solver -- that relies on stochastic optimization of a certain cost function -- with suitable causal information expressed by a Bayesian network, search for a falsifying input value can be efficient. Our experiment results show the idea's viability. version:1
arxiv-1709-02249 | Uncertainty-Aware Learning from Demonstration using Mixture Density Networks with Sampling-Free Variance Modeling | http://arxiv.org/abs/1709.02249 | id:1709.02249 author:Sungjoon Choi, Kyungjae Lee, Sungbin Lim, Songhwai Oh category:cs.CV cs.AI cs.RO  published:2017-09-03 summary:In this paper, we propose an uncertainty-aware learning from demonstration method by presenting a novel uncertainty estimation method utilizing a mixture density network appropriate for modeling complex and noisy human behaviors. The proposed uncertainty acquisition can be done with a single forward path without Monte Carlo sampling and is suitable for real-time robotics applications. The properties of the proposed uncertainty measure are analyzed through three different synthetic examples, absence of data, heavy measurement noise, and composition of functions scenarios. We show that each case can be distinguished using the proposed uncertainty measure and presented an uncertainty-aware learn- ing from demonstration method of an autonomous driving using this property. The proposed uncertainty-aware learning from demonstration method outperforms other compared methods in terms of safety using a complex real-world driving dataset. version:2
arxiv-1707-08860 | Approximations and Bounds for (n, k) Fork-Join Queues: A Linear Transformation Approach | http://arxiv.org/abs/1707.08860 | id:1707.08860 author:Huajin Wang, Jianhui Li, Zhihong Shen, Yuanchun Zhou category:cs.PF cs.DC cs.NI stat.AP  published:2017-07-27 summary:Compared to basic fork-join queues, a job in (n, k) fork-join queues only needs its k out of all n sub-tasks to be finished. Since (n, k) fork-join queues are prevalent in modern popular distributed systems such as Cassandra, MapReduce and Spark, estimating the sojourn time of such queues is critical for the performance measurement and resource plan of these systems. However, the estimating keeps to be a well-known open challenge for years, and only rough bounds for a partial range of load factors have been given. In this paper, we developed a close-form linear transformation technique for identical random variables: An order statistic can be represented by a linear combination of maxima. This brand-new technique is then used to transform the sojourn time of non-purging (n, k) fork-join queues into a linear combination of the sojourn times of basic (k, k)~(n, n) fork-join queues. Consequently, existing approximations for basic fork-join queues can be bridged to the approximations for non-purging (n, k) fork-join queues. The uncovered approximations are then used to improve the upper bounds for purging (n, k) fork-join queues. Simulation experiments show that this linear transformation approach is practiced well for moderate n and relatively large k. version:5
arxiv-1709-02533 | Adaptive Processing of Spatial-Keyword Data Over a Distributed Streaming Cluster | http://arxiv.org/abs/1709.02533 | id:1709.02533 author:Ahmed R. Mahmood, Anas Daghistani, Ahmed M. Aly, Walid G. Aref, Mingjie Tang, Saleh Basalamah, Sunil Prabhakar category:cs.DC  published:2017-09-08 summary:The widespread use of GPS-enabled smartphones along with the popularity of micro-blogging and social networking applications, e.g., Twitter and Facebook, has resulted in the generation of huge streams of geo-tagged textual data. Many applications require real-time processing of these streams. For example, location-based e-coupon and ad-targeting systems enable advertisers to register millions of ads to millions of users. The number of users is typically very high and they are continuously moving, and the ads change frequently as well. Hence sending the right ad to the matching users is very challenging. Existing streaming systems are either centralized or are not spatial-keyword aware, and cannot efficiently support the processing of rapidly arriving spatial-keyword data streams. This paper presents Tornado, a distributed spatial-keyword stream processing system. Tornado features routing units to fairly distribute the workload, and furthermore, co-locate the data objects and the corresponding queries at the same processing units. The routing units use the Augmented-Grid, a novel structure that is equipped with an efficient search algorithm for distributing the data objects and queries. Tornado uses evaluators to process the data objects against the queries. The routing units minimize the redundant communication by not sending data updates for processing when these updates do not match any query. By applying dynamically evaluated cost formulae that continuously represent the processing overhead at each evaluator, Tornado is adaptive to changes in the workload. Extensive experimental evaluation using spatio-textual range queries over real Twitter data indicates that Tornado outperforms the non-spatio-textually aware approaches by up to two orders of magnitude in terms of the overall system throughput. version:1
arxiv-1709-02520 | Sorting with GPUs: A Survey | http://arxiv.org/abs/1709.02520 | id:1709.02520 author:Dmitri I. Arkhipov, Di Wu, Keqin Li, Amelia C. Regan category:cs.DC  published:2017-09-08 summary:Sorting is a fundamental operation in computer science and is a bottleneck in many important fields. Sorting is critical to database applications, online search and indexing,biomedical computing, and many other applications. The explosive growth in computational power and availability of GPU coprocessors has allowed sort operations on GPUs to be done much faster than any equivalently priced CPU. Current trends in GPU computing shows that this explosive growth in GPU capabilities is likely to continue for some time. As such, there is a need to develop algorithms to effectively harness the power of GPUs for crucial applications such as sorting. version:1
arxiv-1610-08602 | A Review of 40 Years of Cognitive Architecture Research: Core Cognitive Abilities and Practical Applications | http://arxiv.org/abs/1610.08602 | id:1610.08602 author:Iuliia Kotseruba, John K. Tsotsos category:cs.AI  published:2016-10-27 summary:In this paper we present a broad overview of the last 40 years of research on cognitive architectures. Although the number of existing architectures is nearing several hundred, most of the existing surveys do not reflect this growth and focus on a handful of well-established architectures. Thus, in this survey we wanted to shift the focus towards a more inclusive and high-level overview of the research on cognitive architectures. Our final set of 85 architectures includes 49 that are still actively developed, and borrow from a diverse set of disciplines, spanning areas from psychoanalysis to neuroscience. To keep the length of this paper within reasonable limits we discuss only the core cognitive abilities, such as perception, attention mechanisms, action selection, memory, learning and reasoning. In order to assess the breadth of practical applications of cognitive architectures we gathered information on over 900 practical projects implemented using the cognitive architectures in our list. We use various visualization techniques to highlight overall trends in the development of the field. In addition to summarizing the current state-of-the-art in the cognitive architecture research, this survey describes a variety of methods and ideas that have been tried and their relative success in modeling human cognitive abilities, as well as which aspects of cognitive behavior need more research with respect to their mechanistic counterparts and thus can further inform how cognitive science might progress. version:2
arxiv-1709-02513 | Intelligent Subset Selection of Power Generators for Economic Dispatch | http://arxiv.org/abs/1709.02513 | id:1709.02513 author:Biswarup Bhattacharya, Abhishek Sinha category:cs.CE cs.AI  published:2017-09-08 summary:Sustainable and economical generation of electrical power is an essential and mandatory component of infrastructure in today's world. Optimal generation (generator subset selection) of power requires a careful evaluation of various factors like type of source, generation, transmission & storage capacities, congestion among others which makes this a difficult task. We created a grid to simulate various conditions including stimuli like generator supply, weather and load demand using Siemens PSS/E software and this data is trained using deep learning methods and subsequently tested. The results are highly encouraging. As per our knowledge, this is the first paper to propose a working and scalable deep learning model for this problem. version:1
arxiv-1709-02477 | Inferring Generative Model Structure with Static Analysis | http://arxiv.org/abs/1709.02477 | id:1709.02477 author:Paroma Varma, Bryan He, Payal Bajaj, Imon Banerjee, Nishith Khandwala, Daniel L. Rubin, Christopher Ré category:cs.LG cs.AI stat.ML  published:2017-09-07 summary:Obtaining enough labeled data to robustly train complex discriminative models is a major bottleneck in the machine learning pipeline. A popular solution is combining multiple sources of weak supervision using generative models. The structure of these models affects training label quality, but is difficult to learn without any ground truth labels. We instead rely on these weak supervision sources having some structure by virtue of being encoded programmatically. We present Coral, a paradigm that infers generative model structure by statically analyzing the code for these heuristics, thus reducing the data required to learn structure significantly. We prove that Coral's sample complexity scales quasilinearly with the number of heuristics and number of relations found, improving over the standard sample complexity, which is exponential in $n$ for identifying $n^{\textrm{th}}$ degree relations. Experimentally, Coral matches or outperforms traditional structure learning approaches by up to 3.81 F1 points. Using Coral to model dependencies instead of assuming independence results in better performance than a fully supervised model by 3.07 accuracy points when heuristics are used to label radiology data without ground truth labels. version:1
arxiv-1709-02456 | Attack-Aware Multi-Sensor Integration Algorithm for Autonomous Vehicle Navigation Systems | http://arxiv.org/abs/1709.02456 | id:1709.02456 author:Sangjun Lee, Yongbum Cho, Byung-Cheol Min category:math.OC cs.RO cs.SY  published:2017-09-07 summary:In this paper, we propose a fault detection and isolation based attack-aware multi-sensor integration algorithm for the detection of cyberattacks in autonomous vehicle navigation systems. The proposed algorithm uses an extended Kalman filter to construct robust residuals in the presence of noise, and then uses a parametric statistical tool to identify cyberattacks. The parametric statistical tool is based on the residuals constructed by the measurement history rather than one measurement at a time in the properties of discrete-time signals and dynamic systems. This approach allows the proposed multi-sensor integration algorithm to provide quick detection and low false alarm rates for applications in dynamic systems. An example of INS/GNSS integration of autonomous navigation systems is presented to validate the proposed algorithm by using a software-in-the-loop simulation. version:1
arxiv-1709-02435 | An Analysis of ISO 26262: Using Machine Learning Safely in Automotive Software | http://arxiv.org/abs/1709.02435 | id:1709.02435 author:Rick Salay, Rodrigo Queiroz, Krzysztof Czarnecki category:cs.AI cs.LG cs.SE cs.SY  published:2017-09-07 summary:Machine learning (ML) plays an ever-increasing role in advanced automotive functionality for driver assistance and autonomous operation; however, its adequacy from the perspective of safety certification remains controversial. In this paper, we analyze the impacts that the use of ML as an implementation approach has on ISO 26262 safety lifecycle and ask what could be done to address them. We then provide a set of recommendations on how to adapt the standard to accommodate ML. version:1
arxiv-1709-02425 | A Stochastic Approach to Shortcut Bridging in Programmable Matter | http://arxiv.org/abs/1709.02425 | id:1709.02425 author:Marta Andrés Arroyo, Sarah Cannon, Joshua J. Daymude, Dana Randall, Andréa W. Richa category:cs.DC  published:2017-09-07 summary:In a self-organizing particle system, an abstraction of programmable matter, simple computational elements called particles with limited memory and communication self-organize to solve system-wide problems of movement, coordination, and configuration. In this paper, we consider stochastic, distributed, local, asynchronous algorithms for "shortcut bridging", in which particles self-assemble bridges over gaps that simultaneously balance minimizing the length and cost of the bridge. Army ants of the genus Eciton have been observed exhibiting a similar behavior in their foraging trails, dynamically adjusting their bridges to satisfy an efficiency tradeoff using local interactions. Using techniques from Markov chain analysis, we rigorously analyze our algorithm, show it achieves a near-optimal balance between the competing factors of path length and bridge cost, and prove that it exhibits a dependence on the angle of the gap being "shortcut" similar to that of the ant bridges. We also present simulation results that qualitatively compare our algorithm with the army ant bridging behavior. Our work presents a plausible explanation of how convergence to globally optimal configurations can be achieved via local interactions by simple organisms (e.g., ants) with some limited computational power and access to random bits. The proposed algorithm demonstrates the robustness of the stochastic approach to algorithms for programmable matter, as it is a surprisingly simple extension of a stochastic algorithm for compression. version:1
arxiv-1709-02357 | Learning from lions: inferring the utility of agents from their trajectories | http://arxiv.org/abs/1709.02357 | id:1709.02357 author:Adam D. Cobb, Andrew Markham, Stephen J. Roberts category:cs.AI stat.AP stat.ML  published:2017-09-07 summary:We build a model using Gaussian processes to infer a spatio-temporal vector field from observed agent trajectories. Significant landmarks or influence points in agent surroundings are jointly derived through vector calculus operations that indicate presence of sources and sinks. We evaluate these influence points by using the Kullback-Leibler divergence between the posterior and prior Laplacian of the inferred spatio-temporal vector field. Through locating significant features that influence trajectories, our model aims to give greater insight into underlying causal utility functions that determine agent decision-making. A key feature of our model is that it infers a joint Gaussian process over the observed trajectories, the time-varying vector field of utility and canonical vector calculus operators. We apply our model to both synthetic data and lion GPS data collected at the Bubye Valley Conservancy in southern Zimbabwe. version:1
arxiv-1709-02349 | A Deep Reinforcement Learning Chatbot | http://arxiv.org/abs/1709.02349 | id:1709.02349 author:Iulian V. Serban, Chinnadhurai Sankar, Mathieu Germain, Saizheng Zhang, Zhouhan Lin, Sandeep Subramanian, Taesup Kim, Michael Pieper, Sarath Chandar, Nan Rosemary Ke, Sai Mudumba, Alexandre de Brebisson, Jose M. R. Sotelo, Dendi Suhubdy, Vincent Michalski, Alexandre Nguyen, Joelle Pineau, Yoshua Bengio category:cs.CL cs.AI cs.LG cs.NE stat.ML I.5.1; I.2.7  published:2017-09-07 summary:We present MILABOT: a deep reinforcement learning chatbot developed by the Montreal Institute for Learning Algorithms (MILA) for the Amazon Alexa Prize competition. MILABOT is capable of conversing with humans on popular small talk topics through both speech and text. The system consists of an ensemble of natural language generation and retrieval models, including template-based models, bag-of-words models, sequence-to-sequence neural network and latent variable neural network models. By applying reinforcement learning to crowdsourced data and real-world user interactions, the system has been trained to select an appropriate response from the models in its ensemble. The system has been evaluated through A/B testing with real-world users, where it performed significantly better than competing systems. Due to its machine learning architecture, the system is likely to improve with additional data. version:1
arxiv-1709-02327 | Feature selection in high-dimensional dataset using MapReduce | http://arxiv.org/abs/1709.02327 | id:1709.02327 author:Claudio Reggiani, Yann-Aël Le Borgne, Gianluca Bontempi category:cs.DC cs.LG stat.ML 68W15 D.1.3  published:2017-09-07 summary:This paper describes a distributed MapReduce implementation of the minimum Redundancy Maximum Relevance algorithm, a popular feature selection method in bioinformatics and network inference problems. The proposed approach handles both tall/narrow and wide/short datasets. We further provide an open source implementation based on Hadoop/Spark, and illustrate its scalability on datasets involving millions of observations or features. version:1
arxiv-1709-02316 | Fastron: An Online Learning-Based Model and Active Learning Strategy for Proxy Collision Detection | http://arxiv.org/abs/1709.02316 | id:1709.02316 author:Nikhil Das, Naman Gupta, Michael Yip category:cs.RO  published:2017-09-07 summary:We introduce the Fastron, a configuration space (C-space) model to be used as a proxy to kinematic-based collision detection. The Fastron allows iterative updates to account for a changing environment through a combination of a novel formulation of the kernel perceptron learning algorithm and an active learning strategy. Our simulations on a 7 degree-of-freedom arm indicate that proxy collision checks may be performed at least 2 times faster than an efficient polyhedral collision checker and at least 8 times faster than an efficient high-precision collision checker. The Fastron model provides conservative collision status predictions by padding C-space obstacles, and proxy collision checking time does not scale poorly as the number of workspace obstacles increases. All results were achieved without GPU acceleration or parallel computing. version:1
arxiv-1709-02296 | A Propagative Model of Simultaneous Impact: Existence, Uniqueness, and Design Consequences | http://arxiv.org/abs/1709.02296 | id:1709.02296 author:Vlad Seghete, Todd Murphey category:cs.RO  published:2017-09-07 summary:This paper presents existence and uniqueness results for a propagative model of simultaneous impacts that is guaranteed to conserve energy and momentum in the case of elastic impacts with extensions to perfectly plastic and inelastic impacts. A corresponding time-stepping algorithm that guarantees conservation of continuous energy and discrete momentum is developed, also with extensions to plastic and inelastic impacts. The model is illustrated in simulation using billiard balls and a two-dimensional legged robot as examples; the latter is optimized over geometry and gait parameters to achieve unique simultaneous impacts. version:1
arxiv-1709-02759 | Semantic Preserving Embeddings for Generalized Graphs | http://arxiv.org/abs/1709.02759 | id:1709.02759 author:Pedro Almagro-Blanco, Fernando Sancho-Caparrini category:cs.AI cs.LG 68T30 I.2.4; I.2.6  published:2017-09-07 summary:A new approach to the study of Generalized Graphs as semantic data structures using machine learning techniques is presented. We show how vector representations maintaining semantic characteristics of the original data can be obtained from a given graph using neural encoding architectures and considering the topological properties of the graph. Semantic features of these new representations are tested by using some machine learning tasks and new directions on efficient link discovery, entitity retrieval and long distance query methodologies on large relational datasets are investigated using real datasets. ---- En este trabajo se presenta un nuevo enfoque en el contexto del aprendizaje autom\'atico multi-relacional para el estudio de Grafos Generalizados. Se muestra c\'omo se pueden obtener representaciones vectoriales que mantienen caracter\'isticas sem\'anticas del grafo original utilizando codificadores neuronales y considerando las propiedades topol\'ogicas del grafo. Adem\'as, se eval\'uan las caracter\'isticas sem\'anticas capturadas por estas nuevas representaciones y se investigan nuevas metodolog\'ias eficientes relacionadas con Link Discovery, Entity Retrieval y consultas a larga distancia en grandes conjuntos de datos relacionales haciendo uso de bases de datos reales. version:1
arxiv-1709-02169 | Bayesian Optimisation for Safe Navigation under Localisation Uncertainty | http://arxiv.org/abs/1709.02169 | id:1709.02169 author:Rafael Oliveira, Lionel Ott, Vitor Guizilini, Fabio Ramos category:cs.RO cs.AI cs.LG  published:2017-09-07 summary:In outdoor environments, mobile robots are required to navigate through terrain with varying characteristics, some of which might significantly affect the integrity of the platform. Ideally, the robot should be able to identify areas that are safe for navigation based on its own percepts about the environment while avoiding damage to itself. Bayesian optimisation (BO) has been successfully applied to the task of learning a model of terrain traversability while guiding the robot through more traversable areas. An issue, however, is that localisation uncertainty can end up guiding the robot to unsafe areas and distort the model being learnt. In this paper, we address this problem and present a novel method that allows BO to consider localisation uncertainty by applying a Gaussian process model for uncertain inputs as a prior. We evaluate the proposed method in simulation and in experiments with a real robot navigating over rough terrain and compare it to standard BO methods which assume deterministic inputs. version:1
arxiv-1709-01532 | Interacting Attention-gated Recurrent Networks for Recommendation | http://arxiv.org/abs/1709.01532 | id:1709.01532 author:Wenjie Pei, Jie Yang, Zhu Sun, Jie Zhang, Alessandro Bozzon, David M. J. Tax category:cs.IR cs.AI cs.LG cs.SI  published:2017-09-05 summary:Capturing the temporal dynamics of user preferences over items is important for recommendation. Existing methods mainly assume that all time steps in user-item interaction history are equally relevant to recommendation, which however does not apply in real-world scenarios where user-item interactions can often happen accidentally. More importantly, they learn user and item dynamics separately, thus failing to capture their joint effects on user-item interactions. To better model user and item dynamics, we present the Interacting Attention-gated Recurrent Network (IARN) which adopts the attention model to measure the relevance of each time step. In particular, we propose a novel attention scheme to learn the attention scores of user and item history in an interacting way, thus to account for the dependencies between user and item dynamics in shaping user-item interactions. By doing so, IARN can selectively memorize different time steps of a user's history when predicting her preferences over different items. Our model can therefore provide meaningful interpretations for recommendation results, which could be further enhanced by auxiliary features. Extensive validation on real-world datasets shows that IARN consistently outperforms state-of-the-art methods. version:2
arxiv-1709-02153 | Real-time convolutional networks for sonar image classification in low-power embedded systems | http://arxiv.org/abs/1709.02153 | id:1709.02153 author:Matias Valdenegro-Toro category:cs.CV cs.RO  published:2017-09-07 summary:Deep Neural Networks have impressive classification performance, but this comes at the expense of significant computational resources at inference time. Autonomous Underwater Vehicles use low-power embedded systems for sonar image perception, and cannot execute large neural networks in real-time. We propose the use of max-pooling aggressively, and we demonstrate it with a Fire-based module and a new Tiny module that includes max-pooling in each module. By stacking them we build networks that achieve the same accuracy as bigger ones, while reducing the number of parameters and considerably increasing computational performance. Our networks can classify a 96x96 sonar image with 98.8 - 99.7 accuracy on only 41 to 61 milliseconds on a Raspberry Pi 2, which corresponds to speedups of 28.6 - 19.7. version:1
arxiv-1709-02150 | Improving Sonar Image Patch Matching via Deep Learning | http://arxiv.org/abs/1709.02150 | id:1709.02150 author:Matias Valdenegro-Toro category:cs.CV cs.RO  published:2017-09-07 summary:Matching sonar images with high accuracy has been a problem for a long time, as sonar images are inherently hard to model due to reflections, noise and viewpoint dependence. Autonomous Underwater Vehicles require good sonar image matching capabilities for tasks such as tracking, simultaneous localization and mapping (SLAM) and some cases of object detection/recognition. We propose the use of Convolutional Neural Networks (CNN) to learn a matching function that can be trained from labeled sonar data, after pre-processing to generate matching and non-matching pairs. In a dataset of 39K training pairs, we obtain 0.91 Area under the ROC Curve (AUC) for a CNN that outputs a binary classification matching decision, and 0.89 AUC for another CNN that outputs a matching score. In comparison, classical keypoint matching methods like SIFT, SURF, ORB and AKAZE obtain AUC 0.61 to 0.68. Alternative learning methods obtain similar results, with a Random Forest Classifier obtaining AUC 0.79, and a Support Vector Machine resulting in AUC 0.66. version:1
arxiv-1709-02128 | CNN for Very Fast Ground Segmentation in Velodyne LiDAR Data | http://arxiv.org/abs/1709.02128 | id:1709.02128 author:Martin Velas, Michal Spanel, Michal Hradis, Adam Herout category:cs.RO  published:2017-09-07 summary:This paper presents a novel method for ground segmentation in Velodyne point clouds. We propose an encoding of sparse 3D data from the Velodyne sensor suitable for training a convolutional neural network (CNN). This general purpose approach is used for segmentation of the sparse point cloud into ground and non-ground points. The LiDAR data are represented as a multi-channel 2D signal where the horizontal axis corresponds to the rotation angle and the vertical axis the indexes channels (i.e. laser beams). Multiple topologies of relatively shallow CNNs (i.e. 3-5 convolutional layers) are trained and evaluated using a manually annotated dataset we prepared. The results show significant improvement of performance over the state-of-the-art method by Zhang et al. in terms of speed and also minor improvements in terms of accuracy. version:1
arxiv-1709-02126 | Proceedings First Workshop on Formal Verification of Autonomous Vehicles | http://arxiv.org/abs/1709.02126 | id:1709.02126 author:Lukas Bulwahn, Maryam Kamali, Sven Linker category:cs.SY cs.AI  published:2017-09-07 summary:These are the proceedings of the workshop on Formal Verification of Autonomous Vehicles, held on September 19th, 2017 in Turin, Italy, as an affiliated workshop of the International Conference on integrated Formal Methods (iFM 2017). The workshop aim is to bring together researchers from the formal verification community that are developing formal methods for autonomous vehicles as well as researchers working, e.g., in the area of control theory or robotics, interested in applying verification techniques for designing and developing of autonomous vehicles. version:1
arxiv-1709-02125 | Beyond 16GB: Out-of-Core Stencil Computations | http://arxiv.org/abs/1709.02125 | id:1709.02125 author:Istvan Z Reguly, Gihan R Mudalige, Michael B Giles category:cs.DC  published:2017-09-07 summary:Stencil computations are a key class of applications, widely used in the scientific computing community, and a class that has particularly benefited from performance improvements on architectures with high memory bandwidth. Unfortunately, such architectures come with a limited amount of fast memory, which is limiting the size of the problems that can be efficiently solved. In this paper, we address this challenge by applying the well-known cache-blocking tiling technique to large scale stencil codes implemented using the OPS domain specific language, such as CloverLeaf 2D, CloverLeaf 3D, and OpenSBLI. We introduce a number of techniques and optimisations to help manage data resident in fast memory, and minimise data movement. Evaluating our work on Intel's Knights Landing Platform as well as NVIDIA P100 GPUs, we demonstrate that it is possible to solve 3 times larger problems than the on-chip memory size with at most 15\% loss in efficiency version:1
arxiv-1709-02108 | ParaPlan: A Tool for Parallel Reachability Analysis of Planar Polygonal Differential Inclusion Systems | http://arxiv.org/abs/1709.02108 | id:1709.02108 author:Andrei Sandler, Olga Tveretina category:cs.DC cs.PF  published:2017-09-07 summary:We present the ParaPlan tool which provides the reachability analysis of planar hybrid systems defined by differential inclusions (SPDI). It uses the parallelized and optimized version of the algorithm underlying the SPeeDI tool. The performance comparison demonstrates the speed-up of up to 83 times with respect to the sequential implementation on various benchmarks. Some of the benchmarks we used are randomly generated with the novel approach based on the partitioning of the plane with Voronoi diagrams. version:1
arxiv-1709-02066 | Formulation of Deep Reinforcement Learning Architecture Toward Autonomous Driving for On-Ramp Merge | http://arxiv.org/abs/1709.02066 | id:1709.02066 author:Pin Wang, Ching-Yao Chan category:cs.LG cs.AI  published:2017-09-07 summary:Multiple automakers have in development or in production automated driving systems (ADS) that offer freeway-pilot functions. This type of ADS is typically limited to restricted-access freeways only, that is, the transition from manual to automated modes takes place only after the ramp merging process is completed manually. One major challenge to extend the automation to ramp merging is that the automated vehicle needs to incorporate and optimize long-term objectives (e.g. successful and smooth merge) when near-term actions must be safely executed. Moreover, the merging process involves interactions with other vehicles whose behaviors are sometimes hard to predict but may influence the merging vehicle optimal actions. To tackle such a complicated control problem, we propose to apply Deep Reinforcement Learning (DRL) techniques for finding an optimal driving policy by maximizing the long-term reward in an interactive environment. Specifically, we apply a Long Short-Term Memory (LSTM) architecture to model the interactive environment, from which an internal state containing historical driving information is conveyed to a Deep Q-Network (DQN). The DQN is used to approximate the Q-function, which takes the internal state as input and generates Q-values as output for action selection. With this DRL architecture, the historical impact of interactive environment on the long-term reward can be captured and taken into account for deciding the optimal control policy. The proposed architecture has the potential to be extended and applied to other autonomous driving scenarios such as driving through a complex intersection or changing lanes under varying traffic flow conditions. version:1
arxiv-1709-02381 | A Non-volatile Near-Memory Read Mapping Accelerator | http://arxiv.org/abs/1709.02381 | id:1709.02381 author:S. Karen Khatamifard, Zamshed Chowdhury, Nakul Pande, Meisam Razaviyayn, Chris Kim, Ulya R. Karpuzcu category:cs.DC cs.AR  published:2017-09-07 summary:DNA sequencing entails the process of determining the precise physical order of the four bases (Adenine, Guanine, Cytosine, Thymine) in a DNA strand. As semiconductor technology revolutionized computing, DNA sequencing technology, termed often as Next Generation Sequencing (NGS), revolutionized genomic research. Modern NGS platforms can sequence millions of short DNA fragments in parallel. The resulting short DNA sequences are termed (short) reads. Mapping each read to a reference genome of the same species (which itself represents a full-fledged assembly of already sequenced reads), sequence mapping, is an emerging application. Sequence mapping enables detailed study of genetic variations, and thereby catalyzes personalized health care solutions. Due to the large scale of the problem, well-studied pair-wise sequence similarity detection (or sequence alignment) algorithms fall short of efficiently mapping individual reads to the reference genome. Mapping represents a search-heavy data-intensive operation and barely features any complex floating point arithmetic. Therefore, sequence mapping can greatly benefit from in- or near-memory search and processing. Fast parallel associative search enabled by Ternary Content Addressable Memory (TCAM) can particularly help, however CMOS-based TCAM implementations cannot accommodate the large memory footprint in an area and energy efficient manner, where non-volatile TCAM comes to rescue. Still, brute-force TCAM search over as large of a search space as sequence mapping demands consumes unacceptably high energy. This paper provides an effective solution to the energy problem to tap the potential of non-volatile TCAM for high-throughput, energy-efficient sequence mapping: BioCAM. BioCAM can improve the throughput of sequence mapping by 7.5x; the energy consumption, by 109.0x when compared to a highly-optimized software implementation for modern GPUs. version:1
arxiv-1709-01989 | Artificial Intelligence and Data Science in the Automotive Industry | http://arxiv.org/abs/1709.01989 | id:1709.01989 author:Martin Hofmann, Florian Neukart, Thomas Bäck category:cs.AI cs.CY  published:2017-09-06 summary:Data science and machine learning are the key technologies when it comes to the processes and products with automatic learning and optimization to be used in the automotive industry of the future. This article defines the terms "data science" (also referred to as "data analytics") and "machine learning" and how they are related. In addition, it defines the term "optimizing analytics" and illustrates the role of automatic optimization as a key technology in combination with data analytics. It also uses examples to explain the way that these technologies are currently being used in the automotive industry on the basis of the major subprocesses in the automotive value chain (development, procurement; logistics, production, marketing, sales and after-sales, connected customer). Since the industry is just starting to explore the broad range of potential uses for these technologies, visionary application examples are used to illustrate the revolutionary possibilities that they offer. Finally, the article demonstrates how these technologies can make the automotive industry more efficient and enhance its customer focus throughout all its operations and activities, extending from the product and its development process to the customers and their connection to the product. version:1
arxiv-1708-03800 | Energy saving for building heating via a simple and efficient model-free control design: First steps with computer simulations | http://arxiv.org/abs/1708.03800 | id:1708.03800 author:Hassane Abouaïssa, Ola Alhaj Hasan, Cédric Join, Michel Fliess, Didier Defer category:cs.SY cs.AI math.OC  published:2017-08-12 summary:The model-based control of building heating systems for energy saving encounters severe physical, mathematical and calibration difficulties in the numerous attempts that has been published until now. This topic is addressed here via a new model-free control setting, where the need of any mathematical description disappears. Several convincing computer simulations are presented. Comparisons with classic PI controllers and flatness-based predictive control are provided. version:2
arxiv-1709-01965 | Cost Modeling and Projection for Stacked Nanowire Fabric | http://arxiv.org/abs/1709.01965 | id:1709.01965 author:Naveen Kumar Macha, Mostafizur Rahman category:cs.ET cs.AR  published:2017-09-06 summary:To continue scaling beyond 2-D CMOS with 3-D integration, any new 3-D IC technology has to be comparable or better than 2-D CMOS in terms of scalability, enhanced functionality, density, power, performance, cost, and reliability. Transistor-level 3-D integration carries the most potential in this regard. Recently, we proposed a stacked horizontal nanowire based transistor-level 3-D integration approach, called SN3D [1][2] that solves scaling challenges and achieves tremendous benefits with respect to 2-D CMOS while keeping manageable thermal profile. In this paper, we present the cost analysis of SN3D and show comparison with 2-D CMOS (2D), conventional TSV based 3-D (T3D) and Monolithic 3-D integrations (M3D). In our cost model, we capture the implications of manufacturing, circuit density, interconnects, bonding and heat in determining die cost, and evaluate how cost scales as transistor count increases. Since SN3D is a new 3-D IC fabric, based on our proposed manufacturing pathway[1] we assumed complexity of fabrication steps as proportionality constants in our cost estimation model. Our analysis revealed 86%, 72% and 74% reduction in area; 55%, 43% and 43% reduction in interconnects distribution and total interconnect length for SN3D, which largely contributed to 70%, 67% and 68% reduction in cost in comparison to 2D, T3D and M3D respectively. version:1
arxiv-1709-01947 | Feedback Synthesis for Controllable Underactuated Systems using Sequential Second Order Actions | http://arxiv.org/abs/1709.01947 | id:1709.01947 author:Giorgos Mamakoukas, Malcolm A. MacIver, Todd D. Murphey category:math.OC cs.RO  published:2017-09-06 summary:This paper derives nonlinear feedback control synthesis for general control affine systems using second-order actions---the needle variations of optimal control---as the basis for choosing each control response to the current state. A second result of the paper is that the method provably exploits the nonlinear controllability of a system by virtue of an explicit dependence of the second-order needle variation on the Lie bracket between vector fields. As a result, each control decision necessarily decreases the objective when the system is nonlinearly controllable using first-order Lie brackets. Simulation results using a differential drive cart, an underactuated kinematic vehicle in three dimensions, and an underactuated dynamic model of an underwater vehicle demonstrate that the method finds control solutions when the first-order analysis is singular. Moreover, the simulated examples demonstrate superior convergence when compared to synthesis based on first-order needle variations. Lastly, the underactuated dynamic underwater vehicle model demonstrates the convergence even in the presence of a velocity field. version:1
arxiv-1709-01915 | Towards Neural Machine Translation with Latent Tree Attention | http://arxiv.org/abs/1709.01915 | id:1709.01915 author:James Bradbury, Richard Socher category:cs.CL cs.AI  published:2017-09-06 summary:Building models that take advantage of the hierarchical structure of language without a priori annotation is a longstanding goal in natural language processing. We introduce such a model for the task of machine translation, pairing a recurrent neural network grammar encoder with a novel attentional RNNG decoder and applying policy gradient reinforcement learning to induce unsupervised tree structures on both the source and target. When trained on character-level datasets with no explicit segmentation or parse annotation, the model learns a plausible segmentation and shallow parse, obtaining performance close to an attentional baseline. version:1
arxiv-1709-01887 | Measuring the Similarity of Sentential Arguments in Dialog | http://arxiv.org/abs/1709.01887 | id:1709.01887 author:Amita Misra, Brian Ecker, Marilyn A. Walker category:cs.CL cs.AI  published:2017-09-06 summary:When people converse about social or political topics, similar arguments are often paraphrased by different speakers, across many different conversations. Debate websites produce curated summaries of arguments on such topics; these summaries typically consist of lists of sentences that represent frequently paraphrased propositions, or labels capturing the essence of one particular aspect of an argument, e.g. Morality or Second Amendment. We call these frequently paraphrased propositions ARGUMENT FACETS. Like these curated sites, our goal is to induce and identify argument facets across multiple conversations, and produce summaries. However, we aim to do this automatically. We frame the problem as consisting of two steps: we first extract sentences that express an argument from raw social media dialogs, and then rank the extracted arguments in terms of their similarity to one another. Sets of similar arguments are used to represent argument facets. We show here that we can predict ARGUMENT FACET SIMILARITY with a correlation averaging 0.63 compared to a human topline averaging 0.68 over three debate topics, easily beating several reasonable baselines. version:1
arxiv-1709-01879 | Progress-Space Tradeoffs in Single-Writer Memory Implementations | http://arxiv.org/abs/1709.01879 | id:1709.01879 author:Damien Imbs, Petr Kuznetsov, Thibault Rieutord category:cs.DC C.2.4; F.1.1  published:2017-09-06 summary:Most algorithms designed for shared-memory distributed systems assume the single-writer multi-reader (SWMR) setting where each process is provided with a unique register readable by all. In a system where computation is performed by a bounded number n of processes coming from a very large (possibly unbounded) set of potential participants, the assumption of a SWMR memory is no longer reasonable. If only a bounded number of multi-writer multi-reader (MWMR) registers are provided, we cannot rely on an a priori assignment of processes to registers. In this setting, simulating SWMR memory, or equivalently, ensuring stable writing (i.e., every written value persists in the memory), is desirable. In this paper, we propose a SWMR simulation that adapts the number of MWMR registers used to the desired progress condition. For any given k from 1 to n, we present an algorithm that uses only n+k-1 registers to simulate a k-lock-free SWMR memory. We also give a matching lower bound of n+1 registers required for the case of 2-lock-freedom, which supports our conjectures that the algorithm is space-optimal. Our lower bound holds for the strictly weaker progress condition of 2-obstruction-freedom, which suggests that the space complexity for k-obstruction-free and k-lock-free SWMR simulations might coincide. version:1
arxiv-1604-05692 | Proving the Incompatibility of Efficiency and Strategyproofness via SMT Solving | http://arxiv.org/abs/1604.05692 | id:1604.05692 author:Florian Brandl, Felix Brandt, Manuel Eberl, Christian Geist category:cs.GT cs.AI cs.LO  published:2016-04-19 summary:Two important requirements when aggregating the preferences of multiple agents are that the outcome should be economically efficient and the aggregation mechanism should not be manipulable. In this paper, we provide a computer-aided proof of a sweeping impossibility using these two conditions for randomized aggregation mechanisms. More precisely, we show that every efficient aggregation mechanism can be manipulated for all expected utility representations of the agents' preferences. This settles an open problem and strengthens a number of existing theorems, including statements that were shown within the special domain of assignment. Our proof is obtained by formulating the claim as a satisfiability problem over predicates from real-valued arithmetic, which is then checked using an SMT (satisfiability modulo theories) solver. In order to verify the correctness of the result, a minimal unsatisfiable set of constraints returned by the SMT solver was translated back into a proof in higher-order logic, which was automatically verified by an interactive theorem prover. To the best of our knowledge, this is the first application of SMT solvers in computational social choice. version:4
arxiv-1709-01821 | SPECTRE: Supporting Consumption Policies in Window-Based Parallel Complex Event Processing | http://arxiv.org/abs/1709.01821 | id:1709.01821 author:Ruben Mayer, Ahmad Slo, Muhammad Adnan Tariq, Kurt Rothermel, Manuel Gräber, Umakishore Ramachandran category:cs.DC  published:2017-09-06 summary:Distributed Complex Event Processing (DCEP) is a paradigm to infer the occurrence of complex situations in the surrounding world from basic events like sensor readings. In doing so, DCEP operators detect event patterns on their incoming event streams. To yield high operator throughput, data parallelization frameworks divide the incoming event streams of an operator into overlapping windows that are processed in parallel by a number of operator instances. In doing so, the basic assumption is that the different windows can be processed independently from each other. However, consumption policies enforce that events can only be part of one pattern instance; then, they are consumed, i.e., removed from further pattern detection. That implies that the constituent events of a pattern instance detected in one window are excluded from all other windows as well, which breaks the data parallelism between different windows. In this paper, we tackle this problem by means of speculation: Based on the likelihood of an event's consumption in a window, subsequent windows may speculatively suppress that event. We propose the SPECTRE framework for speculative processing of multiple dependent windows in parallel. Our evaluations show an up to linear scalability of SPECTRE with the number of CPU cores. version:1
arxiv-1709-00821 | GPU-Accelerated Parallel Finite-Difference Time-Domain Method for Electromagnetic Waves Propagation in Unmagnetized Plasma Media | http://arxiv.org/abs/1709.00821 | id:1709.00821 author:Xi-min Wang, Lang-lang Xiong, Song Liu, Zhi-yun Peng, Shuang-ying Zhong category:physics.comp-ph cs.CE cs.DC  published:2017-09-04 summary:The finite-difference time-domain (FDTD) method has been commonly utilized in the numerical solution of electromagnetic (EM) waves propagation through the plasma media. However, the FDTD method may bring about a significant increment in additional run-times consuming for computationally large and complicated EM problems. Graphics Processing Unit (GPU) computing based on Compute Unified Device Architecture (CUDA) has grown in response to increased concern for reduction of run-times. We represent the CUDA-based FDTD method with the Runge-Kutta exponential time differencing scheme (RKETD) for the unmagnetized plasma implemented on GPU. In the paper, we derive the RKETD-FDTD formulation for the unmagnetized plasma comprehensively, and describe the detailed flowchart of CUDA-implemented RKETD-FDTD method on GPU. The accuracy and acceleration performance of the posed CUDA-based RKETD-FDTD method implemented on GPU are substantiated by the numerical experiment that simulates the EM waves traveling through the unmagnetized plasma slab, compared with merely CPU-based RKETD-FDTD method. The accuracy is validated by calculating the reflection and transmission coefficients for one-dimensional unmagnetized plasma slab. Comparison between the elapsed times of two methods proves that the GPU-based RKETD-FDTD method can acquire better application acceleration performance with sufficient accuracy. version:2
arxiv-1709-01921 | Distributed Deep Neural Networks over the Cloud, the Edge and End Devices | http://arxiv.org/abs/1709.01921 | id:1709.01921 author:Surat Teerapittayanon, Bradley McDanel, H. T. Kung category:cs.CV cs.DC  published:2017-09-06 summary:We propose distributed deep neural networks (DDNNs) over distributed computing hierarchies, consisting of the cloud, the edge (fog) and end devices. While being able to accommodate inference of a deep neural network (DNN) in the cloud, a DDNN also allows fast and localized inference using shallow portions of the neural network at the edge and end devices. When supported by a scalable distributed computing hierarchy, a DDNN can scale up in neural network size and scale out in geographical span. Due to its distributed nature, DDNNs enhance sensor fusion, system fault tolerance and data privacy for DNN applications. In implementing a DDNN, we map sections of a DNN onto a distributed computing hierarchy. By jointly training these sections, we minimize communication and resource usage for devices and maximize usefulness of extracted features which are utilized in the cloud. The resulting system has built-in support for automatic sensor fusion and fault tolerance. As a proof of concept, we show a DDNN can exploit geographical diversity of sensors to improve object recognition accuracy and reduce communication cost. In our experiment, compared with the traditional method of offloading raw sensor data to be processed in the cloud, DDNN locally processes most sensor data on end devices while achieving high accuracy and is able to reduce the communication cost by a factor of over 20x. version:1
arxiv-1709-01619 | A Comparative Study of 2D Numerical Methods with GPU Computing | http://arxiv.org/abs/1709.01619 | id:1709.01619 author:Ben J. Zimmerman, Jonathan D. Regele, Bong Wie category:cs.DC math.NA physics.comp-ph 68W15  published:2017-09-05 summary:Graphics Processing Unit (GPU) computing is becoming an alternate computing platform for numerical simulations. However, it is not clear which numerical scheme will provide the highest computational efficiency for different types of problems. To this end, numerical accuracies and computational work of several numerical methods are compared using a GPU computing implementation. The Correction Procedure via Reconstruction (CPR), Discontinuous Galerkin (DG), Nodal Discontinuous Galerkin (NDG), Spectral Difference (SD), and Finite Volume (FV) methods are investigated using various reconstruction orders. Both smooth and discontinuous cases are considered for two-dimensional simulations. For discontinuous problems, MUSCL schemes are employed with FV, while CPR, DG, NDG, and SD use slope limiting. The computation time to reach a set error criteria and total time to complete solutions are compared across the methods. It is shown that while FV methods can produce solutions with low computational times, they produce larger errors than high-order methods for smooth problems at the same order of accuracy. For discontinuous problems, the methods show good agreement with one another in terms of solution profiles, and the total computational times between FV, CPR, and SD are comparable. version:1
arxiv-1709-01613 | Machine Learning and Social Robotics for Detecting Early Signs of Dementia | http://arxiv.org/abs/1709.01613 | id:1709.01613 author:Patrik Jonell, Joseph Mendelson, Thomas Storskog, Goran Hagman, Per Ostberg, Iolanda Leite, Taras Kucherenko, Olga Mikheeva, Ulrika Akenine, Vesna Jelic, Alina Solomon, Jonas Beskow, Joakim Gustafson, Miia Kivipelto, Hedvig Kjellstrom category:cs.HC cs.AI cs.CY  published:2017-09-05 summary:This paper presents the EACare project, an ambitious multi-disciplinary collaboration with the aim to develop an embodied system, capable of carrying out neuropsychological tests to detect early signs of dementia, e.g., due to Alzheimer's disease. The system will use methods from Machine Learning and Social Robotics, and be trained with examples of recorded clinician-patient interactions. The interaction will be developed using a participatory design approach. We describe the scope and method of the project, and report on a first Wizard of Oz prototype. version:1
arxiv-1709-01610 | A second order primal-dual method for nonsmooth convex composite optimization | http://arxiv.org/abs/1709.01610 | id:1709.01610 author:Neil K. Dhingra, Sei Zhen Khong, Mihailo R. Jovanović category:math.OC cs.AI cs.SY nlin.AO  published:2017-09-05 summary:We develop a second order primal-dual method for optimization problems in which the objective function is given by the sum of a strongly convex twice differentiable term and a possibly nondifferentiable convex regularizer. After introducing an auxiliary variable, we utilize the proximal operator of the nonsmooth regularizer to transform the associated augmented Lagrangian into a function that is once, but not twice, continuously differentiable. The saddle point of this function corresponds to the solution of the original optimization problem. We employ a generalization of the Hessian to define second order updates on this function and prove global exponential stability of the corresponding differential inclusion. Furthermore, we develop a globally convergent customized algorithm that utilizes the primal-dual augmented Lagrangian as a merit function. We show that the search direction can be computed efficiently and prove quadratic/superlinear asymptotic convergence. We use the $\ell_1$-regularized least squares problem and the problem of designing a distributed controller for a spatially-invariant system to demonstrate the merits and the effectiveness of our method. version:1
arxiv-1709-01574 | Opening the Black Box of Financial AI with CLEAR-Trade: A CLass-Enhanced Attentive Response Approach for Explaining and Visualizing Deep Learning-Driven Stock Market Prediction | http://arxiv.org/abs/1709.01574 | id:1709.01574 author:Devinder Kumar, Graham W Taylor, Alexander Wong category:cs.AI cs.CV cs.NE  published:2017-09-05 summary:Deep learning has been shown to outperform traditional machine learning algorithms across a wide range of problem domains. However, current deep learning algorithms have been criticized as uninterpretable "black-boxes" which cannot explain their decision making processes. This is a major shortcoming that prevents the widespread application of deep learning to domains with regulatory processes such as finance. As such, industries such as finance have to rely on traditional models like decision trees that are much more interpretable but less effective than deep learning for complex problems. In this paper, we propose CLEAR-Trade, a novel financial AI visualization framework for deep learning-driven stock market prediction that mitigates the interpretability issue of deep learning methods. In particular, CLEAR-Trade provides a effective way to visualize and explain decisions made by deep stock market prediction models. We show the efficacy of CLEAR-Trade in enhancing the interpretability of stock market prediction by conducting experiments based on S&P 500 stock index prediction. The results demonstrate that CLEAR-Trade can provide significant insight into the decision-making process of deep learning-driven financial models, particularly for regulatory processes, thus improving their potential uptake in the financial industry. version:1
arxiv-1709-01568 | Model-Based Control Using Koopman Operators | http://arxiv.org/abs/1709.01568 | id:1709.01568 author:Ian Abraham, Gerardo De La Torre, Todd D. Murphey category:cs.RO math.OC  published:2017-09-05 summary:This paper explores the application of Koopman operator theory to the control of robotic systems. The operator is introduced as a method to generate data-driven models that have utility for model-based control methods. We then motivate the use of the Koopman operator towards augmenting model-based control. Specifically, we illustrate how the operator can be used to obtain a linearizable data-driven model for an unknown dynamical process that is useful for model-based control synthesis. Simulated results show that with increasing complexity in the choice of the basis functions, a closed-loop controller is able to invert and stabilize a cart- and VTOL-pendulum systems. Furthermore, the specification of the basis function are shown to be of importance when generating a Koopman operator for specific robotic systems. Experimental results with the Sphero SPRK robot explore the utility of the Koopman operator in a reduced state representation setting where increased complexity in the basis function improve open- and closed-loop controller performance in various terrains, including sand. version:1
