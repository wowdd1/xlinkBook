arxiv-7200-1 | Early Recognition of Human Activities from First-Person Videos Using Onset Representations | http://arxiv.org/abs/1406.5309 | author:M. S. Ryoo, Thomas J. Fuchs, Lu Xia, J. K. Aggarwal, Larry Matthies category:cs.CV published:2014-06-20 summary:In this paper, we propose a methodology for early recognition of humanactivities from videos taken with a first-person viewpoint. Early recognition,which is also known as activity prediction, is an ability to infer an ongoingactivity at its early stage. We present an algorithm to perform recognition ofactivities targeted at the camera from streaming videos, making the system topredict intended activities of the interacting person and avoid harmful eventsbefore they actually happen. We introduce the novel concept of 'onset' thatefficiently summarizes pre-activity observations, and design an approach toconsider event history in addition to ongoing video observation for earlyfirst-person recognition of activities. We propose to represent onset usingcascade histograms of time series gradients, and we describe a novelalgorithmic setup to take advantage of onset for early recognition ofactivities. The experimental results clearly illustrate that the proposedconcept of onset enables better/earlier recognition of human activities fromfirst-person videos.
arxiv-7200-2 | Identifiability of the Simplex Volume Minimization Criterion for Blind Hyperspectral Unmixing: The No Pure-Pixel Case | http://arxiv.org/abs/1406.5273 | author:Chia-Hsiang Lin, Wing-Kin Ma, Wei-Chiang Li, Chong-Yung Chi, ArulMurugan Ambikapathi category:stat.ML cs.IT math.IT math.OC published:2014-06-20 summary:In blind hyperspectral unmixing (HU), the pure-pixel assumption is well-knownto be powerful in enabling simple and effective blind HU solutions. However,the pure-pixel assumption is not always satisfied in an exact sense, especiallyfor scenarios where pixels are heavily mixed. In the no pure-pixel case, a goodblind HU approach to consider is the minimum volume enclosing simplex (MVES).Empirical experience has suggested that MVES algorithms can perform wellwithout pure pixels, although it was not totally clear why this is true from atheoretical viewpoint. This paper aims to address the latter issue. We developan analysis framework wherein the perfect endmember identifiability of MVES isstudied under the noiseless case. We prove that MVES is indeed robust againstlack of pure pixels, as long as the pixels do not get too heavily mixed and tooasymmetrically spread. The theoretical results are verified by numericalsimulations.
arxiv-7200-3 | Predicting the Future Behavior of a Time-Varying Probability Distribution | http://arxiv.org/abs/1406.5362 | author:Christoph H. Lampert category:stat.ML cs.LG published:2014-06-20 summary:We study the problem of predicting the future, though only in theprobabilistic sense of estimating a future state of a time-varying probabilitydistribution. This is not only an interesting academic problem, but solvingthis extrapolation problem also has many practical application, e.g. fortraining classifiers that have to operate under time-varying conditions. Ourmain contribution is a method for predicting the next step of the time-varyingdistribution from a given sequence of sample sets from earlier time steps. Forthis we rely on two recent machine learning techniques: embedding probabilitydistributions into a reproducing kernel Hilbert space, and learning operatorsby vector-valued regression. We illustrate the working principles and thepractical usefulness of our method by experiments on synthetic and real data.We also highlight an exemplary application: training a classifier in a domainadaptation setting without having access to examples from the test timedistribution at training time.
arxiv-7200-4 | Fast Edge Detection Using Structured Forests | http://arxiv.org/abs/1406.5549 | author:Piotr Dollár, C. Lawrence Zitnick category:cs.CV published:2014-06-20 summary:Edge detection is a critical component of many vision systems, includingobject detectors and image segmentation algorithms. Patches of edges exhibitwell-known forms of local structure, such as straight lines or T-junctions. Inthis paper we take advantage of the structure present in local image patches tolearn both an accurate and computationally efficient edge detector. Weformulate the problem of predicting local edge masks in a structured learningframework applied to random decision forests. Our novel approach to learningdecision trees robustly maps the structured labels to a discrete space on whichstandard information gain measures may be evaluated. The result is an approachthat obtains realtime performance that is orders of magnitude faster than manycompeting state-of-the-art approaches, while also achieving state-of-the-artedge detection results on the BSDS500 Segmentation dataset and NYU Depthdataset. Finally, we show the potential of our approach as a general purposeedge detector by showing our learned edge models generalize well acrossdatasets.
arxiv-7200-5 | Caffe: Convolutional Architecture for Fast Feature Embedding | http://arxiv.org/abs/1408.5093 | author:Yangqing Jia, Evan Shelhamer, Jeff Donahue, Sergey Karayev, Jonathan Long, Ross Girshick, Sergio Guadarrama, Trevor Darrell category:cs.CV cs.LG cs.NE published:2014-06-20 summary:Caffe provides multimedia scientists and practitioners with a clean andmodifiable framework for state-of-the-art deep learning algorithms and acollection of reference models. The framework is a BSD-licensed C++ librarywith Python and MATLAB bindings for training and deploying general-purposeconvolutional neural networks and other deep models efficiently on commodityarchitectures. Caffe fits industry and internet-scale media needs by CUDA GPUcomputation, processing over 40 million images a day on a single K40 or TitanGPU ($\approx$ 2.5 ms per image). By separating model representation fromactual implementation, Caffe allows experimentation and seamless switchingamong platforms for ease of development and deployment from prototypingmachines to cloud environments. Caffe is maintained and developed by theBerkeley Vision and Learning Center (BVLC) with the help of an active communityof contributors on GitHub. It powers ongoing research projects, large-scaleindustrial applications, and startup prototypes in vision, speech, andmultimedia.
arxiv-7200-6 | Generalized Dantzig Selector: Application to the k-support norm | http://arxiv.org/abs/1406.5291 | author:Soumyadeep Chatterjee, Sheng Chen, Arindam Banerjee category:stat.ML cs.LG published:2014-06-20 summary:We propose a Generalized Dantzig Selector (GDS) for linear models, in whichany norm encoding the parameter structure can be leveraged for estimation. Weinvestigate both computational and statistical aspects of the GDS. Based onconjugate proximal operator, a flexible inexact ADMM framework is designed forsolving GDS, and non-asymptotic high-probability bounds are established on theestimation error, which rely on Gaussian width of unit norm ball and suitableset encompassing estimation error. Further, we consider a non-trivial exampleof the GDS using $k$-support norm. We derive an efficient method to compute theproximal operator for $k$-support norm since existing methods are inapplicablein this setting. For statistical analysis, we provide upper bounds for theGaussian widths needed in the GDS analysis, yielding the first statisticalrecovery guarantee for estimation with the $k$-support norm. The experimentalresults confirm our theoretical analysis.
arxiv-7200-7 | Inferring the Why in Images | http://arxiv.org/abs/1406.5472 | author:Hamed Pirsiavash, Carl Vondrick, Antonio Torralba category:cs.CV published:2014-06-20 summary:Humans have the remarkable capability to infer the motivations of otherpeople's actions, likely due to cognitive skills known in psychophysics as thetheory of mind. In this paper, we strive to build a computational model thatpredicts the motivation behind the actions of people from images. To ourknowledge, this challenging problem has not yet been extensively explored incomputer vision. We present a novel learning based framework that useshigh-level visual recognition to infer why people are performing an actions inimages. However, the information in an image alone may not be sufficient toautomatically solve this task. Since humans can rely on their own experiencesto infer motivation, we propose to give computer vision systems access to someof these experiences by using recently developed natural language models tomine knowledge stored in massive amounts of text. While we are still far awayfrom automatically inferring motivation, our results suggest that transferringknowledge from language into vision can help machines understand why a personmight be performing an action in an image.
arxiv-7200-8 | A Primal-Dual Algorithmic Framework for Constrained Convex Minimization | http://arxiv.org/abs/1406.5403 | author:Quoc Tran-Dinh, Volkan Cevher category:math.OC stat.ML published:2014-06-20 summary:We present a primal-dual algorithmic framework to obtain approximatesolutions to a prototypical constrained convex optimization problem, andrigorously characterize how common structural assumptions affect the numericalefficiency. Our main analysis technique provides a fresh perspective onNesterov's excessive gap technique in a structured fashion and unifies it withsmoothing and primal-dual methods. For instance, through the choices of a dualsmoothing strategy and a center point, our framework subsumes decompositionalgorithms, augmented Lagrangian as well as the alternating directionmethod-of-multipliers methods as its special cases, and provides optimalconvergence rates on the primal objective residual as well as the primalfeasibility gap of the iterates for all.
arxiv-7200-9 | Noise-adaptive Margin-based Active Learning and Lower Bounds under Tsybakov Noise Condition | http://arxiv.org/abs/1406.5383 | author:Yining Wang, Aarti Singh category:stat.ML cs.LG published:2014-06-20 summary:We present a simple noise-robust margin-based active learning algorithm tofind homogeneous (passing the origin) linear separators and analyze its errorconvergence when labels are corrupted by noise. We show that when the imposednoise satisfies the Tsybakov low noise condition (Mammen, Tsybakov, and others1999; Tsybakov 2004) the algorithm is able to adapt to unknown level of noiseand achieves optimal statistical rate up to poly-logarithmic factors. We alsoderive lower bounds for margin based active learning algorithms under Tsybakovnoise conditions (TNC) for the membership query synthesis scenario (Angluin1988). Our result implies lower bounds for the stream based selective samplingscenario (Cohn 1990) under TNC for some fairly simple data distributions. Quitesurprisingly, we show that the sample complexity cannot be improved even if theunderlying data distribution is as simple as the uniform distribution on theunit ball. Our proof involves the construction of a well separated hypothesisset on the d-dimensional unit ball along with carefully designed labeldistributions for the Tsybakov noise condition. Our analysis might provideinsights for other forms of lower bounds as well.
arxiv-7200-10 | Rows vs Columns for Linear Systems of Equations - Randomized Kaczmarz or Coordinate Descent? | http://arxiv.org/abs/1406.5295 | author:Aaditya Ramdas category:math.OC cs.LG cs.NA math.NA stat.ML published:2014-06-20 summary:This paper is about randomized iterative algorithms for solving a linearsystem of equations $X \beta = y$ in different settings. Recent interest in thetopic was reignited when Strohmer and Vershynin (2009) proved the linearconvergence rate of a Randomized Kaczmarz (RK) algorithm that works on the rowsof $X$ (data points). Following that, Leventhal and Lewis (2010) proved thelinear convergence of a Randomized Coordinate Descent (RCD) algorithm thatworks on the columns of $X$ (features). The aim of this paper is to simplifyour understanding of these two algorithms, establish the direct relationshipsbetween them (though RK is often compared to Stochastic Gradient Descent), andexamine the algorithmic commonalities or tradeoffs involved with working onrows or columns. We also discuss Kernel Ridge Regression and present aKaczmarz-style algorithm that works on data points and having the advantage ofsolving the problem without ever storing or forming the Gram matrix, one of therecognized problems encountered when scaling kernelized methods.
arxiv-7200-11 | Enhancing Pure-Pixel Identification Performance via Preconditioning | http://arxiv.org/abs/1406.5286 | author:Nicolas Gillis, Wing-Kin Ma category:stat.ML cs.LG math.NA math.OC published:2014-06-20 summary:In this paper, we analyze different preconditionings designed to enhancerobustness of pure-pixel search algorithms, which are used for blindhyperspectral unmixing and which are equivalent to near-separable nonnegativematrix factorization algorithms. Our analysis focuses on the successiveprojection algorithm (SPA), a simple, efficient and provably robust algorithmin the pure-pixel algorithm class. Recently, a provably robust preconditioningwas proposed by Gillis and Vavasis (arXiv:1310.2273) which requires theresolution of a semidefinite program (SDP) to find a data points-enclosingminimum volume ellipsoid. Since solving the SDP in high precisions can be timeconsuming, we generalize the robustness analysis to approximate solutions ofthe SDP, that is, solutions whose objective function values are somemultiplicative factors away from the optimal value. It is shown that a highaccuracy solution is not crucial for robustness, which paves the way for fasterpreconditionings (e.g., based on first-order optimization methods). This firstcontribution also allows us to provide a robustness analysis for two otherpreconditionings. The first one is pre-whitening, which can be interpreted asan optimal solution of the same SDP with additional constraints. We analyzerobustness of pre-whitening which allows us to characterize situations in whichit performs competitively with the SDP-based preconditioning. The second one isbased on SPA itself and can be interpreted as an optimal solution of arelaxation of the SDP. It is extremely fast while competing with the SDP-basedpreconditioning on several synthetic data sets.
arxiv-7200-12 | Towards A Deeper Geometric, Analytic and Algorithmic Understanding of Margins | http://arxiv.org/abs/1406.5311 | author:Aaditya Ramdas, Javier Peña category:math.OC cs.AI cs.LG math.NA stat.ML published:2014-06-20 summary:Given a matrix $A$, a linear feasibility problem (of which linearclassification is a special case) aims to find a solution to a primal problem$w: A^Tw > \textbf{0}$ or a certificate for the dual problem which is aprobability distribution $p: Ap = \textbf{0}$. Inspired by the continuedimportance of "large-margin classifiers" in machine learning, this paperstudies a condition measure of $A$ called its \textit{margin} that determinesthe difficulty of both the above problems. To aid geometrical intuition, wefirst establish new characterizations of the margin in terms of relevant balls,cones and hulls. Our second contribution is analytical, where we presentgeneralizations of Gordan's theorem, and variants of Hoffman's theorems, bothusing margins. We end by proving some new results on a classical iterativescheme, the Perceptron, whose convergence rates famously depends on the margin.Our results are relevant for a deeper understanding of margin-based learningand proving convergence rates of iterative schemes, apart from providing aunifying perspective on this vast topic.
arxiv-7200-13 | Learning computationally efficient dictionaries and their implementation as fast transforms | http://arxiv.org/abs/1406.5388 | author:Luc Le Magoarou, Rémi Gribonval category:cs.LG published:2014-06-20 summary:Dictionary learning is a branch of signal processing and machine learningthat aims at finding a frame (called dictionary) in which some training dataadmits a sparse representation. The sparser the representation, the better thedictionary. The resulting dictionary is in general a dense matrix, and itsmanipulation can be computationally costly both at the learning stage and laterin the usage of this dictionary, for tasks such as sparse coding. Dictionarylearning is thus limited to relatively small-scale problems. In this paper,inspired by usual fast transforms, we consider a general dictionary structurethat allows cheaper manipulation, and propose an algorithm to learn suchdictionaries --and their fast implementation-- over training data. The approachis demonstrated experimentally with the factorization of the Hadamard matrixand with synthetic dictionary learning experiments.
arxiv-7200-14 | Inner Product Similarity Search using Compositional Codes | http://arxiv.org/abs/1406.4966 | author:Chao Du, Jingdong Wang category:cs.CV cs.LG stat.ML published:2014-06-19 summary:This paper addresses the nearest neighbor search problem under inner productsimilarity and introduces a compact code-based approach. The idea is toapproximate a vector using the composition of several elements selected from asource dictionary and to represent this vector by a short code composed of theindices of the selected elements. The inner product between a query vector anda database vector is efficiently estimated from the query vector and the shortcode of the database vector. We show the superior performance of the proposedgroup $M$-selection algorithm that selects $M$ elements from $M$ sourcedictionaries for vector approximation in terms of search accuracy andefficiency for compact codes of the same length via theoretical and empiricalanalysis. Experimental results on large-scale datasets ($1M$ and $1B$ SIFTfeatures, $1M$ linear models and Netflix) demonstrate the superiority of theproposed approach.
arxiv-7200-15 | Zipf's law holds for phrases, not words | http://arxiv.org/abs/1406.5181 | author:Jake Ryland Williams, Paul R. Lessard, Suma Desu, Eric Clark, James P. Bagrow, Christopher M. Danforth, Peter Sheridan Dodds category:cs.CL physics.soc-ph published:2014-06-19 summary:With Zipf's law being originally and most famously observed for wordfrequency, it is surprisingly limited in its applicability to human language,holding over no more than three to four orders of magnitude before hitting aclear break in scaling. Here, building on the simple observation that phrasesof one or more words comprise the most coherent units of meaning in language,we show empirically that Zipf's law for phrases extends over as many as nineorders of rank magnitude. In doing so, we develop a principled and scalablestatistical mechanical method of random text partitioning, which opens up arich frontier of rigorous text analysis via a rank ordering of mixed lengthphrases.
arxiv-7200-16 | The Sample Complexity of Learning Linear Predictors with the Squared Loss | http://arxiv.org/abs/1406.5143 | author:Ohad Shamir category:cs.LG stat.ML published:2014-06-19 summary:In this short note, we provide tight sample complexity bounds for learninglinear predictors with respect to the squared loss. Our focus is on an agnosticsetting, where no assumptions are made on the data distribution. This contrastswith standard results in the literature, which either make distributionalassumptions, refer to specific parameter settings, or use other performancemeasures.
arxiv-7200-17 | Brain-like associative learning using a nanoscale non-volatile phase change synaptic device array | http://arxiv.org/abs/1406.4951 | author:Sukru Burc Eryilmaz, Duygu Kuzum, Rakesh Jeyasingh, SangBum Kim, Matthew BrightSky, Chung Lam, H. -S. Philip Wong category:cs.NE cs.LG published:2014-06-19 summary:Recent advances in neuroscience together with nanoscale electronic devicetechnology have resulted in huge interests in realizing brain-like computinghardwares using emerging nanoscale memory devices as synaptic elements.Although there has been experimental work that demonstrated the operation ofnanoscale synaptic element at the single device level, network level studieshave been limited to simulations. In this work, we demonstrate, usingexperiments, array level associative learning using phase change synapticdevices connected in a grid like configuration similar to the organization ofthe biological brain. Implementing Hebbian learning with phase change memorycells, the synaptic grid was able to store presented patterns and recallmissing patterns in an associative brain-like fashion. We found that the systemis robust to device variations, and large variations in cell resistance statescan be accommodated by increasing the number of training epochs. We illustratedthe tradeoff between variation tolerance of the network and the overall energyconsumption, and found that energy consumption is decreased significantly forlower variation tolerance.
arxiv-7200-18 | Fast Support Vector Machines Using Parallel Adaptive Shrinking on Distributed Systems | http://arxiv.org/abs/1406.5161 | author:Jeyanthi Narasimhan, Abhinav Vishnu, Lawrence Holder, Adolfy Hoisie category:cs.DC cs.LG published:2014-06-19 summary:Support Vector Machines (SVM), a popular machine learning technique, has beenapplied to a wide range of domains such as science, finance, and socialnetworks for supervised learning. Whether it is identifying high-risk patientsby health-care professionals, or potential high-school students to enroll incollege by school districts, SVMs can play a major role for social good. Thispaper undertakes the challenge of designing a scalable parallel SVM trainingalgorithm for large scale systems, which includes commodity multi-coremachines, tightly connected supercomputers and cloud computing systems.Intuitive techniques for improving the time-space complexity including adaptiveelimination of samples for faster convergence and sparse format representationare proposed. Under sample elimination, several heuristics for {\em earliestpossible} to {\em lazy} elimination of non-contributing samples are proposed.In several cases, where an early sample elimination might result in a falsepositive, low overhead mechanisms for reconstruction of key data structures areproposed. The algorithm and heuristics are implemented and evaluated on variouspublicly available datasets. Empirical evaluation shows up to 26x speedimprovement on some datasets against the sequential baseline, when evaluated onmultiple compute nodes, and an improvement in execution time up to 30-60\% isreadily observed on a number of other datasets against our parallel baseline.
arxiv-7200-19 | Why are images smooth? | http://arxiv.org/abs/1406.5035 | author:Uriel Feige category:cs.CV published:2014-06-19 summary:It is a well observed phenomenon that natural images are smooth, in the sensethat nearby pixels tend to have similar values. We describe a mathematicalmodel of images that makes no assumptions on the nature of the environment thatimages depict. It only assumes that images can be taken at different scales(zoom levels). We provide quantitative bounds on the smoothness of a typicalimage in our model, as a function of the number of available scales. Thesebounds can serve as a baseline against which to compare the observed smoothnessof natural images.
arxiv-7200-20 | R-CNNs for Pose Estimation and Action Detection | http://arxiv.org/abs/1406.5212 | author:Georgia Gkioxari, Bharath Hariharan, Ross Girshick, Jitendra Malik category:cs.CV published:2014-06-19 summary:We present convolutional neural networks for the tasks of keypoint (pose)prediction and action classification of people in unconstrained images. Ourapproach involves training an R-CNN detector with loss functions depending onthe task being tackled. We evaluate our method on the challenging PASCAL VOCdataset and compare it to previous leading approaches. Our method givesstate-of-the-art results for keypoint and action prediction. Additionally, weintroduce a new dataset for action detection, the task of simultaneouslylocalizing people and classifying their actions, and present results using ourapproach.
arxiv-7200-21 | Inferring causal structure: a quantum advantage | http://arxiv.org/abs/1406.5036 | author:Katja Ried, Megan Agnew, Lydia Vermeyden, Dominik Janzing, Robert W. Spekkens, Kevin J. Resch category:quant-ph cs.LG gr-qc stat.ML published:2014-06-19 summary:The problem of using observed correlations to infer causal relations isrelevant to a wide variety of scientific disciplines. Yet given correlationsbetween just two classical variables, it is impossible to determine whetherthey arose from a causal influence of one on the other or a common causeinfluencing both, unless one can implement a randomized intervention. We hereconsider the problem of causal inference for quantum variables. We introducecausal tomography, which unifies and generalizes conventional quantumtomography schemes to provide a complete solution to the causal inferenceproblem using a quantum analogue of a randomized trial. We furthermore showthat, in contrast to the classical case, observed quantum correlations alonecan sometimes provide a solution. We implement a quantum-optical experimentthat allows us to control the causal relation between two optical modes, andtwo measurement schemes -- one with and one without randomization -- thatextract this relation from the observed correlations. Our results show thatentanglement and coherence, known to be central to quantum informationprocessing, also provide a quantum advantage for causal inference.
arxiv-7200-22 | Robust Outlier Detection Technique in Data Mining: A Univariate Approach | http://arxiv.org/abs/1406.5074 | author:Singh Vijendra, Pathak Shivani category:cs.CV published:2014-06-19 summary:Outliers are the points which are different from or inconsistent with therest of the data. They can be novel, new, abnormal, unusual or noisyinformation. Outliers are sometimes more interesting than the majority of thedata. The main challenges of outlier detection with the increasing complexity,size and variety of datasets, are how to catch similar outliers as a group, andhow to evaluate the outliers. This paper describes an approach which usesUnivariate outlier detection as a pre-processing step to detect the outlier andthen applies K-means algorithm hence to analyse the effects of the outliers onthe cluster analysis of dataset.
arxiv-7200-23 | MRF-based Background Initialisation for Improved Foreground Detection in Cluttered Surveillance Videos | http://arxiv.org/abs/1406.5095 | author:Vikas Reddy, Conrad Sanderson, Andres Sanin, Brian C. Lovell category:cs.CV published:2014-06-19 summary:Robust foreground object segmentation via background modelling is a difficultproblem in cluttered environments, where obtaining a clear view of thebackground to model is almost impossible. In this paper, we propose a methodcapable of robustly estimating the background and detecting regions of interestin such environments. In particular, we propose to extend the backgroundinitialisation component of a recent patch-based foreground detection algorithmwith an elaborate technique based on Markov Random Fields, where the optimallabelling solution is computed using iterated conditional modes. Rather thanrelying purely on local temporal statistics, the proposed technique takes intoaccount the spatial continuity of the entire background. Experiments withseveral tracking algorithms on the CAVIAR dataset indicate that the proposedmethod leads to considerable improvements in object tracking accuracy, whencompared to methods based on Gaussian mixture models and feature histograms.
arxiv-7200-24 | Divide-and-Conquer with Sequential Monte Carlo | http://arxiv.org/abs/1406.4993 | author:Fredrik Lindsten, Adam M. Johansen, Christian A. Naesseth, Bonnie Kirkpatrick, Thomas B. Schön, John Aston, Alexandre Bouchard-Côté category:stat.CO stat.ML published:2014-06-19 summary:We propose a novel class of Sequential Monte Carlo (SMC) algorithms,appropriate for inference in probabilistic graphical models. This class ofalgorithms adopts a divide-and-conquer approach based upon an auxiliarytree-structured decomposition of the model of interest, turning the overallinferential task into a collection of recursively solved sub-problems. Theproposed method is applicable to a broad class of probabilistic graphicalmodels, including models with loops. Unlike a standard SMC sampler, theproposed Divide-and-Conquer SMC employs multiple independent populations ofweighted particles, which are resampled, merged, and propagated as the methodprogresses. We illustrate empirically that this approach can outperformstandard methods in terms of the accuracy of the posterior expectation andmarginal likelihood approximations. Divide-and-Conquer SMC also opens up novelparallel implementation options and the possibility of concentrating thecomputational effort on the most challenging sub-problems. We demonstrate itsperformance on a Markov random field and on a hierarchical logistic regressionproblem.
arxiv-7200-25 | Primitives for Dynamic Big Model Parallelism | http://arxiv.org/abs/1406.4580 | author:Seunghak Lee, Jin Kyu Kim, Xun Zheng, Qirong Ho, Garth A. Gibson, Eric P. Xing category:stat.ML cs.DC cs.LG published:2014-06-18 summary:When training large machine learning models with many variables orparameters, a single machine is often inadequate since the model may be toolarge to fit in memory, while training can take a long time even withstochastic updates. A natural recourse is to turn to distributed clustercomputing, in order to harness additional memory and processors. However,naive, unstructured parallelization of ML algorithms can make inefficient useof distributed memory, while failing to obtain proportional convergencespeedups - or can even result in divergence. We develop a framework ofprimitives for dynamic model-parallelism, STRADS, in order to explorepartitioning and update scheduling of model variables in distributed MLalgorithms - thus improving their memory efficiency while presenting newopportunities to speed up convergence without compromising inferencecorrectness. We demonstrate the efficacy of model-parallel algorithmsimplemented in STRADS versus popular implementations for Topic Modeling, MatrixFactorization and Lasso.
arxiv-7200-26 | A Sober Look at Spectral Learning | http://arxiv.org/abs/1406.4631 | author:Han Zhao, Pascal Poupart category:cs.LG published:2014-06-18 summary:Spectral learning recently generated lots of excitement in machine learning,largely because it is the first known method to produce consistent estimates(under suitable conditions) for several latent variable models. In contrast,maximum likelihood estimates may get trapped in local optima due to thenon-convex nature of the likelihood function of latent variable models. In thispaper, we do an empirical evaluation of spectral learning (SL) and expectationmaximization (EM), which reveals an important gap between the theory and thepractice. First, SL often leads to negative probabilities. Second, EM oftenyields better estimates than spectral learning and it does not seem to getstuck in local optima. We discuss how the rank of the model parameters and theamount of training data can yield negative probabilities. We also question thecommon belief that maximum likelihood estimators are necessarily inconsistent.
arxiv-7200-27 | Spatial Pyramid Pooling in Deep Convolutional Networks for Visual Recognition | http://arxiv.org/abs/1406.4729 | author:Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun category:cs.CV published:2014-06-18 summary:Existing deep convolutional neural networks (CNNs) require a fixed-size(e.g., 224x224) input image. This requirement is "artificial" and may reducethe recognition accuracy for the images or sub-images of an arbitrarysize/scale. In this work, we equip the networks with another pooling strategy,"spatial pyramid pooling", to eliminate the above requirement. The new networkstructure, called SPP-net, can generate a fixed-length representationregardless of image size/scale. Pyramid pooling is also robust to objectdeformations. With these advantages, SPP-net should in general improve allCNN-based image classification methods. On the ImageNet 2012 dataset, wedemonstrate that SPP-net boosts the accuracy of a variety of CNN architecturesdespite their different designs. On the Pascal VOC 2007 and Caltech101datasets, SPP-net achieves state-of-the-art classification results using asingle full-image representation and no fine-tuning. The power of SPP-net is also significant in object detection. Using SPP-net,we compute the feature maps from the entire image only once, and then poolfeatures in arbitrary regions (sub-images) to generate fixed-lengthrepresentations for training the detectors. This method avoids repeatedlycomputing the convolutional features. In processing test images, our method is24-102x faster than the R-CNN method, while achieving better or comparableaccuracy on Pascal VOC 2007. In ImageNet Large Scale Visual Recognition Challenge (ILSVRC) 2014, ourmethods rank #2 in object detection and #3 in image classification among all 38teams. This manuscript also introduces the improvement made for thiscompetition.
arxiv-7200-28 | A Generalized Markov-Chain Modelling Approach to $(1,λ)$-ES Linear Optimization: Technical Report | http://arxiv.org/abs/1406.4619 | author:Alexandre Chotard, Martin Holena category:cs.NA cs.LG cs.NE published:2014-06-18 summary:Several recent publications investigated Markov-chain modelling of linearoptimization by a $(1,\lambda)$-ES, considering both unconstrained and linearlyconstrained optimization, and both constant and varying step size. All of themassume normality of the involved random steps, and while this is consistentwith a black-box scenario, information on the function to be optimized (e.g.separability) may be exploited by the use of another distribution. Theobjective of our contribution is to complement previous studies realized withnormal steps, and to give sufficient conditions on the distribution of therandom steps for the success of a constant step-size $(1,\lambda)$-ES on thesimple problem of a linear function with a linear constraint. The decompositionof a multidimensional distribution into its marginals and the copula combiningthem is applied to the new distributional assumptions, particular attentionbeing paid to distributions with Archimedean copulas.
arxiv-7200-29 | An Entropy Search Portfolio for Bayesian Optimization | http://arxiv.org/abs/1406.4625 | author:Bobak Shahriari, Ziyu Wang, Matthew W. Hoffman, Alexandre Bouchard-Côté, Nando de Freitas category:stat.ML cs.LG published:2014-06-18 summary:Bayesian optimization is a sample-efficient method for black-box globaloptimization. How- ever, the performance of a Bayesian optimization method verymuch depends on its exploration strategy, i.e. the choice of acquisitionfunction, and it is not clear a priori which choice will result in superiorperformance. While portfolio methods provide an effective, principled way ofcombining a collection of acquisition functions, they are often based onmeasures of past performance which can be misleading. To address this issue, weintroduce the Entropy Search Portfolio (ESP): a novel approach to portfolioconstruction which is motivated by information theoretic considerations. Weshow that ESP outperforms existing portfolio methods on several real andsynthetic problems, including geostatistical datasets and simulated controltasks. We not only show that ESP is able to offer performance as good as thebest, but unknown, acquisition function, but surprisingly it often gives betterperformance. Finally, over a wide range of conditions we find that ESP isrobust to the inclusion of poor acquisition functions.
arxiv-7200-30 | Exact Decoding on Latent Variable Conditional Models is NP-Hard | http://arxiv.org/abs/1406.4682 | author:Xu Sun category:cs.AI cs.CC cs.LG published:2014-06-18 summary:Latent variable conditional models, including the latent conditional randomfields as a special case, are popular models for many natural languageprocessing and vision processing tasks. The computational complexity of theexact decoding/inference in latent conditional random fields is unclear. Inthis paper, we try to clarify the computational complexity of the exactdecoding. We analyze the complexity and demonstrate that it is an NP-hardproblem even on a sequential labeling setting. Furthermore, we propose thelatent-dynamic inference (LDI-Naive) method and its bounded version(LDI-Bounded), which are able to perform exact-inference oralmost-exact-inference by using top-$n$ search and dynamic programming.
arxiv-7200-31 | The Frobenius anatomy of word meanings II: possessive relative pronouns | http://arxiv.org/abs/1406.4690 | author:Mehrnoosh Sadrzadeh, Stephen Clark, Bob Coecke category:cs.CL math.CT 18Dxx, 18Axx I.2.7; F.4.1 published:2014-06-18 summary:Within the categorical compositional distributional model of meaning, weprovide semantic interpretations for the subject and object roles of thepossessive relative pronoun `whose'. This is done in terms of Frobeniusalgebras over compact closed categories. These algebras and their diagrammaticlanguage expose how meanings of words in relative clauses interact with eachother. We show how our interpretation is related to Montague-style semanticsand provide a truth-theoretic interpretation. We also show how vector spacesprovide a concrete interpretation and provide preliminary corpus-basedexperimental evidence. In a prequel to this paper, we used similar methods anddealt with the case of subject and object relative pronouns.
arxiv-7200-32 | Variational Gaussian Process State-Space Models | http://arxiv.org/abs/1406.4905 | author:Roger Frigola, Yutian Chen, Carl E. Rasmussen category:cs.LG cs.RO cs.SY stat.ML published:2014-06-18 summary:State-space models have been successfully used for more than fifty years indifferent areas of science and engineering. We present a procedure forefficient variational Bayesian learning of nonlinear state-space models basedon sparse Gaussian processes. The result of learning is a tractable posteriorover nonlinear dynamical systems. In comparison to conventional parametricmodels, we offer the possibility to straightforwardly trade off model capacityand computational cost whilst avoiding overfitting. Our main algorithm uses ahybrid inference approach combining variational Bayes and sequential MonteCarlo. We also present stochastic variational inference and online learningapproaches for fast learning with long time series.
arxiv-7200-33 | Scalable Latent Tree Model and its Application to Health Analytics | http://arxiv.org/abs/1406.4566 | author:Furong Huang, Niranjan U. N., Ioakeim Perros, Robert Chen, Jimeng Sun, Anima Anandkumar category:cs.LG stat.ML published:2014-06-18 summary:We present an integrated approach to structure and parameter estimation inlatent tree graphical models, where some nodes are hidden. Our overall approachfollows a "divide-and-conquer" strategy that learns models over small groups ofvariables and iteratively merges into a global solution. The structure learninginvolves combinatorial operations such as minimum spanning tree constructionand local recursive grouping; the parameter learning is based on the method ofmoments and on tensor decompositions. Our method is guaranteed to correctlyrecover the unknown tree structure and the model parameters with low samplecomplexity for the class of linear multivariate latent tree models whichincludes discrete and Gaussian distributions, and Gaussian mixtures. Our bulkasynchronous parallel algorithm is implemented in parallel using the OpenMPframework and scales logarithmically with the number of variables and linearlywith dimensionality of each variable. Our experiments confirm a high degree ofefficiency and accuracy on large datasets of electronic health records. Theproposed algorithm also generates intuitive and clinically meaningful diseasehierarchies.
arxiv-7200-34 | Typed Hilbert Epsilon Operators and the Semantics of Determiner Phrases (Invited Lecture) | http://arxiv.org/abs/1406.4710 | author:Christian Retoré category:cs.CL cs.AI cs.LO math.LO published:2014-06-18 summary:The semantics of determiner phrases, be they definite de- scriptions,indefinite descriptions or quantified noun phrases, is often as- sumed to be afully solved question: common nouns are properties, and determiners aregeneralised quantifiers that apply to two predicates: the propertycorresponding to the common noun and the one corresponding to the verb phrase.We first present a criticism of this standard view. Firstly, the semantics ofdeterminers does not follow the syntactical structure of the sentence. Secondlythe standard interpretation of the indefinite article cannot ac- count fornominal sentences. Thirdly, the standard view misses the linguis- tic asymmetrybetween the two properties of a generalised quantifier. In the sequel, wepropose a treatment of determiners and quantifiers as Hilbert terms in a richlytyped system that we initially developed for lexical semantics, using a manysorted logic for semantical representations. We present this semanticalframework called the Montagovian generative lexicon and show how these termsbetter match the syntactical structure and avoid the aforementioned problems ofthe standard approach. Hilbert terms rather differ from choice functions inthat there is one polymorphic operator and not one operator per formula. Theyalso open an intriguing connection between the logic for meaning assembly, thetyped lambda calculus handling compositionality and the many-sorted logic forsemantical representations. Furthermore epsilon terms naturally introducetype-judgements and confirm the claim that type judgment are a form ofpresupposition.
arxiv-7200-35 | On the Application of Generic Summarization Algorithms to Music | http://arxiv.org/abs/1406.4877 | author:Francisco Raposo, Ricardo Ribeiro, David Martins de Matos category:cs.IR cs.LG cs.SD H.5.5 published:2014-06-18 summary:Several generic summarization algorithms were developed in the past andsuccessfully applied in fields such as text and speech summarization. In thispaper, we review and apply these algorithms to music. To evaluate thissummarization's performance, we adopt an extrinsic approach: we compare a FadoGenre Classifier's performance using truncated contiguous clips against thesummaries extracted with those algorithms on 2 different datasets. We show thatMaximal Marginal Relevance (MMR), LexRank and Latent Semantic Analysis (LSA)all improve classification performance in both datasets used for testing.
arxiv-7200-36 | Improved Densification of One Permutation Hashing | http://arxiv.org/abs/1406.4784 | author:Anshumali Shrivastava, Ping Li category:stat.ME cs.DS cs.IR cs.LG published:2014-06-18 summary:The existing work on densification of one permutation hashing reduces thequery processing cost of the $(K,L)$-parameterized Locality Sensitive Hashing(LSH) algorithm with minwise hashing, from $O(dKL)$ to merely $O(d + KL)$,where $d$ is the number of nonzeros of the data vector, $K$ is the number ofhashes in each hash table, and $L$ is the number of hash tables. While that isa substantial improvement, our analysis reveals that the existing densificationscheme is sub-optimal. In particular, there is no enough randomness in thatprocedure, which affects its accuracy on very sparse datasets. In this paper, we provide a new densification procedure which is provablybetter than the existing scheme. This improvement is more significant for verysparse datasets which are common over the web. The improved technique has thesame cost of $O(d + KL)$ for query processing, thereby making it strictlypreferable over the existing procedure. Experimental evaluations on publicdatasets, in the task of hashing based near neighbor search, support ourtheoretical findings.
arxiv-7200-37 | An Experimental Evaluation of Nearest Neighbour Time Series Classification | http://arxiv.org/abs/1406.4757 | author:Anthony Bagnall, Jason Lines category:cs.LG published:2014-06-18 summary:Data mining research into time series classification (TSC) has focussed onalternative distance measures for nearest neighbour classifiers. It is standardpractice to use 1-NN with Euclidean or dynamic time warping (DTW) distance as astraw man for comparison. As part of a wider investigation into elasticdistance measures for TSC~\cite{lines14elastic}, we perform a series ofexperiments to test whether this standard practice is valid. Specifically, we compare 1-NN classifiers with Euclidean and DTW distance tostandard classifiers, examine whether the performance of 1-NN Euclideanapproaches that of 1-NN DTW as the number of cases increases, assess whetherthere is any benefit of setting $k$ for $k$-NN through cross validation whetherit is worth setting the warping path for DTW through cross validation andfinally is it better to use a window or weighting for DTW. Based on experimentson 77 problems, we conclude that 1-NN with Euclidean distance is fairly easy tobeat but 1-NN with DTW is not, if window size is set through cross validation.
arxiv-7200-38 | Predictive Modelling of Bone Age through Classification and Regression of Bone Shapes | http://arxiv.org/abs/1406.4781 | author:Anthony Bagnall, Luke Davis category:cs.LG physics.med-ph published:2014-06-18 summary:Bone age assessment is a task performed daily in hospitals worldwide. Thisinvolves a clinician estimating the age of a patient from a radiograph of thenon-dominant hand. Our approach to automated bone age assessment is to modularise the algorithminto the following three stages: segment and verify hand outline; segment andverify bones; use the bone outlines to construct models of age. In this paperwe address the final question: given outlines of bones, can we learn how topredict the bone age of the patient? We examine two alternative approaches.Firstly, we attempt to train classifiers on individual bones to predict thebone stage categories commonly used in bone ageing. Secondly, we constructregression models to directly predict patient age. We demonstrate that models built on summary features of the bone outlineperform better than those built using the one dimensional representation of theoutline, and also do at least as well as other automated systems. We show thatmodels constructed on just three bones are as accurate at predicting age asexpert human assessors using the standard technique. We also demonstrate theutility of the model by quantifying the importance of ethnicity and sex on agedevelopment. Our conclusion is that the feature based system of separating theimage processing from the age modelling is the best approach for automated boneageing, since it offers flexibility and transparency and produces accurateestimates.
arxiv-7200-39 | Deep Learning Face Representation by Joint Identification-Verification | http://arxiv.org/abs/1406.4773 | author:Yi Sun, Xiaogang Wang, Xiaoou Tang category:cs.CV published:2014-06-18 summary:The key challenge of face recognition is to develop effective featurerepresentations for reducing intra-personal variations while enlarginginter-personal differences. In this paper, we show that it can be well solvedwith deep learning and using both face identification and verification signalsas supervision. The Deep IDentification-verification features (DeepID2) arelearned with carefully designed deep convolutional networks. The faceidentification task increases the inter-personal variations by drawing DeepID2extracted from different identities apart, while the face verification taskreduces the intra-personal variations by pulling DeepID2 extracted from thesame identity together, both of which are essential to face recognition. Thelearned DeepID2 features can be well generalized to new identities unseen inthe training data. On the challenging LFW dataset, 99.15% face verificationaccuracy is achieved. Compared with the best deep learning result on LFW, theerror rate has been significantly reduced by 67%.
arxiv-7200-40 | Mass Classification Method in Mammogram Using Fuzzy K-Nearest Neighbour Equality | http://arxiv.org/abs/1406.4770 | author:I. Laurence Aroquiaraj, K. Thangavel category:cs.CV published:2014-06-18 summary:Mass classification of objects is an important area of research andapplication in a variety of fields. In this paper, we present an efficientcomputer aided mass classification method in digitized mammograms using FuzzyK-Nearest Neighbor Equality, which performs benign or malignant classificationon region of interest that contains mass. One of the major mammographiccharacteristics for mass classification is texture. Fuzzy K-Nearest NeighborEquality exploits this important factor to classify the mass into benign ormalignant. The statistical textural features used in characterizing the massesare Haralick and Run length features. The main aim of the method is to increasethe effectiveness and efficiency of the classification process in an objectivemanner to reduce the numbers of false positive of malignancies. In this paperproposes a novel Fuzzy K-Nearest Neighbor Equality algorithm for classifyingthe marked regions into benign and malignant and 94.46 sensitivity,96.81specificity and 96.52 accuracy is achieved that is very much promising compareto the radiologists' accuracy.
arxiv-7200-41 | Authorship Attribution through Function Word Adjacency Networks | http://arxiv.org/abs/1406.4469 | author:Santiago Segarra, Mark Eisen, Alejandro Ribeiro category:cs.CL cs.LG stat.ML published:2014-06-17 summary:A method for authorship attribution based on function word adjacency networks(WANs) is introduced. Function words are parts of speech that expressgrammatical relationships between other words but do not carry lexical meaningon their own. In the WANs in this paper, nodes are function words and directededges stand in for the likelihood of finding the sink word in the orderedvicinity of the source word. WANs of different authors can be interpreted astransition probabilities of a Markov chain and are therefore compared in termsof their relative entropies. Optimal selection of WAN parameters is studied andattribution accuracy is benchmarked across a diverse pool of authors andvarying text lengths. This analysis shows that, since function words areindependent of content, their use tends to be specific to an author and thatthe relational data captured by function WANs is a good summary of stylometricfingerprints. Attribution accuracy is observed to exceed the one achieved bymethods that rely on word frequencies alone. Further combining WANs withmethods that rely on word frequencies alone, results in larger attributionaccuracy, indicating that both sources of information encode different aspectsof authorial styles.
arxiv-7200-42 | Sparse Estimation with the Swept Approximated Message-Passing Algorithm | http://arxiv.org/abs/1406.4311 | author:Andre Manoel, Florent Krzakala, Eric W. Tramel, Lenka Zdeborová category:cs.IT math.IT stat.ML published:2014-06-17 summary:Approximate Message Passing (AMP) has been shown to be a superior method forinference problems, such as the recovery of signals from sets of noisy,lower-dimensionality measurements, both in terms of reconstruction accuracy andin computational efficiency. However, AMP suffers from serious convergenceissues in contexts that do not exactly match its assumptions. We propose a newapproach to stabilizing AMP in these contexts by applying AMP updates toindividual coefficients rather than in parallel. Our results show that thischange to the AMP iteration can provide theoretically expected, but hithertounobtainable, performance for problems on which the standard AMP iterationdiverges. Additionally, we find that the computational costs of this sweptcoefficient update scheme is not unduly burdensome, allowing it to be appliedefficiently to signals of large dimensionality.
arxiv-7200-43 | Block matching algorithm based on Harmony Search optimization for motion estimation | http://arxiv.org/abs/1406.4484 | author:Erik Cuevas category:cs.CV published:2014-06-17 summary:Motion estimation is one of the major problems in developing video codingapplications. Among all motion estimation approaches, Block-matching (BM)algorithms are the most popular methods due to their effectiveness andsimplicity for both software and hardware implementations. A BM approachassumes that the movement of pixels within a defined region of the currentframe can be modeled as a translation of pixels contained in the previousframe. In this procedure, the motion vector is obtained by minimizing a certainmatching metric that is produced for the current frame over a determined searchwindow from the previous frame. Unfortunately, the evaluation of such matchingmeasurement is computationally expensive and represents the most consumingoperation in the BM process. Therefore, BM motion estimation can be viewed asan optimization problem whose goal is to find the best-matching block within asearch space. The simplest available BM method is the Full Search Algorithm(FSA) which finds the most accurate motion vector through an exhaustivecomputation of all the elements of the search space. Recently, several fast BMalgorithms have been proposed to reduce the search positions by calculatingonly a fixed subset of motion vectors despite lowering its accuracy. On theother hand, the Harmony Search (HS) algorithm is a population-basedoptimization method that is inspired by the music improvisation process inwhich a musician searches for harmony and continues to polish the pitches toobtain a better harmony. In this paper, a new BM algorithm that combines HSwith a fitness approximation model is proposed. The approach uses motionvectors belonging to the search window as potential solutions. A fitnessfunction evaluates the matching quality of each motion vector candidate.
arxiv-7200-44 | An Evolutionary Approach for Optimal Citing and Sizing of Micro-Grid in Radial Distribution Systems | http://arxiv.org/abs/1406.4237 | author:Eswari. J, Dr. S. Jeyadevi category:cs.NE published:2014-06-17 summary:This Paper presents the methodology of penetration of Micro-Grids (MG) in theradial distribution system (RDS). The aim of this paper is to minimize a totalreal power loss that descends the performance of the radial distribution systemby integrating various renewable resources as Distributed Generation (DG). Thecombination of different types of renewable energy resources contributes asustainable MG. These resources are optimally sized and located usingevolutionary approach in various penetration levels. The optimal solutions areexperimented with IEEE 33 radial distribution system using Particle SwarmOptimization (PSO) technique. The results are quite promising and authenticateits potential to solve problem in radial distribution system effectively.
arxiv-7200-45 | Self-Learning Camera: Autonomous Adaptation of Object Detectors to Unlabeled Video Streams | http://arxiv.org/abs/1406.4296 | author:Adrien Gaidon, Gloria Zen, Jose A. Rodriguez-Serrano category:cs.CV cs.LG published:2014-06-17 summary:Learning object detectors requires massive amounts of labeled trainingsamples from the specific data source of interest. This is impractical whendealing with many different sources (e.g., in camera networks), or constantlychanging ones such as mobile cameras (e.g., in robotics or driving assistantsystems). In this paper, we address the problem of self-learning detectors inan autonomous manner, i.e. (i) detectors continuously updating themselves toefficiently adapt to streaming data sources (contrary to transductivealgorithms), (ii) without any labeled data strongly related to the target datastream (contrary to self-paced learning), and (iii) without manual interventionto set and update hyper-parameters. To that end, we propose an unsupervised,on-line, and self-tuning learning algorithm to optimize a multi-task learningconvex objective. Our method uses confident but laconic oracles (high-precisionbut low-recall off-the-shelf generic detectors), and exploits the structure ofthe problem to jointly learn on-line an ensemble of instance-level trackers,from which we derive an adapted category-level object detector. Our approach isvalidated on real-world publicly available video object datasets.
arxiv-7200-46 | DFacTo: Distributed Factorization of Tensors | http://arxiv.org/abs/1406.4519 | author:Joon Hee Choi, S. V. N. Vishwanathan category:stat.ML published:2014-06-17 summary:We present a technique for significantly speeding up Alternating LeastSquares (ALS) and Gradient Descent (GD), two widely used algorithms for tensorfactorization. By exploiting properties of the Khatri-Rao product, we show howto efficiently address a computationally challenging sub-step of bothalgorithms. Our algorithm, DFacTo, only requires two sparse matrix-vectorproducts and is easy to parallelize. DFacTo is not only scalable but also onaverage 4 to 10 times faster than competing algorithms on a variety ofdatasets. For instance, DFacTo only takes 480 seconds on 4 machines to performone iteration of the ALS algorithm and 1,143 seconds to perform one iterationof the GD algorithm on a 6.5 million x 2.5 million x 1.5 million dimensionaltensor with 1.2 billion non-zero entries.
arxiv-7200-47 | Mapping the Economic Crisis: Some Preliminary Investigations | http://arxiv.org/abs/1406.4211 | author:Pierre Bourreau, Thierry Poibeau category:cs.CL published:2014-06-17 summary:In this paper we describe our contribution to the PoliInformatics 2014Challenge on the 2007-2008 financial crisis. We propose a state of the arttechnique to extract information from texts and provide differentrepresentations, giving first a static overview of the domain and then adynamic representation of its main evolutions. We show that this strategyprovides a practical solution to some recent theories in social sciences thatare facing a lack of methods and tools to automatically extract informationfrom natural language texts.
arxiv-7200-48 | Lifted Tree-Reweighted Variational Inference | http://arxiv.org/abs/1406.4200 | author:Hung Hai Bui, Tuyen N. Huynh, David Sontag category:cs.AI stat.ML published:2014-06-17 summary:We analyze variational inference for highly symmetric graphical models suchas those arising from first-order probabilistic models. We first show that forthese graphical models, the tree-reweighted variational objective lends itselfto a compact lifted formulation which can be solved much more efficiently thanthe standard TRW formulation for the ground graphical model. Compared toearlier work on lifted belief propagation, our formulation leads to a convexoptimization problem for lifted marginal inference and provides an upper boundon the partition function. We provide two approaches for improving the liftedTRW upper bound. The first is a method for efficiently computing maximumspanning trees in highly symmetric graphs, which can be used to optimize theTRW edge appearance probabilities. The second is a method for tightening therelaxation of the marginal polytope using lifted cycle inequalities and novelexchangeable cluster consistency constraints.
arxiv-7200-49 | Replicating Kernels with a Short Stride Allows Sparse Reconstructions with Fewer Independent Kernels | http://arxiv.org/abs/1406.4205 | author:Peter F. Schultz, Dylan M. Paiton, Wei Lu, Garrett T. Kenyon category:q-bio.QM cs.CV published:2014-06-17 summary:In sparse coding it is common to tile an image into nonoverlapping patches,and then use a dictionary to create a sparse representation of each tileindependently. In this situation, the overcompleteness of the dictionary is thenumber of dictionary elements divided by the patch size. In deconvolutionalneural networks (DCNs), dictionaries learned on nonoverlapping tiles arereplaced by a family of convolution kernels. Hence adjacent points in thefeature maps (V1 layers) have receptive fields in the image that aretranslations of each other. The translational distance is determined by thedimensions of V1 in comparison to the dimensions of the image space. We referto this translational distance as the stride. We implement a type of DCN using a modified Locally Competitive Algorithm(LCA) to investigate the relationship between the number of kernels, thestride, the receptive field size, and the quality of reconstruction. We find,for example, that for 16x16-pixel receptive fields, using eight kernels and astride of 2 leads to sparse reconstructions of comparable quality as using 512kernels and a stride of 16 (the nonoverlapping case). We also find that for agiven stride and number of kernels, the patch size does not significantlyaffect reconstruction quality. Instead, the learned convolution kernels have anatural support radius independent of the patch size.
arxiv-7200-50 | Construction of non-convex polynomial loss functions for training a binary classifier with quantum annealing | http://arxiv.org/abs/1406.4203 | author:Ryan Babbush, Vasil Denchev, Nan Ding, Sergei Isakov, Hartmut Neven category:cs.LG quant-ph published:2014-06-17 summary:Quantum annealing is a heuristic quantum algorithm which exploits quantumresources to minimize an objective function embedded as the energy levels of aprogrammable physical system. To take advantage of a potential quantumadvantage, one needs to be able to map the problem of interest to the nativehardware with reasonably low overhead. Because experimental considerationsconstrain our objective function to take the form of a low degree PUBO(polynomial unconstrained binary optimization), we employ non-convex lossfunctions which are polynomial functions of the margin. We show that these lossfunctions are robust to label noise and provide a clear advantage over convexmethods. These loss functions may also be useful for classical approaches asthey compile to regularized risk expressions which can be evaluated in constanttime with respect to the number of training examples.
arxiv-7200-51 | Notes on hierarchical ensemble methods for DAG-structured taxonomies | http://arxiv.org/abs/1406.4472 | author:Giorgio Valentini category:cs.AI cs.LG stat.ML I.2.6 published:2014-06-17 summary:Several real problems ranging from text classification to computationalbiology are characterized by hierarchical multi-label classification tasks.Most of the methods presented in literature focused on tree-structuredtaxonomies, but only few on taxonomies structured according to a DirectedAcyclic Graph (DAG). In this contribution novel classification ensemblealgorithms for DAG-structured taxonomies are introduced. In particularHierarchical Top-Down (HTD-DAG) and True Path Rule (TPR-DAG) for DAGs arepresented and discussed.
arxiv-7200-52 | Extracting information from S-curves of language change | http://arxiv.org/abs/1406.4498 | author:Fakhteh Ghanbarnejad, Martin Gerlach, Jose M. Miotto, Eduardo G. Altmann category:physics.soc-ph cs.CL published:2014-06-17 summary:It is well accepted that adoption of innovations are described by S-curves(slow start, accelerating period, and slow end). In this paper, we analyze howmuch information on the dynamics of innovation spreading can be obtained from aquantitative description of S-curves. We focus on the adoption of linguisticinnovations for which detailed databases of written texts from the last 200years allow for an unprecedented statistical precision. Combining data analysiswith simulations of simple models (e.g., the Bass dynamics on complex networks)we identify signatures of endogenous and exogenous factors in the S-curves ofadoption. We propose a measure to quantify the strength of these factors andthree different methods to estimate it from S-curves. We obtain cases in whichthe exogenous factors are dominant (in the adoption of German orthographicreforms and of one irregular verb) and cases in which endogenous factors aredominant (in the adoption of conventions for romanization of Russian names andin the regularization of most studied verbs). These results show that the shapeof S-curve is not universal and contains information on the adoption mechanism.(published at "J. R. Soc. Interface, vol. 11, no. 101, (2014) 1044"; DOI:http://dx.doi.org/10.1098/rsif.2014.1044)
arxiv-7200-53 | Person Re-identification by Local Maximal Occurrence Representation and Metric Learning | http://arxiv.org/abs/1406.4216 | author:Shengcai Liao, Yang Hu, Xiangyu Zhu, Stan Z. Li category:cs.CV published:2014-06-17 summary:Person re-identification is an important technique towards automatic searchof a person's presence in a surveillance video. Two fundamental problems arecritical for person re-identification, feature representation and metriclearning. An effective feature representation should be robust to illuminationand viewpoint changes, and a discriminant metric should be learned to matchvarious person images. In this paper, we propose an effective featurerepresentation called Local Maximal Occurrence (LOMO), and a subspace andmetric learning method called Cross-view Quadratic Discriminant Analysis(XQDA). The LOMO feature analyzes the horizontal occurrence of local features,and maximizes the occurrence to make a stable representation against viewpointchanges. Besides, to handle illumination variations, we apply the Retinextransform and a scale invariant texture operator. To learn a discriminantmetric, we propose to learn a discriminant low dimensional subspace bycross-view quadratic discriminant analysis, and simultaneously, a QDA metric islearned on the derived subspace. We also present a practical computation methodfor XQDA, as well as its regularization. Experiments on four challenging personre-identification databases, VIPeR, QMUL GRID, CUHK Campus, and CUHK03, showthat the proposed method improves the state-of-the-art rank-1 identificationrates by 2.2%, 4.88%, 28.91%, and 31.55% on the four databases, respectively.
arxiv-7200-54 | Scaling laws and fluctuations in the statistics of word frequencies | http://arxiv.org/abs/1406.4441 | author:Martin Gerlach, Eduardo G. Altmann category:physics.soc-ph cs.CL published:2014-06-17 summary:In this paper we combine statistical analysis of large text databases andsimple stochastic models to explain the appearance of scaling laws in thestatistics of word frequencies. Besides the sublinear scaling of the vocabularysize with database size (Heaps' law), here we report a new scaling of thefluctuations around this average (fluctuation scaling analysis). We explainboth scaling laws by modeling the usage of words by simple stochastic processesin which the overall distribution of word-frequencies is fat tailed (Zipf'slaw) and the frequency of a single word is subject to fluctuations acrossdocuments (as in topic models). In this framework, the mean and the variance ofthe vocabulary size can be expressed as quenched averages, implying that: i)the inhomogeneous dissemination of words cause a reduction of the averagevocabulary size in comparison to the homogeneous case, and ii) correlations inthe co-occurrence of words lead to an increase in the variance and thevocabulary size becomes a non-self-averaging quantity. We address theimplications of these observations to the measurement of lexical richness. Wetest our results in three large text databases (Google-ngram, EnlgishWikipedia, and a collection of scientific articles).
arxiv-7200-55 | Distributed Stochastic Optimization of the Regularized Risk | http://arxiv.org/abs/1406.4363 | author:Shin Matsushima, Hyokun Yun, Xinhua Zhang, S. V. N. Vishwanathan category:stat.ML cs.LG published:2014-06-17 summary:Many machine learning algorithms minimize a regularized risk, and stochasticoptimization is widely used for this task. When working with massive data, itis desirable to perform stochastic optimization in parallel. Unfortunately,many existing stochastic optimization algorithms cannot be parallelizedefficiently. In this paper we show that one can rewrite the regularized riskminimization problem as an equivalent saddle-point problem, and propose anefficient distributed stochastic optimization (DSO) algorithm. We prove thealgorithm's rate of convergence; remarkably, our analysis shows that thealgorithm scales almost linearly with the number of processors. We also verifywith empirical evaluations that the proposed algorithm is competitive withother parallel, general purpose stochastic and batch optimization algorithmsfor regularized risk minimization.
arxiv-7200-56 | Semantic Graph for Zero-Shot Learning | http://arxiv.org/abs/1406.4112 | author:Zhen-Yong Fu, Tao Xiang, Shaogang Gong category:cs.CV cs.LG published:2014-06-16 summary:Zero-shot learning aims to classify visual objects without any training datavia knowledge transfer between seen and unseen classes. This is typicallyachieved by exploring a semantic embedding space where the seen and unseenclasses can be related. Previous works differ in what embedding space is usedand how different classes and a test image can be related. In this paper, weutilize the annotation-free semantic word space for the former and focus onsolving the latter issue of modeling relatedness. Specifically, in contrast toprevious work which ignores the semantic relationships between seen classes andfocus merely on those between seen and unseen classes, in this paper a novelapproach based on a semantic graph is proposed to represent the relationshipsbetween all the seen and unseen class in a semantic word space. Based on thissemantic graph, we design a special absorbing Markov chain process, in whicheach unseen class is viewed as an absorbing state. After incorporating one testimage into the semantic graph, the absorbing probabilities from the test datato each unseen class can be effectively computed; and zero-shot classificationcan be achieved by finding the class label with the highest absorbingprobability. The proposed model has a closed-form solution which is linear withrespect to the number of test images. We demonstrate the effectiveness andcomputational efficiency of the proposed method over the state-of-the-arts onthe AwA (animals with attributes) dataset.
arxiv-7200-57 | Multi-stage Multi-task feature learning via adaptive threshold | http://arxiv.org/abs/1406.4465 | author:Yaru Fan, Yilun Wang category:cs.LG cs.CV stat.ML 68T10 F.2.2 published:2014-06-16 summary:Multi-task feature learning aims to identity the shared features among tasksto improve generalization. It has been shown that by minimizing non-convexlearning models, a better solution than the convex alternatives can beobtained. Therefore, a non-convex model based on the capped-$\ell_{1},\ell_{1}$regularization was proposed in \cite{Gong2013}, and a corresponding efficientmulti-stage multi-task feature learning algorithm (MSMTFL) was presented.However, this algorithm harnesses a prescribed fixed threshold in thedefinition of the capped-$\ell_{1},\ell_{1}$ regularization and the lack ofadaptivity might result in suboptimal performance. In this paper we propose toemploy an adaptive threshold in the capped-$\ell_{1},\ell_{1}$ regularizedformulation, where the corresponding variant of MSMTFL will incorporate anadditional component to adaptively determine the threshold value. This variantis expected to achieve a better feature selection performance over the originalMSMTFL algorithm. In particular, the embedded adaptive threshold componentcomes from our previously proposed iterative support detection (ISD) method\cite{Wang2010}. Empirical studies on both synthetic and real-world data setsdemonstrate the effectiveness of this new variant over the original MSMTFL.
arxiv-7200-58 | Personalized Medical Treatments Using Novel Reinforcement Learning Algorithms | http://arxiv.org/abs/1406.3922 | author:Yousuf M. Soliman category:cs.LG stat.ML published:2014-06-16 summary:In both the fields of computer science and medicine there is very stronginterest in developing personalized treatment policies for patients who havevariable responses to treatments. In particular, I aim to find an optimalpersonalized treatment policy which is a non-deterministic function of thepatient specific covariate data that maximizes the expected survival time orclinical outcome. I developed an algorithmic framework to solve multistagedecision problem with a varying number of stages that are subject to censoringin which the "rewards" are expected survival times. In specific, I developed anovel Q-learning algorithm that dynamically adjusts for these parameters.Furthermore, I found finite upper bounds on the generalized error of thetreatment paths constructed by this algorithm. I have also shown that when theoptimal Q-function is an element of the approximation space, the anticipatedsurvival times for the treatment regime constructed by the algorithm willconverge to the optimal treatment path. I demonstrated the performance of theproposed algorithmic framework via simulation studies and through the analysisof chronic depression data and a hypothetical clinical trial. The censoredQ-learning algorithm I developed is more effective than the state of the artclinical decision support systems and is able to operate in environments whenmany covariate parameters may be unobtainable or censored.
arxiv-7200-59 | Embedded Controlled Languages | http://arxiv.org/abs/1406.4057 | author:Aarne Ranta category:cs.CL published:2014-06-16 summary:Inspired by embedded programming languages, an embedded CNL (controllednatural language) is a proper fragment of an entire natural language (its hostlanguage), but it has a parser that recognizes the entire host language. Thismakes it possible to process out-of-CNL input and give useful feedback tousers, instead of just reporting syntax errors. This extended abstract explainsthe main concepts of embedded CNL implementation in GF (Grammatical Framework),with examples from machine translation and some other ongoing work.
arxiv-7200-60 | Impact of Exponent Parameter Value for the Partition Matrix on the Performance of Fuzzy C Means Algorithm | http://arxiv.org/abs/1406.4007 | author:Dibya Jyoti Bora, Anil Kumar Gupta category:cs.CV published:2014-06-16 summary:Soft Clustering plays a very important rule on clustering real world datawhere a data item contributes to more than one cluster. Fuzzy logic basedalgorithms are always suitable for performing soft clustering tasks. Fuzzy CMeans (FCM) algorithm is a very popular fuzzy logic based algorithm. In case offuzzy logic based algorithm, the parameter like exponent for the partitionmatrix that we have to fix for the clustering task plays a very important ruleon the performance of the algorithm. In this paper, an experimental analysis isdone on FCM algorithm to observe the impact of this parameter on theperformance of the algorithm.
arxiv-7200-61 | Towards an Error Correction Memory to Enhance Technical Texts Authoring in LELIE | http://arxiv.org/abs/1406.3987 | author:Juyeon Kang, Patrick Saint Dizier category:cs.CL published:2014-06-16 summary:In this paper, we investigate and experiment the notion of error correctionmemory applied to error correction in technical texts. The main purpose is toinduce relatively generic correction patterns associated with more contextualcorrection recommendations, based on previously memorized and analyzedcorrections. The notion of error correction memory is developed within theframework of the LELIE project and illustrated on the case of fuzzy lexicalitems, which is a major problem in technical texts.
arxiv-7200-62 | Handling non-compositionality in multilingual CNLs | http://arxiv.org/abs/1406.3976 | author:Ramona Enache, Inari Listenmaa, Prasanth Kolachina category:cs.CL published:2014-06-16 summary:In this paper, we describe methods for handling multilingualnon-compositional constructions in the framework of GF. We specifically look atmethods to detect and extract non-compositional phrases from parallel texts andpropose methods to handle such constructions in GF grammars. We expect that themethods to handle non-compositional constructions will enrich CNLs by providingmore flexibility in the design of controlled languages. We look at two specificuse cases of non-compositional constructions: a general-purpose method todetect and extract multilingual multiword expressions and a procedure toidentify nominal compounds in German. We evaluate our procedure for multiwordexpressions by performing a qualitative analysis of the results. For theexperiments on nominal compounds, we incorporate the detected compounds in afull SMT pipeline and evaluate the impact of our method in machine translationprocess.
arxiv-7200-63 | Translation Of Telugu-Marathi and Vice-Versa using Rule Based Machine Translation | http://arxiv.org/abs/1406.3969 | author:Siddhartha Ghosh, Sujata Thamke, Kalyani U. R. S category:cs.CL published:2014-06-16 summary:In todays digital world automated Machine Translation of one language toanother has covered a long way to achieve different kinds of success stories.Whereas Babel Fish supports a good number of foreign languages and only Hindifrom Indian languages, the Google Translator takes care of about 10 Indianlanguages. Though most of the Automated Machine Translation Systems are doingwell but handling Indian languages needs a major care while handling the localproverbs/ idioms. Most of the Machine Translation system follows the directtranslation approach while translating one Indian language to other. Ourresearch at KMIT R&D Lab found that handling the local proverbs/idioms is notgiven enough attention by the earlier research work. This paper focuses on twoof the majorly spoken Indian languages Marathi and Telugu, and translationbetween them. Handling proverbs and idioms of both the languages have beengiven a special care, and the research outcome shows a significant achievementin this direction.
arxiv-7200-64 | A Fusion of Labeled-Grid Shape Descriptors with Weighted Ranking Algorithm for Shapes Recognition | http://arxiv.org/abs/1406.3949 | author:Jamil Ahmad, Zahoor Jan, Zia-ud-Din, Shoaib Muhammad Khan category:cs.CV published:2014-06-16 summary:Retrieving similar images from a large dataset based on the image content hasbeen a very active research area and is a very challenging task. Studies haveshown that retrieving similar images based on their shape is a very effectivemethod. For this purpose a large number of methods exist in literature. Thecombination of more than one feature has also been investigated for thispurpose and has shown promising results. In this paper a fusion based shapesrecognition method has been proposed. A set of local boundary based and regionbased features are derived from the labeled grid based representation of theshape and are combined with a few global shape features to produce a compositeshape descriptor. This composite shape descriptor is then used in a weightedranking algorithm to find similarities among shapes from a large dataset. Theexperimental analysis has shown that the proposed method is powerful enough todiscriminate the geometrically similar shapes from the non-similar ones.
arxiv-7200-65 | From Denoising to Compressed Sensing | http://arxiv.org/abs/1406.4175 | author:Christopher A. Metzler, Arian Maleki, Richard G. Baraniuk category:cs.IT math.IT math.ST stat.ML stat.TH published:2014-06-16 summary:A denoising algorithm seeks to remove noise, errors, or perturbations from asignal. Extensive research has been devoted to this arena over the last severaldecades, and as a result, today's denoisers can effectively remove largeamounts of additive white Gaussian noise. A compressed sensing (CS)reconstruction algorithm seeks to recover a structured signal acquired using asmall number of randomized measurements. Typical CS reconstruction algorithmscan be cast as iteratively estimating a signal from a perturbed observation.This paper answers a natural question: How can one effectively employ a genericdenoiser in a CS reconstruction algorithm? In response, we develop an extensionof the approximate message passing (AMP) framework, called Denoising-based AMP(D-AMP), that can integrate a wide class of denoisers within its iterations. Wedemonstrate that, when used with a high performance denoiser for naturalimages, D-AMP offers state-of-the-art CS recovery performance while operatingtens of times faster than competing methods. We explain the exceptionalperformance of D-AMP by analyzing some of its theoretical features. A keyelement in D-AMP is the use of an appropriate Onsager correction term in itsiterations, which coerces the signal perturbation at each iteration to be veryclose to the white Gaussian noise that denoisers are typically designed toremove.
arxiv-7200-66 | Bayesian Optimal Control of Smoothly Parameterized Systems: The Lazy Posterior Sampling Algorithm | http://arxiv.org/abs/1406.3926 | author:Yasin Abbasi-Yadkori, Csaba Szepesvari category:cs.LG stat.ML published:2014-06-16 summary:We study Bayesian optimal control of a general class of smoothlyparameterized Markov decision problems. Since computing the optimal control iscomputationally expensive, we design an algorithm that trades off performancefor computational efficiency. The algorithm is a lazy posterior sampling methodthat maintains a distribution over the unknown parameter. The algorithm changesits policy only when the variance of the distribution is reduced sufficiently.Importantly, we analyze the algorithm and show the precise nature of theperformance vs. computation tradeoff. Finally, we show the effectiveness of themethod on a web server control application.
arxiv-7200-67 | A Bengali HMM Based Speech Synthesis System | http://arxiv.org/abs/1406.3915 | author:Sankar Mukherjee, Shyamal Kumar Das Mandal category:cs.SD cs.CL cs.MM published:2014-06-16 summary:The paper presents the capability of an HMM-based TTS system to produceBengali speech. In this synthesis method, trajectories of speech parameters aregenerated from the trained Hidden Markov Models. A final speech waveform issynthesized from those speech parameters. In our experiments, spectralproperties were represented by Mel Cepstrum Coefficients. Both the training andsynthesis issues are investigated in this paper using annotated Bengali speechdatabase. Experimental evaluation depicts that the developed text-to-speechsystem is capable of producing adequately natural speech in terms ofintelligibility and intonation for Bengali.
arxiv-7200-68 | Human-Machine CRFs for Identifying Bottlenecks in Holistic Scene Understanding | http://arxiv.org/abs/1406.3906 | author:Roozbeh Mottaghi, Sanja Fidler, Alan Yuille, Raquel Urtasun, Devi Parikh category:cs.CV published:2014-06-16 summary:Recent trends in image understanding have pushed for holistic sceneunderstanding models that jointly reason about various tasks such as objectdetection, scene recognition, shape analysis, contextual reasoning, and localappearance based classifiers. In this work, we are interested in understandingthe roles of these different tasks in improved scene understanding, inparticular semantic segmentation, object detection and scene recognition.Towards this goal, we "plug-in" human subjects for each of the variouscomponents in a state-of-the-art conditional random field model. Comparisonsamong various hybrid human-machine CRFs give us indications of how much "headroom" there is to improve scene understanding by focusing research efforts onvarious individual tasks.
arxiv-7200-69 | Freeze-Thaw Bayesian Optimization | http://arxiv.org/abs/1406.3896 | author:Kevin Swersky, Jasper Snoek, Ryan Prescott Adams category:stat.ML cs.LG published:2014-06-16 summary:In this paper we develop a dynamic form of Bayesian optimization for machinelearning models with the goal of rapidly finding good hyperparameter settings.Our method uses the partial information gained during the training of a machinelearning model in order to decide whether to pause training and start a newmodel, or resume the training of a previously-considered model. We specificallytailor our method to machine learning problems by developing a novelpositive-definite covariance kernel to capture a variety of training curves.Furthermore, we develop a Gaussian process prior that scales gracefully withadditional temporal observations. Finally, we provide an information-theoreticframework to automate the decision process. Experiments on several commonmachine learning models show that our approach is extremely effective inpractice.
arxiv-7200-70 | The Laplacian K-modes algorithm for clustering | http://arxiv.org/abs/1406.3895 | author:Weiran Wang, Miguel Á. Carreira-Perpiñán category:cs.LG stat.ME stat.ML published:2014-06-16 summary:In addition to finding meaningful clusters, centroid-based clusteringalgorithms such as K-means or mean-shift should ideally find centroids that arevalid patterns in the input space, representative of data in their cluster.This is challenging with data having a nonconvex or manifold structure, as withimages or text. We introduce a new algorithm, Laplacian K-modes, whichnaturally combines three powerful ideas in clustering: the explicit use ofassignment variables (as in K-means); the estimation of cluster centroids whichare modes of each cluster's density estimate (as in mean-shift); and theregularizing effect of the graph Laplacian, which encourages similarassignments for nearby points (as in spectral clustering). The optimizationalgorithm alternates an assignment step, which is a convex quadratic program,and a mean-shift step, which separates for each cluster centroid. The algorithmfinds meaningful density estimates for each cluster, even with challengingproblems where the clusters have manifold structure, are highly nonconvex or inhigh dimension. It also provides centroids that are valid patterns, trulyrepresentative of their cluster (unlike K-means), and an out-of-sample mappingthat predicts soft assignments for a new point.
arxiv-7200-71 | Learning An Invariant Speech Representation | http://arxiv.org/abs/1406.3884 | author:Georgios Evangelopoulos, Stephen Voinea, Chiyuan Zhang, Lorenzo Rosasco, Tomaso Poggio category:cs.SD cs.LG published:2014-06-16 summary:Recognition of speech, and in particular the ability to generalize and learnfrom small sets of labelled examples like humans do, depends on an appropriaterepresentation of the acoustic input. We formulate the problem of findingrobust speech features for supervised learning with small sample complexity asa problem of learning representations of the signal that are maximallyinvariant to intraclass transformations and deformations. We propose anextension of a theory for unsupervised learning of invariant visualrepresentations to the auditory domain and empirically evaluate its validityfor voiced speech sound classification. Our version of the theory requires thememory-based, unsupervised storage of acoustic templates -- such as specificphones or words -- together with all the transformations of each that normallyoccur. A quasi-invariant representation for a speech segment can be obtained byprojecting it to each template orbit, i.e., the set of transformed signals, andcomputing the associated one-dimensional empirical probability distributions.The computations can be performed by modules of filtering and pooling, andextended to hierarchical architectures. In this paper, we apply a single-layer,multicomponent representation for phonemes and demonstrate improved accuracyand decreased sample complexity for vowel classification compared to standardspectral, cepstral and perceptual features.
arxiv-7200-72 | Interval Forecasting of Electricity Demand: A Novel Bivariate EMD-based Support Vector Regression Modeling Framework | http://arxiv.org/abs/1406.3792 | author:Tao Xiong, Yukun Bao, Zhongyi Hu category:cs.LG stat.AP published:2014-06-15 summary:Highly accurate interval forecasting of electricity demand is fundamental tothe success of reducing the risk when making power system planning andoperational decisions by providing a range rather than point estimation. Inthis study, a novel modeling framework integrating bivariate empirical modedecomposition (BEMD) and support vector regression (SVR), extended from thewell-established empirical mode decomposition (EMD) based time series modelingframework in the energy demand forecasting literature, is proposed for intervalforecasting of electricity demand. The novelty of this study arises from theemployment of BEMD, a new extension of classical empirical model decomposition(EMD) destined to handle bivariate time series treated as complex-valued timeseries, as decomposition method instead of classical EMD only capable ofdecomposing one-dimensional single-valued time series. This proposed modelingframework is endowed with BEMD to decompose simultaneously both the lower andupper bounds time series, constructed in forms of complex-valued time series,of electricity demand on a monthly per hour basis, resulting in capturing thepotential interrelationship between lower and upper bounds. The proposedmodeling framework is justified with monthly interval-valued electricity demanddata per hour in Pennsylvania-New Jersey-Maryland Interconnection, indicatingit as a promising method for interval-valued electricity demand forecasting.
arxiv-7200-73 | Spectral Methods meet EM: A Provably Optimal Algorithm for Crowdsourcing | http://arxiv.org/abs/1406.3824 | author:Yuchen Zhang, Xi Chen, Dengyong Zhou, Michael I. Jordan category:stat.ML published:2014-06-15 summary:Crowdsourcing is a popular paradigm for effectively collecting labels at lowcost. The Dawid-Skene estimator has been widely used for inferring the truelabels from the noisy labels provided by non-expert crowdsourcing workers.However, since the estimator maximizes a non-convex log-likelihood function, itis hard to theoretically justify its performance. In this paper, we propose atwo-stage efficient algorithm for multi-class crowd labeling problems. Thefirst stage uses the spectral method to obtain an initial estimate ofparameters. Then the second stage refines the estimation by optimizing theobjective function of the Dawid-Skene estimator via the EM algorithm. We showthat our algorithm achieves the optimal convergence rate up to a logarithmicfactor. We conduct extensive experiments on synthetic and real datasets.Experimental results demonstrate that the proposed algorithm is comparable tothe most accurate empirical approach, while outperforming several otherrecently proposed methods.
arxiv-7200-74 | Neural tuning size is a key factor underlying holistic face processing | http://arxiv.org/abs/1406.3793 | author:Cheston Tan, Tomaso Poggio category:cs.AI cs.CV cs.NE q-bio.NC published:2014-06-15 summary:Faces are a class of visual stimuli with unique significance, for a varietyof reasons. They are ubiquitous throughout the course of a person's life, andface recognition is crucial for daily social interaction. Faces are also unlikeany other stimulus class in terms of certain physical stimulus characteristics.Furthermore, faces have been empirically found to elicit certain characteristicbehavioral phenomena, which are widely held to be evidence of "holistic"processing of faces. However, little is known about the neural mechanismsunderlying such holistic face processing. In other words, for the processing offaces by the primate visual system, the input and output characteristics arerelatively well known, but the internal neural computations are not. The mainaim of this work is to further the fundamental understanding of what causes thevisual processing of faces to be different from that of objects. In thiscomputational modeling work, we show that a single factor - "neural tuningsize" - is able to account for three key phenomena that are characteristic offace processing, namely the Composite Face Effect (CFE), Face Inversion Effect(FIE) and Whole-Part Effect (WPE). Our computational proof-of-principleprovides specific neural tuning properties that correspond to thepoorly-understood notion of holistic face processing, and connects these neuralproperties to psychophysical behavior. Overall, our work provides a unified andparsimonious theoretical account for the disparate empirical data onface-specific processing, deepening the fundamental understanding of faceprocessing.
arxiv-7200-75 | Human language reveals a universal positivity bias | http://arxiv.org/abs/1406.3855 | author:Peter Sheridan Dodds, Eric M. Clark, Suma Desu, Morgan R. Frank, Andrew J. Reagan, Jake Ryland Williams, Lewis Mitchell, Kameron Decker Harris, Isabel M. Kloumann, James P. Bagrow, Karine Megerdoomian, Matthew T. McMahon, Brian F. Tivnan, Christopher M. Danforth category:physics.soc-ph cs.CL cs.SI published:2014-06-15 summary:Using human evaluation of 100,000 words spread across 24 corpora in 10languages diverse in origin and culture, we present evidence of a deep imprintof human sociality in language, observing that (1) the words of natural humanlanguage possess a universal positivity bias; (2) the estimated emotionalcontent of words is consistent between languages under translation; and (3)this positivity bias is strongly independent of frequency of word usage.Alongside these general regularities, we describe inter-language variations inthe emotional spectrum of languages which allow us to rank corpora. We alsoshow how our word evaluations can be used to construct physical-likeinstruments for both real-time and offline measurement of the emotional contentof large-scale texts.
arxiv-7200-76 | A low variance consistent test of relative dependency | http://arxiv.org/abs/1406.3852 | author:Wacha Bounliphone, Arthur Gretton, Arthur Tenenhaus, Matthew Blaschko category:stat.ML cs.LG stat.CO published:2014-06-15 summary:We describe a novel non-parametric statistical hypothesis test of relativedependence between a source variable and two candidate target variables. Such atest enables us to determine whether one source variable is significantly moredependent on a first target variable or a second. Dependence is measured viathe Hilbert-Schmidt Independence Criterion (HSIC), resulting in a pair ofempirical dependence measures (source-target 1, source-target 2). We testwhether the first dependence measure is significantly larger than the second.Modeling the covariance between these HSIC statistics leads to a provably morepowerful test than the construction of independent HSIC statistics bysub-sampling. The resulting test is consistent and unbiased, and (being basedon U-statistics) has favorable convergence properties. The test can be computedin quadratic time, matching the computational complexity of standard empiricalHSIC estimators. The effectiveness of the test is demonstrated on severalreal-world problems: we identify language groups from a multilingual corpus,and we prove that tumor location is more dependent on gene expression thanchromosomal imbalances. Source code is available for download athttps://github.com/wbounliphone/reldep.
arxiv-7200-77 | Semi-Separable Hamiltonian Monte Carlo for Inference in Bayesian Hierarchical Models | http://arxiv.org/abs/1406.3843 | author:Yichuan Zhang, Charles Sutton category:stat.CO cs.AI cs.LG published:2014-06-15 summary:Sampling from hierarchical Bayesian models is often difficult for MCMCmethods, because of the strong correlations between the model parameters andthe hyperparameters. Recent Riemannian manifold Hamiltonian Monte Carlo (RMHMC)methods have significant potential advantages in this setting, but arecomputationally expensive. We introduce a new RMHMC method, which we callsemi-separable Hamiltonian Monte Carlo, which uses a specially designed massmatrix that allows the joint Hamiltonian over model parameters andhyperparameters to decompose into two simpler Hamiltonians. This structure isexploited by a new integrator which we call the alternating blockwise leapfrogalgorithm. The resulting method can mix faster than simpler Gibbs samplingwhile being simpler and more efficient than previous instances of RMHMC.
arxiv-7200-78 | Simultaneous Model Selection and Optimization through Parameter-free Stochastic Learning | http://arxiv.org/abs/1406.3816 | author:Francesco Orabona category:cs.LG stat.ML published:2014-06-15 summary:Stochastic gradient descent algorithms for training linear and kernelpredictors are gaining more and more importance, thanks to their scalability.While various methods have been proposed to speed up their convergence, themodel selection phase is often ignored. In fact, in theoretical works most ofthe time assumptions are made, for example, on the prior knowledge of the normof the optimal solution, while in the practical world validation methods remainthe only viable approach. In this paper, we propose a new kernel-basedstochastic gradient descent algorithm that performs model selection whiletraining, with no parameters to tune, nor any form of cross-validation. Thealgorithm builds on recent advancement in online learning theory forunconstrained settings, to estimate over time the right regularization in adata-dependent way. Optimal rates of convergence are proved under standardsmoothness assumptions on the target function, using the range space of thefractional integral operator associated with the kernel.
arxiv-7200-79 | Optimal Resource Allocation with Semi-Bandit Feedback | http://arxiv.org/abs/1406.3840 | author:Tor Lattimore, Koby Crammer, Csaba Szepesvári category:cs.LG published:2014-06-15 summary:We study a sequential resource allocation problem involving a fixed number ofrecurring jobs. At each time-step the manager should distribute availableresources among the jobs in order to maximise the expected number of completedjobs. Allocating more resources to a given job increases the probability thatit completes, but with a cut-off. Specifically, we assume a linear model wherethe probability increases linearly until it equals one, after which allocatingadditional resources is wasteful. We assume the difficulty of each job isunknown and present the first algorithm for this problem and prove upper andlower bounds on its regret. Despite its apparent simplicity, the problem has arich structure: we show that an appropriate optimistic algorithm can improveits learning speed dramatically beyond the results one normally expects forsimilar problems as the problem becomes resource-laden.
arxiv-7200-80 | An Incremental Reseeding Strategy for Clustering | http://arxiv.org/abs/1406.3837 | author:Xavier Bresson, Huiyi Hu, Thomas Laurent, Arthur Szlam, James von Brecht category:stat.ML cs.LG published:2014-06-15 summary:In this work we propose a simple and easily parallelizable algorithm formultiway graph partitioning. The algorithm alternates between three basiccomponents: diffusing seed vertices over the graph, thresholding the diffusedseeds, and then randomly reseeding the thresholded clusters. We demonstrateexperimentally that the proper combination of these ingredients leads to analgorithm that achieves state-of-the-art performance in terms of cluster purityon standard benchmarks datasets. Moreover, the algorithm runs an order ofmagnitude faster than the other algorithms that achieve comparable results interms of accuracy. We also describe a coarsen, cluster and refine approachsimilar to GRACLUS and METIS that removes an additional order of magnitude fromthe runtime of our algorithm while still maintaining competitive accuracy.
arxiv-7200-81 | A Heuristic Method to Generate Better Initial Population for Evolutionary Methods | http://arxiv.org/abs/1406.4518 | author:Erfan Khaji, Amin Satlikh Mohammadi category:cs.NE published:2014-06-15 summary:Initial population plays an important role in heuristic algorithms such as GAas it help to decrease the time those algorithms need to achieve an acceptableresult. Furthermore, it may influence the quality of the final answer given byevolutionary algorithms. In this paper, we shall introduce a heuristic methodto generate a target based initial population which possess two mentionedcharacteristics. The efficiency of the proposed method has been shown bypresenting the results of our tests on the benchmarks.
arxiv-7200-82 | Modelling, Visualising and Summarising Documents with a Single Convolutional Neural Network | http://arxiv.org/abs/1406.3830 | author:Misha Denil, Alban Demiraj, Nal Kalchbrenner, Phil Blunsom, Nando de Freitas category:cs.CL cs.LG stat.ML published:2014-06-15 summary:Capturing the compositional process which maps the meaning of words to thatof documents is a central challenge for researchers in Natural LanguageProcessing and Information Retrieval. We introduce a model that is able torepresent the meaning of documents by embedding them in a low dimensionalvector space, while preserving distinctions of word and sentence order crucialfor capturing nuanced semantics. Our model is based on an extended DynamicConvolution Neural Network, which learns convolution filters at both thesentence and document level, hierarchically learning to capture and compose lowlevel lexical features into high level semantic concepts. We demonstrate theeffectiveness of this model on a range of document modelling tasks, achievingstrong results with no feature engineering and with a more compact model.Inspired by recent advances in visualising deep convolution networks forcomputer vision, we present a novel visualisation technique for our documentnetworks which not only provides insight into their learning process, but alsocan be interpreted to produce a compelling automatic summarisation system fortexts.
arxiv-7200-83 | Analyzing Social and Stylometric Features to Identify Spear phishing Emails | http://arxiv.org/abs/1406.3692 | author:Prateek Dewan, Anand Kashyap, Ponnurangam Kumaraguru category:cs.CY cs.LG cs.SI published:2014-06-14 summary:Spear phishing is a complex targeted attack in which, an attacker harvestsinformation about the victim prior to the attack. This information is then usedto create sophisticated, genuine-looking attack vectors, drawing the victim tocompromise confidential information. What makes spear phishing different, andmore powerful than normal phishing, is this contextual information about thevictim. Online social media services can be one such source for gathering vitalinformation about an individual. In this paper, we characterize and examine atrue positive dataset of spear phishing, spam, and normal phishing emails fromSymantec's enterprise email scanning service. We then present a model to detectspear phishing emails sent to employees of 14 international organizations, byusing social features extracted from LinkedIn. Our dataset consists of 4,742targeted attack emails sent to 2,434 victims, and 9,353 non targeted attackemails sent to 5,912 non victims; and publicly available information from theirLinkedIn profiles. We applied various machine learning algorithms to thislabeled data, and achieved an overall maximum accuracy of 97.76% in identifyingspear phishing emails. We used a combination of social features from LinkedInprofiles, and stylometric features extracted from email subjects, bodies, andattachments. However, we achieved a slightly better accuracy of 98.28% withoutthe social features. Our analysis revealed that social features extracted fromLinkedIn do not help in identifying spear phishing emails. To the best of ourknowledge, this is one of the first attempts to make use of a combination ofstylometric features extracted from emails, and social features extracted froman online social network to detect targeted spear phishing emails.
arxiv-7200-84 | Evaluation of Machine Learning Techniques for Green Energy Prediction | http://arxiv.org/abs/1406.3726 | author:Ankur Sahai category:cs.LG published:2014-06-14 summary:We evaluate the following Machine Learning techniques for Green Energy (Wind,Solar) Prediction: Bayesian Inference, Neural Networks, Support VectorMachines, Clustering techniques (PCA). Our objective is to predict green energyusing weather forecasts, predict deviations from forecast green energy, findcorrelation amongst different weather parameters and green energy availability,recover lost or missing energy (/ weather) data. We use historical weather dataand weather forecasts for the same.
arxiv-7200-85 | Question Answering with Subgraph Embeddings | http://arxiv.org/abs/1406.3676 | author:Antoine Bordes, Sumit Chopra, Jason Weston category:cs.CL published:2014-06-14 summary:This paper presents a system which learns to answer questions on a broadrange of topics from a knowledge base using few hand-crafted features. Ourmodel learns low-dimensional embeddings of words and knowledge baseconstituents; these representations are used to score natural languagequestions against candidate answers. Training our system using pairs ofquestions and structured representations of their answers, and pairs ofquestion paraphrases, yields competitive results on a competitive benchmark ofthe literature.
arxiv-7200-86 | Dimensionality reduction for time series data | http://arxiv.org/abs/1406.3711 | author:Diego Vidaurre, Iead Rezek, Samuel L. Harrison, Stephen S. Smith, Mark Woolrich category:stat.ML published:2014-06-14 summary:Despite the fact that they do not consider the temporal nature of data,classic dimensionality reduction techniques, such as PCA, are widely applied totime series data. In this paper, we introduce a factor decomposition specificfor time series that builds upon the Bayesian multivariate autoregressive modeland hence evades the assumption that data points are mutually independent. Thekey is to find a low-rank estimation of the autoregressive matrices. As in theprobabilistic version of other factor models, this induces a latentlow-dimensional representation of the original data. We discuss some possiblegeneralisations and alternatives, with the most relevant being a technique forsimultaneous smoothing and dimensionality reduction. To illustrate thepotential applications, we apply the model on a synthetic data set anddifferent types of neuroimaging data (EEG and ECoG).
arxiv-7200-87 | From Stochastic Mixability to Fast Rates | http://arxiv.org/abs/1406.3781 | author:Nishant A. Mehta, Robert C. Williamson category:cs.LG stat.ML published:2014-06-14 summary:Empirical risk minimization (ERM) is a fundamental learning rule forstatistical learning problems where the data is generated according to someunknown distribution $\mathsf{P}$ and returns a hypothesis $f$ chosen from afixed class $\mathcal{F}$ with small loss $\ell$. In the parametric setting,depending upon $(\ell, \mathcal{F},\mathsf{P})$ ERM can have slow$(1/\sqrt{n})$ or fast $(1/n)$ rates of convergence of the excess risk as afunction of the sample size $n$. There exist several results that givesufficient conditions for fast rates in terms of joint properties of $\ell$,$\mathcal{F}$, and $\mathsf{P}$, such as the margin condition and the Bernsteincondition. In the non-statistical prediction with expert advice setting, thereis an analogous slow and fast rate phenomenon, and it is entirely characterizedin terms of the mixability of the loss $\ell$ (there being no role there for$\mathcal{F}$ or $\mathsf{P}$). The notion of stochastic mixability builds abridge between these two models of learning, reducing to classical mixabilityin a special case. The present paper presents a direct proof of fast rates forERM in terms of stochastic mixability of $(\ell,\mathcal{F}, \mathsf{P})$, andin so doing provides new insight into the fast-rates phenomenon. The proofexploits an old result of Kemperman on the solution to the general momentproblem. We also show a partial converse that suggests a characterization offast rates for ERM in terms of stochastic mixability is possible.
arxiv-7200-88 | Mining of product reviews at aspect level | http://arxiv.org/abs/1406.3714 | author:Richa Sharma, Shweta Nigam, Rekha Jain category:cs.CL cs.IR published:2014-06-14 summary:Todays world is a world of Internet, almost all work can be done with thehelp of it, from simple mobile phone recharge to biggest business deals can bedone with the help of this technology. People spent their most of the times onsurfing on the Web it becomes a new source of entertainment, education,communication, shopping etc. Users not only use these websites but also givetheir feedback and suggestions that will be useful for other users. In this waya large amount of reviews of users are collected on the Web that needs to beexplored, analyse and organized for better decision making. Opinion Mining orSentiment Analysis is a Natural Language Processing and Information Extractiontask that identifies the users views or opinions explained in the form ofpositive, negative or neutral comments and quotes underlying the text. Aspectbased opinion mining is one of the level of Opinion mining that determines theaspect of the given reviews and classify the review for each feature. In thispaper an aspect based opinion mining system is proposed to classify the reviewsas positive, negative and neutral for each feature. Negation is also handled inthe proposed system. Experimental results using reviews of products show theeffectiveness of the system.
arxiv-7200-89 | Restricted Boltzmann Machine for Classification with Hierarchical Correlated Prior | http://arxiv.org/abs/1406.3407 | author:Gang Chen, Sargur H. Srihari category:cs.LG 68T10 I.2.6 published:2014-06-13 summary:Restricted Boltzmann machines (RBM) and its variants have become hot researchtopics recently, and widely applied to many classification problems, such ascharacter recognition and document categorization. Often, classification RBMignores the interclass relationship or prior knowledge of sharing informationamong classes. In this paper, we are interested in RBM with the hierarchicalprior over classes. We assume parameters for nearby nodes are correlated in thehierarchical tree, and further the parameters at each node of the tree beorthogonal to those at its ancestors. We propose a hierarchical correlated RBMfor classification problem, which generalizes the classification RBM withsharing information among different classes. In order to reduce the redundancybetween node parameters in the hierarchy, we also introduce orthogonalrestrictions to our objective function. We test our method on challengedatasets, and show promising results compared to competitive baselines.
arxiv-7200-90 | PRISM: Person Re-Identification via Structured Matching | http://arxiv.org/abs/1406.4444 | author:Ziming Zhang, Venkatesh Saligrama category:cs.CV cs.LG stat.ML published:2014-06-13 summary:Person re-identification (re-id), an emerging problem in visual surveillance,deals with maintaining entities of individuals whilst they traverse variouslocations surveilled by a camera network. From a visual perspective re-id ischallenging due to significant changes in visual appearance of individuals incameras with different pose, illumination and calibration. Globally thechallenge arises from the need to maintain structurally consistent matchesamong all the individual entities across different camera views. We proposePRISM, a structured matching method to jointly account for these challenges. Weview the global problem as a weighted graph matching problem and estimate edgeweights by learning to predict them based on the co-occurrences of visualpatterns in the training examples. These co-occurrence based scores in turnaccount for appearance changes by inferring likely and unlikely visualco-occurrences appearing in training instances. We implement PRISM on singleshot and multi-shot scenarios. PRISM uniformly outperforms state-of-the-art interms of matching rate while being computationally efficient.
arxiv-7200-91 | LOCO: Distributing Ridge Regression with Random Projections | http://arxiv.org/abs/1406.3469 | author:Christina Heinze, Brian McWilliams, Nicolai Meinshausen, Gabriel Krummenacher category:stat.ML published:2014-06-13 summary:We propose LOCO, an algorithm for large-scale ridge regression whichdistributes the features across workers on a cluster. Important dependenciesbetween variables are preserved using structured random projections which arecheap to compute and must only be communicated once. We show that LOCO obtainsa solution which is close to the exact ridge regression solution in the fixeddesign setting. We verify this experimentally in a simulation study as well asan application to climate prediction. Furthermore, we show that LOCO achievessignificant speedups compared with a state-of-the-art distributed algorithm ona large-scale regression problem.
arxiv-7200-92 | Quaternion Gradient and Hessian | http://arxiv.org/abs/1406.3587 | author:Dongpo Xu, Danilo P. Mandic category:math.NA cs.LG published:2014-06-13 summary:The optimization of real scalar functions of quaternion variables, such asthe mean square error or array output power, underpins many practicalapplications. Solutions often require the calculation of the gradient andHessian, however, real functions of quaternion variables are essentiallynon-analytic. To address this issue, we propose new definitions of quaterniongradient and Hessian, based on the novel generalized HR (GHR) calculus, thusmaking possible efficient derivation of optimization algorithms directly in thequaternion field, rather than transforming the problem to the real domain, asis current practice. In addition, unlike the existing quaternion gradients, theGHR calculus allows for the product and chain rule, and for a one-to-onecorrespondence of the proposed quaternion gradient and Hessian with their realcounterparts. Properties of the quaternion gradient and Hessian relevant tonumerical applications are elaborated, and the results illuminate theusefulness of the GHR calculus in greatly simplifying the derivation of thequaternion least mean squares, and in quaternion least square and Newtonalgorithm. The proposed gradient and Hessian are also shown to enable the samegeneric forms as the corresponding real- and complex-valued algorithms, furtherillustrating the advantages in algorithm design and evaluation.
arxiv-7200-93 | Smoothed Gradients for Stochastic Variational Inference | http://arxiv.org/abs/1406.3650 | author:Stephan Mandt, David Blei category:stat.ML cs.LG published:2014-06-13 summary:Stochastic variational inference (SVI) lets us scale up Bayesian computationto massive data. It uses stochastic optimization to fit a variationaldistribution, following easy-to-compute noisy natural gradients. As with mosttraditional stochastic optimization methods, SVI takes precautions to useunbiased stochastic gradients whose expectations are equal to the truegradients. In this paper, we explore the idea of following biased stochasticgradients in SVI. Our method replaces the natural gradient with a similarlyconstructed vector that uses a fixed-window moving average of some of itsprevious terms. We will demonstrate the many advantages of this technique.First, its computational cost is the same as for SVI and storage requirementsonly multiply by a constant factor. Second, it enjoys significant variancereduction over the unbiased estimates, smaller bias than averaged gradients,and leads to smaller mean-squared error against the full gradient. We test ourmethod on latent Dirichlet allocation with three large corpora.
arxiv-7200-94 | RAPID: Rapidly Accelerated Proximal Gradient Algorithms for Convex Minimization | http://arxiv.org/abs/1406.4445 | author:Ziming Zhang, Venkatesh Saligrama category:stat.ML cs.LG math.OC published:2014-06-13 summary:In this paper, we propose a new algorithm to speed-up the convergence ofaccelerated proximal gradient (APG) methods. In order to minimize a convexfunction $f(\mathbf{x})$, our algorithm introduces a simple line search stepafter each proximal gradient step in APG so that a biconvex function$f(\theta\mathbf{x})$ is minimized over scalar variable $\theta>0$ while fixingvariable $\mathbf{x}$. We propose two new ways of constructing the auxiliaryvariables in APG based on the intermediate solutions of the proximal gradientand the line search steps. We prove that at arbitrary iteration step $t(t\geq1)$, our algorithm can achieve a smaller upper-bound for the gap betweenthe current and optimal objective values than those in the traditional APGmethods such as FISTA, making it converge faster in practice. In fact, ouralgorithm can be potentially applied to many important convex optimizationproblems, such as sparse linear regression and kernel SVMs. Our experimentalresults clearly demonstrate that our algorithm converges faster than APG in allof the applications above, even comparable to some sophisticated solvers.
arxiv-7200-95 | Multi-objective Reinforcement Learning with Continuous Pareto Frontier Approximation Supplementary Material | http://arxiv.org/abs/1406.3497 | author:Matteo Pirotta, Simone Parisi, Marcello Restelli category:cs.AI cs.LG published:2014-06-13 summary:This document contains supplementary material for the paper "Multi-objectiveReinforcement Learning with Continuous Pareto Frontier Approximation",published at the Twenty-Ninth AAAI Conference on Artificial Intelligence(AAAI-15). The paper is about learning a continuous approximation of the Paretofrontier in Multi-Objective Markov Decision Problems (MOMDPs). We propose apolicy-based approach that exploits gradient information to generate solutionsclose to the Pareto ones. Differently from previous policy-gradientmulti-objective algorithms, where n optimization routines are use to have nsolutions, our approach performs a single gradient-ascent run that at each stepgenerates an improved continuous approximation of the Pareto frontier. The ideais to exploit a gradient-based approach to optimize the parameters of afunction that defines a manifold in the policy parameter space so that thecorresponding image in the objective space gets as close as possible to thePareto frontier. Besides deriving how to compute and estimate such gradient, wewill also discuss the non-trivial issue of defining a metric to assess thequality of the candidate Pareto frontiers. Finally, the properties of theproposed approach are empirically evaluated on two interesting MOMDPs.
arxiv-7200-96 | Fingers' Angle Calculation using Level-Set Method | http://arxiv.org/abs/1406.3418 | author:Ankit Chaudhary, J. L. Raheja, K. Das, S. Raheja category:cs.CV published:2014-06-13 summary:In the current age, use of natural communication in human computerinteraction is a known and well installed thought. Hand gesture recognition andgesture based applications has gained a significant amount of popularityamongst people all over the world. It has a number of applications ranging fromsecurity to entertainment. These applications generally are real timeapplications and need fast, accurate communication with machines. On the otherend, gesture based communications have few limitations also like bent fingerinformation is not provided in vision based techniques. In this paper, a novelmethod for fingertip detection and for angle calculation of both hands bentfingers is discussed. Angle calculation has been done before with sensor basedgloves/devices. This study has been conducted in the context of naturalcomputing for calculating angles without using any wired equipment, colors,marker or any device. The pre-processing and segmentation of the region ofinterest is performed in a HSV color space and a binary format respectively.Fingertips are detected using level-set method and angles were calculated usinggeometrical analysis. This technique requires no training for system to performthe task.
arxiv-7200-97 | EigenEvent: An Algorithm for Event Detection from Complex Data Streams in Syndromic Surveillance | http://arxiv.org/abs/1406.3496 | author:Hadi Fanaee-T, João Gama category:cs.AI cs.LG stat.AP published:2014-06-13 summary:Syndromic surveillance systems continuously monitor multiple pre-diagnosticdaily streams of indicators from different regions with the aim of earlydetection of disease outbreaks. The main objective of these systems is todetect outbreaks hours or days before the clinical and laboratory confirmation.The type of data that is being generated via these systems is usuallymultivariate and seasonal with spatial and temporal dimensions. The algorithmWhat's Strange About Recent Events (WSARE) is the state-of-the-art method forsuch problems. It exhaustively searches for contrast sets in the multivariatedata and signals an alarm when find statistically significant rules. Thisbottom-up approach presents a much lower detection delay comparing the existingtop-down approaches. However, WSARE is very sensitive to the small-scalechanges and subsequently comes with a relatively high rate of false alarms. Wepropose a new approach called EigenEvent that is neither fully top-down norbottom-up. In this method, we instead of top-down or bottom-up search, trackchanges in data correlation structure via eigenspace techniques. This newmethodology enables us to detect both overall changes (via eigenvalue) anddimension-level changes (via eigenvectors). Experimental results on hundredsets of benchmark data reveals that EigenEvent presents a better overallperformance comparing state-of-the-art, in particular in terms of the falsealarm rate.
arxiv-7200-98 | Heterogeneous Multi-task Learning for Human Pose Estimation with Deep Convolutional Neural Network | http://arxiv.org/abs/1406.3474 | author:Sijin Li, Zhi-Qiang Liu, Antoni B. Chan category:cs.CV cs.LG cs.NE published:2014-06-13 summary:We propose an heterogeneous multi-task learning framework for human poseestimation from monocular image with deep convolutional neural network. Inparticular, we simultaneously learn a pose-joint regressor and a sliding-windowbody-part detector in a deep network architecture. We show that including thebody-part detection task helps to regularize the network, directing it toconverge to a good solution. We report competitive and state-of-art results onseveral data sets. We also empirically show that the learned neurons in themiddle layer of our network are tuned to localized body parts.
arxiv-7200-99 | Are Style Guides Controlled Languages? The Case of Koenig & Bauer AG | http://arxiv.org/abs/1406.3460 | author:Karolina Suchowolec category:cs.CL published:2014-06-13 summary:Controlled natural languages for industrial application are often regarded asa response to the challenges of translation and multilingual communication.This paper presents a quite different approach taken by Koenig & Bauer AG,where the main goal was the improvement of the authoring process for technicaldocumentation. Most importantly, this paper explores the notion of a controlledlanguage and demonstrates how style guides can emerge from non-linguisticconsiderations. Moreover, it shows the transition from loose languagerecommendations into precise and prescriptive rules and investigates whethersuch rules can be regarded as a full-fledged controlled language.
arxiv-7200-100 | Evolutionary Robotics on the Web with WebGL and Javascript | http://arxiv.org/abs/1406.3337 | author:Jared Moore, Anthony Clark, Philip McKinley category:cs.NE cs.HC published:2014-06-12 summary:Web-based applications are highly accessible to users, providing rich,interactive content while eliminating the need to install software locally.However, evolutionary robotics (ER) has faced challenges in this domain asweb-based technologies have not been amenable to 3D physics simulations.Traditionally, physics-based simulations require a local installation and ahigh degree of user knowledge to configure an environment, but the emergence ofJavascript-based physics engines enables complex simulations to be executed inweb browsers. These developments create opportunities for ER research to reachnew audiences by increasing accessibility. In this work, we introduce twoweb-based tools we have built to facilitate the exchange of ideas with otherresearchers as well as outreach to K-12 students and the general public. Thefirst tool is intended to distribute and exchange ER research results, whilethe second is a completely browser-based implementation of an ER environment.
arxiv-7200-101 | Fast and Robust Least Squares Estimation in Corrupted Linear Models | http://arxiv.org/abs/1406.3175 | author:Brian McWilliams, Gabriel Krummenacher, Mario Lucic, Joachim M. Buhmann category:stat.ML published:2014-06-12 summary:Subsampling methods have been recently proposed to speed up least squaresestimation in large scale settings. However, these algorithms are typically notrobust to outliers or corruptions in the observed covariates. The concept of influence that was developed for regression diagnostics can beused to detect such corrupted observations as shown in this paper. Thisproperty of influence -- for which we also develop a randomized approximation-- motivates our proposed subsampling algorithm for large scale corruptedlinear regression which limits the influence of data points since highlyinfluential points contribute most to the residual error. Under a general modelof corrupted observations, we show theoretically and empirically on a varietyof simulated and real datasets that our algorithm improves over the currentstate-of-the-art approximation schemes for ordinary least squares.
arxiv-7200-102 | Expressive Power and Approximation Errors of Restricted Boltzmann Machines | http://arxiv.org/abs/1406.3140 | author:Guido Montufar, Johannes Rauh, Nihat Ay category:stat.ML math.PR 82C32, 68Q99 published:2014-06-12 summary:We present explicit classes of probability distributions that can be learnedby Restricted Boltzmann Machines (RBMs) depending on the number of units thatthey contain, and which are representative for the expressive power of themodel. We use this to show that the maximal Kullback-Leibler divergence to theRBM model with $n$ visible and $m$ hidden units is bounded from above by $n -\left\lfloor \log(m+1) \right\rfloor -\frac{m+1}{2^{\left\lfloor\log(m+1)\right\rfloor}} \approx (n -1) - \log(m+1)$.In this way we can specify the number of hidden units that guarantees asufficiently rich model containing different classes of distributions andrespecting a given error tolerance.
arxiv-7200-103 | Learning ELM network weights using linear discriminant analysis | http://arxiv.org/abs/1406.3100 | author:Philip de Chazal, Jonathan Tapson, André van Schaik category:cs.NE cs.LG stat.ML published:2014-06-12 summary:We present an alternative to the pseudo-inverse method for determining thehidden to output weight values for Extreme Learning Machines performingclassification tasks. The method is based on linear discriminant analysis andprovides Bayes optimal single point estimates for the weight values.
arxiv-7200-104 | Deep Neural Networks Rival the Representation of Primate IT Cortex for Core Visual Object Recognition | http://arxiv.org/abs/1406.3284 | author:Charles F. Cadieu, Ha Hong, Daniel L. K. Yamins, Nicolas Pinto, Diego Ardila, Ethan A. Solomon, Najib J. Majaj, James J. DiCarlo category:q-bio.NC cs.NE published:2014-06-12 summary:The primate visual system achieves remarkable visual object recognitionperformance even in brief presentations and under changes to object exemplar,geometric transformations, and background variation (a.k.a. core visual objectrecognition). This remarkable performance is mediated by the representationformed in inferior temporal (IT) cortex. In parallel, recent advances inmachine learning have led to ever higher performing models of objectrecognition using artificial deep neural networks (DNNs). It remains unclear,however, whether the representational performance of DNNs rivals that of thebrain. To accurately produce such a comparison, a major difficulty has been aunifying metric that accounts for experimental limitations such as the amountof noise, the number of neural recording sites, and the number trials, andcomputational limitations such as the complexity of the decoding classifier andthe number of classifier training examples. In this work we perform a directcomparison that corrects for these experimental limitations and computationalconsiderations. As part of our methodology, we propose an extension of "kernelanalysis" that measures the generalization accuracy as a function ofrepresentational complexity. Our evaluations show that, unlike previousbio-inspired models, the latest DNNs rival the representational performance ofIT cortex on this visual object recognition task. Furthermore, we show thatmodels that perform well on measures of representational performance alsoperform well on measures of representational similarity to IT and on measuresof predicting individual IT multi-unit responses. Whether these DNNs rely oncomputational mechanisms similar to the primate visual system is yet to bedetermined, but, unlike all previous bio-inspired models, that possibilitycannot be ruled out merely on representational performance grounds.
arxiv-7200-105 | A Cascade Neural Network Architecture investigating Surface Plasmon Polaritons propagation for thin metals in OpenMP | http://arxiv.org/abs/1406.3149 | author:Francesco Bonanno, Giacomo Capizzi, Grazia Lo Sciuto, Christian Napoli, Giuseppe Pappalardo, Emiliano Tramontana category:cs.NE cs.DC cs.LG 68T05 published:2014-06-12 summary:Surface plasmon polaritons (SPPs) confined along metal-dielectric interfacehave attracted a relevant interest in the area of ultracompact photoniccircuits, photovoltaic devices and other applications due to their strong fieldconfinement and enhancement. This paper investigates a novel cascade neuralnetwork (NN) architecture to find the dependance of metal thickness on the SPPpropagation. Additionally, a novel training procedure for the proposed cascadeNN has been developed using an OpenMP-based framework, thus greatly reducingtraining time. The performed experiments confirm the effectiveness of theproposed NN architecture for the problem at hand.
arxiv-7200-106 | Online Optimization for Large-Scale Max-Norm Regularization | http://arxiv.org/abs/1406.3190 | author:Jie Shen, Huan Xu, Ping Li category:stat.ML cs.LG published:2014-06-12 summary:Max-norm regularizer has been extensively studied in the last decade as itpromotes an effective low-rank estimation for the underlying data. However,such max-norm regularized problems are typically formulated and solved in abatch manner, which prevents it from processing big data due to possible memorybudget. In this paper, hence, we propose an online algorithm that is scalableto large-scale setting. Particularly, we consider the matrix decompositionproblem as an example, although a simple variant of the algorithm and analysiscan be adapted to other important problems such as matrix completion. Thecrucial technique in our implementation is to reformulating the max-norm to anequivalent matrix factorization form, where the factors consist of a (possiblyovercomplete) basis component and a coefficients one. In this way, we maymaintain the basis component in the memory and optimize over it and thecoefficients for each sample alternatively. Since the memory footprint of thebasis component is independent of the sample size, our algorithm is appealingwhen manipulating a large collection of samples. We prove that the sequence ofthe solutions (i.e., the basis component) produced by our algorithm convergesto a stationary point of the expected loss function asymptotically. Numericalstudy demonstrates encouraging results for the efficacy and robustness of ouralgorithm compared to the widely used nuclear norm solvers.
arxiv-7200-107 | Generalization and Robustness of Batched Weighted Average Algorithm with V-geometrically Ergodic Markov Data | http://arxiv.org/abs/1406.3166 | author:Nguyen Viet Cuong, Lam Si Tung Ho, Vu Dinh category:stat.ML published:2014-06-12 summary:We analyze the generalization and robustness of the batched weighted averagealgorithm for V-geometrically ergodic Markov data. This algorithm is a goodalternative to the empirical risk minimization algorithm when the lattersuffers from overfitting or when optimizing the empirical risk is hard. For thegeneralization of the algorithm, we prove a PAC-style bound on the trainingsample size for the expected $L_1$-loss to converge to the optimal loss whentraining data are V-geometrically ergodic Markov chains. For the robustness, weshow that if the training target variable's values contain bounded noise, thenthe generalization bound of the algorithm deviates at most by the range of thenoise. Our results can be applied to the regression problem, the classificationproblem, and the case where there exists an unknown deterministic targethypothesis.
arxiv-7200-108 | A swarm optimization algorithm inspired in the behavior of the social-spider | http://arxiv.org/abs/1406.3282 | author:Erik Cuevas, Miguel Cienfuegos, Daniel Zaldivar, Marco Perez category:cs.NE published:2014-06-12 summary:Swarm intelligence is a research field that models the collective behavior inswarms of insects or animals. Several algorithms arising from such models havebeen proposed to solve a wide range of complex optimization problems. In thispaper, a novel swarm algorithm called the Social Spider Optimization (SSO) isproposed for solving optimization tasks. The SSO algorithm is based on thesimulation of cooperative behavior of social-spiders. In the proposedalgorithm, individuals emulate a group of spiders which interact to each otherbased on the biological laws of the cooperative colony. The algorithm considerstwo different search agents (spiders): males and females. Depending on gender,each individual is conducted by a set of different evolutionary operators whichmimic different cooperative behaviors that are typically found in the colony.In order to illustrate the proficiency and robustness of the proposed approach,it is compared to other well-known evolutionary methods. The comparisonexamines several standard benchmark functions that are commonly consideredwithin the literature of evolutionary algorithms. The outcome shows a highperformance of the proposed method for searching a global optimum with severalbenchmark functions.
arxiv-7200-109 | Scheduled denoising autoencoders | http://arxiv.org/abs/1406.3269 | author:Krzysztof J. Geras, Charles Sutton category:cs.LG stat.ML published:2014-06-12 summary:We present a representation learning method that learns features at multipledifferent levels of scale. Working within the unsupervised framework ofdenoising autoencoders, we observe that when the input is heavily corruptedduring training, the network tends to learn coarse-grained features, whereaswhen the input is only slightly corrupted, the network tends to learnfine-grained features. This motivates the scheduled denoising autoencoder,which starts with a high level of noise that lowers as training progresses. Wefind that the resulting representation yields a significant boost on a latersupervised task compared to the original input, or to a standard denoisingautoencoder trained at a single noise level. After supervised fine-tuning ourbest model achieves the lowest ever reported error on the CIFAR-10 data setamong permutation-invariant methods.
arxiv-7200-110 | A hybrid neuro--wavelet predictor for QoS control and stability | http://arxiv.org/abs/1406.3156 | author:Christian Napoli, Giuseppe Pappalardo, Emiliano Tramontana category:cs.NE cs.DC cs.NI cs.PF cs.SY 68T05 published:2014-06-12 summary:For distributed systems to properly react to peaks of requests, theiradaptation activities would benefit from the estimation of the amount ofrequests. This paper proposes a solution to produce a short-term forecast basedon data characterising user behaviour of online services. We use \emph{waveletanalysis}, providing compression and denoising on the observed time series ofthe amount of past user requests; and a \emph{recurrent neural network} trainedwith observed data and designed so as to provide well-timed estimations offuture requests. The said ensemble has the ability to predict the amount offuture user requests with a root mean squared error below 0.06\%. Thanks toprediction, advance resource provision can be performed for the duration of arequest peak and for just the right amount of resources, hence avoidingover-provisioning and associated costs. Moreover, reliable provision lets usersenjoy a level of availability of services unaffected by load variations.
arxiv-7200-111 | What is India speaking: The "Hinglish" invasion | http://arxiv.org/abs/1406.4824 | author:Rana D. Parshad, Vineeta Chand, Neha Sinha, Nitu Kumari category:cs.CL math.DS published:2014-06-12 summary:While language competition models of diachronic language shift areincreasingly sophisticated, drawing on sociolinguistic components like variablelanguage prestige, distance from language centers and intermediate bilingualtransitionary populations, in one significant way they fall short. They fail toconsider contact-based outcomes resulting in mixed language practices, e.g.outcome scenarios such as creoles or unmarked code switching as an emergentcommunicative norm. On these lines something very interesting is uncovered inIndia, where traditionally there have been monolingual Hindi speakers andHindi/English bilinguals, but virtually no monolingual English speakers. Whilethe Indian census data reports a sharp increase in the proportion ofHindi/English bilinguals, we argue that the number of Hindi/English bilingualsin India is inaccurate, given a new class of urban individuals speaking a mixedlect of Hindi and English, popularly known as "Hinglish". Based onpredator-prey, sociolinguistic theories, salient local ecological factors andthe rural-urban divide in India, we propose a new mathematical model ofinteracting monolingual Hindi speakers, Hindi/English bilinguals and Hinglishspeakers. The model yields globally asymptotic stable states of coexistence, aswell as bilingual extinction. To validate our model, sociolinguistic data fromdifferent Indian classes are contrasted with census reports: We see thatpurported urban Hindi/English bilinguals are unable to maintain fluent Hindispeech and instead produce Hinglish, whereas rural speakers evidencemonolingual Hindi. Thus we present evidence for the first time where anunrecognized mixed lect involving English but not "English", has possibly takenover a sizeable faction of a large global population.
arxiv-7200-112 | A Clustering Analysis of Tweet Length and its Relation to Sentiment | http://arxiv.org/abs/1406.3287 | author:Matthew Mayo category:cs.CL cs.IR cs.SI published:2014-06-12 summary:Sentiment analysis of Twitter data is performed. The researcher has made thefollowing contributions via this paper: (1) an innovative method for derivingsentiment score dictionaries using an existing sentiment dictionary as seedwords is explored, and (2) an analysis of clustered tweet sentiment scoresbased on tweet length is performed.
arxiv-7200-113 | Convolutional Kernel Networks | http://arxiv.org/abs/1406.3332 | author:Julien Mairal, Piotr Koniusz, Zaid Harchaoui, Cordelia Schmid category:cs.CV cs.LG stat.ML published:2014-06-12 summary:An important goal in visual recognition is to devise image representationsthat are invariant to particular transformations. In this paper, we addressthis goal with a new type of convolutional neural network (CNN) whoseinvariance is encoded by a reproducing kernel. Unlike traditional approacheswhere neural networks are learned either to represent data or for solving aclassification task, our network learns to approximate the kernel feature mapon training data. Such an approach enjoys several benefits over classical ones.First, by teaching CNNs to be invariant, we obtain simple network architecturesthat achieve a similar accuracy to more complex ones, while being easy to trainand robust to overfitting. Second, we bridge a gap between the neural networkliterature and kernels, which are natural tools to model invariance. Weevaluate our methodology on visual recognition tasks where CNNs have proven toperform well, e.g., digit recognition with the MNIST dataset, and the morechallenging CIFAR-10 and STL-10 datasets, where our accuracy is competitivewith the state of the art.
arxiv-7200-114 | Truncated Nuclear Norm Minimization for Image Restoration Based On Iterative Support Detection | http://arxiv.org/abs/1406.2969 | author:Yilun Wang, Xinhua Su category:cs.CV cs.LG stat.ML published:2014-06-11 summary:Recovering a large matrix from limited measurements is a challenging taskarising in many real applications, such as image inpainting, compressivesensing and medical imaging, and this kind of problems are mostly formulated aslow-rank matrix approximation problems. Due to the rank operator beingnon-convex and discontinuous, most of the recent theoretical studies use thenuclear norm as a convex relaxation and the low-rank matrix recovery problem issolved through minimization of the nuclear norm regularized problem. However, amajor limitation of nuclear norm minimization is that all the singular valuesare simultaneously minimized and the rank may not be well approximated\cite{hu2012fast}. Correspondingly, in this paper, we propose a new multi-stagealgorithm, which makes use of the concept of Truncated Nuclear NormRegularization (TNNR) proposed in \citep{hu2012fast} and Iterative SupportDetection (ISD) proposed in \citep{wang2010sparse} to overcome the abovelimitation. Besides matrix completion problems considered in\citep{hu2012fast}, the proposed method can be also extended to the generallow-rank matrix recovery problems. Extensive experiments well validate thesuperiority of our new algorithms over other state-of-the-art methods.
arxiv-7200-115 | POS Tagging and its Applications for Mathematics | http://arxiv.org/abs/1406.2880 | author:Ulf Schöneberg, Wolfram Sperber category:cs.DL cs.CL cs.IR published:2014-06-11 summary:Content analysis of scientific publications is a nontrivial task, but auseful and important one for scientific information services. In the Gutenbergera it was a domain of human experts; in the digital age many machine-basedmethods, e.g., graph analysis tools and machine-learning techniques, have beendeveloped for it. Natural Language Processing (NLP) is a powerfulmachine-learning approach to semiautomatic speech and language processing,which is also applicable to mathematics. The well established methods of NLPhave to be adjusted for the special needs of mathematics, in particular forhandling mathematical formulae. We demonstrate a mathematics-aware part ofspeech tagger and give a short overview about our adaptation of NLP methods formathematical publications. We show the use of the tools developed for keyphrase extraction and classification in the database zbMATH.
arxiv-7200-116 | A machine-compiled macroevolutionary history of Phanerozoic life | http://arxiv.org/abs/1406.2963 | author:Shanan E. Peters, Ce Zhang, Miron Livny, Christopher Ré category:cs.DB cs.CL cs.LG q-bio.PE published:2014-06-11 summary:Many aspects of macroevolutionary theory and our understanding of bioticresponses to global environmental change derive from literature-basedcompilations of palaeontological data. Existing manually assembled databasesare, however, incomplete and difficult to assess and enhance. Here, we developand validate the quality of a machine reading system, PaleoDeepDive, thatautomatically locates and extracts data from heterogeneous text, tables, andfigures in publications. PaleoDeepDive performs comparably to humans in complexdata extraction and inference tasks and generates congruent syntheticmacroevolutionary results. Unlike traditional databases, PaleoDeepDive producesa probabilistic database that systematically improves as information is added.We also show that the system can readily accommodate sophisticated data types,such as morphological data in biological illustrations and associated textualdescriptions. Our machine reading approach to scientific data integration andsynthesis brings within reach many questions that are currently underdeterminedand does so in ways that may stimulate entirely new modes of inquiry.
arxiv-7200-117 | Explicit Computation of Input Weights in Extreme Learning Machines | http://arxiv.org/abs/1406.2889 | author:Jonathan Tapson, Philip de Chazal, André van Schaik category:cs.NE published:2014-06-11 summary:We present a closed form expression for initializing the input weights in amulti-layer perceptron, which can be used as the first step in synthesis of anExtreme Learning Ma-chine. The expression is based on the standard function fora separating hyperplane as computed in multilayer perceptrons and linearSupport Vector Machines; that is, as a linear combination of input datasamples. In the absence of supervised training for the input weights, randomlinear combinations of training data samples are used to project the input datato a higher dimensional hidden layer. The hidden layer weights are solved inthe standard ELM fashion by computing the pseudoinverse of the hidden layeroutputs and multiplying by the desired output values. All weights for thismethod can be computed in a single pass, and the resulting networks are moreaccurate and more consistent on some standard problems than regular ELMnetworks of the same size.
arxiv-7200-118 | Joint Training of a Convolutional Network and a Graphical Model for Human Pose Estimation | http://arxiv.org/abs/1406.2984 | author:Jonathan Tompson, Arjun Jain, Yann LeCun, Christoph Bregler category:cs.CV published:2014-06-11 summary:This paper proposes a new hybrid architecture that consists of a deepConvolutional Network and a Markov Random Field. We show how this architectureis successfully applied to the challenging problem of articulated human poseestimation in monocular images. The architecture can exploit structural domainconstraints such as geometric relationships between body joint locations. Weshow that joint training of these two model paradigms improves performance andallows us to significantly outperform existing state-of-the-art techniques.
arxiv-7200-119 | Acoustic Gait-based Person Identification using Hidden Markov Models | http://arxiv.org/abs/1406.2895 | author:Jürgen T. Geiger, Maximilian Kneißl, Björn Schuller, Gerhard Rigoll category:cs.HC cs.CV published:2014-06-11 summary:We present a system for identifying humans by their walking sounds. Thisproblem is also known as acoustic gait recognition. The goal of the system isto analyse sounds emitted by walking persons (mostly the step sounds) andidentify those persons. These sounds are characterised by the gait pattern andare influenced by the movements of the arms and legs, but also depend on thetype of shoe. We extract cepstral features from the recorded audio signals anduse hidden Markov models for dynamic classification. A cyclic model topology isemployed to represent individual gait cycles. This topology allows to model anddetect individual steps, leading to very promising identification rates. Forexperimental validation, we use the publicly available TUM GAID database, whichis a large gait recognition database containing 3050 recordings of 305 subjectsin three variations. In the best setup, an identification rate of 65.5 % isachieved out of 155 subjects. This is a relative improvement of almost 30 %compared to our previous work, which used various audio features and supportvector machines.
arxiv-7200-120 | Algebraic-Combinatorial Methods for Low-Rank Matrix Completion with Application to Athletic Performance Prediction | http://arxiv.org/abs/1406.2864 | author:Duncan A. J. Blythe, Louis Theran, Franz Kiraly category:stat.ML published:2014-06-11 summary:This paper presents novel algorithms which exploit the intrinsic algebraicand combinatorial structure of the matrix completion task for estimatingmissing en- tries in the general low rank setting. For positive data, weachieve results out- performing the state of the art nuclear norm, both inaccuracy and computational efficiency, in simulations and in the task ofpredicting athletic performance from partially observed data.
arxiv-7200-121 | Distributed Parameter Estimation in Probabilistic Graphical Models | http://arxiv.org/abs/1406.3070 | author:Yariv Dror Mizrahi, Misha Denil, Nando de Freitas category:stat.ML published:2014-06-11 summary:This paper presents foundational theoretical results on distributed parameterestimation for undirected probabilistic graphical models. It introduces ageneral condition on composite likelihood decompositions of these models whichguarantees the global consistency of distributed estimators, provided the localestimators are consistent.
arxiv-7200-122 | A Hitchhiker's Guide to Search-Based Software Engineering for Software Product Lines | http://arxiv.org/abs/1406.2823 | author:Roberto E. Lopez-Herrejon, Javier Ferrer, Francisco Chicano, Lukas Linsbauer, Alexander Egyed, Enrique Alba category:cs.SE cs.NE published:2014-06-11 summary:Search Based Software Engineering (SBSE) is an emerging discipline thatfocuses on the application of search-based optimization techniques to softwareengineering problems. The capacity of SBSE techniques to tackle problemsinvolving large search spaces make their application attractive for SoftwareProduct Lines (SPLs). In recent years, several publications have appeared thatapply SBSE techniques to SPL problems. In this paper, we present the results ofa systematic mapping study of such publications. We identified the stages ofthe SPL life cycle where SBSE techniques have been used, what case studies havebeen employed and how they have been analysed. This mapping study revealedpotential venues for further research as well as common misunderstanding andpitfalls when applying SBSE techniques that we address by providing a guidelinefor researchers and practitioners interested in exploiting these techniques.
arxiv-7200-123 | A Brief State of the Art for Ontology Authoring | http://arxiv.org/abs/1406.2903 | author:Hazem Safwat, Brian Davis category:cs.CL published:2014-06-11 summary:One of the main challenges for building the Semantic web is OntologyAuthoring. Controlled Natural Languages CNLs offer a user friendly means fornon-experts to author ontologies. This paper provides a snapshot of thestate-of-the-art for the core CNLs for ontology authoring and reviews theirrespective evaluations.
arxiv-7200-124 | Provable Tensor Factorization with Missing Data | http://arxiv.org/abs/1406.2784 | author:Prateek Jain, Sewoong Oh category:stat.ML published:2014-06-11 summary:We study the problem of low-rank tensor factorization in the presence ofmissing data. We ask the following question: how many sampled entries do weneed, to efficiently and exactly reconstruct a tensor with a low-rankorthogonal decomposition? We propose a novel alternating minimization basedmethod which iteratively refines estimates of the singular vectors. We showthat under certain standard assumptions, our method can recover a three-mode$n\times n\times n$ dimensional rank-$r$ tensor exactly from $O(n^{3/2} r^5\log^4 n)$ randomly sampled entries. In the process of proving this result, wesolve two challenging sub-problems for tensors with missing data. First, in theprocess of analyzing the initialization step, we prove a generalization of acelebrated result by Szemer\'edie et al. on the spectrum of random graphs.Next, we prove global convergence of alternating minimization with a goodinitialization. Simulations suggest that the dependence of the sample size ondimensionality $n$ is indeed tight.
arxiv-7200-125 | "Mental Rotation" by Optimizing Transforming Distance | http://arxiv.org/abs/1406.3010 | author:Weiguang Ding, Graham W. Taylor category:cs.LG cs.CV published:2014-06-11 summary:The human visual system is able to recognize objects despite transformationsthat can drastically alter their appearance. To this end, much effort has beendevoted to the invariance properties of recognition systems. Invariance can beengineered (e.g. convolutional nets), or learned from data explicitly (e.g.temporal coherence) or implicitly (e.g. by data augmentation). One idea thathas not, to date, been explored is the integration of latent variables whichpermit a search over a learned space of transformations. Motivated by evidencethat people mentally simulate transformations in space while comparingexamples, so-called "mental rotation", we propose a transforming distance.Here, a trained relational model actively transforms pairs of examples so thatthey are maximally similar in some feature space yet respect the learnedtransformational constraints. We apply our method to nearest-neighbour problemson the Toronto Face Database and NORB.
arxiv-7200-126 | Bird Species Categorization Using Pose Normalized Deep Convolutional Nets | http://arxiv.org/abs/1406.2952 | author:Steve Branson, Grant Van Horn, Serge Belongie, Pietro Perona category:cs.CV published:2014-06-11 summary:We propose an architecture for fine-grained visual categorization thatapproaches expert human performance in the classification of bird species. Ourarchitecture first computes an estimate of the object's pose; this is used tocompute local image features which are, in turn, used for classification. Thefeatures are computed by applying deep convolutional nets to image patches thatare located and normalized by the pose. We perform an empirical study of anumber of pose normalization schemes, including an investigation of higherorder geometric warping functions. We propose a novel graph-based clusteringalgorithm for learning a compact pose normalization space. We perform adetailed investigation of state-of-the-art deep convolutional featureimplementations and fine-tuning feature learning for fine-grainedclassification. We observe that a model that integrates lower-level featurelayers with pose-normalized extraction routines and higher-level feature layerswith unaligned image features works best. Our experiments advancestate-of-the-art performance on bird species recognition, with a largeimprovement of correct classification rates over previous methods (75% vs.55-65%).
arxiv-7200-127 | The Poisson transform for unnormalised statistical models | http://arxiv.org/abs/1406.2839 | author:Simon Barthelmé, Nicolas Chopin category:stat.CO stat.ML 62F99 G.3 published:2014-06-11 summary:Contrary to standard statistical models, unnormalised statistical models onlyspecify the likelihood function up to a constant. While such models are naturaland popular, the lack of normalisation makes inference much more difficult.Here we show that inferring the parameters of a unnormalised model on a space$\Omega$ can be mapped onto an equivalent problem of estimating the intensityof a Poisson point process on $\Omega$. The unnormalised statistical model nowspecifies an intensity function that does not need to be normalised.Effectively, the normalisation constant may now be inferred as just anotherparameter, at no loss of information. The result can be extended to covernon-IID models, which includes for example unnormalised models for sequences ofgraphs (dynamical graphs), or for sequences of binary vectors. As aconsequence, we prove that unnormalised parameteric inference in non-IID modelscan be turned into a semi-parametric estimation problem. Moreover, we show thatthe noise-contrastive divergence of Gutmann & Hyv\"arinen (2012) can beunderstood as an approximation of the Poisson transform, and extended tonon-IID settings. We use our results to fit spatial Markov chain models of eyemovements, where the Poisson transform allows us to turn a highly non-standardmodel into vanilla semi-parametric logistic regression.
arxiv-7200-128 | Techniques for Learning Binary Stochastic Feedforward Neural Networks | http://arxiv.org/abs/1406.2989 | author:Tapani Raiko, Mathias Berglund, Guillaume Alain, Laurent Dinh category:stat.ML cs.LG cs.NE published:2014-06-11 summary:Stochastic binary hidden units in a multi-layer perceptron (MLP) network giveat least three potential benefits when compared to deterministic MLP networks.(1) They allow to learn one-to-many type of mappings. (2) They can be used instructured prediction problems, where modeling the internal structure of theoutput is important. (3) Stochasticity has been shown to be an excellentregularizer, which makes generalization performance potentially better ingeneral. However, training stochastic networks is considerably more difficult.We study training using M samples of hidden activations per input. We show thatthe case M=1 leads to a fundamentally different behavior where the networktries to avoid stochasticity. We propose two new estimators for the traininggradient and propose benchmark tests for comparing training algorithms. Ourexperiments confirm that training stochastic networks is difficult and showthat the proposed two estimators perform favorably among all the five knownestimators.
arxiv-7200-129 | The Secrets of Salient Object Segmentation | http://arxiv.org/abs/1406.2807 | author:Yin Li, Xiaodi Hou, Christof Koch, James M. Rehg, Alan L. Yuille category:cs.CV published:2014-06-11 summary:In this paper we provide an extensive evaluation of fixation prediction andsalient object segmentation algorithms as well as statistics of major datasets.Our analysis identifies serious design flaws of existing salient objectbenchmarks, called the dataset design bias, by over emphasizing thestereotypical concepts of saliency. The dataset design bias does not onlycreate the discomforting disconnection between fixations and salient objectsegmentation, but also misleads the algorithm designing. Based on our analysis,we propose a new high quality dataset that offers both fixation and salientobject segmentation ground-truth. With fixations and salient object beingpresented simultaneously, we are able to bridge the gap between fixations andsalient objects, and propose a novel method for salient object segmentation.Finally, we report significant benchmark progress on three existing datasets ofsegmenting salient objects
arxiv-7200-130 | Reweighted Wake-Sleep | http://arxiv.org/abs/1406.2751 | author:Jörg Bornschein, Yoshua Bengio category:cs.LG published:2014-06-11 summary:Training deep directed graphical models with many hidden variables andperforming inference remains a major challenge. Helmholtz machines and deepbelief networks are such models, and the wake-sleep algorithm has been proposedto train them. The wake-sleep algorithm relies on training not just thedirected generative model but also a conditional generative model (theinference network) that runs backward from visible to latent, estimating theposterior distribution of latent given visible. We propose a novelinterpretation of the wake-sleep algorithm which suggests that betterestimators of the gradient can be obtained by sampling latent variablesmultiple times from the inference network. This view is based on importancesampling as an estimator of the likelihood, with the approximate inferencenetwork as a proposal distribution. This interpretation is confirmedexperimentally, showing that better likelihood can be achieved with thisreweighted wake-sleep procedure. Based on this interpretation, we propose thata sigmoidal belief network is not sufficiently powerful for the layers of theinference network in order to recover a good estimator of the posteriordistribution of latent variables. Our experiments show that using a morepowerful layer model, such as NADE, yields substantially better generativemodels.
arxiv-7200-131 | Maximizing Diversity for Multimodal Optimization | http://arxiv.org/abs/1406.2539 | author:Fabricio Olivetti de Franca category:cs.NE published:2014-06-10 summary:Most multimodal optimization algorithms use the so called \textit{nichingmethods}~\cite{mahfoud1995niching} in order to promote diversity duringoptimization, while others, like \textit{Artificial ImmuneSystems}~\cite{de2010conceptual} try to find multiple solutions as its mainobjective. One of such algorithms, called\textit{dopt-aiNet}~\cite{de2005artificial}, introduced the Line Distance thatmeasures the distance between two solutions regarding their basis ofattraction. In this short abstract I propose the use of the Line Distancemeasure as the main objective-function in order to locate multiple optima atonce in a population.
arxiv-7200-132 | Why do linear SVMs trained on HOG features perform so well? | http://arxiv.org/abs/1406.2419 | author:Hilton Bristow, Simon Lucey category:cs.CV cs.LG published:2014-06-10 summary:Linear Support Vector Machines trained on HOG features are now a de factostandard across many visual perception tasks. Their popularisation can largelybe attributed to the step-change in performance they brought to pedestriandetection, and their subsequent successes in deformable parts models. Thispaper explores the interactions that make the HOG-SVM symbiosis perform sowell. By connecting the feature extraction and learning processes rather thantreating them as disparate plugins, we show that HOG features can be viewed asdoing two things: (i) inducing capacity in, and (ii) adding prior to a linearSVM trained on pixels. From this perspective, preserving second-orderstatistics and locality of interactions are key to good performance. Wedemonstrate surprising accuracy on expression recognition and pedestriandetection tasks, by assuming only the importance of preserving such localsecond-order interactions.
arxiv-7200-133 | Predictive Entropy Search for Efficient Global Optimization of Black-box Functions | http://arxiv.org/abs/1406.2541 | author:José Miguel Hernández-Lobato, Matthew W. Hoffman, Zoubin Ghahramani category:stat.ML cs.LG published:2014-06-10 summary:We propose a novel information-theoretic approach for Bayesian optimizationcalled Predictive Entropy Search (PES). At each iteration, PES selects the nextevaluation point that maximizes the expected information gained with respect tothe global maximum. PES codifies this intractable acquisition function in termsof the expected reduction in the differential entropy of the predictivedistribution. This reformulation allows PES to obtain approximations that areboth more accurate and efficient than other alternatives such as Entropy Search(ES). Furthermore, PES can easily perform a fully Bayesian treatment of themodel hyperparameters while ES cannot. We evaluate PES in both synthetic andreal-world applications, including optimization problems in machine learning,finance, biotechnology, and robotics. We show that the increased accuracy ofPES leads to significant gains in optimization performance.
arxiv-7200-134 | A Flexible Fitness Function for Community Detection in Complex Networks | http://arxiv.org/abs/1406.2545 | author:Fabricio Olivetti de Franca, Guilherme Palermo Coelho category:cs.NE cs.SI physics.soc-ph published:2014-06-10 summary:Most community detection algorithms from the literature work as optimizationtools that minimize a given \textit{fitness function}, while assuming that eachnode belongs to a single community. Since there is no hard concept of what acommunity is, most proposed fitness functions focus on a particular definition.As such, these functions do not always lead to partitions that correspond tothose observed in practice. This paper proposes a new flexible fitness functionthat allows the identification of communities with distinct characteristics.Such flexibility was evaluated through the adoption of an immune-inspiredoptimization algorithm, named cob-aiNet[C], to identify both disjoint andoverlapping communities in a set of benchmark networks. The results have shownthat the obtained partitions are much closer to the ground-truth than thoseobtained by the optimization of the modularity function.
arxiv-7200-135 | Optimization Methods for Convolutional Sparse Coding | http://arxiv.org/abs/1406.2407 | author:Hilton Bristow, Simon Lucey category:cs.CV published:2014-06-10 summary:Sparse and convolutional constraints form a natural prior for manyoptimization problems that arise from physical processes. Detecting motifs inspeech and musical passages, super-resolving images, compressing videos, andreconstructing harmonic motions can all leverage redundancies introduced byconvolution. Solving problems involving sparse and convolutional constraintsremains a difficult computational problem, however. In this paper we present anoverview of convolutional sparse coding in a consistent framework. Theobjective involves iteratively optimizing a convolutional least-squares termfor the basis functions, followed by an L1-regularized least squares term forthe sparse coefficients. We discuss a range of optimization methods for solvingthe convolutional sparse coding objective, and the properties that make eachmethod suitable for different applications. In particular, we concentrate oncomputational complexity, speed to {\epsilon} convergence, memory usage, andthe effect of implied boundary conditions. We present a broad suite of examplescovering different signal and application domains to illustrate the generalapplicability of convolutional sparse coding, and the efficacy of the availableoptimization methods.
arxiv-7200-136 | Identifying and attacking the saddle point problem in high-dimensional non-convex optimization | http://arxiv.org/abs/1406.2572 | author:Yann Dauphin, Razvan Pascanu, Caglar Gulcehre, Kyunghyun Cho, Surya Ganguli, Yoshua Bengio category:cs.LG math.OC stat.ML published:2014-06-10 summary:A central challenge to many fields of science and engineering involvesminimizing non-convex error functions over continuous, high dimensional spaces.Gradient descent or quasi-Newton methods are almost ubiquitously used toperform such minimizations, and it is often thought that a main source ofdifficulty for these local methods to find the global minimum is theproliferation of local minima with much higher error than the global minimum.Here we argue, based on results from statistical physics, random matrix theory,neural network theory, and empirical evidence, that a deeper and more profounddifficulty originates from the proliferation of saddle points, not localminima, especially in high dimensional problems of practical interest. Suchsaddle points are surrounded by high error plateaus that can dramatically slowdown learning, and give the illusory impression of the existence of a localminimum. Motivated by these arguments, we propose a new approach tosecond-order optimization, the saddle-free Newton method, that can rapidlyescape high dimensional saddle points, unlike gradient descent and quasi-Newtonmethods. We apply this algorithm to deep or recurrent neural network training,and provide numerical evidence for its superior optimization performance.
arxiv-7200-137 | Controlled Natural Language Generation from a Multilingual FrameNet-based Grammar | http://arxiv.org/abs/1406.2400 | author:Dana Dannélls, Normunds Grūzītis category:cs.CL published:2014-06-10 summary:This paper presents a currently bilingual but potentially multilingualFrameNet-based grammar library implemented in Grammatical Framework. Thecontribution of this paper is two-fold. First, it offers a methodologicalapproach to automatically generate the grammar based on semantico-syntacticvalence patterns extracted from FrameNet-annotated corpora. Second, it providesa proof of concept for two use cases illustrating how the acquired multilingualgrammar can be exploited in different CNL applications in the domains of artsand tourism.
arxiv-7200-138 | FrameNet CNL: a Knowledge Representation and Information Extraction Language | http://arxiv.org/abs/1406.2538 | author:Guntis Barzdins category:cs.CL cs.AI cs.IR cs.LG published:2014-06-10 summary:The paper presents a FrameNet-based information extraction and knowledgerepresentation framework, called FrameNet-CNL. The framework is used on naturallanguage documents and represents the extracted knowledge in a tailor-madeFrame-ontology from which unambiguous FrameNet-CNL paraphrase text can begenerated automatically in multiple languages. This approach brings togetherthe fields of information extraction and CNL, because a source text can beconsidered belonging to FrameNet-CNL, if information extraction parser producesthe correct knowledge representation as a result. We describe astate-of-the-art information extraction parser used by a national news agencyand speculate that FrameNet-CNL eventually could shape the natural languagesubset used for writing the newswire articles.
arxiv-7200-139 | ExpertBayes: Automatically refining manually built Bayesian networks | http://arxiv.org/abs/1406.2395 | author:Ezilda Almeida, Pedro Ferreira, Tiago Vinhoza, Inês Dutra, Jingwei Li, Yirong Wu, Elizabeth Burnside category:cs.AI cs.LG stat.ML published:2014-06-10 summary:Bayesian network structures are usually built using only the data andstarting from an empty network or from a naive Bayes structure. Very often, insome domains, like medicine, a prior structure knowledge is already known. Thisstructure can be automatically or manually refined in search for betterperformance models. In this work, we take Bayesian networks built byspecialists and show that minor perturbations to this original network canyield better classifiers with a very small computational cost, whilemaintaining most of the intended meaning of the original model.
arxiv-7200-140 | WebAL-1: Workshop on Artificial Life and the Web 2014 Proceedings | http://arxiv.org/abs/1406.2507 | author:Tim Taylor category:cs.NE cs.MA published:2014-06-10 summary:Proceedings of WebAL-1: Workshop on Artificial Life and the Web 2014, held atthe 14th International Conference on the Synthesis and Simulation of LivingSystems (ALIFE 14), New York, NY, 31 July 2014.
arxiv-7200-141 | Denosing Using Wavelets and Projections onto the L1-Ball | http://arxiv.org/abs/1406.2528 | author:A. Enis Cetin, Mohammad Tofighi category:math.OC cs.CV published:2014-06-10 summary:Both wavelet denoising and denosing methods using the concept of sparsity arebased on soft-thresholding. In sparsity based denoising methods, it is assumedthat the original signal is sparse in some transform domains such as thewavelet domain and the wavelet subsignals of the noisy signal are projectedonto L1-balls to reduce noise. In this lecture note, it is shown that the sizeof the L1-ball or equivalently the soft threshold value can be determined usinglinear algebra. The key step is an orthogonal projection onto the epigraph setof the L1-norm cost function.
arxiv-7200-142 | Exploring Algorithmic Limits of Matrix Rank Minimization under Affine Constraints | http://arxiv.org/abs/1406.2504 | author:Bo Xin, David Wipf category:cs.LG stat.ML published:2014-06-10 summary:Many applications require recovering a matrix of minimal rank within anaffine constraint set, with matrix completion a notable special case. Becausethe problem is NP-hard in general, it is common to replace the matrix rank withthe nuclear norm, which acts as a convenient convex surrogate. While eleganttheoretical conditions elucidate when this replacement is likely to besuccessful, they are highly restrictive and convex algorithms fail when theambient rank is too high or when the constraint set is poorly structured.Non-convex alternatives fare somewhat better when carefully tuned; however,convergence to locally optimal solutions remains a continuing source offailure. Against this backdrop we derive a deceptively simple andparameter-free probabilistic PCA-like algorithm that is capable, over a widebattery of empirical tests, of successful recovery even at the theoreticallimit where the number of measurements equal the degrees of freedom in theunknown low-rank matrix. Somewhat surprisingly, this is possible even when theaffine constraint set is highly ill-conditioned. While proving general recoveryguarantees remains evasive for non-convex algorithms, Bayesian-inspired orotherwise, we nonetheless show conditions whereby the underlying cost functionhas a unique stationary point located at the global optimum; no existing costfunction we are aware of satisfies this same property. We conclude with asimple computer vision application involving image rectification and a standardcollaborative filtering benchmark.
arxiv-7200-143 | Identification of Orchid Species Using Content-Based Flower Image Retrieval | http://arxiv.org/abs/1406.2580 | author:D. H. Apriyanti, A. A. Arymurthy, L. T. Handoko category:cs.CV cs.IR cs.LG published:2014-06-10 summary:In this paper, we developed the system for recognizing the orchid species byusing the images of flower. We used MSRM (Maximal Similarity based on RegionMerging) method for segmenting the flower object from the background andextracting the shape feature such as the distance from the edge to the centroidpoint of the flower, aspect ratio, roundness, moment invariant, fractaldimension and also extract color feature. We used HSV color feature withignoring the V value. To retrieve the image, we used Support Vector Machine(SVM) method. Orchid is a unique flower. It has a part of flower called lip(labellum) that distinguishes it from other flowers even from other types oforchids. Thus, in this paper, we proposed to do feature extraction not only onflower region but also on lip (labellum) region. The result shows that ourproposed method can increase the accuracy value of content based flower imageretrieval for orchid species up to $\pm$ 14%. The most dominant feature isCentroid Contour Distance, Moment Invariant and HSV Color. The system accuracyis 85,33% in validation phase and 79,33% in testing phase.
arxiv-7200-144 | Graph Approximation and Clustering on a Budget | http://arxiv.org/abs/1406.2602 | author:Ethan Fetaya, Ohad Shamir, Shimon Ullman category:stat.ML cs.AI cs.CV cs.LG published:2014-06-10 summary:We consider the problem of learning from a similarity matrix (such asspectral clustering and lowd imensional embedding), when computing pairwisesimilarities are costly, and only a limited number of entries can be observed.We provide a theoretical analysis using standard notions of graphapproximation, significantly generalizing previous results (which focused onspectral clustering with two clusters). We also propose a new algorithmicapproach based on adaptive sampling, which experimentally matches or improveson previous methods, while being considerably more general and computationallycheaper.
arxiv-7200-145 | PlanIt: A Crowdsourcing Approach for Learning to Plan Paths from Large Scale Preference Feedback | http://arxiv.org/abs/1406.2616 | author:Ashesh Jain, Debarghya Das, Jayesh K Gupta, Ashutosh Saxena category:cs.RO cs.AI cs.LG published:2014-06-10 summary:We consider the problem of learning user preferences over robot trajectoriesfor environments rich in objects and humans. This is challenging because thecriterion defining a good trajectory varies with users, tasks and interactionsin the environment. We represent trajectory preferences using a cost functionthat the robot learns and uses it to generate good trajectories in newenvironments. We design a crowdsourcing system - PlanIt, where non-expert userslabel segments of the robot's trajectory. PlanIt allows us to collect a largeamount of user feedback, and using the weak and noisy labels from PlanIt welearn the parameters of our model. We test our approach on 122 differentenvironments for robotic navigation and manipulation tasks. Our extensiveexperiments show that the learned cost function generates preferredtrajectories in human environments. Our crowdsourcing system is publiclyavailable for the visualization of the learned costs and for providingpreference feedback: \url{http://planit.cs.cornell.edu}
arxiv-7200-146 | Equivalence of Learning Algorithms | http://arxiv.org/abs/1406.2622 | author:Julien Audiffren, Hachem Kadri category:cs.LG stat.ML published:2014-06-10 summary:The purpose of this paper is to introduce a concept of equivalence betweenmachine learning algorithms. We define two notions of algorithmic equivalence,namely, weak and strong equivalence. These notions are of paramount importancefor identifying when learning prop erties from one learning algorithm can betransferred to another. Using regularized kernel machines as a case study, weillustrate the importance of the introduced equivalence concept by analyzingthe relation between kernel ridge regression (KRR) and m-power regularizedleast squares regression (M-RLSR) algorithms.
arxiv-7200-147 | Learning with Cross-Kernels and Ideal PCA | http://arxiv.org/abs/1406.2646 | author:Franz J Király, Martin Kreuzer, Louis Theran category:cs.LG math.AC stat.ML published:2014-06-10 summary:We describe how cross-kernel matrices, that is, kernel matrices between thedata and a custom chosen set of `feature spanning points' can be used forlearning. The main potential of cross-kernels lies in the fact that (a) onlyone side of the matrix scales with the number of data points, and (b)cross-kernels, as opposed to the usual kernel matrices, can be used to certifyfor the data manifold. Our theoretical framework, which is based on a dualityinvolving the feature space and vanishing ideals, indicates that cross-kernelshave the potential to be used for any kind of kernel learning. We present anovel algorithm, Ideal PCA (IPCA), which cross-kernelizes PCA. We demonstrateon real and synthetic data that IPCA allows to (a) obtain PCA-like featuresfaster and (b) to extract novel and empirically validated features certifyingfor the data manifold.
arxiv-7200-148 | Generative Adversarial Networks | http://arxiv.org/abs/1406.2661 | author:Ian J. Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair, Aaron Courville, Yoshua Bengio category:stat.ML cs.LG published:2014-06-10 summary:We propose a new framework for estimating generative models via anadversarial process, in which we simultaneously train two models: a generativemodel G that captures the data distribution, and a discriminative model D thatestimates the probability that a sample came from the training data rather thanG. The training procedure for G is to maximize the probability of D making amistake. This framework corresponds to a minimax two-player game. In the spaceof arbitrary functions G and D, a unique solution exists, with G recovering thetraining data distribution and D equal to 1/2 everywhere. In the case where Gand D are defined by multilayer perceptrons, the entire system can be trainedwith backpropagation. There is no need for any Markov chains or unrolledapproximate inference networks during either training or generation of samples.Experiments demonstrate the potential of the framework through qualitative andquantitative evaluation of the generated samples.
arxiv-7200-149 | Conceptors: an easy introduction | http://arxiv.org/abs/1406.2671 | author:Herbert Jaeger category:cs.NE published:2014-06-10 summary:Conceptors provide an elementary neuro-computational mechanism which sheds afresh and unifying light on a diversity of cognitive phenomena. A number ofdemanding learning and processing tasks can be solved with unprecedented ease,robustness and accuracy. Some of these tasks were impossible to solve before.This entirely informal paper introduces the basic principles of conceptors andhighlights some of their usages.
arxiv-7200-150 | A Multiplicative Model for Learning Distributed Text-Based Attribute Representations | http://arxiv.org/abs/1406.2710 | author:Ryan Kiros, Richard S. Zemel, Ruslan Salakhutdinov category:cs.LG cs.CL published:2014-06-10 summary:In this paper we propose a general framework for learning distributedrepresentations of attributes: characteristics of text whose representationscan be jointly learned with word embeddings. Attributes can correspond todocument indicators (to learn sentence vectors), language indicators (to learndistributed language representations), meta-data and side information (such asthe age, gender and industry of a blogger) or representations of authors. Wedescribe a third-order model where word context and attribute vectors interactmultiplicatively to predict the next word in a sequence. This leads to thenotion of conditional word similarity: how meanings of words change whenconditioned on different attributes. We perform several experimental tasksincluding sentiment classification, cross-lingual document classification, andblog authorship attribution. We also qualitatively evaluate conditional wordneighbours and attribute-conditioned text generation.
arxiv-7200-151 | Learning Latent Variable Gaussian Graphical Models | http://arxiv.org/abs/1406.2721 | author:Zhaoshi Meng, Brian Eriksson, Alfred O. Hero III category:stat.ML cs.LG math.ST stat.TH published:2014-06-10 summary:Gaussian graphical models (GGM) have been widely used in manyhigh-dimensional applications ranging from biological and financial data torecommender systems. Sparsity in GGM plays a central role both statisticallyand computationally. Unfortunately, real-world data often does not fit well tosparse graphical models. In this paper, we focus on a family of latent variableGaussian graphical models (LVGGM), where the model is conditionally sparsegiven latent variables, but marginally non-sparse. In LVGGM, the inversecovariance matrix has a low-rank plus sparse structure, and can be learned in aregularized maximum likelihood framework. We derive novel parameter estimationerror bounds for LVGGM under mild conditions in the high-dimensional setting.These results complement the existing theory on the structural learning, andopen up new possibilities of using LVGGM for statistical inference.
arxiv-7200-152 | Deep Epitomic Convolutional Neural Networks | http://arxiv.org/abs/1406.2732 | author:George Papandreou category:cs.CV cs.LG published:2014-06-10 summary:Deep convolutional neural networks have recently proven extremely competitivein challenging image recognition tasks. This paper proposes the epitomicconvolution as a new building block for deep neural networks. An epitomicconvolution layer replaces a pair of consecutive convolution and max-poolinglayers found in standard deep convolutional neural networks. The main versionof the proposed model uses mini-epitomes in place of filters and computesresponses invariant to small translations by epitomic search instead ofmax-pooling over image positions. The topographic version of the proposed modeluses large epitomes to learn filter maps organized in translationaltopographies. We show that error back-propagation can successfully learnmultiple epitomic layers in a supervised fashion. The effectiveness of theproposed method is assessed in image classification tasks on standardbenchmarks. Our experiments on Imagenet indicate improved recognitionperformance compared to standard convolutional neural networks of similararchitecture. Our models pre-trained on Imagenet perform excellently onCaltech-101. We also obtain competitive image classification results on thesmall-image MNIST and CIFAR-10 datasets.
arxiv-7200-153 | Maximum Likelihood-based Online Adaptation of Hyper-parameters in CMA-ES | http://arxiv.org/abs/1406.2623 | author:Ilya Loshchilov, Marc Schoenauer, Michèle Sebag, Nikolaus Hansen category:cs.NE cs.AI published:2014-06-10 summary:The Covariance Matrix Adaptation Evolution Strategy (CMA-ES) is widelyaccepted as a robust derivative-free continuous optimization algorithm fornon-linear and non-convex optimization problems. CMA-ES is well known to bealmost parameterless, meaning that only one hyper-parameter, the populationsize, is proposed to be tuned by the user. In this paper, we propose aprincipled approach called self-CMA-ES to achieve the online adaptation ofCMA-ES hyper-parameters in order to improve its overall performance.Experimental results show that for larger-than-default population size, thedefault settings of hyper-parameters of CMA-ES are far from being optimal, andthat self-CMA-ES allows for dynamically approaching optimal settings.
arxiv-7200-154 | Probabilistic ODE Solvers with Runge-Kutta Means | http://arxiv.org/abs/1406.2582 | author:Michael Schober, David Duvenaud, Philipp Hennig category:stat.ML cs.LG cs.NA math.NA published:2014-06-10 summary:Runge-Kutta methods are the classic family of solvers for ordinarydifferential equations (ODEs), and the basis for the state of the art. Likemost numerical methods, they return point estimates. We construct a family ofprobabilistic numerical methods that instead return a Gauss-Markov processdefining a probability distribution over the ODE solution. In contrast to priorwork, we construct this family such that posterior means match the outputs ofthe Runge-Kutta family exactly, thus inheriting their proven good properties.Remaining degrees of freedom not identified by the match to Runge-Kutta arechosen such that the posterior probability measure fits the observed structureof the ODE. Our results shed light on the structure of Runge-Kutta solvers froma new direction, provide a richer, probabilistic output, have low computationalcost, and raise new research questions.
arxiv-7200-155 | Mondrian Forests: Efficient Online Random Forests | http://arxiv.org/abs/1406.2673 | author:Balaji Lakshminarayanan, Daniel M. Roy, Yee Whye Teh category:stat.ML cs.LG published:2014-06-10 summary:Ensembles of randomized decision trees, usually referred to as randomforests, are widely used for classification and regression tasks in machinelearning and statistics. Random forests achieve competitive predictiveperformance and are computationally efficient to train and test, making themexcellent candidates for real-world prediction tasks. The most popular randomforest variants (such as Breiman's random forest and extremely randomizedtrees) operate on batches of training data. Online methods are now in greaterdemand. Existing online random forests, however, require more training datathan their batch counterpart to achieve comparable predictive performance. Inthis work, we use Mondrian processes (Roy and Teh, 2009) to construct ensemblesof random decision trees we call Mondrian forests. Mondrian forests can begrown in an incremental/online fashion and remarkably, the distribution ofonline Mondrian forests is the same as that of batch Mondrian forests. Mondrianforests achieve competitive predictive performance comparable with existingonline random forests and periodically re-trained batch random forests, whilebeing more than an order of magnitude faster, thus representing a bettercomputation vs accuracy tradeoff.
arxiv-7200-156 | Budget-Constrained Item Cold-Start Handling in Collaborative Filtering Recommenders via Optimal Design | http://arxiv.org/abs/1406.2431 | author:Oren Anava, Shahar Golan, Nadav Golbandi, Zohar Karnin, Ronny Lempel, Oleg Rokhlenko, Oren Somekh category:cs.IR cs.LG 62K05 published:2014-06-10 summary:It is well known that collaborative filtering (CF) based recommender systemsprovide better modeling of users and items associated with considerable ratinghistory. The lack of historical ratings results in the user and the itemcold-start problems. The latter is the main focus of this work. Most of thecurrent literature addresses this problem by integrating content-basedrecommendation techniques to model the new item. However, in many cases suchcontent is not available, and the question arises is whether this problem canbe mitigated using CF techniques only. We formalize this problem as anoptimization problem: given a new item, a pool of available users, and a budgetconstraint, select which users to assign with the task of rating the new itemin order to minimize the prediction error of our model. We show that theobjective function is monotone-supermodular, and propose efficient optimaldesign based algorithms that attain an approximation to its optimum. Ourfindings are verified by an empirical study using the Netflix dataset, wherethe proposed algorithms outperform several baselines for the problem at hand.
arxiv-7200-157 | Training Convolutional Networks with Noisy Labels | http://arxiv.org/abs/1406.2080 | author:Sainbayar Sukhbaatar, Joan Bruna, Manohar Paluri, Lubomir Bourdev, Rob Fergus category:cs.CV cs.LG cs.NE published:2014-06-09 summary:The availability of large labeled datasets has allowed Convolutional Networkmodels to achieve impressive recognition results. However, in many settingsmanual annotation of the data is impractical; instead our data has noisylabels, i.e. there is some freely available label for each image which may ormay not be accurate. In this paper, we explore the performance ofdiscriminatively-trained Convnets when trained on such noisy data. We introducean extra noise layer into the network which adapts the network outputs to matchthe noisy label distribution. The parameters of this noise layer can beestimated as part of the training process and involve simple modifications tocurrent training infrastructures for deep networks. We demonstrate theapproaches on several datasets, including large scale experiments on theImageNet classification benchmark.
arxiv-7200-158 | Reducing the Effects of Detrimental Instances | http://arxiv.org/abs/1406.2237 | author:Michael R. Smith, Tony Martinez category:stat.ML cs.LG published:2014-06-09 summary:Not all instances in a data set are equally beneficial for inducing a modelof the data. Some instances (such as outliers or noise) can be detrimental.However, at least initially, the instances in a data set are generallyconsidered equally in machine learning algorithms. Many current approaches forhandling noisy and detrimental instances make a binary decision about whetheran instance is detrimental or not. In this paper, we 1) extend this paradigm byweighting the instances on a continuous scale and 2) present a methodology formeasuring how detrimental an instance may be for inducing a model of the data.We call our method of identifying and weighting detrimental instances reduceddetrimental instance learning (RDIL). We examine RIDL on a set of 54 data setsand 5 learning algorithms and compare RIDL with other weighting and filteringapproaches. RDIL is especially useful for learning algorithms where everyinstance can affect the classification boundary and the training instances areconsidered individually, such as multilayer perceptrons trained withbackpropagation (MLPs). Our results also suggest that a more accurate estimateof which instances are detrimental can have a significant positive impact forhandling them.
arxiv-7200-159 | Two-Stream Convolutional Networks for Action Recognition in Videos | http://arxiv.org/abs/1406.2199 | author:Karen Simonyan, Andrew Zisserman category:cs.CV published:2014-06-09 summary:We investigate architectures of discriminatively trained deep ConvolutionalNetworks (ConvNets) for action recognition in video. The challenge is tocapture the complementary information on appearance from still frames andmotion between frames. We also aim to generalise the best performinghand-crafted features within a data-driven learning framework. Our contribution is three-fold. First, we propose a two-stream ConvNetarchitecture which incorporates spatial and temporal networks. Second, wedemonstrate that a ConvNet trained on multi-frame dense optical flow is able toachieve very good performance in spite of limited training data. Finally, weshow that multi-task learning, applied to two different action classificationdatasets, can be used to increase the amount of training data and improve theperformance on both. Our architecture is trained and evaluated on the standard video actionsbenchmarks of UCF-101 and HMDB-51, where it is competitive with the state ofthe art. It also exceeds by a large margin previous attempts to use deep netsfor video classification.
arxiv-7200-160 | Unsupervised Deep Haar Scattering on Graphs | http://arxiv.org/abs/1406.2390 | author:Xu Chen, Xiuyuan Cheng, Stéphane Mallat category:cs.LG cs.CV published:2014-06-09 summary:The classification of high-dimensional data defined on graphs is particularlydifficult when the graph geometry is unknown. We introduce a Haar scatteringtransform on graphs, which computes invariant signal descriptors. It isimplemented with a deep cascade of additions, subtractions and absolute values,which iteratively compute orthogonal Haar wavelet transforms. Multiscaleneighborhoods of unknown graphs are estimated by minimizing an average totalvariation, with a pair matching algorithm of polynomial complexity. Supervisedclassification with dimension reduction is tested on data bases of scrambledimages, and for signals sampled on unknown irregular grids on a sphere.
arxiv-7200-161 | Parsing Semantic Parts of Cars Using Graphical Models and Segment Appearance Consistency | http://arxiv.org/abs/1406.2375 | author:Wenhao Lu, Xiaochen Lian, Alan Yuille category:cs.CV published:2014-06-09 summary:This paper addresses the problem of semantic part parsing (segmentation) ofcars, i.e.assigning every pixel within the car to one of the parts (e.g.body,window, lights, license plates and wheels). We formulate this as a landmarkidentification problem, where a set of landmarks specifies the boundaries ofthe parts. A novel mixture of graphical models is proposed, which dynamicallycouples the landmarks to a hierarchy of segments. When modeling pairwiserelation between landmarks, this coupling enables our model to exploit thelocal image contents in addition to spatial deformation, an aspect that mostexisting graphical models ignore. In particular, our model enforces appearanceconsistency between segments within the same part. Parsing the car, includingfinding the optimal coupling between landmarks and segments in the hierarchy,is performed by dynamic programming. We evaluate our method on a subset ofPASCAL VOC 2010 car images and on the car subset of 3D Object Category dataset(CAR3D). We show good results and, in particular, quantify the effectiveness ofusing the segment appearance consistency in terms of accuracy of partlocalization and segmentation.
arxiv-7200-162 | Log-Euclidean Bag of Words for Human Action Recognition | http://arxiv.org/abs/1406.2139 | author:Masoud Faraki, Maziar Palhang, Conrad Sanderson category:cs.CV I.4.9; I.5.4 published:2014-06-09 summary:Representing videos by densely extracted local space-time features hasrecently become a popular approach for analysing actions. In this paper, wetackle the problem of categorising human actions by devising Bag of Words (BoW)models based on covariance matrices of spatio-temporal features, with thefeatures formed from histograms of optical flow. Since covariance matrices forma special type of Riemannian manifold, the space of Symmetric Positive Definite(SPD) matrices, non-Euclidean geometry should be taken into account whilediscriminating between covariance matrices. To this end, we propose to embedSPD manifolds to Euclidean spaces via a diffeomorphism and extend the BoWapproach to its Riemannian version. The proposed BoW approach takes intoaccount the manifold geometry of SPD matrices during the generation of thecodebook and histograms. Experiments on challenging human action datasets showthat the proposed method obtains notable improvements in discriminationaccuracy, in comparison to several state-of-the-art methods.
arxiv-7200-163 | Fast and Flexible ADMM Algorithms for Trend Filtering | http://arxiv.org/abs/1406.2082 | author:Aaditya Ramdas, Ryan J. Tibshirani category:stat.ML cs.LG cs.NA math.OC stat.AP published:2014-06-09 summary:This paper presents a fast and robust algorithm for trend filtering, arecently developed nonparametric regression tool. It has been shown that, forestimating functions whose derivatives are of bounded variation, trendfiltering achieves the minimax optimal error rate, while other popular methodslike smoothing splines and kernels do not. Standing in the way of a morewidespread practical adoption, however, is a lack of scalable and numericallystable algorithms for fitting trend filtering estimates. This paper presents ahighly efficient, specialized ADMM routine for trend filtering. Our algorithmis competitive with the specialized interior point methods that are currentlyin use, and yet is far more numerically robust. Furthermore, the proposed ADMMimplementation is very simple, and importantly, it is flexible enough to extendto many interesting related problems, such as sparse trend filtering andisotonic trend filtering. Software for our method is freely available, in boththe C and R languages.
arxiv-7200-164 | Synthetic Data and Artificial Neural Networks for Natural Scene Text Recognition | http://arxiv.org/abs/1406.2227 | author:Max Jaderberg, Karen Simonyan, Andrea Vedaldi, Andrew Zisserman category:cs.CV published:2014-06-09 summary:In this work we present a framework for the recognition of natural scenetext. Our framework does not require any human-labelled data, and performs wordrecognition on the whole image holistically, departing from the character basedrecognition systems of the past. The deep neural network models at the centreof this framework are trained solely on data produced by a synthetic textgeneration engine -- synthetic data that is highly realistic and sufficient toreplace real data, giving us infinite amounts of training data. This excess ofdata exposes new possibilities for word recognition models, and here weconsider three models, each one "reading" words in a different way: via 90k-waydictionary encoding, character sequence encoding, and bag-of-N-grams encoding.In the scenarios of language based and completely unconstrained textrecognition we greatly improve upon state-of-the-art performance on standarddatasets, using our fast, simple machinery and requiring zero data-acquisitioncosts.
arxiv-7200-165 | Memristor models for machine learning | http://arxiv.org/abs/1406.2210 | author:Juan Pablo Carbajal, Joni Dambre, Michiel Hermans, Benjamin Schrauwen category:cs.LG published:2014-06-09 summary:In the quest for alternatives to traditional CMOS, it is being suggested thatdigital computing efficiency and power can be improved by matching theprecision to the application. Many applications do not need the high precisionthat is being used today. In particular, large gains in area- and powerefficiency could be achieved by dedicated analog realizations of approximatecomputing engines. In this work, we explore the use of memristor networks foranalog approximate computation, based on a machine learning framework calledreservoir computing. Most experimental investigations on the dynamics ofmemristors focus on their nonvolatile behavior. Hence, the volatility that ispresent in the developed technologies is usually unwanted and it is notincluded in simulation models. In contrast, in reservoir computing, volatilityis not only desirable but necessary. Therefore, in this work, we propose twodifferent ways to incorporate it into memristor simulation models. The first isan extension of Strukov's model and the second is an equivalent Wiener modelapproximation. We analyze and compare the dynamical properties of these modelsand discuss their implications for the memory and the nonlinear processingcapacity of memristor networks. Our results indicate that device variability,increasingly causing problems in traditional computer design, is an asset inthe context of reservoir computing. We conclude that, although both modelscould lead to useful memristor based reservoir computing systems, theircomputational performance will differ. Therefore, experimental modelingresearch is required for the development of accurate volatile memristor models.
arxiv-7200-166 | RuleCNL: A Controlled Natural Language for Business Rule Specifications | http://arxiv.org/abs/1406.2096 | author:Paul Brillant Feuto Njonko, Sylviane Cardey, Peter Greenfield, Walid El Abed category:cs.SE cs.CL published:2014-06-09 summary:Business rules represent the primary means by which companies define theirbusiness, perform their actions in order to reach their objectives. Thus, theyneed to be expressed unambiguously to avoid inconsistencies between businessstakeholders and formally in order to be machine-processed. A promisingsolution is the use of a controlled natural language (CNL) which is a goodmediator between natural and formal languages. This paper presents RuleCNL,which is a CNL for defining business rules. Its core feature is the alignmentof the business rule definition with the business vocabulary which ensurestraceability and consistency with the business domain. The RuleCNL toolprovides editors that assist end-users in the writing process and automaticmappings into the Semantics of Business Vocabulary and Business Rules (SBVR)standard. SBVR is grounded in first order logic and includes constructs calledsemantic formulations that structure the meaning of rules.
arxiv-7200-167 | On the Decreasing Power of Kernel and Distance based Nonparametric Hypothesis Tests in High Dimensions | http://arxiv.org/abs/1406.2083 | author:Sashank J. Reddi, Aaditya Ramdas, Barnabás Póczos, Aarti Singh, Larry Wasserman category:stat.ML cs.IT cs.LG math.IT math.ST stat.ME stat.TH published:2014-06-09 summary:This paper is about two related decision theoretic problems, nonparametrictwo-sample testing and independence testing. There is a belief that tworecently proposed solutions, based on kernels and distances between pairs ofpoints, behave well in high-dimensional settings. We identify different sourcesof misconception that give rise to the above belief. Specifically, wedifferentiate the hardness of estimation of test statistics from the hardnessof testing whether these statistics are zero or not, and explicitly discuss anotion of "fair" alternative hypotheses for these problems as dimensionincreases. We then demonstrate that the power of these tests actually dropspolynomially with increasing dimension against fair alternatives. We end withsome theoretical insights and shed light on the \textit{median heuristic} forkernel bandwidth selection. Our work advances the current understanding of thepower of modern nonparametric hypothesis tests in high dimensions.
arxiv-7200-168 | Learning directed acyclic graphs via bootstrap aggregating | http://arxiv.org/abs/1406.2098 | author:Ru Wang, Jie Peng category:stat.ML stat.CO stat.ME published:2014-06-09 summary:Probabilistic graphical models are graphical representations of probabilitydistributions. Graphical models have applications in many fields includingbiology, social sciences, linguistic, neuroscience. In this paper, we proposedirected acyclic graphs (DAGs) learning via bootstrap aggregating. The proposedprocedure is named as DAGBag. Specifically, an ensemble of DAGs is firstlearned based on bootstrap resamples of the data and then an aggregated DAG isderived by minimizing the overall distance to the entire ensemble. A family ofmetrics based on the structural hamming distance is defined for the space ofDAGs (of a given node set) and is used for aggregation. Under thehigh-dimensional-low-sample size setting, the graph learned on one data setoften has excessive number of false positive edges due to over-fitting of thenoise. Aggregation overcomes over-fitting through variance reduction and thusgreatly reduces false positives. We also develop an efficient implementation ofthe hill climbing search algorithm of DAG learning which makes the proposedmethod computationally competitive for the high-dimensional regime. The DAGBagprocedure is implemented in the R package dagbag.
arxiv-7200-169 | Feature Selection For High-Dimensional Clustering | http://arxiv.org/abs/1406.2240 | author:Larry Wasserman, Martin Azizyan, Aarti Singh category:math.ST stat.ML stat.TH published:2014-06-09 summary:We present a nonparametric method for selecting informative features inhigh-dimensional clustering problems. We start with a screening step that usesa test for multimodality. Then we apply kernel density estimation and modeclustering to the selected features. The output of the method consists of alist of relevant features, and cluster assignments. We provide explicit boundson the error rate of the resulting clustering. In addition, we provide thefirst error bounds on mode based clustering.
arxiv-7200-170 | How Easy is it to Learn a Controlled Natural Language for Building a Knowledge Base? | http://arxiv.org/abs/1406.2204 | author:Sandra Williams, Richard Power, Allan Third category:cs.CL published:2014-06-09 summary:Recent developments in controlled natural language editors for knowledgeengineering (KE) have given rise to expectations that they will make KE tasksmore accessible and perhaps even enable non-engineers to build knowledge bases.This exploratory research focussed on novices and experts in knowledgeengineering during their attempts to learn a controlled natural language (CNL)known as OWL Simplified English and use it to build a small knowledge base.Participants' behaviours during the task were observed through eye-tracking andscreen recordings. This was an attempt at a more ambitious user study than inprevious research because we used a naturally occurring text as the source ofdomain knowledge, and left them without guidance on which information toselect, or how to encode it. We have identified a number of skills(competencies) required for this difficult task and key problems that authorsface.
arxiv-7200-171 | Robust Estimation of 3D Human Poses from a Single Image | http://arxiv.org/abs/1406.2282 | author:Chunyu Wang, Yizhou Wang, Zhouchen Lin, Alan L. Yuille, Wen Gao category:cs.CV published:2014-06-09 summary:Human pose estimation is a key step to action recognition. We propose amethod of estimating 3D human poses from a single image, which works inconjunction with an existing 2D pose/joint detector. 3D pose estimation ischallenging because multiple 3D poses may correspond to the same 2D pose afterprojection due to the lack of depth information. Moreover, current 2D poseestimators are usually inaccurate which may cause errors in the 3D estimation.We address the challenges in three ways: (i) We represent a 3D pose as a linearcombination of a sparse set of bases learned from 3D human skeletons. (ii) Weenforce limb length constraints to eliminate anthropomorphically implausibleskeletons. (iii) We estimate a 3D pose by minimizing the $L_1$-norm errorbetween the projection of the 3D pose and the corresponding 2D detection. The$L_1$-norm loss term is robust to inaccurate 2D joint estimations. We use thealternating direction method (ADM) to solve the optimization problemefficiently. Our approach outperforms the state-of-the-arts on three benchmarkdatasets.
arxiv-7200-172 | Efficient Sparse Clustering of High-Dimensional Non-spherical Gaussian Mixtures | http://arxiv.org/abs/1406.2206 | author:Martin Azizyan, Aarti Singh, Larry Wasserman category:math.ST stat.ML stat.TH published:2014-06-09 summary:We consider the problem of clustering data points in high dimensions, i.e.when the number of data points may be much smaller than the number ofdimensions. Specifically, we consider a Gaussian mixture model (GMM) withnon-spherical Gaussian components, where the clusters are distinguished by onlya few relevant dimensions. The method we propose is a combination of a recentapproach for learning parameters of a Gaussian mixture model and sparse lineardiscriminant analysis (LDA). In addition to cluster assignments, the methodreturns an estimate of the set of features relevant for clustering. Our resultsindicate that the sample complexity of clustering depends on the sparsity ofthe relevant feature set, while only scaling logarithmically with the ambientdimension. Additionally, we require much milder assumptions than existing workon clustering in high dimensions. In particular, we do not require sphericalclusters nor necessitate mean separation along relevant dimensions.
arxiv-7200-173 | Depth Map Prediction from a Single Image using a Multi-Scale Deep Network | http://arxiv.org/abs/1406.2283 | author:David Eigen, Christian Puhrsch, Rob Fergus category:cs.CV published:2014-06-09 summary:Predicting depth is an essential component in understanding the 3D geometryof a scene. While for stereo images local correspondence suffices forestimation, finding depth relations from a single image is lessstraightforward, requiring integration of both global and local informationfrom various cues. Moreover, the task is inherently ambiguous, with a largesource of uncertainty coming from the overall scale. In this paper, we presenta new method that addresses this task by employing two deep network stacks: onethat makes a coarse global prediction based on the entire image, and anotherthat refines this prediction locally. We also apply a scale-invariant error tohelp measure depth relations rather than scale. By leveraging the raw datasetsas large sources of training data, our method achieves state-of-the-art resultson both NYU Depth and KITTI, and matches detailed depth boundaries without theneed for superpixelation.
arxiv-7200-174 | Explaining Violation Traces with Finite State Natural Language Generation Models | http://arxiv.org/abs/1406.2298 | author:Gordon J. Pace, Michael Rosner category:cs.SE cs.CL published:2014-06-09 summary:An essential element of any verification technique is that of identifying andcommunicating to the user, system behaviour which leads to a deviation from theexpected behaviour. Such behaviours are typically made available as long tracesof system actions which would benefit from a natural language explanation ofthe trace and especially in the context of business logic level specifications.In this paper we present a natural language generation model which can be usedto explain such traces. A key idea is that the explanation language is a CNLthat is, formally speaking, regular language susceptible transformations thatcan be expressed with finite state machinery. At the same time it admitsvarious forms of abstraction and simplification which contribute to thenaturalness of explanations that are communicated to the user.
arxiv-7200-175 | Image Tag Completion by Low-rank Factorization with Dual Reconstruction Structure Preserved | http://arxiv.org/abs/1406.2049 | author:Xue Li, Yu-Jin Zhang, Bin Shen, Bao-Di Liu category:cs.CV cs.IR published:2014-06-09 summary:A novel tag completion algorithm is proposed in this paper, which is designedwith the following features: 1) Low-rank and error s-parsity: the incompleteinitial tagging matrix D is decomposed into the complete tagging matrix A and asparse error matrix E. However, instead of minimizing its nuclear norm, A isfurther factor-ized into a basis matrix U and a sparse coefficient matrix V,i.e. D=UV+E. This low-rank formulation encapsulating sparse coding enables ouralgorithm to recover latent structures from noisy initial data and avoidperforming too much denoising; 2) Local reconstruction structure consistency:to steer the completion of D, the local linear reconstruction structures infeature space and tag space are obtained and preserved by U and V respectively.Such a scheme could alleviate the negative effect of distances measured bylow-level features and incomplete tags. Thus, we can seek a balance betweenexploiting as much information and not being mislead to suboptimal performance.Experiments conducted on Corel5k dataset and the newly issued Flickr30Conceptsdataset demonstrate the effectiveness and efficiency of the proposed method.
arxiv-7200-176 | A Hybrid Latent Variable Neural Network Model for Item Recommendation | http://arxiv.org/abs/1406.2235 | author:Michael R. Smith, Tony Martinez, Michael Gashler category:cs.LG cs.IR cs.NE stat.ML published:2014-06-09 summary:Collaborative filtering is used to recommend items to a user withoutrequiring a knowledge of the item itself and tends to outperform othertechniques. However, collaborative filtering suffers from the cold-startproblem, which occurs when an item has not yet been rated or a user has notrated any items. Incorporating additional information, such as item or userdescriptions, into collaborative filtering can address the cold-start problem.In this paper, we present a neural network model with latent input variables(latent neural network or LNN) as a hybrid collaborative filtering techniquethat addresses the cold-start problem. LNN outperforms a broad selection ofcontent-based filters (which make recommendations based on item descriptions)and other hybrid approaches while maintaining the accuracy of state-of-the-artcollaborative filtering techniques.
arxiv-7200-177 | Detect What You Can: Detecting and Representing Objects using Holistic Models and Body Parts | http://arxiv.org/abs/1406.2031 | author:Xianjie Chen, Roozbeh Mottaghi, Xiaobai Liu, Sanja Fidler, Raquel Urtasun, Alan Yuille category:cs.CV published:2014-06-08 summary:Detecting objects becomes difficult when we need to deal with large shapedeformation, occlusion and low resolution. We propose a novel approach to i)handle large deformations and partial occlusions in animals (as examples ofhighly deformable objects), ii) describe them in terms of body parts, and iii)detect them when their body parts are hard to detect (e.g., animals depicted atlow resolution). We represent the holistic object and body parts separately anduse a fully connected model to arrange templates for the holistic object andbody parts. Our model automatically decouples the holistic object or body partsfrom the model when they are hard to detect. This enables us to represent alarge number of holistic object and body part combinations to better deal withdifferent "detectability" patterns caused by deformations, occlusion and/or lowresolution. We apply our method to the six animal categories in the PASCAL VOC datasetand show that our method significantly improves state-of-the-art (by 4.1% AP)and provides a richer representation for objects. During training we useannotations for body parts (e.g., head, torso, etc), making use of a newdataset of fully annotated object parts for PASCAL VOC 2010, which provides amask for each part.
arxiv-7200-178 | Two-dimensional Sentiment Analysis of text | http://arxiv.org/abs/1406.2022 | author:Rahul Tejwani category:cs.IR cs.CL published:2014-06-08 summary:Sentiment Analysis aims to get the underlying viewpoint of the text, whichcould be anything that holds a subjective opinion, such as an online review,Movie rating, Comments on Blog posts etc. This paper presents a novel approachthat classify text in two-dimensional Emotional space, based on the sentimentsof the author. The approach uses existing lexical resources to extract featureset, which is trained using Supervised Learning techniques.
arxiv-7200-179 | Learning Word Representations with Hierarchical Sparse Coding | http://arxiv.org/abs/1406.2035 | author:Dani Yogatama, Manaal Faruqui, Chris Dyer, Noah A. Smith category:cs.CL cs.LG stat.ML published:2014-06-08 summary:We propose a new method for learning word representations using hierarchicalregularization in sparse coding inspired by the linguistic study of wordmeanings. We show an efficient learning algorithm based on stochastic proximalmethods that is significantly faster than previous approaches, making itpossible to perform hierarchical sparse coding on a corpus of billions of wordtokens. Experiments on various benchmark tasks---word similarity ranking,analogies, sentence completion, and sentiment analysis---demonstrate that themethod outperforms or is competitive with state-of-the-art methods. Our wordrepresentations are available at\url{http://www.ark.cs.cmu.edu/dyogatam/wordvecs/}.
arxiv-7200-180 | Structured Dictionary Learning for Classification | http://arxiv.org/abs/1406.1943 | author:Yuanming Suo, Minh Dao, Umamahesh Srinivas, Vishal Monga, Trac D. Tran category:cs.CV published:2014-06-08 summary:Sparsity driven signal processing has gained tremendous popularity in thelast decade. At its core, the assumption is that the signal of interest issparse with respect to either a fixed transformation or a signal dependentdictionary. To better capture the data characteristics, various dictionarylearning methods have been proposed for both reconstruction and classificationtasks. For classification particularly, most approaches proposed so far havefocused on designing explicit constraints on the sparse code to improveclassification accuracy while simply adopting $l_0$-norm or $l_1$-norm forsparsity regularization. Motivated by the success of structured sparsity in thearea of Compressed Sensing, we propose a structured dictionary learningframework (StructDL) that incorporates the structure information on both groupand task levels in the learning process. Its benefits are two-fold: (i) thelabel consistency between dictionary atoms and training data are implicitlyenforced; and (ii) the classification performance is more robust in the casesof a small dictionary size or limited training data than other techniques.Using the subspace model, we derive the conditions for StructDL to guaranteethe performance and show theoretically that StructDL is superior to $l_0$-normor $l_1$-norm regularized dictionary learning for classification. Extensiveexperiments have been performed on both synthetic simulations and real worldapplications, such as face recognition and object classification, todemonstrate the validity of the proposed DL framework.
arxiv-7200-181 | Automatic Extraction of Protein Interaction in Literature | http://arxiv.org/abs/1406.1953 | author:Peilei Liu, Ting Wang category:cs.CL cs.CE H.2.8; H.3.5 published:2014-06-08 summary:Protein-protein interaction extraction is the key precondition of theconstruction of protein knowledge network, and it is very important for theresearch in the biomedicine. This paper extracted directional protein-proteininteraction from the biological text, using the SVM-based method. Experimentswere evaluated on the LLL05 corpus with good results. The results show thatdependency features are import for the protein-protein interaction extractionand features related to the interaction word are effective for the interactiondirection judgment. At last, we analyzed the effects of different features andplaned for the next step.
arxiv-7200-182 | Fine-grained Activity Recognition with Holistic and Pose based Features | http://arxiv.org/abs/1406.1881 | author:Leonid Pishchulin, Mykhaylo Andriluka, Bernt Schiele category:cs.CV published:2014-06-07 summary:Holistic methods based on dense trajectories are currently the de factostandard for recognition of human activities in video. Whether holisticrepresentations will sustain or will be superseded by higher level videoencoding in terms of body pose and motion is the subject of an ongoing debate.In this paper we aim to clarify the underlying factors responsible for goodperformance of holistic and pose-based representations. To that end we build onour recent dataset leveraging the existing taxonomy of human activities. Thisdataset includes 24,920 video snippets covering 410 human activities in total.Our analysis reveals that holistic and pose-based methods are highlycomplementary, and their performance varies significantly depending on theactivity. We find that holistic methods are mostly affected by the number andspeed of trajectories, whereas pose-based methods are mostly influenced byviewpoint of the person. We observe striking performance differences acrossactivities: for certain activities results with pose-based features are morethan twice as accurate compared to holistic features, and vice versa. The bestperforming approach in our comparison is based on the combination of holisticand pose-based approaches, which again underlines their complementarity.
arxiv-7200-183 | Application and Verification of Algorithm Learning Based Neural Network | http://arxiv.org/abs/1406.2614 | author:Rizwana Kalsoom, Moomal Qureshi category:cs.NE published:2014-06-07 summary:This paper has been withdrawn by the author due to a crucial accuracy errorin Fig. 5. For precise performance of ALBNN please refer to Yoon et al.'s workin the following article. Yoon, H., Park, C. S., Kim, J. S., & Baek, J. G.(2013). Algorithm learning based neural network integrating feature selectionand classification. Expert Systems with Applications, 40(1), 231-241.http://www.sciencedirect.com/science/article/pii/S0957417412008731
arxiv-7200-184 | A Novel Test for Additivity in Supervised Ensemble Learners | http://arxiv.org/abs/1406.1845 | author:Lucas Mentch, Giles Hooker category:stat.ML stat.AP published:2014-06-07 summary:Additive models remain popular statistical tools due to their ease ofinterpretation and as a result, hypothesis tests for additivity have beendeveloped to assess the appropriateness of these models. However, as data growsin size and complexity, learning algorithms continue to gain popularity due totheir exceptional predictive performance. Due to the black-box nature of theselearning methods, the increase in predictive power is assumed to come at thecost of interpretability and inference. However, recent work suggests that manypopular learning techniques, such as bagged trees and random forests, havedesirable asymptotic properties which allow for formal statistical inferencewhen base learners are built with proper subsamples. This work extendshypothesis tests previously developed and demonstrates that by enforcing a gridstructure on an appropriate test set, we may perform formal hypothesis testsfor additivity among features. We develop notions of total and partialadditivity and demonstrate that both tests can be carried out at no additionalcomputational cost. We also suggest a new testing procedure based on randomprojections that allows for testing on larger grids, even when the grid size islarger than that of the training set. Simulations and demonstrations on realdata are provided.
arxiv-7200-185 | Efficient programmable learning to search | http://arxiv.org/abs/1406.1837 | author:Kai-Wei Chang, Hal Daumé III, John Langford, Stephane Ross category:cs.LG published:2014-06-07 summary:We improve "learning to search" approaches to structured prediction in twoways. First, we show that the search space can be defined by an arbitraryimperative program, reducing the number of lines of code required to developnew structured prediction tasks by orders of magnitude. Second, we makestructured prediction orders of magnitude faster through various algorithmicimprovements. We demonstrate the feasibility of our approach on threestructured prediction tasks: two variants of sequence labeling andentity-relation resolution. In all cases we obtain accuracies at least as highas alternative approaches, at drastically reduced execution and programmingtime.
arxiv-7200-186 | Nonparametric Independence Testing for Small Sample Sizes | http://arxiv.org/abs/1406.1922 | author:Aaditya Ramdas, Leila Wehbe category:stat.ML published:2014-06-07 summary:This paper deals with the problem of nonparametric independence testing, afundamental decision-theoretic problem that asks if two arbitrary (possiblymultivariate) random variables $X,Y$ are independent or not, a question thatcomes up in many fields like causality and neuroscience. While quantities likecorrelation of $X,Y$ only test for (univariate) linear independence, naturalalternatives like mutual information of $X,Y$ are hard to estimate due to aserious curse of dimensionality. A recent approach, avoiding both issues,estimates norms of an \textit{operator} in Reproducing Kernel Hilbert Spaces(RKHSs). Our main contribution is strong empirical evidence that by employing\textit{shrunk} operators when the sample size is small, one can attain animprovement in power at low false positive rates. We analyze the effects ofStein shrinkage on a popular test statistic called HSIC (Hilbert-SchmidtIndependence Criterion). Our observations provide insights into two recentlyproposed shrinkage estimators, SCOSE and FCOSE - we prove that SCOSE is(essentially) the optimal linear shrinkage method for \textit{estimating} thetrue operator; however, the non-linearly shrunk FCOSE usually achieves greaterimprovements in \textit{test power}. This work is important for more powerfulnonparametric detection of subtle nonlinear dependencies for small samples.
arxiv-7200-187 | A Drifting-Games Analysis for Online Learning and Applications to Boosting | http://arxiv.org/abs/1406.1856 | author:Haipeng Luo, Robert E. Schapire category:cs.LG published:2014-06-07 summary:We provide a general mechanism to design online learning algorithms based ona minimax analysis within a drifting-games framework. Different online learningsettings (Hedge, multi-armed bandit problems and online convex optimization)are studied by converting into various kinds of drifting games. The originalminimax analysis for drifting games is then used and generalized by applying aseries of relaxations, starting from choosing a convex surrogate of the 0-1loss function. With different choices of surrogates, we not only recoverexisting algorithms, but also propose new algorithms that are totallyparameter-free and enjoy other useful properties. Moreover, our drifting-gamesframework naturally allows us to study high probability bounds withoutresorting to any concentration results, and also a generalized notion of regretthat measures how good the algorithm is compared to all but the top smallfraction of candidates. Finally, we translate our new Hedge algorithm into anew adaptive boosting algorithm that is computationally faster as shown inexperiments, since it ignores a large number of examples on each round.
arxiv-7200-188 | Spectral Clustering of Graphs with the Bethe Hessian | http://arxiv.org/abs/1406.1880 | author:Alaa Saade, Florent Krzakala, Lenka Zdeborová category:cs.SI physics.soc-ph stat.ML published:2014-06-07 summary:Spectral clustering is a standard approach to label nodes on a graph bystudying the (largest or lowest) eigenvalues of a symmetric real matrix such ase.g. the adjacency or the Laplacian. Recently, it has been argued that usinginstead a more complicated, non-symmetric and higher dimensional operator,related to the non-backtracking walk on the graph, leads to improvedperformance in detecting clusters, and even to optimal performance for thestochastic block model. Here, we propose to use instead a simpler object, asymmetric real matrix known as the Bethe Hessian operator, or deformedLaplacian. We show that this approach combines the performances of thenon-backtracking operator, thus detecting clusters all the way down to thetheoretical limit in the stochastic block model, with the computational,theoretical and memory advantages of real symmetric matrices.
arxiv-7200-189 | Refinement-Cut: User-Guided Segmentation Algorithm for Translational Science | http://arxiv.org/abs/1406.1906 | author:Jan Egger category:cs.CV published:2014-06-07 summary:In this contribution, a semi-automatic segmentation algorithm for (medical)image analysis is presented. More precise, the approach belongs to the categoryof interactive contouring algorithms, which provide real-time feedback of thesegmentation result. However, even with interactive real-time contouringapproaches there are always cases where the user cannot find a satisfyingsegmentation, e.g. due to homogeneous appearances between the object and thebackground, or noise inside the object. For these difficult cases the algorithmstill needs additional user support. However, this additional user supportshould be intuitive and rapid integrated into the segmentation process, withoutbreaking the interactive real-time segmentation feedback. I propose a solutionwhere the user can support the algorithm by an easy and fast placement of oneor more seed points to guide the algorithm to a satisfying segmentation resultalso in difficult cases. These additional seed(s) restrict(s) the calculationof the segmentation for the algorithm, but at the same time, still enable tocontinue with the interactive real-time feedback segmentation. For a practicaland genuine application in translational science, the approach has been testedon medical data from the clinical routine in 2D and 3D.
arxiv-7200-190 | Model-based Reinforcement Learning and the Eluder Dimension | http://arxiv.org/abs/1406.1853 | author:Ian Osband, Benjamin Van Roy category:stat.ML cs.LG published:2014-06-07 summary:We consider the problem of learning to optimize an unknown Markov decisionprocess (MDP). We show that, if the MDP can be parameterized within some knownfunction class, we can obtain regret bounds that scale with the dimensionality,rather than cardinality, of the system. We characterize this dependenceexplicitly as $\tilde{O}(\sqrt{d_K d_E T})$ where $T$ is time elapsed, $d_K$ isthe Kolmogorov dimension and $d_E$ is the \emph{eluder dimension}. Theserepresent the first unified regret bounds for model-based reinforcementlearning and provide state of the art guarantees in several important settings.Moreover, we present a simple and computationally efficient algorithm\emph{posterior sampling for reinforcement learning} (PSRL) that satisfiesthese bounds.
arxiv-7200-191 | Toward verbalizing ontologies in isiZulu | http://arxiv.org/abs/1406.1870 | author:C. Maria Keet, Langa Khumalo category:cs.CL I.2.1 published:2014-06-07 summary:IsiZulu is one of the eleven official languages of South Africa and roughlyhalf the population can speak it. It is the first (home) language for over 10million people in South Africa. Only a few computational resources exist forisiZulu and its related Nguni languages, yet the imperative for tooldevelopment exists. We focus on natural language generation, and the grammaroptions and preferences in particular, which will inform verbalization ofknowledge representation languages and could contribute to machine translation.The verbalization pattern specification shows that the grammar rules areelaborate and there are several options of which one may have preference. Wedevised verbalization patterns for subsumption, basic disjointness, existentialand universal quantification, and conjunction. This was evaluated in a surveyamong linguists and non-linguists. Some differences between linguists andnon-linguists can be observed, with the former much more in agreement, andpreferences depend on the overall structure of the sentence, such as singularfor subsumption and plural in other cases.
arxiv-7200-192 | Simulation based Hardness Evaluation of a Multi-Objective Genetic Algorithm | http://arxiv.org/abs/1406.2613 | author:Shahab U. Ansari, Sameen Mansha category:cs.NE published:2014-06-07 summary:Studies have shown that multi-objective optimization problems are hardproblems. Such problems either require longer time to converge to an optimumsolution, or may not converge at all. Recently some researchers have claimedthat real culprit for increasing the hardness of multi-objective problems arenot the number of objectives themselves rather it is the increased size ofsolution set, incompatibility of solutions, and high probability of findingsuboptimal solution due to increased number of local maxima. In this work, wehave setup a simple framework for the evaluation of hardness of multi-objectivegenetic algorithms (MOGA). The algorithm is designed for a pray-predator gamewhere a player is to improve its lifespan, challenging level and usability ofthe game arena through number of generations. A rigorous set of experiments areperformed for quantifying the hardness in terms of evolution for increasingnumber of objective functions. In genetic algorithm, crossover and mutationwith equal probability are applied to create offspring in each generation.First, each objective function is maximized individually by ranking thecompeting players on the basis of the fitness (cost) function, and then amulti-objective cost function (sum of individual cost functions) is maximizedwith ranking, and also without ranking where dominated solutions are alsoallowed to evolve.
arxiv-7200-193 | Shape-from-intrinsic operator | http://arxiv.org/abs/1406.1925 | author:Davide Boscaini, Davide Eynard, Michael M. Bronstein category:cs.CV published:2014-06-07 summary:Shape-from-X is an important class of problems in the fields of geometryprocessing, computer graphics, and vision, attempting to recover the structureof a shape from some observations. In this paper, we formulate the problem ofshape-from-operator (SfO), recovering an embedding of a mesh from intrinsicdifferential operators defined on the mesh. Particularly interesting instancesof our SfO problem include synthesis of shape analogies, shape-from-Laplacianreconstruction, and shape exaggeration. Numerically, we approach the SfOproblem by splitting it into two optimization sub-problems that are applied inan alternating scheme: metric-from-operator (reconstruction of the discretemetric from the intrinsic operator) and embedding-from-metric (finding a shapeembedding that would realize a given metric, a setting of the multidimensionalscaling problem).
arxiv-7200-194 | Compressed Gaussian Process | http://arxiv.org/abs/1406.1916 | author:Rajarshi Guhaniyogi, David B. Dunson category:stat.ML published:2014-06-07 summary:Nonparametric regression for massive numbers of samples (n) and features (p)is an increasingly important problem. In big n settings, a common strategy isto partition the feature space, and then separately apply simple models to eachpartition set. We propose an alternative approach, which avoids suchpartitioning and the associated sensitivity to neighborhood choice and distancemetrics, by using random compression combined with Gaussian process regression.The proposed approach is particularly motivated by the setting in which theresponse is conditionally independent of the features given the projection to alow dimensional manifold. Conditionally on the random compression matrix and asmoothness parameter, the posterior distribution for the regression surface andposterior predictive distributions are available analytically. Running theanalysis in parallel for many random compression matrices and smoothnessparameters, model averaging is used to combine the results. The algorithm canbe implemented rapidly even in very big n and p problems, has strongtheoretical justification, and is found to yield state of the art predictiveperformance.
arxiv-7200-195 | Unsupervised Feature Learning through Divergent Discriminative Feature Accumulation | http://arxiv.org/abs/1406.1833 | author:Paul A. Szerlip, Gregory Morse, Justin K. Pugh, Kenneth O. Stanley category:cs.NE cs.LG published:2014-06-06 summary:Unlike unsupervised approaches such as autoencoders that learn to reconstructtheir inputs, this paper introduces an alternative approach to unsupervisedfeature learning called divergent discriminative feature accumulation (DDFA)that instead continually accumulates features that make novel discriminationsamong the training set. Thus DDFA features are inherently discriminative fromthe start even though they are trained without knowledge of the ultimateclassification problem. Interestingly, DDFA also continues to add new featuresindefinitely (so it does not depend on a hidden layer size), is not based onminimizing error, and is inherently divergent instead of convergent, therebyproviding a unique direction of research for unsupervised feature learning. Inthis paper the quality of its learned features is demonstrated on the MNISTdataset, where its performance confirms that indeed DDFA is a viable techniquefor learning useful features.
arxiv-7200-196 | Small Sample Learning of Superpixel Classifiers for EM Segmentation- Extended Version | http://arxiv.org/abs/1406.1774 | author:Toufiq Parag, Stephen Plaza, Louis Scheffer category:cs.CV published:2014-06-06 summary:Pixel and superpixel classifiers have become essential tools for EMsegmentation algorithms. Training these classifiers remains a major bottleneckprimarily due to the requirement of completely annotating the dataset which istedious, error-prone and costly. In this paper, we propose an interactivelearning scheme for the superpixel classifier for EM segmentation. Ouralgorithm is "active semi-supervised" because it requests the labels of a smallnumber of examples from user and applies label propagation technique togenerate these queries. Using only a small set ($<20\%$) of all datapoints, theproposed algorithm consistently generates a classifier almost as accurate asthat estimated from a complete groundtruth. We provide segmentation results onmultiple datasets to show the strength of these classifiers.
arxiv-7200-197 | Variational inference of latent state sequences using Recurrent Networks | http://arxiv.org/abs/1406.1655 | author:Justin Bayer, Christian Osendorfer category:stat.ML cs.LG published:2014-06-06 summary:Recent advances in the estimation of deep directed graphical models andrecurrent networks let us contribute to the removal of a blind spot in the areaof probabilistc modelling of time series. The proposed methods i) can inferdistributed latent state-space trajectories with nonlinear transitions, ii)scale to large data sets thanks to the use of a stochastic objective and fast,approximate inference, iii) enable the design of rich emission models which iv)will naturally lead to structured outputs. Two different paths of introducinglatent state sequences are pursued, leading to the variational recurrent autoencoder (VRAE) and the variational one step predictor (VOSP). The use ofindependent Wiener processes as priors on the latent state sequence is a viablecompromise between efficient computation of the Kullback-Leibler divergencefrom the variational approximation of the posterior and maintaining areasonable belief in the dynamics. We verify our methods empirically, obtainingresults close or superior to the state of the art. We also show qualitativeresults for denoising and missing value imputation.
arxiv-7200-198 | Learning to Discover Efficient Mathematical Identities | http://arxiv.org/abs/1406.1584 | author:Wojciech Zaremba, Karol Kurach, Rob Fergus category:cs.LG published:2014-06-06 summary:In this paper we explore how machine learning techniques can be applied tothe discovery of efficient mathematical identities. We introduce an attributegrammar framework for representing symbolic expressions. Given a set of grammarrules we build trees that combine different rules, looking for branches whichyield compositions that are analytically equivalent to a target expression, butof lower computational complexity. However, as the size of the trees growsexponentially with the complexity of the target expression, brute force searchis impractical for all but the simplest of expressions. Consequently, weintroduce two novel learning approaches that are able to learn from simplerexpressions to guide the tree search. The first of these is a simple n-grammodel, the other being a recursive neural-network. We show how these approachesenable us to derive complex identities, beyond reach of brute-force search, orhuman derivation.
arxiv-7200-199 | Analyzing noise in autoencoders and deep networks | http://arxiv.org/abs/1406.1831 | author:Ben Poole, Jascha Sohl-Dickstein, Surya Ganguli category:cs.NE cs.LG published:2014-06-06 summary:Autoencoders have emerged as a useful framework for unsupervised learning ofinternal representations, and a wide variety of apparently conceptuallydisparate regularization techniques have been proposed to generate usefulfeatures. Here we extend existing denoising autoencoders to additionally injectnoise before the nonlinearity, and at the hidden unit activations. We show thata wide variety of previous methods, including denoising, contractive, andsparse autoencoders, as well as dropout can be interpreted using thisframework. This noise injection framework reaps practical benefits by providinga unified strategy to develop new internal representations by designing thenature of the injected noise. We show that noisy autoencoders outperformdenoising autoencoders at the very task of denoising, and are competitive withother single-layer techniques on MNIST, and CIFAR-10. We also show that typesof noise other than dropout improve performance in a deep network throughsparsifying, decorrelating, and spreading information across representations.
arxiv-7200-200 | A New 2.5D Representation for Lymph Node Detection using Random Sets of Deep Convolutional Neural Network Observations | http://arxiv.org/abs/1406.2639 | author:Holger R. Roth, Le Lu, Ari Seff, Kevin M. Cherry, Joanne Hoffman, Shijun Wang, Jiamin Liu, Evrim Turkbey, Ronald M. Summers category:cs.CV cs.LG cs.NE published:2014-06-06 summary:Automated Lymph Node (LN) detection is an important clinical diagnostic taskbut very challenging due to the low contrast of surrounding structures inComputed Tomography (CT) and to their varying sizes, poses, shapes and sparselydistributed locations. State-of-the-art studies show the performance range of52.9% sensitivity at 3.1 false-positives per volume (FP/vol.), or 60.9% at 6.1FP/vol. for mediastinal LN, by one-shot boosting on 3D HAAR features. In thispaper, we first operate a preliminary candidate generation stage, towards 100%sensitivity at the cost of high FP levels (40 per patient), to harvest volumesof interest (VOI). Our 2.5D approach consequently decomposes any 3D VOI byresampling 2D reformatted orthogonal views N times, via scale, randomtranslations, and rotations with respect to the VOI centroid coordinates. Theserandom views are then used to train a deep Convolutional Neural Network (CNN)classifier. In testing, the CNN is employed to assign LN probabilities for allN random views that can be simply averaged (as a set) to compute the finalclassification probability per VOI. We validate the approach on two datasets:90 CT volumes with 388 mediastinal LNs and 86 patients with 595 abdominal LNs.We achieve sensitivities of 70%/83% at 3 FP/vol. and 84%/90% at 6 FP/vol. inmediastinum and abdomen respectively, which drastically improves over theprevious state-of-the-art work.
arxiv-7200-201 | A Comprehensive Approach to Mode Clustering | http://arxiv.org/abs/1406.1780 | author:Yen-Chi Chen, Christopher R. Genovese, Larry Wasserman category:stat.ME stat.ML published:2014-06-06 summary:Mode clustering is a nonparametric method for clustering that definesclusters using the basins of attraction of a density estimator's modes. Weprovide several enhancements to mode clustering: (i) a soft variant of clusterassignment, (ii) a measure of connectivity between clusters, (iii) a techniquefor choosing the bandwidth, (iv) a method for denoising small clusters, and (v)an approach to visualizing the clusters. Combining all these enhancements givesus a complete procedure for clustering in multivariate problems. We alsocompare mode clustering to other clustering methods in several examples
arxiv-7200-202 | Recursive Neural Networks Can Learn Logical Semantics | http://arxiv.org/abs/1406.1827 | author:Samuel R. Bowman, Christopher Potts, Christopher D. Manning category:cs.CL cs.LG cs.NE published:2014-06-06 summary:Tree-structured recursive neural networks (TreeRNNs) for sentence meaninghave been successful for many applications, but it remains an open questionwhether the fixed-length representations that they learn can support tasks asdemanding as logical deduction. We pursue this question by evaluating whethertwo such models---plain TreeRNNs and tree-structured neural tensor networks(TreeRNTNs)---can correctly learn to identify logical relationships such asentailment and contradiction using these representations. In our first set ofexperiments, we generate artificial data from a logical grammar and use it toevaluate the models' ability to learn to handle basic relational reasoning,recursive structures, and quantification. We then evaluate the models on themore natural SICK challenge data. Both models perform competitively on the SICKdata and generalize well in all three experiments on simulated data, suggestingthat they can learn suitable representations for logical inference in naturallanguage.
arxiv-7200-203 | Computational role of eccentricity dependent cortical magnification | http://arxiv.org/abs/1406.1770 | author:Tomaso Poggio, Jim Mutch, Leyla Isik category:cs.LG q-bio.NC published:2014-06-06 summary:We develop a sampling extension of M-theory focused on invariance to scaleand translation. Quite surprisingly, the theory predicts an architecture ofearly vision with increasing receptive field sizes and a high resolution fovea-- in agreement with data about the cortical magnification factor, V1 and theretina. From the slope of the inverse of the magnification factor, M-theorypredicts a cortical "fovea" in V1 in the order of $40$ by $40$ basic units ateach receptive field size -- corresponding to a foveola of size around $26$minutes of arc at the highest resolution, $\approx 6$ degrees at the lowestresolution. It also predicts uniform scale invariance over a fixed range ofscales independently of eccentricity, while translation invariance shoulddepend linearly on spatial frequency. Bouma's law of crowding follows in thetheory as an effect of cortical area-by-cortical area pooling; the Boumaconstant is the value expected if the signature responsible for recognition inthe crowding experiments originates in V2. From a broader perspective, theemerging picture suggests that visual recognition under natural conditionstakes place by composing information from a set of fixations, with eachfixation providing recognition from a space-scale image fragment -- that is animage patch represented at a set of increasing sizes and decreasingresolutions.
arxiv-7200-204 | Linguistic Analysis of Requirements of a Space Project and their Conformity with the Recommendations Proposed by a Controlled Natural Language | http://arxiv.org/abs/1406.1765 | author:Anne Condamines, Maxime Warnier category:cs.SE cs.CL published:2014-06-06 summary:The long term aim of the project carried out by the French National SpaceAgency (CNES) is to design a writing guide based on the real and regularwriting of requirements. As a first step in the project, this paper proposes alin-guistic analysis of requirements written in French by CNES engineers. Theaim is to determine to what extent they conform to two rules laid down inINCOSE, a recent guide for writing requirements. Although CNES engineers arenot obliged to follow any Controlled Natural Language in their writing ofrequirements, we believe that language regularities are likely to emerge fromthis task, mainly due to the writers' experience. The issue is approached usingnatural language processing tools to identify sentences that do not comply withINCOSE rules. We further review these sentences to understand why therecommendations cannot (or should not) always be applied when specifyinglarge-scale projects.
arxiv-7200-205 | Towards a Better Understanding of the Local Attractor in Particle Swarm Optimization: Speed and Solution Quality | http://arxiv.org/abs/1406.1691 | author:Vanessa Lange, Manuel Schmitt, Rolf Wanka category:cs.NE I.2.8 published:2014-06-06 summary:Particle Swarm Optimization (PSO) is a popular nature-inspired meta-heuristicfor solving continuous optimization problems. Although this technique is widelyused, the understanding of the mechanisms that make swarms so successful isstill limited. We present the first substantial experimental investigation ofthe influence of the local attractor on the quality of exploration andexploitation. We compare in detail classical PSO with the social-only variantwhere local attractors are ignored. To measure the exploration capabilities, wedetermine how frequently both variants return results in the neighborhood ofthe global optimum. We measure the quality of exploitation by considering onlyfunction values from runs that reached a search point sufficiently close to theglobal optimum and then comparing in how many digits such values still deviatefrom the global minimum value. It turns out that the local attractorsignificantly improves the exploration, but sometimes reduces the quality ofthe exploitation. As a compromise, we propose and evaluate a hybrid PSO whichswitches off its local attractors at a certain point in time. The effectsmentioned can also be observed by measuring the potential of the swarm.
arxiv-7200-206 | Ant Colony Optimization for Inferring Key Gene Interactions | http://arxiv.org/abs/1406.1626 | author:Khalid Raza, Mahish Kohli category:cs.NE cs.CE published:2014-06-06 summary:Inferring gene interaction network from gene expression data is an importanttask in systems biology research. The gene interaction network, especially keyinteractions, plays an important role in identifying biomarkers for diseasethat further helps in drug design. Ant colony optimization is an optimizationalgorithm based on natural evolution and has been used in many optimizationproblems. In this paper, we applied ant colony optimization algorithm forinferring the key gene interactions from gene expression data. The algorithmhas been tested on two different kinds of benchmark datasets and observed thatit successfully identify some key gene interactions.
arxiv-7200-207 | Separable Cosparse Analysis Operator Learning | http://arxiv.org/abs/1406.1621 | author:Matthias Seibert, Julian Wörmann, Rémi Gribonval, Martin Kleinsteuber category:cs.LG stat.ML published:2014-06-06 summary:The ability of having a sparse representation for a certain class of signalshas many applications in data analysis, image processing, and other researchfields. Among sparse representations, the cosparse analysis model has recentlygained increasing interest. Many signals exhibit a multidimensional structure,e.g. images or three-dimensional MRI scans. Most data analysis and learningalgorithms use vectorized signals and thereby do not account for thisunderlying structure. The drawback of not taking the inherent structure intoaccount is a dramatic increase in computational cost. We propose an algorithmfor learning a cosparse Analysis Operator that adheres to the preexistingstructure of the data, and thus allows for a very efficient implementation.This is achieved by enforcing a separable structure on the learned operator.Our learning algorithm is able to deal with multidimensional data of arbitraryorder. We evaluate our method on volumetric data at the example ofthree-dimensional MRI scans.
arxiv-7200-208 | Logarithmic Time Online Multiclass prediction | http://arxiv.org/abs/1406.1822v13.pdf | author:Anna Choromanska, John Langford category:cs.LG published:2014-06-06 summary:We study the problem of multiclass classification with an extremely largenumber of classes (k), with the goal of obtaining train and test timecomplexity logarithmic in the number of classes. We develop top-down treeconstruction approaches for constructing logarithmic depth trees. On thetheoretical front, we formulate a new objective function, which is optimized ateach node of the tree and creates dynamic partitions of the data which are bothpure (in terms of class labels) and balanced. We demonstrate that underfavorable conditions, we can construct logarithmic depth trees that have leaveswith low label entropy. However, the objective function at the nodes ischallenging to optimize computationally. We address the empirical problem witha new online decision tree construction procedure. Experiments demonstrate thatthis online algorithm quickly achieves improvement in test error compared tomore common logarithmic training time approaches, which makes it a plausiblemethod in computationally constrained large-k applications.
arxiv-7200-209 | Machine learning approach for text and document mining | http://arxiv.org/abs/1406.1580 | author:Vishwanath Bijalwan, Pinki Kumari, Jordan Pascual, Vijay Bhaskar Semwal category:cs.IR cs.LG published:2014-06-06 summary:Text Categorization (TC), also known as Text Classification, is the task ofautomatically classifying a set of text documents into different categoriesfrom a predefined set. If a document belongs to exactly one of the categories,it is a single-label classification task; otherwise, it is a multi-labelclassification task. TC uses several tools from Information Retrieval (IR) andMachine Learning (ML) and has received much attention in the last years fromboth researchers in the academia and industry developers. In this paper, wefirst categorize the documents using KNN based machine learning approach andthen return the most relevant documents.
arxiv-7200-210 | Consistent procedures for cluster tree estimation and pruning | http://arxiv.org/abs/1406.1546 | author:Kamalika Chaudhuri, Sanjoy Dasgupta, Samory Kpotufe, Ulrike von Luxburg category:stat.ML published:2014-06-05 summary:For a density $f$ on ${\mathbb R}^d$, a {\it high-density cluster} is anyconnected component of $\{x: f(x) \geq \lambda\}$, for some $\lambda > 0$. Theset of all high-density clusters forms a hierarchy called the {\it clustertree} of $f$. We present two procedures for estimating the cluster tree givensamples from $f$. The first is a robust variant of the single linkage algorithmfor hierarchical clustering. The second is based on the $k$-nearest neighborgraph of the samples. We give finite-sample convergence rates for thesealgorithms which also imply consistency, and we derive lower bounds on thesample complexity of cluster tree estimation. Finally, we study a tree pruningprocedure that guarantees, under milder conditions than usual, to removeclusters that are spurious while recovering those that are salient.
arxiv-7200-211 | Towards building a Crowd-Sourced Sky Map | http://arxiv.org/abs/1406.1528 | author:Dustin Lang, David W. Hogg, Bernhard Scholkopf category:cs.CV astro-ph.IM published:2014-06-05 summary:We describe a system that builds a high dynamic-range and wide-angle image ofthe night sky by combining a large set of input images. The method makes use ofpixel-rank information in the individual input images to improve a "consensus"pixel rank in the combined image. Because it only makes use of ranks and thecomplexity of the algorithm is linear in the number of images, the method isuseful for large sets of uncalibrated images that might have undergone unknownnon-linear tone mapping transformations for visualization or aesthetic reasons.We apply the method to images of the night sky (of unknown provenance)discovered on the Web. The method permits discovery of astronomical objects orfeatures that are not visible in any of the input images taken individually.More importantly, however, it permits scientific exploitation of a huge sourceof astronomical images that would not be available to astronomical researchwithout our automatic system.
arxiv-7200-212 | Bayesian matrix completion: prior specification | http://arxiv.org/abs/1406.1440 | author:Pierre Alquier, Vincent Cottet, Nicolas Chopin, Judith Rousseau category:stat.ML math.ST stat.CO stat.TH published:2014-06-05 summary:Low-rank matrix estimation from incomplete measurements recently receivedincreased attention due to the emergence of several challenging applications,such as recommender systems; see in particular the famous Netflix challenge.While the behaviour of algorithms based on nuclear norm minimization is nowwell understood, an as yet unexplored avenue of research is the behaviour ofBayesian algorithms in this context. In this paper, we briefly review thepriors used in the Bayesian literature for matrix completion. A standardapproach is to assign an inverse gamma prior to the singular values of acertain singular value decomposition of the matrix of interest; this prior isconjugate. However, we show that two other types of priors (again for thesingular values) may be conjugate for this model: a gamma prior, and a discreteprior. Conjugacy is very convenient, as it makes it possible to implementeither Gibbs sampling or Variational Bayes. Interestingly enough, the maximum aposteriori for these different priors is related to the nuclear normminimization problems. We also compare all these priors on simulated datasets,and on the classical MovieLens and Netflix datasets.
arxiv-7200-213 | Learning the Information Divergence | http://arxiv.org/abs/1406.1385 | author:Onur Dikmen, Zhirong Yang, Erkki Oja category:cs.LG published:2014-06-05 summary:Information divergence that measures the difference between two nonnegativematrices or tensors has found its use in a variety of machine learningproblems. Examples are Nonnegative Matrix/Tensor Factorization, StochasticNeighbor Embedding, topic models, and Bayesian network optimization. Thesuccess of such a learning task depends heavily on a suitable divergence. Alarge variety of divergences have been suggested and analyzed, but very fewresults are available for an objective choice of the optimal divergence for agiven task. Here we present a framework that facilitates automatic selection ofthe best divergence among a given family, based on standard maximum likelihoodestimation. We first propose an approximated Tweedie distribution for thebeta-divergence family. Selecting the best beta then becomes a machine learningproblem solved by maximum likelihood. Next, we reformulate alpha-divergence interms of beta-divergence, which enables automatic selection of alpha by maximumlikelihood with reuse of the learning principle for beta-divergence.Furthermore, we show the connections between gamma and beta-divergences as wellas R\'enyi and alpha-divergences, such that our automatic selection frameworkis extended to non-separable divergences. Experiments on both synthetic andreal-world data demonstrate that our method can quite accurately selectinformation divergence across different learning problems and variousdivergence families.
arxiv-7200-214 | Basis Identification for Automatic Creation of Pronunciation Lexicon for Proper Names | http://arxiv.org/abs/1406.1280 | author:Sunil Kumar Kopparapu, M Laxminarayana category:cs.CL published:2014-06-05 summary:Development of a proper names pronunciation lexicon is usually a manualeffort which can not be avoided. Grapheme to phoneme (G2P) conversion modules,in literature, are usually rule based and work best for non-proper names in aparticular language. Proper names are foreign to a G2P module. We follow anoptimization approach to enable automatic construction of proper namespronunciation lexicon. The idea is to construct a small orthogonal set of words(basis) which can span the set of names in a given database. We propose twoalgorithms for the construction of this basis. The transcription lexicon of allthe proper names in a database can be produced by the manual transcription ofonly the small set of basis words. We first construct a cost function and showthat the minimization of the cost function results in a basis. We deriveconditions for convergence of this cost function and validate themexperimentally on a very large proper name database. Experiments show thetranscription can be achieved by transcribing a set of small number of basiswords. The algorithms proposed are generic and independent of language; howeverperformance is better if the proper names have same origin, namely, samelanguage or geographical region.
arxiv-7200-215 | Illusory Shapes via Phase Transition | http://arxiv.org/abs/1406.1265 | author:Yoon Mo Jung, Jianhong Jackie Shen category:math.OC cs.CV q-bio.NC published:2014-06-05 summary:We propose a new variational illusory shape (VIS) model via phase fields andphase transitions. It is inspired by the first-order variational illusorycontour (VIC) model proposed by Jung and Shen [{\em J. Visual Comm. ImageRepres.}, {\bf 19}:42-55, 2008]. Under the new VIS model, illusory shapes arerepresented by phase values close to 1 while the rest by values close to 0. The0-1 transition is achieved by an elliptic energy with a double-well potential,as in the theory of $\Gamma$-convergence. The VIS model is non-convex, with thezero field as its trivial global optimum. To seek visually meaningful localoptima that can induce illusory shapes, an iterative algorithm is designed andits convergence behavior is closely studied. Several generic numerical examplesconfirm the versatility of the model and the algorithm.
arxiv-7200-216 | Advances in Learning Bayesian Networks of Bounded Treewidth | http://arxiv.org/abs/1406.1411 | author:Siqi Nie, Denis Deratani Maua, Cassio Polpo de Campos, Qiang Ji category:cs.AI cs.LG stat.ML 68T37 published:2014-06-05 summary:This work presents novel algorithms for learning Bayesian network structureswith bounded treewidth. Both exact and approximate methods are developed. Theexact method combines mixed-integer linear programming formulations forstructure learning and treewidth computation. The approximate method consistsin uniformly sampling $k$-trees (maximal graphs of treewidth $k$), andsubsequently selecting, exactly or approximately, the best structure whosemoral graph is a subgraph of that $k$-tree. Some properties of these methodsare discussed and proven. The approaches are empirically compared to each otherand to a state-of-the-art method for learning bounded treewidth structures on acollection of public data sets with up to 100 variables. The experiments showthat our exact algorithm outperforms the state of the art, and that theapproximate approach is fairly accurate.
arxiv-7200-217 | Shared Representation Learning for Heterogeneous Face Recognition | http://arxiv.org/abs/1406.1247 | author:Dong Yi, Zhen Lei, Shengcai Liao, Stan Z. Li category:cs.CV published:2014-06-05 summary:After intensive research, heterogenous face recognition is still achallenging problem. The main difficulties are owing to the complexrelationship between heterogenous face image spaces. The heterogeneity isalways tightly coupled with other variations, which makes the relationship ofheterogenous face images highly nonlinear. Many excellent methods have beenproposed to model the nonlinear relationship, but they apt to overfit to thetraining set, due to limited samples. Inspired by the unsupervised algorithmsin deep learning, this paper proposes an novel framework for heterogeneous facerecognition. We first extract Gabor features at some localized facial points,and then use Restricted Boltzmann Machines (RBMs) to learn a sharedrepresentation locally to remove the heterogeneity around each facial point.Finally, the shared representations of local RBMs are connected together andprocessed by PCA. Two problems (Sketch-Photo and NIR-VIS) and three databasesare selected to evaluate the proposed method. For Sketch-Photo problem, weobtain perfect results on the CUFS database. For NIR-VIS problem, we producenew state-of-the-art performance on the CASIA HFB and NIR-VIS 2.0 databases.
arxiv-7200-218 | Faster Rates for the Frank-Wolfe Method over Strongly-Convex Sets | http://arxiv.org/abs/1406.1305 | author:Dan Garber, Elad Hazan category:math.OC cs.LG published:2014-06-05 summary:The Frank-Wolfe method (a.k.a. conditional gradient algorithm) for smoothoptimization has regained much interest in recent years in the context of largescale optimization and machine learning. A key advantage of the method is thatit avoids projections - the computational bottleneck in many applications -replacing it by a linear optimization step. Despite this advantage, the knownconvergence rates of the FW method fall behind standard first order methods formost settings of interest. It is an active line of research to derive fasterlinear optimization-based algorithms for various settings of convexoptimization. In this paper we consider the special case of optimization over stronglyconvex sets, for which we prove that the vanila FW method converges at a rateof $\frac{1}{t^2}$. This gives a quadratic improvement in convergence ratecompared to the general case, in which convergence is of the order$\frac{1}{t}$, and known to be tight. We show that various balls induced by$\ell_p$ norms, Schatten norms and group norms are strongly convex on one handand on the other hand, linear optimization over these sets is straightforwardand admits a closed-form solution. We further show how several previousfast-rate results for the FW method follow easily from our analysis.
arxiv-7200-219 | Systematic N-tuple Networks for Position Evaluation: Exceeding 90% in the Othello League | http://arxiv.org/abs/1406.1509 | author:Wojciech Jaśkowski category:cs.NE cs.AI cs.LG 68T05 published:2014-06-05 summary:N-tuple networks have been successfully used as position evaluation functionsfor board games such as Othello or Connect Four. The effectiveness of suchnetworks depends on their architecture, which is determined by the placement ofconstituent n-tuples, sequences of board locations, providing input to thenetwork. The most popular method of placing n-tuples consists in randomlygenerating a small number of long, snake-shaped board location sequences. Incomparison, we show that learning n-tuple networks is significantly moreeffective if they involve a large number of systematically placed, short,straight n-tuples. Moreover, we demonstrate that in order to obtain the bestperformance and the steepest learning curve for Othello it is enough to usen-tuples of size just 2, yielding a network consisting of only 288 weights. Thebest such network evolved in this study has been evaluated in the onlineOthello League, obtaining the performance of nearly 96% --- more than any otherplayer to date.
arxiv-7200-220 | Iterative Neural Autoregressive Distribution Estimator (NADE-k) | http://arxiv.org/abs/1406.1485 | author:Tapani Raiko, Li Yao, Kyunghyun Cho, Yoshua Bengio category:stat.ML cs.LG published:2014-06-05 summary:Training of the neural autoregressive density estimator (NADE) can be viewedas doing one step of probabilistic inference on missing values in data. Wepropose a new model that extends this inference scheme to multiple steps,arguing that it is easier to learn to improve a reconstruction in $k$ stepsrather than to learn to reconstruct in a single inference step. The proposedmodel is an unsupervised building block for deep learning that combines thedesirable properties of NADE and multi-predictive training: (1) Its testlikelihood can be computed analytically, (2) it is easy to generate independentsamples from it, and (3) it uses an inference engine that is a superset ofvariational inference for Boltzmann machines. The proposed NADE-k iscompetitive with the state-of-the-art in density estimation on the two datasetstested.
arxiv-7200-221 | A Context-aware Delayed Agglomeration Framework for Electron Microscopy Segmentation | http://arxiv.org/abs/1406.1476 | author:Toufiq Parag, Anirban Chakraborty, Stephen Plaza, Lou Scheffer category:cs.CV published:2014-06-05 summary:Electron Microscopy (EM) image (or volume) segmentation has becomesignificantly important in recent years as an instrument for connectomics. Thispaper proposes a novel agglomerative framework for EM segmentation. Inparticular, given an over-segmented image or volume, we propose a novelframework for accurately clustering regions of the same neuron. Unlike existingagglomerative methods, the proposed context-aware algorithm divides superpixels(over-segmented regions) of different biological entities into differentsubsets and agglomerates them separately. In addition, this paper describes a"delayed" scheme for agglomerative clustering that postpones some of the mergedecisions, pertaining to newly formed bodies, in order to generate a moreconfident boundary prediction. We report significant improvements attained bythe proposed approach in segmentation accuracy over existing standard methodson 2D and 3D datasets.
arxiv-7200-222 | Local Decorrelation For Improved Detection | http://arxiv.org/abs/1406.1134 | author:Woonhyun Nam, Piotr Dollár, Joon Hee Han category:cs.CV published:2014-06-04 summary:Even with the advent of more sophisticated, data-hungry methods, boosteddecision trees remain extraordinarily successful for fast rigid objectdetection, achieving top accuracy on numerous datasets. While effective, mostboosted detectors use decision trees with orthogonal (single feature) splits,and the topology of the resulting decision boundary may not be well matched tothe natural topology of the data. Given highly correlated data, decision treeswith oblique (multiple feature) splits can be effective. Use of oblique splits,however, comes at considerable computational expense. Inspired by recent workon discriminative decorrelation of HOG features, we instead propose anefficient feature transform that removes correlations in local neighborhoods.The result is an overcomplete but locally decorrelated representation ideallysuited for use with orthogonal decision trees. In fact, orthogonal trees withour locally decorrelated features outperform oblique trees trained over theoriginal features at a fraction of the computational cost. The overallimprovement in accuracy is dramatic: on the Caltech Pedestrian Dataset, wereduce false positives nearly tenfold over the previous state-of-the-art.
arxiv-7200-223 | Linear Convergence of Variance-Reduced Stochastic Gradient without Strong Convexity | http://arxiv.org/abs/1406.1102 | author:Pinghua Gong, Jieping Ye category:cs.NA cs.LG stat.CO stat.ML published:2014-06-04 summary:Stochastic gradient algorithms estimate the gradient based on only one or afew samples and enjoy low computational cost per iteration. They have beenwidely used in large-scale optimization problems. However, stochastic gradientalgorithms are usually slow to converge and achieve sub-linear convergencerates, due to the inherent variance in the gradient computation. To acceleratethe convergence, some variance-reduced stochastic gradient algorithms, e.g.,proximal stochastic variance-reduced gradient (Prox-SVRG) algorithm, haverecently been proposed to solve strongly convex problems. Under the stronglyconvex condition, these variance-reduced stochastic gradient algorithms achievea linear convergence rate. However, many machine learning problems are convexbut not strongly convex. In this paper, we introduce Prox-SVRG and itsprojected variant called Variance-Reduced Projected Stochastic Gradient (VRPSG)to solve a class of non-strongly convex optimization problems widely used inmachine learning. As the main technical contribution of this paper, we showthat both VRPSG and Prox-SVRG achieve a linear convergence rate without strongconvexity. A key ingredient in our proof is a Semi-Strongly Convex (SSC)inequality which is the first to be rigorously proved for a class ofnon-strongly convex problems in both constrained and regularized settings.Moreover, the SSC inequality is independent of algorithms and may be applied toanalyze other stochastic gradient algorithms besides VRPSG and Prox-SVRG, whichmay be of independent interest. To the best of our knowledge, this is the firstwork that establishes the linear convergence rate for the variance-reducedstochastic gradient algorithms on solving both constrained and regularizedproblems without strong convexity.
arxiv-7200-224 | The Best Templates Match Technique For Example Based Machine Translation | http://arxiv.org/abs/1406.1241 | author:T. El-Shishtawy, A. El-Sammak category:cs.CL published:2014-06-04 summary:It has been proved that large scale realistic Knowledge Based MachineTranslation applications require acquisition of huge knowledge about languageand about the world. This knowledge is encoded in computational grammars,lexicons and domain models. Another approach which avoids the need forcollecting and analyzing massive knowledge, is the Example Based approach,which is the topic of this paper. We show through the paper that using ExampleBased in its native form is not suitable for translating into Arabic. Thereforea modification to the basic approach is presented to improve the accuracy ofthe translation process. The basic idea of the new approach is to improve thetechnique by which template-based approaches select the appropriate templates.
arxiv-7200-225 | A Geometric Method to Obtain the Generation Probability of a Sentence | http://arxiv.org/abs/1406.1234 | author:Chen Lijiang category:cs.CL cs.AI math.ST stat.CO stat.ME stat.TH published:2014-06-04 summary:"How to generate a sentence" is the most critical and difficult problem inall the natural language processing technologies. In this paper, we present anew approach to explain the generation process of a sentence from theperspective of mathematics. Our method is based on the premise that in ourbrain a sentence is a part of a word network which is formed by many wordnodes. Experiments show that the probability of the entire sentence can beobtained by the probabilities of single words and the probabilities of theco-occurrence of word pairs, which indicate that human use the synthesis methodto generate a sentence.
arxiv-7200-226 | Multi-task Neural Networks for QSAR Predictions | http://arxiv.org/abs/1406.1231 | author:George E. Dahl, Navdeep Jaitly, Ruslan Salakhutdinov category:stat.ML cs.LG cs.NE published:2014-06-04 summary:Although artificial neural networks have occasionally been used forQuantitative Structure-Activity/Property Relationship (QSAR/QSPR) studies inthe past, the literature has of late been dominated by other machine learningtechniques such as random forests. However, a variety of new neural nettechniques along with successful applications in other domains have renewedinterest in network approaches. In this work, inspired by the winning team'suse of neural networks in a recent QSAR competition, we used an artificialneural network to learn a function that predicts activities of compounds formultiple assays at the same time. We conducted experiments leveraging recentmethods for dealing with overfitting in neural networks as well as other tricksfrom the neural networks literature. We compared our methods to alternativemethods reported to perform well on these tasks and found that our neural netmethods provided superior performance.
arxiv-7200-227 | A Semantic Approach to Summarization | http://arxiv.org/abs/1406.1203 | author:Divyanshu Bhartiya, Ashudeep Singh category:cs.CL published:2014-06-04 summary:Sentence extraction based summarization methods has some limitations as itdoesn't go into the semantics of the document. Also, it lacks the capability ofsentence generation which is intuitive to humans. Here we present a novelmethod to summarize text documents taking the process to semantic levels withthe use of WordNet and other resources, and using a technique for sentencegeneration. We involve semantic role labeling to get the semanticrepresentation of text and use of segmentation to form clusters of the relatedpieces of text. Picking out the centroids and sentence generation completes thetask. We evaluate our system against human composed summaries and also presentan evaluation done by humans to measure the quality attributes of oursummaries.
arxiv-7200-228 | Identifying Duplicate and Contradictory Information in Wikipedia | http://arxiv.org/abs/1406.1143 | author:Sarah Weissman, Samet Ayhan, Joshua Bradley, Jimmy Lin category:cs.IR cs.CL cs.DL cs.SI published:2014-06-04 summary:Our study identifies sentences in Wikipedia articles that are eitheridentical or highly similar by applying techniques for near-duplicate detectionof web pages. This is accomplished with a MapReduce implementation of minhashto identify clusters of sentences with high Jaccard similarity. We show thatthese clusters can be categorized into six different types, two of which areparticularly interesting: identical sentences quantify the extent to whichcontent in Wikipedia is copied and pasted, and near-duplicate sentences thatstate contradictory facts point to quality issues in Wikipedia.
arxiv-7200-229 | PAC Learning, VC Dimension, and the Arithmetic Hierarchy | http://arxiv.org/abs/1406.1111 | author:Wesley Calvert category:math.LO cs.LG cs.LO 03D80, 03D45 I.2.6 published:2014-06-04 summary:We compute that the index set of PAC-learnable concept classes is$m$-complete $\Sigma^0_3$ within the set of indices for all concept classes ofa reasonable form. All concept classes considered are computable enumerationsof computable $\Pi^0_1$ classes, in a sense made precise here. This family ofconcept classes is sufficient to cover all standard examples, and also has theproperty that PAC learnability is equivalent to finite VC dimension.
arxiv-7200-230 | A variational approach to stable principal component pursuit | http://arxiv.org/abs/1406.1089 | author:Aleksandr Aravkin, Stephen Becker, Volkan Cevher, Peder Olsen category:math.OC stat.ML published:2014-06-04 summary:We introduce a new convex formulation for stable principal component pursuit(SPCP) to decompose noisy signals into low-rank and sparse representations. Fornumerical solutions of our SPCP formulation, we first develop a convexvariational framework and then accelerate it with quasi-Newton methods. Weshow, via synthetic and real data experiments, that our approach offersadvantages over the classical SPCP formulations in scalability and practicalparameter selection.
arxiv-7200-231 | Learning to Diversify via Weighted Kernels for Classifier Ensemble | http://arxiv.org/abs/1406.1167 | author:Xu-Cheng Yin, Chun Yang, Hong-Wei Hao category:cs.LG cs.CV I.5 published:2014-06-04 summary:Classifier ensemble generally should combine diverse component classifiers.However, it is difficult to give a definitive connection between diversitymeasure and ensemble accuracy. Given a list of available component classifiers,how to adaptively and diversely ensemble classifiers becomes a big challenge inthe literature. In this paper, we argue that diversity, not direct diversity onsamples but adaptive diversity with data, is highly correlated to ensembleaccuracy, and we propose a novel technology for classifier ensemble, learningto diversify, which learns to adaptively combine classifiers by consideringboth accuracy and diversity. Specifically, our approach, Learning TO Diversifyvia Weighted Kernels (L2DWK), performs classifier combination by optimizing adirect but simple criterion: maximizing ensemble accuracy and adaptivediversity simultaneously by minimizing a convex loss function. Given a measureformulation, the diversity is calculated with weighted kernels (i.e., thediversity is measured on the component classifiers' outputs which are kernelledand weighted), and the kernel weights are automatically learned. We minimizethis loss function by estimating the kernel weights in conjunction with theclassifier weights, and propose a self-training algorithm for conducting thisconvex optimization procedure iteratively. Extensive experiments on a varietyof 32 UCI classification benchmark datasets show that the proposed approachconsistently outperforms state-of-the-art ensembles such as Bagging, AdaBoost,Random Forests, Gasen, Regularized Selective Ensemble, and Ensemble Pruning viaSemi-Definite Programming.
arxiv-7200-232 | Integration of a Predictive, Continuous Time Neural Network into Securities Market Trading Operations | http://arxiv.org/abs/1406.0968 | author:Christopher S Kirk category:q-fin.CP cs.CE cs.NE published:2014-06-04 summary:This paper describes recent development and test implementation of acontinuous time recurrent neural network that has been configured to predictrates of change in securities. It presents outcomes in the context of populartechnical analysis indicators and highlights the potential impact of continuouspredictive capability on securities market trading operations.
arxiv-7200-233 | Beyond $χ^2$ Difference: Learning Optimal Metric for Boundary Detection | http://arxiv.org/abs/1406.0946 | author:Fei He, Shengjin Wang category:cs.CV published:2014-06-04 summary:This letter focuses on solving the challenging problem of detecting naturalimage boundaries. A boundary usually refers to the border between two regionswith different semantic meanings. Therefore, a measurement of dissimilaritybetween image regions plays a pivotal role in boundary detection of naturalimages. To improve the performance of boundary detection, a Learning-basedBoundary Metric (LBM) is proposed to replace $\chi^2$ difference adopted by theclassical algorithm mPb. Compared with $\chi^2$ difference, LBM is composed ofa single layer neural network and an RBF kernel, and is fine-tuned bysupervised learning rather than human-crafted. It is more effective indescribing the dissimilarity between natural image regions while toleratinglarge variance of image data. After substituting $\chi^2$ difference with LBM,the F-measure metric of mPb on the BSDS500 benchmark is increased from 0.69 to0.71. Moreover, when image features are computed on a single scale, theproposed LBM algorithm still achieves competitive results compared with\emph{mPb}, which makes use of multi-scale image features.
arxiv-7200-234 | ACO Implementation for Sequence Alignment with Genetic Algorithms | http://arxiv.org/abs/1406.0930 | author:Aaron Lee, Livia King category:cs.CE cs.NE published:2014-06-04 summary:In this paper, we implement Ant Colony Optimization (ACO) for sequencealignment. ACO is a meta-heuristic recently developed for nearest neighborapproximations in large, NP-hard search spaces. Here we use a genetic algorithmapproach to evolve the best parameters for an ACO designed to align twosequences. We then used the best parameters found to interpolate approximateoptimal parameters for a given string length within a range. The basis of ourcomparison is the alignment given by the Needleman-Wunsch algorithm. We foundthat ACO can indeed be applied to sequence alignment. While it iscomputationally expensive compared to other equivalent algorithms, it is apromising algorithm that can be readily applied to a variety of otherbiological problems.
arxiv-7200-235 | Improvement Tracking Dynamic Programming using Replication Function for Continuous Sign Language Recognition | http://arxiv.org/abs/1406.0909 | author:S. Ildarabadi, M. Ebrahimi, H. R. Pourreza category:cs.CV published:2014-06-04 summary:In this paper we used a Replication Function (R. F.)for improvement trackingwith dynamic programming. The R. F. transforms values of gray level [0 255] to[0 1]. The resulting images of R. F. are more striking and visible in skinregions. The R. F. improves Dynamic Programming (D. P.) in overlapping hand andface. Results show that Tracking Error Rate 11% and Average Tracked Distance 7%reduced
arxiv-7200-236 | Gradient Sliding for Composite Optimization | http://arxiv.org/abs/1406.0919 | author:Guanghui Lan category:math.OC cs.CC stat.ML published:2014-06-04 summary:We consider in this paper a class of composite optimization problems whoseobjective function is given by the summation of a general smooth and nonsmoothcomponent, together with a relatively simple nonsmooth term. We present a newclass of first-order methods, namely the gradient sliding algorithms, which canskip the computation of the gradient for the smooth component from time totime. As a consequence, these algorithms require only ${\calO}(1/\sqrt{\epsilon})$ gradient evaluations for the smooth component in orderto find an $\epsilon$-solution for the composite problem, while stillmaintaining the optimal ${\cal O}(1/\epsilon^2)$ bound on the total number ofsubgradient evaluations for the nonsmooth component. We then present astochastic counterpart for these algorithms and establish similar complexitybounds for solving an important class of stochastic composite optimizationproblems. Moreover, if the smooth component in the composite function isstrongly convex, the developed gradient sliding algorithms can significantlyreduce the number of graduate and subgradient evaluations for the smooth andnonsmooth component to ${\cal O} (\log (1/\epsilon))$ and ${\calO}(1/\epsilon)$, respectively. Finally, we generalize these algorithms to thecase when the smooth component is replaced by a nonsmooth one possessing acertain bi-linear saddle point structure.
arxiv-7200-237 | Discovering Structure in High-Dimensional Data Through Correlation Explanation | http://arxiv.org/abs/1406.1222 | author:Greg Ver Steeg, Aram Galstyan category:cs.LG cs.AI stat.ML published:2014-06-04 summary:We introduce a method to learn a hierarchy of successively more abstractrepresentations of complex data based on optimizing an information-theoreticobjective. Intuitively, the optimization searches for a set of latent factorsthat best explain the correlations in the data as measured by multivariatemutual information. The method is unsupervised, requires no model assumptions,and scales linearly with the number of variables which makes it an attractiveapproach for very high dimensional systems. We demonstrate that CorrelationExplanation (CorEx) automatically discovers meaningful structure for data fromdiverse sources including personality tests, DNA, and human language.
arxiv-7200-238 | Multiscale Fields of Patterns | http://arxiv.org/abs/1406.0924 | author:Pedro F. Felzenszwalb, John G. Oberlin category:cs.CV published:2014-06-04 summary:We describe a framework for defining high-order image models that can be usedin a variety of applications. The approach involves modeling local patterns ina multiscale representation of an image. Local properties of a coarsened imagereflect non-local properties of the original image. In the case of binaryimages local properties are defined by the binary patterns observed over smallneighborhoods around each pixel. With the multiscale representation we capturethe frequency of patterns observed at different scales of resolution. Thisframework leads to expressive priors that depend on a relatively small numberof parameters. For inference and learning we use an MCMC method for blocksampling with very large blocks. We evaluate the approach with two exampleapplications. One involves contour detection. The other involves binarysegmentation.
arxiv-7200-239 | Learning Phrase Representations using RNN Encoder-Decoder for Statistical Machine Translation | http://arxiv.org/abs/1406.1078 | author:Kyunghyun Cho, Bart van Merrienboer, Caglar Gulcehre, Dzmitry Bahdanau, Fethi Bougares, Holger Schwenk, Yoshua Bengio category:cs.CL cs.LG cs.NE stat.ML published:2014-06-03 summary:In this paper, we propose a novel neural network model called RNNEncoder-Decoder that consists of two recurrent neural networks (RNN). One RNNencodes a sequence of symbols into a fixed-length vector representation, andthe other decodes the representation into another sequence of symbols. Theencoder and decoder of the proposed model are jointly trained to maximize theconditional probability of a target sequence given a source sequence. Theperformance of a statistical machine translation system is empirically found toimprove by using the conditional probabilities of phrase pairs computed by theRNN Encoder-Decoder as an additional feature in the existing log-linear model.Qualitatively, we show that the proposed model learns a semantically andsyntactically meaningful representation of linguistic phrases.
arxiv-7200-240 | A Game-theoretic Machine Learning Approach for Revenue Maximization in Sponsored Search | http://arxiv.org/abs/1406.0728 | author:Di He, Wei Chen, Liwei Wang, Tie-Yan Liu category:cs.GT cs.LG published:2014-06-03 summary:Sponsored search is an important monetization channel for search engines, inwhich an auction mechanism is used to select the ads shown to users anddetermine the prices charged from advertisers. There have been several piecesof work in the literature that investigate how to design an auction mechanismin order to optimize the revenue of the search engine. However, due to someunrealistic assumptions used, the practical values of these studies are notvery clear. In this paper, we propose a novel \emph{game-theoretic machinelearning} approach, which naturally combines machine learning and game theory,and learns the auction mechanism using a bilevel optimization framework. Inparticular, we first learn a Markov model from historical data to describe howadvertisers change their bids in response to an auction mechanism, and then forany given auction mechanism, we use the learnt model to predict itscorresponding future bid sequences. Next we learn the auction mechanism throughempirical revenue maximization on the predicted bid sequences. We show that theempirical revenue will converge when the prediction period approaches infinity,and a Genetic Programming algorithm can effectively optimize this empiricalrevenue. Our experiments indicate that the proposed approach is able to producea much more effective auction mechanism than several baselines.
arxiv-7200-241 | Maximum margin classifier working in a set of strings | http://arxiv.org/abs/1406.0597 | author:Hitoshi Koyano, Morihiro Hayashida, Tatsuya Akutsu category:stat.ML published:2014-06-03 summary:Numbers and numerical vectors account for a large portion of data. However,recently the amount of string data generated has increased dramatically.Consequently, classifying string data is a common problem in many fields. Themost widely used approach to this problem is to convert strings into numericalvectors using string kernels and subsequently apply a support vector machinethat works in a numerical vector space. However, this non-one-to-one conversioninvolves a loss of information and makes it impossible to evaluate, usingprobability theory, the generalization error of a learning machine, consideringthat the given data to train and test the machine are strings generatedaccording to probability laws. In this study, we approach this classificationproblem by constructing a classifier that works in a set of strings. Toevaluate the generalization error of such a classifier theoretically,probability theory for strings is required. Therefore, we first extend a limittheorem on the asymptotic behavior of a consensus sequence of strings, which isthe counterpart of the mean of numerical vectors, as demonstrated in theprobability theory on a metric space of strings developed by one of the authorsand his colleague in a previous study [18]. Using the obtained result, we thendemonstrate that our learning machine classifies strings in an asymptoticallyoptimal manner. Furthermore, we demonstrate the usefulness of our machine inpractical data analysis by applying it to predicting protein--proteininteractions using amino acid sequences.
arxiv-7200-242 | Image retrieval with hierarchical matching pursuit | http://arxiv.org/abs/1406.0588 | author:Shasha Bu, Yu-Jin Zhang category:cs.CV published:2014-06-03 summary:A novel representation of images for image retrieval is introduced in thispaper, by using a new type of feature with remarkable discriminative power.Despite the multi-scale nature of objects, most existing models perform featureextraction on a fixed scale, which will inevitably degrade the performance ofthe whole system. Motivated by this, we introduce a hierarchical sparse codingarchitecture for image retrieval to explore multi-scale cues. Sparse codesextracted on lower layers are transmitted to higher layers recursively. Withthis mechanism, cues from different scales are fused. Experiments on theHolidays dataset show that the proposed method achieves an excellent retrievalperformance with a small code length.
arxiv-7200-243 | Supervised classification-based stock prediction and portfolio optimization | http://arxiv.org/abs/1406.0824 | author:Sercan Arik, Sukru Burc Eryilmaz, Adam Goldberg category:q-fin.ST cs.CE cs.LG q-fin.PM stat.ML published:2014-06-03 summary:As the number of publicly traded companies as well as the amount of theirfinancial data grows rapidly, it is highly desired to have tracking, analysis,and eventually stock selections automated. There have been few works focusingon estimating the stock prices of individual companies. However, many of thosehave worked with very small number of financial parameters. In this work, weapply machine learning techniques to address automated stock picking, whileusing a larger number of financial parameters for individual companies than theprevious studies. Our approaches are based on the supervision of predictionparameters using company fundamentals, time-series properties, and correlationinformation between different stocks. We examine a variety of supervisedlearning techniques and found that using stock fundamentals is a usefulapproach for the classification problem, when combined with the highdimensional data handling capabilities of support vector machine. The portfolioour system suggests by predicting the behavior of stocks results in a 3% largergrowth on average than the overall market within a 3-month time period, as theout-of-sample test suggests.
arxiv-7200-244 | Linear Dimensionality Reduction: Survey, Insights, and Generalizations | http://arxiv.org/abs/1406.0873 | author:John P. Cunningham, Zoubin Ghahramani category:stat.ML published:2014-06-03 summary:Linear dimensionality reduction methods are a cornerstone of analyzing highdimensional data, due to their simple geometric interpretations and typicallyattractive computational properties. These methods capture many data featuresof interest, such as covariance, dynamical structure, correlation between datasets, input-output relationships, and margin between data classes. Methods havebeen developed with a variety of names and motivations in many fields, andperhaps as a result the connections between all these methods have not beenhighlighted. Here we survey methods from this disparate literature asoptimization programs over matrix manifolds. We discuss principal componentanalysis, factor analysis, linear multidimensional scaling, Fisher's lineardiscriminant analysis, canonical correlations analysis, maximum autocorrelationfactors, slow feature analysis, sufficient dimensionality reduction,undercomplete independent component analysis, linear regression, distancemetric learning, and more. This optimization framework gives insight to somerarely discussed shortcomings of well-known methods, such as the suboptimalityof certain eigenvector solutions. Modern techniques for optimization overmatrix manifolds enable a generic linear dimensionality reduction solver, whichaccepts as input data and an objective to be optimized, and returns, as output,an optimal low-dimensional projection of the data. This simple optimizationframework further allows straightforward generalizations and novel variants ofclassical methods, which we demonstrate here by creating anorthogonal-projection canonical correlations analysis. More broadly, thissurvey and generic solver suggest that linear dimensionality reduction can movetoward becoming a blackbox, objective-agnostic numerical technology.
arxiv-7200-245 | Constructing Dynamic Treatment Regimes in Infinite-Horizon Settings | http://arxiv.org/abs/1406.0764 | author:Ashkan Ertefaie category:stat.ME stat.ML published:2014-06-03 summary:The application of existing methods for constructing optimal dynamictreatment regimes is limited to cases where investigators are interested inoptimizing a utility function over a fixed period of time (finite horizon). Inthis manuscript, we develop an inferential procedure based on temporaldifference residuals for optimal dynamic treatment regimes in infinite-horizonsettings, where there is no a priori fixed end of follow-up point. The proposedmethod can be used to determine the optimal regime in chronic diseases wherepatients are monitored and treated throughout their life. We derive largesample results necessary for conducting inference. We also simulate a cohort ofpatients with diabetes to mimic the third wave of the National Health andNutrition Examination Survey, and we examine the performance of the proposedmethod in controlling the level of hemoglobin A1c. Supplementary materials forthis article are available online.
arxiv-7200-246 | Visual Reranking with Improved Image Graph | http://arxiv.org/abs/1406.0680 | author:Ziqiong Liu, Shengjin Wang, Liang Zheng, Qi Tian category:cs.CV published:2014-06-03 summary:This paper introduces an improved reranking method for the Bag-of-Words (BoW)based image search. Built on [1], a directed image graph robust to outlierdistraction is proposed. In our approach, the relevance among images is encodedin the image graph, based on which the initial rank list is refined. Moreover,we show that the rank-level feature fusion can be adopted in this rerankingmethod as well. Taking advantage of the complementary nature of variousfeatures, the reranking performance is further enhanced. Particularly, weexploit the reranking method combining the BoW and color information.Experiments on two benchmark datasets demonstrate that ourmethod yieldssignificant improvements and the reranking results are competitive to thestate-of-the-art methods.
arxiv-7200-247 | Universal Convexification via Risk-Aversion | http://arxiv.org/abs/1406.0554 | author:Krishnamurthy Dvijotham, Maryam Fazel, Emanuel Todorov category:cs.SY cs.LG math.OC published:2014-06-03 summary:We develop a framework for convexifying a fairly general class ofoptimization problems. Under additional assumptions, we analyze thesuboptimality of the solution to the convexified problem relative to theoriginal nonconvex problem and prove additive approximation guarantees. We thendevelop algorithms based on stochastic gradient methods to solve the resultingoptimization problems and show bounds on convergence rates. %We show a simpleapplication of this framework to supervised learning, where one can performintegration explicitly and can use standard (non-stochastic) optimizationalgorithms with better convergence guarantees. We then extend this framework toapply to a general class of discrete-time dynamical systems. In this context,our convexification approach falls under the well-studied paradigm ofrisk-sensitive Markov Decision Processes. We derive the first known model-basedand model-free policy gradient optimization algorithms with guaranteedconvergence to the optimal solution. Finally, we present numerical resultsvalidating our formulation in different applications.
arxiv-7200-248 | The constitution of visual perceptual units in the functional architecture of V1 | http://arxiv.org/abs/1406.0289 | author:Alessandro Sarti, Giovanna Citti category:cs.CV published:2014-06-02 summary:Scope of this paper is to consider a mean field neural model which takes intoaccount the functional neurogeometry of the visual cortex modelled as a groupof rotations and translations. The model generalizes well known results ofBressloff and Cowan which, in absence of input, accounts for hallucinationpatterns. The main result of our study consists in showing that in presence ofa visual input, the eigenmodes of the linearized operator which become stablerepresent perceptual units present in the image. The result is strictly relatedto dimensionality reduction and clustering problems.
arxiv-7200-249 | Transductive Learning for Multi-Task Copula Processes | http://arxiv.org/abs/1406.0304 | author:Markus Schneider, Fabio Ramos category:cs.LG stat.ML published:2014-06-02 summary:We tackle the problem of multi-task learning with copula process.Multivariable prediction in spatial and spatial-temporal processes such asnatural resource estimation and pollution monitoring have been typicallyaddressed using techniques based on Gaussian processes and co-Kriging. Whilethe Gaussian prior assumption is convenient from analytical and computationalperspectives, nature is dominated by non-Gaussian likelihoods. Copula processesare an elegant and flexible solution to handle various non-Gaussian likelihoodsby capturing the dependence structure of random variables with cumulativedistribution functions rather than their marginals. We show how multi-tasklearning for copula processes can be used to improve multivariable predictionfor problems where the simple Gaussianity prior assumption does not hold. Then,we present a transductive approximation for multi-task learning and deriveanalytical expressions for the copula process model. The approach is evaluatedand compared to other techniques in one artificial dataset and two publiclyavailable datasets for natural resource estimation and concrete slumpprediction.
arxiv-7200-250 | Generalized Max Pooling | http://arxiv.org/abs/1406.0312 | author:Naila Murray, Florent Perronnin category:cs.CV published:2014-06-02 summary:State-of-the-art patch-based image representations involve a poolingoperation that aggregates statistics computed from local descriptors. Standardpooling operations include sum- and max-pooling. Sum-pooling lacksdiscriminability because the resulting representation is strongly influenced byfrequent yet often uninformative descriptors, but only weakly influenced byrare yet potentially highly-informative ones. Max-pooling equalizes theinfluence of frequent and rare descriptors but is only applicable torepresentations that rely on count statistics, such as the bag-of-visual-words(BOV) and its soft- and sparse-coding extensions. We propose a novel poolingmechanism that achieves the same effect as max-pooling but is applicable beyondthe BOV and especially to the state-of-the-art Fisher Vector -- hence the nameGeneralized Max Pooling (GMP). It involves equalizing the similarity betweeneach patch and the pooled representation, which is shown to be equivalent tore-weighting the per-patch statistics. We show on five public imageclassification benchmarks that the proposed GMP can lead to significantperformance gains with respect to heuristic alternatives.
arxiv-7200-251 | More Bang For Your Buck: Quorum-Sensing Capabilities Improve the Efficacy of Suicidal Altruism | http://arxiv.org/abs/1406.0416 | author:Anya Elaine Johnson, Eli Strauss, Rodney Pickett, Christoph Adami, Ian Dworkin, Heather J. Goldsby category:cs.NE cs.CE q-bio.PE published:2014-06-02 summary:Within the context of evolution, an altruistic act that benefits thereceiving individual at the expense of the acting individual is a puzzlingphenomenon. An extreme form of altruism can be found in colicinogenic E. coli.These suicidal altruists explode, releasing colicins that kill unrelatedindividuals, which are not colicin resistant. By committing suicide, thealtruist makes it more likely that its kin will have less competition. Thebenefits of this strategy rely on the number of competitors and kin nearby. Ifthe organism explodes at an inopportune time, the suicidal act may not harm anycompetitors. Communication could enable organisms to act altruistically whenenvironmental conditions suggest that that strategy would be most beneficial.Quorum sensing is a form of communication in which bacteria produce a proteinand gauge the amount of that protein around them. Quorum sensing is one meansby which bacteria sense the biotic factors around them and determine when toproduce products, such as antibiotics, that influence competition. Suicidalaltruists could use quorum sensing to determine when exploding is mostbeneficial, but it is challenging to study the selective forces at work inmicrobes. To address these challenges, we use digital evolution (a form ofexperimental evolution that uses self-replicating computer programs asorganisms) to investigate the effects of enabling altruistic organisms tocommunicate via quorum sensing. We found that quorum-sensing altruists killed agreater number of competitors per explosion, winning competitions againstnon-communicative altruists. These findings indicate that quorum sensing couldincrease the beneficial effect of altruism and the suite of conditions underwhich it will evolve.
arxiv-7200-252 | Continuous Action Recognition Based on Sequence Alignment | http://arxiv.org/abs/1406.0288 | author:Kaustubh Kulkarni, Georgios Evangelidis, Jan Cech, Radu Horaud category:cs.CV published:2014-06-02 summary:Continuous action recognition is more challenging than isolated recognitionbecause classification and segmentation must be simultaneously carried out. Webuild on the well known dynamic time warping (DTW) framework and devise a novelvisual alignment technique, namely dynamic frame warping (DFW), which performsisolated recognition based on per-frame representation of videos, and onaligning a test sequence with a model sequence. Moreover, we propose twoextensions which enable to perform recognition concomitant with segmentation,namely one-pass DFW and two-pass DFW. These two methods have their roots in thedomain of continuous recognition of speech and, to the best of our knowledge,their extension to continuous visual action recognition has been overlooked. Wetest and illustrate the proposed techniques with a recently released dataset(RAVEL) and with two public-domain datasets widely used in action recognition(Hollywood-1 and Hollywood-2). We also compare the performances of the proposedisolated and continuous recognition algorithms with several recently publishedmethods.
arxiv-7200-253 | Ambiguous Proximity Distribution | http://arxiv.org/abs/1406.0231 | author:Quanquan Wang, Yongping Li category:cs.CV published:2014-06-02 summary:Proximity Distribution Kernel is an effective method for bag-of-featues basedimage representation. In this paper, we investigate the soft assignment ofvisual words to image features for proximity distribution. Visual wordcontribution function is proposed to model ambiguous proximity distributions.Three ambiguous proximity distributions is developed by three ambiguouscontribution functions. The experiments are conducted on both classificationand retrieval of medical image data sets. The results show that the performanceof the proposed methods, Proximity Distribution Kernel (PDK), is better orcomparable to the state-of-the-art bag-of-features based image representationmethods.
arxiv-7200-254 | Holistic Measures for Evaluating Prediction Models in Smart Grids | http://arxiv.org/abs/1406.0223 | author:Saima Aman, Yogesh Simmhan, Viktor K. Prasanna category:cs.LG published:2014-06-02 summary:The performance of prediction models is often based on "abstract metrics"that estimate the model's ability to limit residual errors between the observedand predicted values. However, meaningful evaluation and selection ofprediction models for end-user domains requires holistic andapplication-sensitive performance measures. Inspired by energy consumptionprediction models used in the emerging "big data" domain of Smart Power Grids,we propose a suite of performance measures to rationally compare models alongthe dimensions of scale independence, reliability, volatility and cost. Weinclude both application independent and dependent measures, the latterparameterized to allow customization by domain experts to fit their scenario.While our measures are generalizable to other domains, we offer an empiricalanalysis using real energy use data for three Smart Grid applications:planning, customer education and demand response, which are relevant for energysustainability. Our results underscore the value of the proposed measures tooffer a deeper insight into models' behavior and their impact on realapplications, which benefit both data mining researchers and practitioners.
arxiv-7200-255 | Causal Inference through a Witness Protection Program | http://arxiv.org/abs/1406.0531 | author:Ricardo Silva, Robin Evans category:stat.ML published:2014-06-02 summary:One of the most fundamental problems in causal inference is the estimation ofa causal effect when variables are confounded. This is difficult in anobservational study, because one has no direct evidence that all confoundershave been adjusted for. We introduce a novel approach for estimating causaleffects that exploits observational conditional independencies to suggest"weak" paths in a unknown causal graph. The widely used faithfulness conditionof Spirtes et al. is relaxed to allow for varying degrees of "pathcancellations" that imply conditional independencies but do not rule out theexistence of confounding causal paths. The outcome is a posterior distributionover bounds on the average causal effect via a linear programming approach andBayesian inference. We claim this approach should be used in regular practicealong with other default tools in observational studies.
arxiv-7200-256 | On Classification with Bags, Groups and Sets | http://arxiv.org/abs/1406.0281 | author:Veronika Cheplygina, David M. J. Tax, Marco Loog category:stat.ML cs.CV cs.LG published:2014-06-02 summary:Many classification problems can be difficult to formulate directly in termsof the traditional supervised setting, where both training and test samples areindividual feature vectors. There are cases in which samples are betterdescribed by sets of feature vectors, that labels are only available for setsrather than individual samples, or, if individual labels are available, thatthese are not independent. To better deal with such problems, severalextensions of supervised learning have been proposed, where either trainingand/or test objects are sets of feature vectors. However, having been proposedrather independently of each other, their mutual similarities and differenceshave hitherto not been mapped out. In this work, we provide an overview of suchlearning scenarios, propose a taxonomy to illustrate the relationships betweenthem, and discuss directions for further research in these areas.
arxiv-7200-257 | Topological and Statistical Behavior Classifiers for Tracking Applications | http://arxiv.org/abs/1406.0214 | author:Paul Bendich, Sang Chin, Jesse Clarke, Jonathan deSena, John Harer, Elizabeth Munch, Andrew Newman, David Porter, David Rouse, Nate Strawn, Adam Watkins category:cs.SY math.AT stat.ML published:2014-06-01 summary:We introduce the first unified theory for target tracking using MultipleHypothesis Tracking, Topological Data Analysis, and machine learning. Ourstring of innovations are 1) robust topological features are used to encodebehavioral information, 2) statistical models are fitted to distributions overthese topological features, and 3) the target type classification methods ofWigren and Bar Shalom et al. are employed to exploit the resulting likelihoodsfor topological features inside of the tracking procedure. To demonstrate theefficacy of our approach, we test our procedure on synthetic vehicular datagenerated by the Simulation of Urban Mobility package.
arxiv-7200-258 | Inference of Sparse Networks with Unobserved Variables. Application to Gene Regulatory Networks | http://arxiv.org/abs/1406.0193 | author:Nikolai Slavov category:stat.ML cs.LG q-bio.MN q-bio.QM stat.AP published:2014-06-01 summary:Networks are a unifying framework for modeling complex systems and networkinference problems are frequently encountered in many fields. Here, I developand apply a generative approach to network inference (RCweb) for the case whenthe network is sparse and the latent (not observed) variables affect theobserved ones. From all possible factor analysis (FA) decompositions explainingthe variance in the data, RCweb selects the FA decomposition that is consistentwith a sparse underlying network. The sparsity constraint is imposed by a novelmethod that significantly outperforms (in terms of accuracy, robustness tonoise, complexity scaling, and computational efficiency) Bayesian methods andMLE methods using l1 norm relaxation such as K-SVD and l1--based sparseprinciple component analysis (PCA). Results from simulated models demonstratethat RCweb recovers exactly the model structures for sparsity as low (asnon-sparse) as 50% and with ratio of unobserved to observed variables as highas 2. RCweb is robust to noise, with gradual decrease in the parameter rangesas the noise level increases.
arxiv-7200-259 | Convex Total Least Squares | http://arxiv.org/abs/1406.0189 | author:Dmitry Malioutov, Nikolai Slavov category:stat.ML cs.LG q-bio.GN q-bio.QM stat.AP published:2014-06-01 summary:We study the total least squares (TLS) problem that generalizes least squaresregression by allowing measurement errors in both dependent and independentvariables. TLS is widely used in applied fields including computer vision,system identification and econometrics. The special case when all dependent andindependent variables have the same level of uncorrelated Gaussian noise, knownas ordinary TLS, can be solved by singular value decomposition (SVD). However,SVD cannot solve many important practical TLS problems with realistic noisestructure, such as having varying measurement noise, known structure on theerrors, or large outliers requiring robust error-norms. To solve such problems,we develop convex relaxation approaches for a general class of structured TLS(STLS). We show both theoretically and experimentally, that while the plainnuclear norm relaxation incurs large approximation errors for STLS, there-weighted nuclear norm approach is very effective, and achieves betteraccuracy on challenging STLS problems than popular non-convex solvers. Wedescribe a fast solution based on augmented Lagrangian formulation, and applyour approach to an important class of biological problems that use populationaverage measurements to infer cell-type and physiological-state specificexpression levels that are very hard to measure directly.
arxiv-7200-260 | $l_1$-regularized Outlier Isolation and Regression | http://arxiv.org/abs/1406.0156 | author:Sheng Han, Suzhen Wang, Xinyu Wu category:cs.CV cs.LG stat.ML published:2014-06-01 summary:This paper proposed a new regression model called $l_1$-regularized outlierisolation and regression (LOIRE) and a fast algorithm based on block coordinatedescent to solve this model. Besides, assuming outliers are gross errorsfollowing a Bernoulli process, this paper also presented a Bernoulli estimatemodel which, in theory, should be very accurate and robust due to its completeelimination of affections caused by outliers. Though this Bernoulli estimate ishard to solve, it could be approximately achieved through a process which takesLOIRE as an important intermediate step. As a result, the approximate Bernoulliestimate is a good combination of Bernoulli estimate's accuracy and LOIREregression's efficiency with several simulations conducted to strongly verifythis point. Moreover, LOIRE can be further extended to realize robust rankfactorization which is powerful in recovering low-rank component from massivecorruptions. Extensive experimental results showed that the proposed methodoutperforms state-of-the-art methods like RPCA and GoDec in the aspect ofcomputation speed with a competitive performance.
arxiv-7200-261 | Evolutionary Search in the Space of Rules for Creation of New Two-Player Board Games | http://arxiv.org/abs/1406.0175 | author:Zahid Halim category:cs.NE cs.AI published:2014-06-01 summary:Games have always been a popular test bed for artificial intelligencetechniques. Game developers are always in constant search for techniques thatcan automatically create computer games minimizing the developer's task. Inthis work we present an evolutionary strategy based solution towards theautomatic generation of two player board games. To guide the evolutionaryprocess towards games, which are entertaining, we propose a set of metrics.These metrics are based upon different theories of entertainment in computergames. This work also compares the entertainment value of the evolved gameswith the existing popular board based games. Further to verify theentertainment value of the evolved games with the entertainment value of thehuman user a human user survey is conducted. In addition to the user survey wecheck the learnability of the evolved games using an artificial neural networkbased controller. The proposed metrics and the evolutionary process can beemployed for generating new and entertaining board games, provided an initialsearch space is given to the evolutionary algorithm.
arxiv-7200-262 | Seeing the Big Picture: Deep Embedding with Contextual Evidences | http://arxiv.org/abs/1406.0132 | author:Liang Zheng, Shengjin Wang, Fei He, Qi Tian category:cs.CV published:2014-06-01 summary:In the Bag-of-Words (BoW) model based image retrieval task, the precision ofvisual matching plays a critical role in improving retrieval performance.Conventionally, local cues of a keypoint are employed. However, such strategydoes not consider the contextual evidences of a keypoint, a problem which wouldlead to the prevalence of false matches. To address this problem, this paperdefines "true match" as a pair of keypoints which are similar on three levels,i.e., local, regional, and global. Then, a principled probabilistic frameworkis established, which is capable of implicitly integrating discriminative cuesfrom all these feature levels. Specifically, the Convolutional Neural Network (CNN) is employed to extractfeatures from regional and global patches, leading to the so-called "DeepEmbedding" framework. CNN has been shown to produce excellent performance on adozen computer vision tasks such as image classification and detection, but fewworks have been done on BoW based image retrieval. In this paper, firstly weshow that proper pre-processing techniques are necessary for effective usage ofCNN feature. Then, in the attempt to fit it into our model, a novel indexingstructure called "Deep Indexing" is introduced, which dramatically reducesmemory usage. Extensive experiments on three benchmark datasets demonstrate that, theproposed Deep Embedding method greatly promotes the retrieval accuracy when CNNfeature is integrated. We show that our method is efficient in terms of bothmemory and time cost, and compares favorably with the state-of-the-art methods.
arxiv-7200-263 | Feature Selection for Linear SVM with Provable Guarantees | http://arxiv.org/abs/1406.0167 | author:Saurabh Paul, Malik Magdon-Ismail, Petros Drineas category:stat.ML cs.LG published:2014-06-01 summary:We give two provably accurate feature-selection techniques for the linearSVM. The algorithms run in deterministic and randomized time respectively. Ouralgorithms can be used in an unsupervised or supervised setting. The supervisedapproach is based on sampling features from support vectors. We prove that themargin in the feature space is preserved to within $\epsilon$-relative error ofthe margin in the full feature space in the worst-case. In the unsupervisedsetting, we also provide worst-case guarantees of the radius of the minimumenclosing ball, thereby ensuring comparable generalization as in the fullfeature space and resolving an open problem posed in Dasgupta et al. We presentextensive experiments on real-world datasets to support our theory and todemonstrate that our method is competitive and often better than priorstate-of-the-art, for which there are no known provable guarantees.
arxiv-7200-264 | Adaptive Reconfiguration Moves for Dirichlet Mixtures | http://arxiv.org/abs/1406.0071 | author:Tue Herlau, Morten Mørup, Yee Whye Teh, Mikkel N. Schmidt category:stat.ML published:2014-05-31 summary:Bayesian mixture models are widely applied for unsupervised learning andexploratory data analysis. Markov chain Monte Carlo based on Gibbs sampling andsplit-merge moves are widely used for inference in these models. However, bothmethods are restricted to limited types of transitions and suffer from torpidmixing and low accept rates even for problems of modest size. We propose amethod that considers a broader range of transitions that are close toequilibrium by exploiting multiple chains in parallel and using the past statesadaptively to inform the proposal distribution. The method significantlyimproves on Gibbs and split-merge sampling as quantified using convergencediagnostics and acceptance rates. Adaptive MCMC methods which use past statesto inform the proposal distribution has given rise to many ingenious samplingschemes for continuous problems and the present work can be seen as animportant first step in bringing these benefits to partition-based problems
arxiv-7200-265 | Improved graph Laplacian via geometric self-consistency | http://arxiv.org/abs/1406.0118 | author:Dominique Perrault-Joncas, Marina Meila category:stat.ML cs.LG published:2014-05-31 summary:We address the problem of setting the kernel bandwidth used by ManifoldLearning algorithms to construct the graph Laplacian. Exploiting the connectionbetween manifold geometry, represented by the Riemannian metric, and theLaplace-Beltrami operator, we set the bandwidth by optimizing the Laplacian'sability to preserve the geometry of the data. Experiments show that thisprincipled approach is effective and robust.
arxiv-7200-266 | Combined Approach for Image Segmentation | http://arxiv.org/abs/1406.0074 | author:Shradha Dakhare, Harshal Chowhan, Manoj B. Chandak category:cs.CV published:2014-05-31 summary:Many image segmentation techniques have been developed over the past twodecades for segmenting the images, which help for object recognition, occlusionboundary estimation within motion or stereo systems, image compression, imageediting. In this, there is a combined approach for segmenting the image. By usinghistogram equalization to the input image, from which it gives contrastenhancement output image .After that by applying median filtering,which willremove noise from contrast output image . At last I applied fuzzy c-meanclustering algorithm to denoising output image, which give segmented outputimage. In this way it produce better segmented image with less computationtime.
arxiv-7200-267 | Optimization via Low-rank Approximation for Community Detection in Networks | http://arxiv.org/abs/1406.0067 | author:Can M. Le, Elizaveta Levina, Roman Vershynin category:stat.ML cs.SI math.ST physics.soc-ph stat.TH 62E10, 62G05 published:2014-05-31 summary:Community detection is one of the fundamental problems of network analysis,for which a number of methods have been proposed. Most model-based orcriteria-based methods have to solve an optimization problem over a discreteset of labels to find communities, which is computationally infeasible. Somefast spectral algorithms have been proposed for specific methods or models, butonly on a case-by-case basis. Here we propose a general approach for maximizinga function of a network adjacency matrix over discrete labels by projecting theset of labels onto a subspace approximating the leading eigenvectors of theexpected adjacency matrix. This projection onto a low-dimensional space makesthe feasible set of labels much smaller and the optimization problem mucheasier. We prove a general result about this method and show how to apply it toseveral previously proposed community detection criteria, establishing itsconsistency for label estimation in each case and demonstrating the fundamentalconnection between spectral properties of the network and various model-basedapproaches to community detection. Simulations and applications to real-worlddata are included to demonstrate our method performs well for multiple problemsover a wide range of parameters.
arxiv-7200-268 | Bridging the gap between Legal Practitioners and Knowledge Engineers using semi-formal KR | http://arxiv.org/abs/1406.0079 | author:Shashishekar Ramakrishna, Adrian Paschke category:cs.CL cs.AI published:2014-05-31 summary:The use of Structured English as a computation independent knowledgerepresentation format for non-technical users in business rules representationhas been proposed in OMGs Semantics and Business Vocabulary Representation(SBVR). In the legal domain we face a similar problem. Formal representationlanguages, such as OASIS LegalRuleML and legal ontologies (LKIF, legal OWL2ontologies etc.) support the technical knowledge engineer and the automatedreasoning. But, they can be hardly used directly by the legal domain expertswho do not have a computer science background. In this paper we adapt the SBVRStructured English approach for the legal domain and implement aproof-of-concept, called KR4IPLaw, which enables legal domain experts torepresent their knowledge in Structured English in a computational independentand hence, for them, more usable way. The benefit of this approach is that theunderlying pre-defined semantics of the Structured English approach makestransformations into formal languages such as OASIS LegalRuleML and OWL2ontologies possible. We exemplify our approach in the domain of patent law.
arxiv-7200-269 | Flip-Flop Sublinear Models for Graphs: Proof of Theorem 1 | http://arxiv.org/abs/1405.7897 | author:Brijnesh Jain category:cs.LG published:2014-05-30 summary:We prove that there is no class-dual for almost all sublinear models ongraphs.
arxiv-7200-270 | ELM Solutions for Event-Based Systems | http://arxiv.org/abs/1405.7780 | author:Jonathan Tapson, André van Schaik category:cs.NE published:2014-05-30 summary:Whilst most engineered systems use signals that are continuous in time, thereis a domain of systems in which signals consist of events. Events, like Diracdelta functions, have no meaningful time duration. Many important real-worldsystems are intrinsically event-based, including the mammalian brain, in whichthe primary packets of data are spike events, or action potentials. In thisdomain, signal processing requires responses to spatio-temporal patterns ofevents. We show that some straightforward modifications to the standard ELMtopology produce networks that are able to perform spatio-temporal eventprocessing online with a high degree of accuracy. The modifications involve there-definition of hidden layer units as synaptic kernels, in which the inputdelta functions are transformed into continuous-valued signals using a varietyof impulse-response functions. This permits the use of linear solution methodsin the output layer, which can produce events as output, if modeled as aclassifier; the output classes are 'event' or 'no event'. We illustrate themethod in application to a spike-processing problem.
arxiv-7200-271 | Online and Adaptive Pseudoinverse Solutions for ELM Weights | http://arxiv.org/abs/1405.7777 | author:André van Schaik, Jonathan Tapson category:cs.NE published:2014-05-30 summary:The ELM method has become widely used for classification and regressionsproblems as a result of its accuracy, simplicity and ease of use. The solutionof the hidden layer weights by means of a matrix pseudoinverse operation is asignificant contributor to the utility of the method; however, the conventionalcalculation of the pseudoinverse by means of a singular value decomposition(SVD) is not always practical for large data sets or for online updates to thesolution. In this paper we discuss incremental methods for solving thepseudoinverse which are suitable for ELM. We show that careful choice ofmethods allows us to optimize for accuracy, ease of computation, oradaptability of the solution.
arxiv-7200-272 | DEM Registration and Error Analysis using ASCII values | http://arxiv.org/abs/1405.7771 | author:Suma Dawn, Vikas Saxena, Bhu Dev Sharma category:cs.CV published:2014-05-30 summary:Digital Elevation Model (DEM), while providing a bare earth look, is heavilyused in many applications including construction modeling, visualization, andGIS. Their registration techniques have not been explored much. Methods likeCoarse-to-fine or pyramid making are common in DEM-to-image or DEM-to-mapregistration. Self-consistency measure is used to detect any change in terrainelevation and hence was used for DEM-to-DEM registration. But these methodsapart from being time and complexity intensive, lack in error matrixevaluation. This paper gives a method of registration of DEMs using specifiedheight values as control points by initially converting these DEMs to ASCIIfiles. These control points may be found by two mannerisms - either by directdetection of appropriate height data in ASCII files or by edge matching alongcongruous quadrangle of the control point, followed by sub-graph matching.Error analysis for the same has also been done.
arxiv-7200-273 | The Shortlist Method for Fast Computation of the Earth Mover's Distance and Finding Optimal Solutions to Transportation Problems | http://arxiv.org/abs/1405.7903 | author:Carsten Gottschlich, Dominic Schuhmacher category:cs.CV published:2014-05-30 summary:Finding solutions to the classical transportation problem is of greatimportance, since this optimization problem arises in many engineering andcomputer science applications. Especially the Earth Mover's Distance is used ina plethora of applications ranging from content-based image retrieval, shapematching, fingerprint recognition, object tracking and phishing web pagedetection to computing color differences in linguistics and biology. Ourstarting point is the well-known revised simplex algorithm, which iterativelyimproves a feasible solution to optimality. The Shortlist Method that wepropose substantially reduces the number of candidates inspected for improvingthe solution, while at the same time balancing the number of pivots required.Tests on simulated benchmarks demonstrate a considerable reduction incomputation time for the new method as compared to the usual revised simplexalgorithm implemented with state-of-the-art initialization and pivotstrategies. As a consequence, the Shortlist Method facilitates the computationof large scale transportation problems in viable time. In addition we describea novel method for finding an initial feasible solution which we coin ModifiedRussell's Method.
arxiv-7200-274 | Semantic Composition and Decomposition: From Recognition to Generation | http://arxiv.org/abs/1405.7908 | author:Peter D. Turney category:cs.CL cs.AI cs.LG published:2014-05-30 summary:Semantic composition is the task of understanding the meaning of text bycomposing the meanings of the individual words in the text. Semanticdecomposition is the task of understanding the meaning of an individual word bydecomposing it into various aspects (factors, constituents, components) thatare latent in the meaning of the word. We take a distributional approach tosemantics, in which a word is represented by a context vector. Much recent workhas considered the problem of recognizing compositions and decompositions, butwe tackle the more difficult generation problem. For simplicity, we focus onnoun-modifier bigrams and noun unigrams. A test for semantic composition is,given context vectors for the noun and modifier in a noun-modifier bigram ("redsalmon"), generate a noun unigram that is synonymous with the given bigram("sockeye"). A test for semantic decomposition is, given a context vector for anoun unigram ("snifter"), generate a noun-modifier bigram that is synonymouswith the given unigram ("brandy glass"). With a vocabulary of about 73,000unigrams from WordNet, there are 73,000 candidate unigram compositions for abigram and 5,300,000,000 (73,000 squared) candidate bigram decompositions for aunigram. We generate ranked lists of potential solutions in two passes. A fastunsupervised learning algorithm generates an initial list of candidates andthen a slower supervised learning algorithm refines the list. We evaluate thecandidate solutions by comparing them to WordNet synonym sets. Fordecomposition (unigram to bigram), the top 100 most highly ranked bigramsinclude a WordNet synonym of the given unigram 50.7% of the time. Forcomposition (bigram to unigram), the top 100 most highly ranked unigramsinclude a WordNet synonym of the given bigram 77.8% of the time.
arxiv-7200-275 | Estimating Vector Fields on Manifolds and the Embedding of Directed Graphs | http://arxiv.org/abs/1406.0013 | author:Dominique Perrault-Joncas, Marina Meila category:stat.ML cs.LG published:2014-05-30 summary:This paper considers the problem of embedding directed graphs in Euclideanspace while retaining directional information. We model a directed graph as afinite set of observations from a diffusion on a manifold endowed with a vectorfield. This is the first generative model of its kind for directed graphs. Weintroduce a graph embedding algorithm that estimates all three features of thismodel: the low-dimensional embedding of the manifold, the data density and thevector field. In the process, we also obtain new theoretical results on thelimits of "Laplacian type" matrices derived from directed graphs. Theapplication of our method to both artificially constructed and real datahighlights its strengths.
arxiv-7200-276 | Optimal CUR Matrix Decompositions | http://arxiv.org/abs/1405.7910 | author:Christos Boutsidis, David P. Woodruff category:cs.DS cs.LG math.NA published:2014-05-30 summary:The CUR decomposition of an $m \times n$ matrix $A$ finds an $m \times c$matrix $C$ with a subset of $c < n$ columns of $A,$ together with an $r \timesn$ matrix $R$ with a subset of $r < m$ rows of $A,$ as well as a $c \times r$low-rank matrix $U$ such that the matrix $C U R$ approximates the matrix $A,$that is, $ A - CUR _F^2 \le (1+\epsilon) A - A_k_F^2$, where$._F$ denotes the Frobenius norm and $A_k$ is the best $m \times n$ matrixof rank $k$ constructed via the SVD. We present input-sparsity-time anddeterministic algorithms for constructing such a CUR decomposition where$c=O(k/\epsilon)$ and $r=O(k/\epsilon)$ and rank$(U) = k$. Up to constantfactors, our algorithms are simultaneously optimal in $c, r,$ and rank$(U)$.
arxiv-7200-277 | Comparing and Combining Sentiment Analysis Methods | http://arxiv.org/abs/1406.0032 | author:Pollyanna Gonçalves, Matheus Araújo, Fabrício Benevenuto, Meeyoung Cha category:cs.CL published:2014-05-30 summary:Several messages express opinions about events, products, and services,political views or even their author's emotional state and mood. Sentimentanalysis has been used in several applications including analysis of therepercussions of events in social networks, analysis of opinions about productsand services, and simply to better understand aspects of social communicationin Online Social Networks (OSNs). There are multiple methods for measuringsentiments, including lexical-based approaches and supervised machine learningmethods. Despite the wide use and popularity of some methods, it is unclearwhich method is better for identifying the polarity (i.e., positive ornegative) of a message as the current literature does not provide a method ofcomparison among existing methods. Such a comparison is crucial forunderstanding the potential limitations, advantages, and disadvantages ofpopular methods in analyzing the content of OSNs messages. Our study aims atfilling this gap by presenting comparisons of eight popular sentiment analysismethods in terms of coverage (i.e., the fraction of messages whose sentiment isidentified) and agreement (i.e., the fraction of identified sentiments that arein tune with ground truth). We develop a new method that combines existingapproaches, providing the best coverage results and competitive agreement. Wealso present a free Web service called iFeel, which provides an open API foraccessing and comparing results across different sentiment methods for a giventext.
arxiv-7200-278 | Generalization Bounds for Learning with Linear, Polygonal, Quadratic and Conic Side Knowledge | http://arxiv.org/abs/1405.7764 | author:Theja Tulabandhula, Cynthia Rudin category:stat.ML cs.LG published:2014-05-30 summary:In this paper, we consider a supervised learning setting where side knowledgeis provided about the labels of unlabeled examples. The side knowledge has theeffect of reducing the hypothesis space, leading to tighter generalizationbounds, and thus possibly better generalization. We consider several types ofside knowledge, the first leading to linear and polygonal constraints on thehypothesis space, the second leading to quadratic constraints, and the lastleading to conic constraints. We show how different types of domain knowledgecan lead directly to these kinds of side knowledge. We prove bounds oncomplexity measures of the hypothesis space for quadratic and conic sideknowledge, and show that these bounds are tight in a specific sense for thequadratic case.
arxiv-7200-279 | Circle detection using electro-magnetism optimization | http://arxiv.org/abs/1406.0023 | author:Erik Cuevas, Diego Oliva, Daniel Zaldivar, Marco Perez-Cisneros, Humberto Sossa category:cs.CV published:2014-05-30 summary:This paper describes a circle detection method based on Electromagnetism-LikeOptimization (EMO). Circle detection has received considerable attention overthe last years thanks to its relevance for many computer vision tasks. EMO is aheuristic method for solving complex optimization problems inspired inelectromagnetism principles. This algorithm searches a solution based in theattraction and repulsion among prototype candidates. In this paper thedetection process is considered to be similar to an optimization problem, thealgorithm uses the combination of three edge points (x, y, r) as parameters todetermine circles candidates in the scene. An objective function determines ifsuch circle candidates are actually present in the image. The EMO algorithm isused to find the circle candidate that is better related with the real circlepresent in the image according to the objective function. The final algorithmis a fast circle detector that locates circles with sub-pixel accuracy evenconsidering complicated conditions and noisy images.
arxiv-7200-280 | Learning to Act Greedily: Polymatroid Semi-Bandits | http://arxiv.org/abs/1405.7752 | author:Branislav Kveton, Zheng Wen, Azin Ashkan, Michal Valko category:cs.LG cs.AI stat.ML published:2014-05-30 summary:Many important optimization problems, such as the minimum spanning tree andminimum-cost flow, can be solved optimally by a greedy method. In this work, westudy a learning variant of these problems, where the model of the problem isunknown and has to be learned by interacting repeatedly with the environment inthe bandit setting. We formalize our learning problem quite generally, aslearning how to maximize an unknown modular function on a known polymatroid. Wepropose a computationally efficient algorithm for solving our problem and boundits expected cumulative regret. Our gap-dependent upper bound is tight up to aconstant and our gap-free upper bound is tight up to polylogarithmic factors.Finally, we evaluate our method on three problems and demonstrate that it ispractical.
arxiv-7200-281 | Universal Compression of Envelope Classes: Tight Characterization via Poisson Sampling | http://arxiv.org/abs/1405.7460 | author:Jayadev Acharya, Ashkan Jafarpour, Alon Orlitsky, Ananda Theertha Suresh category:cs.IT cs.LG math.IT published:2014-05-29 summary:The Poisson-sampling technique eliminates dependencies among symbolappearances in a random sequence. It has been used to simplify the analysis andstrengthen the performance guarantees of randomized algorithms. Applying thismethod to universal compression, we relate the redundancies of fixed-length andPoisson-sampled sequences, use the relation to derive a simple single-letterformula that approximates the redundancy of any envelope class to within anadditive logarithmic term. As a first application, we consider i.i.d.distributions over a small alphabet as a step-envelope class, and provide ashort proof that determines the redundancy of discrete distributions over asmall al- phabet up to the first order terms. We then show the strength of ourmethod by applying the formula to tighten the existing bounds on the redundancyof exponential and power-law classes, in particular answering a question posedby Boucheron, Garivier and Gassiat.
arxiv-7200-282 | Effect of Different Distance Measures on the Performance of K-Means Algorithm: An Experimental Study in Matlab | http://arxiv.org/abs/1405.7471 | author:Mr. Dibya Jyoti Bora, Dr. Anil Kumar Gupta category:cs.LG published:2014-05-29 summary:K-means algorithm is a very popular clustering algorithm which is famous forits simplicity. Distance measure plays a very important rule on the performanceof this algorithm. We have different distance measure techniques available. Butchoosing a proper technique for distance calculation is totally dependent onthe type of the data that we are going to cluster. In this paper anexperimental study is done in Matlab to cluster the iris and wine data setswith different distance measures and thereby observing the variation of theperformances shown.
arxiv-7200-283 | Aspect Based Sentiment Analysis to Extract Meticulous Opinion Value | http://arxiv.org/abs/1405.7519 | author:Deepali Virmani, Vikrant Malhotra, Ridhi Tyagi category:cs.IR cs.CL published:2014-05-29 summary:Opinion Mining and Sentiment Analysis is a process of identifying opinions inlarge unstructured/structured data and then analysing polarity of thoseopinions. Opinion mining and sentiment analysis have found vast application inanalysing online ratings, analysing product based reviews, e-governance, andmanaging hostile content over the internet. This paper proposes an algorithm toimplement aspect level sentiment analysis. The algorithm takes input from theremarks submitted by various teachers of a student. An aspect tree is formedwhich has various levels and weights are assigned to each branch to identifylevel of aspect. Aspect value is calculated by the algorithm by means of theproposed aspect tree. Dictionary based method is implemented to evaluate thepolarity of the remark. The algorithm returns the aspect value clubbed withopinion value and sentiment value which helps in concluding the summarizedvalue of remark.
arxiv-7200-284 | Experimental Demonstration of Array-level Learning with Phase Change Synaptic Devices | http://arxiv.org/abs/1405.7716 | author:S. Burc Eryilmaz, Duygu Kuzum, Rakesh G. D. Jeyasingh, SangBum Kim, Matthew BrightSky, Chung Lam, H. -S. Philip Wong category:cs.NE cs.AI published:2014-05-29 summary:The computational performance of the biological brain has long attractedsignificant interest and has led to inspirations in operating principles,algorithms, and architectures for computing and signal processing. In thiswork, we focus on hardware implementation of brain-like learning in abrain-inspired architecture. We demonstrate, in hardware, that 2-D crossbararrays of phase change synaptic devices can achieve associative learning andperform pattern recognition. Device and array-level studies using anexperimental 10x10 array of phase change synaptic devices have shown thatpattern recognition is robust against synaptic resistance variations and largevariations can be tolerated by increasing the number of training iterations.Our measurements show that increase in initial variation from 9 % to 60 %causes required training iterations to increase from 1 to 11.
arxiv-7200-285 | Feature sampling and partitioning for visual vocabulary generation on large action classification datasets | http://arxiv.org/abs/1405.7545 | author:Michael Sapienza, Fabio Cuzzolin, Philip H. S. Torr category:cs.CV published:2014-05-29 summary:The recent trend in action recognition is towards larger datasets, anincreasing number of action classes and larger visual vocabularies.State-of-the-art human action classification in challenging video data iscurrently based on a bag-of-visual-words pipeline in which space-time featuresare aggregated globally to form a histogram. The strategies chosen to samplefeatures and construct a visual vocabulary are critical to performance, in factoften dominating performance. In this work we provide a critical evaluation ofvarious approaches to building a vocabulary and show that good practises dohave a significant impact. By subsampling and partitioning featuresstrategically, we are able to achieve state-of-the-art results on 5 majoraction recognition datasets using relatively small visual vocabularies.
arxiv-7200-286 | Functional Gaussian processes for regression with linear PDE models | http://arxiv.org/abs/1405.7569 | author:Ngoc-Cuong Nguyen, Jaime Peraire category:math.AP math.PR stat.CO stat.ML published:2014-05-29 summary:In this paper, we present a new statistical approach to the problem ofincorporating experimental observations into a mathematical model described bylinear partial differential equations (PDEs) to improve the prediction of thestate of a physical system. We augment the linear PDE with a functional thataccounts for the uncertainty in the mathematical model and is modeled as a {\emGaussian process}. This gives rise to a stochastic PDE which is characterizedby the Gaussian functional. We develop a {\em functional Gaussian processregression} method to determine the posterior mean and covariance of theGaussian functional, thereby solving the stochastic PDE to obtain the posteriordistribution for our prediction of the physical state. Our method has thefollowing features which distinguish itself from other regression methods.First, it incorporates both the mathematical model and the observations intothe regression procedure. Second, it can handle the observations given in theform of linear functionals of the field variable. Third, the method isnon-parametric in the sense that it provides a systematic way to optimallydetermine the prior covariance operator of the Gaussian functional based on theobservations. Fourth, it provides the posterior distribution quantifying themagnitude of uncertainty in our prediction of the physical state. We presentnumerical results to illustrate these features of the method and compare itsperformance to that of the standard Gaussian process regression.
arxiv-7200-287 | Classification of Basmati Rice Grain Variety using Image Processing and Principal Component Analysis | http://arxiv.org/abs/1405.7626 | author:Rubi Kambo, Amit Yerpude category:cs.CV published:2014-05-29 summary:All important decisions about the variety of rice grain end product are basedon the different features of rice grain.There are various methods available forclassification of basmati rice. This paper proposed a new principal componentanalysis based approach for classification of different variety of basmatirice. The experimental result shows the effectiveness of the proposedmethodology for various samples of different variety of basmati rice.
arxiv-7200-288 | BayesOpt: A Bayesian Optimization Library for Nonlinear Optimization, Experimental Design and Bandits | http://arxiv.org/abs/1405.7430 | author:Ruben Martinez-Cantin category:cs.LG published:2014-05-29 summary:BayesOpt is a library with state-of-the-art Bayesian optimization methods tosolve nonlinear optimization, stochastic bandits or sequential experimentaldesign problems. Bayesian optimization is sample efficient by building aposterior distribution to capture the evidence and prior knowledge for thetarget function. Built in standard C++, the library is extremely efficientwhile being portable and flexible. It includes a common interface for C, C++,Python, Matlab and Octave.
arxiv-7200-289 | Simultaneous Feature and Expert Selection within Mixture of Experts | http://arxiv.org/abs/1405.7624 | author:Billy Peralta category:cs.LG published:2014-05-29 summary:A useful strategy to deal with complex classification scenarios is the"divide and conquer" approach. The mixture of experts (MOE) technique makes useof this strategy by joinly training a set of classifiers, or experts, that arespecialized in different regions of the input space. A global model, or gatefunction, complements the experts by learning a function that weights theirrelevance in different parts of the input space. Local feature selectionappears as an attractive alternative to improve the specialization of expertsand gate function, particularly, for the case of high dimensional data. Ourmain intuition is that particular subsets of dimensions, or subspaces, areusually more appropriate to classify instances located in different regions ofthe input space. Accordingly, this work contributes with a regularized variantof MoE that incorporates an embedded process for local feature selection using$L1$ regularization, with a simultaneous expert selection. The experiments arestill pending.
arxiv-7200-290 | Deformation corrected compressed sensing (DC-CS): a novel framework for accelerated dynamic MRI | http://arxiv.org/abs/1405.7718 | author:Sajan Goud Lingala, Edward DiBella, Mathews Jacob category:cs.CV published:2014-05-29 summary:We propose a novel deformation corrected compressed sensing (DC-CS) frameworkto recover dynamic magnetic resonance images from undersampled measurements. Weintroduce a generalized formulation that is capable of handling a wide class ofsparsity/compactness priors on the deformation corrected dynamic signal. Inthis work, we consider example compactness priors such as sparsity in temporalFourier domain, sparsity in temporal finite difference domain, and nuclear normpenalty to exploit low rank structure. Using variable splitting, we decouplethe complex optimization problem to simpler and well understood sub problems;the resulting algorithm alternates between simple steps of shrinkage baseddenoising, deformable registration, and a quadratic optimization step.Additionally, we employ efficient continuation strategies to minimize the riskof convergence to local minima. The proposed formulation contrasts withexisting DC-CS schemes that are customized for free breathing cardiac cineapplications, and other schemes that rely on fully sampled reference frames ornavigator signals to estimate the deformation parameters. The efficientdecoupling enabled by the proposed scheme allows its application to a widerange of applications including contrast enhanced dynamic MRI. Throughexperiments on numerical phantom and in vivo myocardial perfusion MRI datasets,we demonstrate the utility of the proposed DC-CS scheme in providing robustreconstructions with reduced motion artifacts over classical compressed sensingschemes that utilize the compact priors on the original deformationun-corrected signal.
arxiv-7200-291 | Detection Bank: An Object Detection Based Video Representation for Multimedia Event Recognition | http://arxiv.org/abs/1405.7102 | author:Tim Althoff, Hyun Oh Song, Trevor Darrell category:cs.MM cs.CV published:2014-05-28 summary:While low-level image features have proven to be effective representationsfor visual recognition tasks such as object recognition and sceneclassification, they are inadequate to capture complex semantic meaningrequired to solve high-level visual tasks such as multimedia event detectionand recognition. Recognition or retrieval of events and activities can beimproved if specific discriminative objects are detected in a video sequence.In this paper, we propose an image representation, called Detection Bank, basedon the detection images from a large number of windowed object detectors wherean image is represented by different statistics derived from these detections.This representation is extended to video by aggregating the key frame levelimage representations through mean and max pooling. We empirically show that itcaptures complementary information to state-of-the-art representations such asSpatial Pyramid Matching and Object Bank. These descriptors combined with ourDetection Bank representation significantly outperforms any of therepresentations alone on TRECVID MED 2011 data.
arxiv-7200-292 | A Comparison of Nature Inspired Algorithms for Multi-threshold Image Segmentation | http://arxiv.org/abs/1405.7406 | author:Valentín Osuna-Enciso, Erik Cuevas, Humberto Sossa category:cs.CV cs.NE published:2014-05-28 summary:In the field of image analysis, segmentation is one of the most importantpreprocessing steps. One way to achieve segmentation is by mean of thresholdselection, where each pixel that belongs to a determined class islabeledaccording to the selected threshold, giving as a result pixel groups that sharevisual characteristics in the image. Several methods have been proposed inorder to solve threshold selectionproblems; in this work, it is used the methodbased on the mixture of Gaussian functions to approximate the 1D histogram of agray level image and whose parameters are calculated using three natureinspired algorithms (Particle Swarm Optimization, Artificial Bee ColonyOptimization and Differential Evolution). Each Gaussian function approximatesthehistogram, representing a pixel class and therefore a threshold point.Experimental results are shown, comparing in quantitative and qualitativefashion as well as the main advantages and drawbacks of each algorithm, appliedto multi-threshold problem.
arxiv-7200-293 | A Multi-threshold Segmentation Approach Based on Artificial Bee Colony Optimization | http://arxiv.org/abs/1405.7229 | author:Erik Cuevas, Felipe Sencion, Daniel Zaldivar, Marco Perez, Humberto Sossa category:cs.CV cs.NE published:2014-05-28 summary:This paper explores the use of the Artificial Bee Colony (ABC) algorithm tocompute threshold selection for image segmentation. ABC is a heuristicalgorithm motivated by the intelligent behavior of honey-bees which has beensuccessfully employed to solve complex optimization problems. In this approach,an image 1D histogram is approximated through a Gaussian mixture model whoseparameters are calculated by the ABC algorithm. For the approximation scheme,each Gaussian function represents a pixel class and therefore a threshold.Unlike the Expectation Maximization (EM) algorithm, the ABC based method showsfast convergence and low sensitivity to initial conditions. Remarkably, it alsoimproves complex time consuming computations commonly required bygradient-based methods. Experimental results demonstrate the algorithms abilityto perform automatic multi threshold selection yet showing interestingadvantages by comparison to other well known algorithms.
arxiv-7200-294 | Circle detection by Harmony Search Optimization | http://arxiv.org/abs/1405.7242 | author:Erik Cuevas, Noe Ortega, Daniel Zaldivar, Marco Perez category:cs.CV published:2014-05-28 summary:Automatic circle detection in digital images has received considerableattention over the last years in computer vision as several efforts have aimedfor an optimal circle detector. This paper presents an algorithm for automaticdetection of circular shapes that considers the overall process as anoptimization problem. The approach is based on the Harmony Search Algorithm(HSA), a derivative free meta-heuristic optimization algorithm inspired bymusicians while improvising new harmonies. The algorithm uses the encoding ofthree points as candidate circles (harmonies) over the edge-only image. Anobjective function evaluates (harmony quality) if such candidate circles areactually present in the edge image. Guided by the values of this objectivefunction, the set of encoded candidate circles are evolved using the HSA sothat they can fit to the actual circles on the edge map of the image (optimalharmony). Experimental results from several tests on synthetic and naturalimages with a varying complexity range have been included to validate theefficiency of the proposed technique regarding accuracy, speed and robustness.
arxiv-7200-295 | An HMM Based Named Entity Recognition System for Indian Languages: The JU System at ICON 2013 | http://arxiv.org/abs/1405.7397 | author:Vivekananda Gayen, Kamal Sarkar category:cs.CL published:2014-05-28 summary:This paper reports about our work in the ICON 2013 NLP TOOLS CONTEST on NamedEntity Recognition. We submitted runs for Bengali, English, Hindi, Marathi,Punjabi, Tamil and Telugu. A statistical HMM (Hidden Markov Models) based modelhas been used to implement our system. The system has been trained and testedon the NLP TOOLS CONTEST: ICON 2013 datasets. Our system obtains F-measures of0.8599, 0.7704, 0.7520, 0.4289, 0.5455, 0.4466, and 0.4003 for Bengali,English, Hindi, Marathi, Punjabi, Tamil and Telugu respectively.
arxiv-7200-296 | Marginalization and Conditioning for LWF Chain Graphs | http://arxiv.org/abs/1405.7129 | author:Kayvan Sadeghi category:stat.OT math.ST stat.ML stat.TH published:2014-05-28 summary:In this paper, we deal with the problem of marginalization over andconditioning on two disjoint subsets of the node set of chain graphs (CGs) withthe LWF Markov property. For this purpose, we define the class of chain mixedgraphs (CMGs) with three types of edges and, for this class, provide aseparation criterion under which the class of CMGs is stable undermarginalization and conditioning and contains the class of LWF CGs as itssubclass. We provide a method for generating such graphs after marginalizationand conditioning for a given CMG or a given LWF CG. We then define and studythe class of anterial graphs, which is also stable under marginalization andconditioning and contains LWF CGs, but has a simpler structure than CMGs.
arxiv-7200-297 | Circle detection using Discrete Differential Evolution Optimization | http://arxiv.org/abs/1405.7362 | author:Erik Cuevas, Daniel Zaldivar, Marco Perez, Marte Ramirez category:cs.CV published:2014-05-28 summary:This paper introduces a circle detection method based on DifferentialEvolution (DE) optimization. Just as circle detection has been latelyconsidered as a fundamental component for many computer vision algorithms, DEhas evolved as a successful heuristic method for solving complex optimizationproblems, still keeping a simple structure and an easy implementation. It hasalso shown advantageous convergence properties and remarkable robustness. Thedetection process is considered similar to a combinational optimizationproblem. The algorithm uses the combination of three edge points as parametersto determine circles candidates in the scene yielding a reduction of the searchspace. The objective function determines if some circle candidates are actuallypresent in the image. This paper focuses particularly on one DE-based algorithmknown as the Discrete Differential Evolution (DDE), which eventually has shownbetter results than the original DE in particular for solving combinatorialproblems. In the DDE, suitable conversion routines are incorporated into theDE, aiming to operate from integer values to real values and then gettinginteger values back, following the crossover operation. The final algorithm isa fast circle detector that locates circles with sub-pixel accuracy evenconsidering complicated conditions and noisy images. Experimental results onseveral synthetic and natural images with varying range of complexity validatethe efficiency of the proposed technique considering accuracy, speed, androbustness.
arxiv-7200-298 | An Easy to Use Repository for Comparing and Improving Machine Learning Algorithm Usage | http://arxiv.org/abs/1405.7292 | author:Michael R. Smith, Andrew White, Christophe Giraud-Carrier, Tony Martinez category:stat.ML cs.LG published:2014-05-28 summary:The results from most machine learning experiments are used for a specificpurpose and then discarded. This results in a significant loss of informationand requires rerunning experiments to compare learning algorithms. This alsorequires implementation of another algorithm for comparison, that may notalways be correctly implemented. By storing the results from previousexperiments, machine learning algorithms can be compared easily and theknowledge gained from them can be used to improve their performance. Thepurpose of this work is to provide easy access to previous experimental resultsfor learning and comparison. These stored results are comprehensive -- storingthe prediction for each test instance as well as the learning algorithm,hyperparameters, and training set that were used. Previous results areparticularly important for meta-learning, which, in a broad sense, is theprocess of learning from previous machine learning results such that thelearning process is improved. While other experiment databases do exist, one ofour focuses is on easy access to the data. We provide meta-learning data setsthat are ready to be downloaded for meta-learning experiments. In addition,queries to the underlying database can be made if specific information isdesired. We also differ from previous experiment databases in that ourdatabases is designed at the instance level, where an instance is an example ina data set. We store the predictions of a learning algorithm trained on aspecific training set for each instance in the test set. Data set levelinformation can then be obtained by aggregating the results from the instances.The instance level information can be used for many tasks such as determiningthe diversity of a classifier or algorithmically determining the optimal subsetof training instances for a learning algorithm.
arxiv-7200-299 | Seeking multi-thresholds for image segmentation with Learning Automata | http://arxiv.org/abs/1405.7361 | author:Erik Cuevas, Daniel Zaldivar, Marco Perez category:cs.CV published:2014-05-28 summary:This paper explores the use of the Learning Automata (LA) algorithm tocompute threshold selection for image segmentation as it is a criticalpreprocessing step for image analysis, pattern recognition and computer vision.LA is a heuristic method which is able to solve complex optimization problemswith interesting results in parameter estimation. Despite other techniquescommonly seek through the parameter map, LA explores in the probability spaceproviding appropriate convergence properties and robustness. The segmentationtask is therefore considered as an optimization problem and the LA is used togenerate the image multi-threshold separation. In this approach, one 1Dhistogram of a given image is approximated through a Gaussian mixture modelwhose parameters are calculated using the LA algorithm. Each Gaussian functionapproximating the histogram represents a pixel class and therefore a thresholdpoint. The method shows fast convergence avoiding the typical sensitivity toinitial conditions such as the Expectation Maximization (EM) algorithm or thecomplex time-consuming computations commonly found in gradient methods.Experimental results demonstrate the algorithm ability to perform automaticmulti-threshold selection and show interesting advantages as it is compared toother algorithms solving the same task.
arxiv-7200-300 | An FPGA-based Parallel Architecture for Face Detection using Mixed Color Models | http://arxiv.org/abs/1405.7032 | author:Luo Tao, Shi zaifeng category:cs.CV 68U10 published:2014-05-27 summary:In this paper, a reliable method for detecting human faces in color images isproposed. This system firstly detects skin color in YCgCr and YIQ color space,then filters binary texture and the result is morphological processed, finallyconverts skin tone to the preferred skin color configured by users in YIQ colorspace. The real-time adjusting circuit is implemented and some of simulationresults are given out. Experimental results demonstrate that the method hasachieved high rates and low false positives, another advantage is itssimplicity and minor computational costs.
