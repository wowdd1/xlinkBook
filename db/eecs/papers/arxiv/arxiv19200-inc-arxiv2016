arxiv-1606-07419 | Learning to Poke by Poking: Experiential Learning of Intuitive Physics | http://arxiv.org/abs/1606.07419 | id:1606.07419 author:Pulkit Agrawal, Ashvin Nair, Pieter Abbeel, Jitendra Malik, Sergey Levine category:cs.CV cs.AI cs.RO  published:2016-06-23 summary:We investigate an experiential learning paradigm for acquiring an internal model of intuitive physics. Our model is evaluated on a real-world robotic manipulation task that requires displacing objects to target locations by poking. The robot gathered over 400 hours of experience by executing more than 50K pokes on different objects. We propose a novel approach based on deep neural networks for modeling the dynamics of robot's interactions directly from images, by jointly estimating forward and inverse models of dynamics. The inverse model objective provides supervision to construct informative visual features, which the forward model can then predict and in turn regularize the feature space for the inverse model. The interplay between these two objectives creates useful, accurate models that can then be used for multi-step decision making. This formulation has the additional benefit that it is possible to learn forward models in an abstract feature space and thus alleviate the need of predicting pixels. Our experiments show that this joint modeling approach outperforms alternative methods. We also demonstrate that active data collection using the learned model further improves performance. version:1
arxiv-1606-07415 | Find your Way by Observing the Sun and Other Semantic Cues | http://arxiv.org/abs/1606.07415 | id:1606.07415 author:Wei-Chiu Ma, Shenlong Wang, Marcus A. Brubaker, Sanja Fidler, Raquel Urtasun category:cs.CV  published:2016-06-23 summary:In this paper we present a robust, efficient and affordable approach to self-localization which does not require neither GPS nor knowledge about the appearance of the world. Towards this goal, we utilize freely available cartographic maps and derive a probabilistic model that exploits semantic cues in the form of sun direction, presence of an intersection, road type, speed limit as well as the ego-car trajectory in order to produce very reliable localization results. Our experimental evaluation shows that our approach can localize much faster (in terms of driving time) with less computation and more robustly than competing approaches, which ignore semantic information. version:1
arxiv-1606-07414 | Multiplierless 16-point DCT Approximation for Low-complexity Image and Video Coding | http://arxiv.org/abs/1606.07414 | id:1606.07414 author:T. L. T. Silveira, R. S. Oliveira, F. M. Bayer, R. J. Cintra, A. Madanayake category:cs.CV cs.MM cs.NA stat.ME  published:2016-06-23 summary:An orthogonal 16-point approximate discrete cosine transform (DCT) is introduced. The proposed transform requires neither multiplications nor bit-shifting operations. A fast algorithm based on matrix factorization is introduced, requiring only 44 additions---the lowest arithmetic cost in literature. To assess the introduced transform, computational complexity, similarity with the exact DCT, and coding performance measures are computed. Classical and state-of-the-art 16-point low-complexity transforms were used in a comparative analysis. In the context of image compression, the proposed approximation was evaluated via PSNR and SSIM measurements, attaining the best cost-benefit ratio among the competitors. For video encoding, the proposed approximation was embedded into a HEVC reference software for direct comparison with the original HEVC standard. Physically realized and tested using FPGA hardware, the proposed transform showed 35% and 37% improvements of area-time and area-time-squared VLSI metrics when compared to the best competing transform in the literature. version:1
arxiv-1606-07396 | Fast Multi-Layer Laplacian Enhancement | http://arxiv.org/abs/1606.07396 | id:1606.07396 author:Hossein Talebi, Peyman Milanfar category:cs.CV  published:2016-06-23 summary:A novel, fast and practical way of enhancing images is introduced in this paper. Our approach builds on Laplacian operators of well-known edge-aware kernels, such as bilateral and nonlocal means, and extends these filter's capabilities to perform more effective and fast image smoothing, sharpening and tone manipulation. We propose an approximation of the Laplacian, which does not require normalization of the kernel weights. Multiple Laplacians of the affinity weights endow our method with progressive detail decomposition of the input image from fine to coarse scale. These image components are blended by a structure mask, which avoids noise/artifact magnification or detail loss in the output image. Contributions of the proposed method to existing image editing tools are: (1) Low computational and memory requirements, making it appropriate for mobile device implementations (e.g. as a finish step in a camera pipeline), (2) A range of filtering applications from detail enhancement to denoising with only a few control parameters, enabling the user to apply a combination of various (and even opposite) filtering effects. version:1
arxiv-1606-07384 | Robust Learning of Fixed-Structure Bayesian Networks | http://arxiv.org/abs/1606.07384 | id:1606.07384 author:Ilias Diakonikolas, Daniel Kane, Alistair Stewart category:cs.DS cs.AI cs.LG math.ST stat.TH  published:2016-06-23 summary:We investigate the problem of learning Bayesian networks in an agnostic model where an $\epsilon$-fraction of the samples are adversarially corrupted. Our agnostic learning model is similar to -- in fact, stronger than -- Huber's contamination model in robust statistics. In this work, we study the fully observable Bernoulli case where the structure of the network is given. Even in this basic setting, previous learning algorithms either run in exponential time or lose dimension-dependent factors in their error guarantees. We provide the first computationally efficient agnostic learning algorithm for this problem with dimension-independent error guarantees. Our algorithm has polynomial sample complexity, runs in polynomial time, and achieves error that scales nearly-linearly with the fraction of adversarially corrupted samples. version:1
arxiv-1606-07373 | ViCom: Benchmark and Methods for Video Comprehension | http://arxiv.org/abs/1606.07373 | id:1606.07373 author:Du Tran, Manohar Paluri, Lorenzo Torresani category:cs.CV  published:2016-06-23 summary:There is a widespread agreement that future technology for organizing, browsing and searching videos hinges on the development of methods for high-level semantic understanding of video. But, so far the community has not reached to a consensus on the best way to train and assess models for this task. Casting video understanding as a form of action or event categorization is unsatisfying as it is not clear what the semantic classes or abstractions of this domain should be. Language has been exploited to sidestep the problem of defining abstract video categories by formulating video understanding as the task of captioning or description. However, language is highly complex, redundant and sometimes ambiguous. Many different captions may express the same semantic concept. To account for this ambiguity, quantitative evaluation of video description requires sophisticated metrics, whose performance scores are typically hard to interpret by humans. This paper provides four contributions on this problem. First, we formulate Video Comprehension as a new well-defined task with an easy-to-interpret performance measure. Second, we describe a general semi-automatic procedure to create benchmarks for this task. Third, we publicly release a large-scale video benchmark created with an implementation of this procedure and we include a human study that assesses human performance on our dataset. Finally, we propose and test a varied collection of approaches on this benchmark for the purpose of gaining a better understanding of the new challenges posed by video comprehension. version:1
arxiv-1606-07372 | Automatic Neuron Detection in Calcium Imaging Data Using Convolutional Networks | http://arxiv.org/abs/1606.07372 | id:1606.07372 author:Noah J. Apthorpe, Alexander J. Riordan, Rob E. Aguilar, Jan Homann, Yi Gu, David W. Tank, H. Sebastian Seung category:q-bio.NC cs.CV  published:2016-06-23 summary:Calcium imaging is an important technique for monitoring the activity of thousands of neurons simultaneously. As calcium imaging datasets grow in size, automated detection of individual neurons is becoming important. Here we apply a supervised learning approach to this problem and show that convolutional networks can achieve near-human accuracy and superhuman speed. Accuracy is superior to the popular PCA/ICA method based on precision and recall relative to ground truth annotation by a human expert. These results suggest that convolutional networks are an efficient and flexible tool for the analysis of large-scale calcium imaging data. version:1
arxiv-1606-07365 | Parallel SGD: When does averaging help? | http://arxiv.org/abs/1606.07365 | id:1606.07365 author:Jian Zhang, Christopher De Sa, Ioannis Mitliagkas, Christopher Ré category:stat.ML cs.LG  published:2016-06-23 summary:Consider a number of workers running SGD independently on the same pool of data and averaging the models every once in a while -- a common but not well understood practice. We study model averaging as a variance-reducing mechanism and describe two ways in which the frequency of averaging affects convergence. For convex objectives, we show the benefit of frequent averaging depends on the gradient variance envelope. For non-convex objectives, we illustrate that this benefit depends on the presence of multiple globally optimal points. We complement our findings with multicore experiments on both synthetic and real data. version:1
arxiv-1606-07356 | Analyzing the Behavior of Visual Question Answering Models | http://arxiv.org/abs/1606.07356 | id:1606.07356 author:Aishwarya Agrawal, Dhruv Batra, Devi Parikh category:cs.CL  published:2016-06-23 summary:Recently, a number of deep-learning based models have been proposed for the task of Visual Question Answering (VQA). The performance of most models is clustered around 60-70%. In this paper we propose systematic methods to analyze the behavior of these models as a first step towards recognizing their strengths and weaknesses, and identifying the most fruitful directions for progress. We analyze the best performing models from two major classes of VQA models -- with-attention and without-attention and show the similarities and differences in the behavior of these models. Our behavior analysis reveals that despite recent progress, today's VQA models are "myopic" (tend to fail on sufficiently novel instances), often "jump to conclusions" (converge on a predicted answer after 'listening' to just half the question), and are "stubborn" (do not change their answers across images). version:1
arxiv-1606-07326 | DropNeuron: Simplifying the Structure of Deep Neural Networks | http://arxiv.org/abs/1606.07326 | id:1606.07326 author:Wei Pan, Hao Dong, Yike Guo category:cs.CV cs.LG stat.ML  published:2016-06-23 summary:Deep learning using multi-layer neural networks (NNs) architecture manifests superb power in modern machine learning systems. The trained Deep Neural Networks (DNNs) are typically large. The question we would like to address is whether it is possible to simplify the NN during training process to achieve a rea- sonable performance within an acceptable computational time. We presented a novel approach of optimising a deep neural network through regularisation of net- work architecture. We proposed regularisers which support a simple mechanism of dropping neurons during a network training process. The method supports the construction of a simpler deep neural networks with compatible performance with its simplified version. As a proof of concept, we evaluate the proposed method with examples including sparse linear regression, deep autoencoder and convolutional neural network. The valuations demonstrate excellent performance. The code for this work can be found in http://www.github.com/panweihit/ DropNeuron. version:1
arxiv-1606-07324 | Dynamical optical flow of saliency maps for predicting visual attention | http://arxiv.org/abs/1606.07324 | id:1606.07324 author:Aniello Raffaele Patrone, Christian Valuch, Ulrich Ansorge, Otmar Scherzer category:cs.CV  published:2016-06-23 summary:Saliency maps are used to understand human attention and visual fixation. However, while very well established for static images, there is no general agreement on how to compute a saliency map of dynamic scenes. In this paper we propose a mathematically rigorous approach to this prob- lem, including static saliency maps of each video frame for the calculation of the optical flow. Taking into account static saliency maps for calculating the optical flow allows for overcoming the aperture problem. Our ap- proach is able to explain human fixation behavior in situations which pose challenges to standard approaches, such as when a fixated object disappears behind an occlusion and reappears after several frames. In addition, we quantitatively compare our model against alternative solutions using a large eye tracking data set. Together, our results suggest that assessing optical flow information across a series of saliency maps gives a highly accurate and useful account of human overt attention in dynamic scenes. version:1
arxiv-1606-07315 | Nearly-optimal Robust Matrix Completion | http://arxiv.org/abs/1606.07315 | id:1606.07315 author:Yeshwanth Cherapanamjeri, Kartik Gupta, Prateek Jain category:cs.LG cs.NA  published:2016-06-23 summary:In this paper, we consider the problem of Robust Matrix Completion (RMC) where the goal is to recover a low-rank matrix by observing a small number of its entries out of which a few can be arbitrarily corrupted. We propose a simple projected gradient descent method to estimate the low-rank matrix that alternately performs a projected gradient descent step and cleans up a few of the corrupted entries using hard-thresholding. Our algorithm solves RMC using nearly optimal number of observations as well as nearly optimal number of corruptions. Our result also implies significant improvement over the existing time complexity bounds for the low-rank matrix completion problem. Finally, an application of our result to the robust PCA problem (low-rank+sparse matrix separation) leads to nearly linear time (in matrix dimensions) algorithm for the same; existing state-of-the-art methods require quadratic time. Our empirical results corroborate our theoretical results and show that even for moderate sized problems, our method for robust PCA is an an order of magnitude faster than the existing methods. version:1
arxiv-1606-07312 | Unsupervised preprocessing for Tactile Data | http://arxiv.org/abs/1606.07312 | id:1606.07312 author:Maximilian Karl, Justin Bayer, Patrick van der Smagt category:cs.RO cs.LG stat.ML  published:2016-06-23 summary:Tactile information is important for gripping, stable grasp, and in-hand manipulation, yet the complexity of tactile data prevents widespread use of such sensors. We make use of an unsupervised learning algorithm that transforms the complex tactile data into a compact, latent representation without the need to record ground truth reference data. These compact representations can either be used directly in a reinforcement learning based controller or can be used to calibrate the tactile sensor to physical quantities with only a few datapoints. We show the quality of our latent representation by predicting important features and with a simple control task. version:1
arxiv-1606-07298 | Explaining Predictions of Non-Linear Classifiers in NLP | http://arxiv.org/abs/1606.07298 | id:1606.07298 author:Leila Arras, Franziska Horn, Grégoire Montavon, Klaus-Robert Müller, Wojciech Samek category:cs.CL cs.IR cs.LG cs.NE stat.ML  published:2016-06-23 summary:Layer-wise relevance propagation (LRP) is a recently proposed technique for explaining predictions of complex non-linear classifiers in terms of input variables. In this paper, we apply LRP for the first time to natural language processing (NLP). More precisely, we use it to explain the predictions of a convolutional neural network (CNN) trained on a topic categorization task. Our analysis highlights which words are relevant for a specific prediction of the CNN. We compare our technique to standard sensitivity analysis, both qualitatively and quantitatively, using a "word deleting" perturbation experiment, a PCA analysis, and various visualizations. All experiments validate the suitability of LRP for explaining the CNN predictions, which is also in line with results reported in recent image classification studies. version:1
arxiv-1606-07289 | Non-convex regularization in remote sensing | http://arxiv.org/abs/1606.07289 | id:1606.07289 author:Devis Tuia, Remi Flamary, Michel Barlaud category:stat.ML cs.LG  published:2016-06-23 summary:In this paper, we study the effect of different regularizers and their implications in high dimensional image classification and sparse linear unmixing. Although kernelization or sparse methods are globally accepted solutions for processing data in high dimensions, we present here a study on the impact of the form of regularization used and its parametrization. We consider regularization via traditional squared (2) and sparsity-promoting (1) norms, as well as more unconventional nonconvex regularizers (p and Log Sum Penalty). We compare their properties and advantages on several classification and linear unmixing tasks and provide advices on the choice of the best regularizer for the problem at hand. Finally, we also provide a fully functional toolbox for the community. version:1
arxiv-1606-07287 | Picture It In Your Mind: Generating High Level Visual Representations From Textual Descriptions | http://arxiv.org/abs/1606.07287 | id:1606.07287 author:Fabio Carrara, Andrea Esuli, Tiziano Fagni, Fabrizio Falchi, Alejandro Moreo Fernández category:cs.IR cs.CL cs.CV cs.NE  published:2016-06-23 summary:In this paper we tackle the problem of image search when the query is a short textual description of the image the user is looking for. We choose to implement the actual search process as a similarity search in a visual feature space, by learning to translate a textual query into a visual representation. Searching in the visual feature space has the advantage that any update to the translation model does not require to reprocess the, typically huge, image collection on which the search is performed. We propose Text2Vis, a neural network that generates a visual representation, in the visual feature space of the fc6-fc7 layers of ImageNet, from a short descriptive text. Text2Vis optimizes two loss functions, using a stochastic loss-selection method. A visual-focused loss is aimed at learning the actual text-to-visual feature mapping, while a text-focused loss is aimed at modeling the higher-level semantic concepts expressed in language and countering the overfit on non-relevant visual components of the visual loss. We report preliminary results on the MS-COCO dataset. version:1
arxiv-1606-07286 | Importance sampling strategy for non-convex randomized block-coordinate descent | http://arxiv.org/abs/1606.07286 | id:1606.07286 author:Rémi Flamary, Alain Rakotomamonjy, Gilles Gasso category:cs.LG math.OC  published:2016-06-23 summary:As the number of samples and dimensionality of optimization problems related to statistics an machine learning explode, block coordinate descent algorithms have gained popularity since they reduce the original problem to several smaller ones. Coordinates to be optimized are usually selected randomly according to a given probability distribution. We introduce an importance sampling strategy that helps randomized coordinate descent algorithms to focus on blocks that are still far from convergence. The framework applies to problems composed of the sum of two possibly non-convex terms, one being separable and non-smooth. We have compared our algorithm to a full gradient proximal approach as well as to a randomized block coordinate algorithm that considers uniform sampling and cyclic block coordinate descent. Experimental evidences show the clear benefit of using an importance sampling strategy. version:1
arxiv-1606-07285 | Identifying individual facial expressions by deconstructing a neural network | http://arxiv.org/abs/1606.07285 | id:1606.07285 author:Farhad Arbabzadah, Grégoire Montavon, Klaus-Robert Müller, Wojciech Samek category:cs.CV cs.NE stat.ML  published:2016-06-23 summary:This paper focuses on the problem of explaining predictions of psychological attributes such as attractiveness, happiness, confidence and intelligence from face photographs using deep neural networks. Since psychological attribute datasets typically suffer from small sample sizes, we apply transfer learning with two base models to avoid overfitting. These models were trained on an age and gender prediction task, respectively. Using a novel explanation method we extract heatmaps that highlight the parts of the image most responsible for the prediction. We further observe that the explanation method provides important insights into the nature of features of the base model, which allow one to assess the aptitude of the base model for a given transfer learning task. Finally, we observe that the multiclass model is more feature rich than its binary counterpart. The experimental evaluation is performed on the 2222 images from the 10k US faces dataset containing psychological attribute labels as well as on a subset of KDEF images. version:1
arxiv-1606-07283 | Event Abstraction for Process Mining using Supervised Learning Techniques | http://arxiv.org/abs/1606.07283 | id:1606.07283 author:Niek Tax, Natalia Sidorova, Reinder Haakma, Wil M. P. van der Aalst category:cs.LG  published:2016-06-23 summary:Process mining techniques focus on extracting insight in processes from event logs. In many cases, events recorded in the event log are too fine-grained, causing process discovery algorithms to discover incomprehensible process models or process models that are not representative of the event log. We show that when process discovery algorithms are only able to discover an unrepresentative process model from a low-level event log, structure in the process can in some cases still be discovered by first abstracting the event log to a higher level of granularity. This gives rise to the challenge to bridge the gap between an original low-level event log and a desired high-level perspective on this log, such that a more structured or more comprehensible process model can be discovered. We show that supervised learning can be leveraged for the event abstraction task when annotations with high-level interpretations of the low-level events are available for a subset of the sequences (i.e., traces). We present a method to generate feature vector representations of events based on XES extensions, and describe an approach to abstract events in an event log with Condition Random Fields using these event features. Furthermore, we propose a sequence-focused metric to evaluate supervised event abstraction results that fits closely to the tasks of process discovery and conformance checking. We conclude this paper by demonstrating the usefulness of supervised event abstraction for obtaining more structured and/or more comprehensible process models using both real life event data and synthetic event data. version:1
arxiv-1606-07282 | A review of undirected and acyclic directed Gaussian Markov model selection and estimation | http://arxiv.org/abs/1606.07282 | id:1606.07282 author:Irene Córdoba Sánchez, Concha Bielza, Pedro Larrañaga category:stat.ME cs.AI stat.ML  published:2016-06-23 summary:Markov models lie at the interface between statistical independence in a probability distribution and graph separation properties. We review model selection and estimation in directed and undirected Markov models with Gaussian parametrization, emphasizing the main similarities and differences. These two model types are foundationally similar but not equivalent, as we highlight. We report existing results from a historical perspective, taking into account literature from both the artificial intelligence and statistics research communities, which first developed these models. Finally, we point out the main active research areas and open problems now existing with regard to these traditional, albeit rich, Markov models. version:1
arxiv-1606-07279 | Multiclass feature learning for hyperspectral image classification: sparse and hierarchical solutions | http://arxiv.org/abs/1606.07279 | id:1606.07279 author:Devis Tuia, Rémi Flamary, Nicolas Courty category:stat.ML cs.LG  published:2016-06-23 summary:In this paper, we tackle the question of discovering an effective set of spatial filters to solve hyperspectral classification problems. Instead of fixing a priori the filters and their parameters using expert knowledge, we let the model find them within random draws in the (possibly infinite) space of possible filters. We define an active set feature learner that includes in the model only features that improve the classifier. To this end, we consider a fast and linear classifier, multiclass logistic classification, and show that with a good representation (the filters discovered), such a simple classifier can reach at least state of the art performances. We apply the proposed active set learner in four hyperspectral image classification problems, including agricultural and urban classification at different resolutions, as well as multimodal data. We also propose a hierarchical setting, which allows to generate more complex banks of features that can better describe the nonlinearities present in the data. version:1
arxiv-1606-07268 | Semi-supervised Inference: General Theory and Estimation of Means | http://arxiv.org/abs/1606.07268 | id:1606.07268 author:Anru Zhang, Lawrence D. Brown, T. Tony Cai category:stat.ME math.ST stat.ML stat.TH  published:2016-06-23 summary:We propose a general semi-supervised inference framework focused on the estimation of the population mean. We consider both the ideal semi-supervised setting where infinitely many unlabeled samples are available, as well as the ordinary semi-supervised setting in which only a finite number of unlabeled samples is available. As usual in semi-supervised settings, there exists an unlabeled sample of covariate vectors and a labeled sample consisting of covariate vectors along with real-valued responses ("labels"). Otherwise the formulation is "assumption-lean" in that no major conditions are imposed on the statistical or functional form of the data. Estimators are proposed along with corresponding confidence intervals for the population mean. Theoretical analysis on both the asymptotic behavior and $\ell_2$-risk for the proposed procedures are given. Surprisingly, the proposed estimators, based on a simple form of the least squares method, outperform the ordinary sample mean. The method is further extended to a nonparametric setting, in which the oracle rate can be achieved asymptotically. The proposed estimators are further illustrated by simulation studies and a real data example involving estimation of the homeless population. version:1
arxiv-1606-07262 | On the Theoretical Capacity of Evolution Strategies to Statistically Learn the Landscape Hessian | http://arxiv.org/abs/1606.07262 | id:1606.07262 author:Ofer M. Shir, Jonathan Roslund, Amir Yehudayoff category:cs.NE cs.LG  published:2016-06-23 summary:We study the theoretical capacity to statistically learn local landscape information by Evolution Strategies (ESs). Specifically, we investigate the covariance matrix when constructed by ESs operating with the selection operator alone. We model continuous generation of candidate solutions about quadratic basins of attraction, with deterministic selection of the decision vectors that minimize the objective function values. Our goal is to rigorously show that accumulation of winning individuals carries the potential to reveal valuable information about the search landscape, e.g., as already practically utilized by derandomized ES variants. We first show that the statistically-constructed covariance matrix over such winning decision vectors shares the same eigenvectors with the Hessian matrix about the optimum. We then provide an analytic approximation of this covariance matrix for a non-elitist multi-child $(1,\lambda)$-strategy, which holds for a large population size $\lambda$. Finally, we also numerically corroborate our results. version:1
arxiv-1606-07256 | Saliency Driven Object recognition in egocentric videos with deep CNN | http://arxiv.org/abs/1606.07256 | id:1606.07256 author:Philippe Pérez de San Roman, Jenny Benois-Pineau, Jean-Philippe Domenger, Florent Paclet, Daniel Cataert, Aymar de Rugy category:cs.CV  published:2016-06-23 summary:The problem of object recognition in natural scenes has been recently successfully addressed with Deep Convolutional Neuronal Networks giving a significant break-through in recognition scores. The computational efficiency of Deep CNNs as a function of their depth, allows for their use in real-time applications. One of the key issues here is to reduce the number of windows selected from images to be submitted to a Deep CNN. This is usually solved by preliminary segmentation and selection of specific windows, having outstanding "objectiveness" or other value of indicators of possible location of objects. In this paper we propose a Deep CNN approach and the general framework for recognition of objects in a real-time scenario and in an egocentric perspective. Here the window of interest is built on the basis of visual attention map computed over gaze fixations measured by a glass-worn eye-tracker. The application of this set-up is an interactive user-friendly environment for upper-limb amputees. Vision has to help the subject to control his worn neuro-prosthesis in case of a small amount of remaining muscles when the EMG control becomes unefficient. The recognition results on a specifically recorded corpus of 151 videos with simple geometrical objects show the mAP of 64,6\% and the computational time at the generalization lower than a time of a visual fixation on the object-of-interest. version:1
arxiv-1606-07253 | Robust 3D Hand Pose Estimation in Single Depth Images: from Single-View CNN to Multi-View CNNs | http://arxiv.org/abs/1606.07253 | id:1606.07253 author:Liuhao Ge, Hui Liang, Junsong Yuan, Daniel Thalmann category:cs.CV  published:2016-06-23 summary:Articulated hand pose estimation plays an important role in human-computer interaction. Despite the recent progress, the accuracy of existing methods is still not satisfactory, partially due to the difficulty of embedded high-dimensional and non-linear regression problem. Most existing discriminative methods regress the hand pose directly from a single depth image, which cannot fully utilize the depth information. In this paper, we propose a novel multi-view CNNs based approach for 3D hand pose estimation. The query depth image is projected onto multiple planes, and multi-view CNNs are trained to learn the mapping from projected images to 2D heat-maps which estimate 2D joint positions on each plane. These multi-view heat-maps are then fused to produce final 3D hand pose estimation with learned pose priors. Experimental results show that the proposed method is superior than several state-of-the-art methods on two challenging datasets. Moreover, a quantitative cross-dataset experiment and a qualitative experiment also demonstrate the good generalization ability of the proposed method. version:1
arxiv-1606-07251 | Algorithmic Composition of Melodies with Deep Recurrent Neural Networks | http://arxiv.org/abs/1606.07251 | id:1606.07251 author:Florian Colombo, Samuel P. Muscinelli, Alexander Seeholzer, Johanni Brea, Wulfram Gerstner category:stat.ML cs.LG  published:2016-06-23 summary:A big challenge in algorithmic composition is to devise a model that is both easily trainable and able to reproduce the long-range temporal dependencies typical of music. Here we investigate how artificial neural networks can be trained on a large corpus of melodies and turned into automated music composers able to generate new melodies coherent with the style they have been trained on. We employ gated recurrent unit networks that have been shown to be particularly efficient in learning complex sequential activations with arbitrary long time lags. Our model processes rhythm and melody in parallel while modeling the relation between these two features. Using such an approach, we were able to generate interesting complete melodies or suggest possible continuations of a melody fragment that is coherent with the characteristics of the fragment itself. version:1
arxiv-1606-07247 | Human Computer Interaction Using Marker Based Hand Gesture Recognition | http://arxiv.org/abs/1606.07247 | id:1606.07247 author:Sayem Mohammad Siam, Jahidul Adnan Sakel, Md. Hasanul Kabir category:cs.HC cs.CV  published:2016-06-23 summary:Human Computer Interaction (HCI) has been redefined in this era. People want to interact with their devices in such a way that has physical significance in the real world, in other words, they want ergonomic input devices. In this paper, we propose a new method of interaction with computing devices having a consumer grade camera, that uses two colored markers (red and green) worn on tips of the fingers to generate desired hand gestures, and for marker detection and tracking we used template matching with kalman filter. We have implemented all the usual system commands, i.e., cursor movement, right click, left click, double click, going forward and backward, zoom in and out through different hand gestures. Our system can easily recognize these gestures and give corresponding system commands. Our system is suitable for both desktop devices and devices where touch screen is not feasible like large screens or projected screens. version:1
arxiv-1606-07240 | PAC-Bayesian Theorems for Multiview Learning | http://arxiv.org/abs/1606.07240 | id:1606.07240 author:Anil Goyal, Emilie Morvant, Pascal Germain, Massih-Reza Amini category:stat.ML  published:2016-06-23 summary:We tackle the issue of multiview learning which aims to take advantages of multiple represen-tations/views of the data. In this context, many machine learning algorithms exist. However, the majority of the theoretical studies focus on learning with exactly two representations. In this paper, we propose a general PAC-Bayesian theory for multiview learning with more than two views. We focus our study to binary classification models that take the form of a majority vote. We derive PAC-Bayesian generalization bounds allowing to consider different relations between empirical and true risks by taking into account a notion of diversity of the voters and views, and that can be naturally extended to semi-supervised learning. version:1
arxiv-1606-07239 | Non Local Spatial and Angular Matching : Enabling higher spatial resolution diffusion MRI datasets through adaptive denoising | http://arxiv.org/abs/1606.07239 | id:1606.07239 author:Samuel St-Jean, Pierrick Coupé, Maxime Descoteaux category:cs.CV  published:2016-06-23 summary:Diffusion magnetic resonance imaging datasets suffer from low Signal-to-Noise Ratio, especially at high b-values. Acquiring data at high b-values contains relevant information and is now of great interest for microstructural and connectomics studies. High noise levels bias the measurements due to the non-Gaussian nature of the noise, which in turn can lead to a false and biased estimation of the diffusion parameters. Additionally, the usage of in-plane acceleration techniques during the acquisition leads to a spatially varying noise distribution, which depends on the parallel acceleration method implemented on the scanner. This paper proposes a novel diffusion MRI denoising technique that can be used on all existing data, without adding to the scanning time. We first apply a statistical framework to convert the noise to Gaussian distributed noise, effectively removing the bias. We then introduce a spatially and angular adaptive denoising technique, the Non Local Spatial and Angular Matching (NLSAM) algorithm. Each volume is first decomposed in small 4D overlapping patches to capture the structure of the diffusion data and a dictionary of atoms is learned on those patches. A local sparse decomposition is then found by bounding the reconstruction error with the local noise variance. We compare against three other state-of-the-art denoising methods and show quantitative local and connectivity results on a synthetic phantom and on an in-vivo high resolution dataset. Overall, our method restores perceptual information, removes the noise bias in common diffusion metrics, restores the extracted peaks coherence and improves reproducibility of tractography. Our work paves the way for higher spatial resolution acquisition of diffusion MRI datasets, which could in turn reveal new anatomical details that are not discernible at the spatial resolution currently used by the diffusion MRI community. version:1
arxiv-1606-07230 | Deep Learning Markov Random Field for Semantic Segmentation | http://arxiv.org/abs/1606.07230 | id:1606.07230 author:Ziwei Liu, Xiaoxiao Li, Ping Luo, Chen Change Loy, Xiaoou Tang category:cs.CV cs.LG  published:2016-06-23 summary:Semantic segmentation tasks can be well modeled by Markov Random Field (MRF). This paper addresses semantic segmentation by incorporating high-order relations and mixture of label contexts into MRF. Unlike previous works that optimized MRFs using iterative algorithm, we solve MRF by proposing a Convolutional Neural Network (CNN), namely Deep Parsing Network (DPN), which enables deterministic end-to-end computation in a single forward pass. Specifically, DPN extends a contemporary CNN to model unary terms and additional layers are devised to approximate the mean field (MF) algorithm for pairwise terms. It has several appealing properties. First, different from the recent works that required many iterations of MF during back-propagation, DPN is able to achieve high performance by approximating one iteration of MF. Second, DPN represents various types of pairwise terms, making many existing models as its special cases. Furthermore, pairwise terms in DPN provide a unified framework to encode rich contextual information in high-dimensional data, such as images and videos. Third, DPN makes MF easier to be parallelized and speeded up, thus enabling efficient inference. DPN is thoroughly evaluated on standard semantic image/video segmentation benchmarks, where a single DPN model yields state-of-the-art segmentation accuracies on PASCAL VOC 2012, Cityscapes dataset and CamVid dataset. version:1
arxiv-1606-07219 | Learning Dynamic Classes of Events using Stacked Multilayer Perceptron Networks | http://arxiv.org/abs/1606.07219 | id:1606.07219 author:Nattiya Kanhabua, Huamin Ren, Thomas B. Moeslund category:cs.IR cs.LG  published:2016-06-23 summary:People often use a web search engine to find information about events of interest, for example, sport competitions, political elections, festivals and entertainment news. In this paper, we study a problem of detecting event-related queries, which is the first step before selecting a suitable time-aware retrieval model. In general, event-related information needs can be observed in query streams through various temporal patterns of user search behavior, e.g., spiky peaks for popular events, and periodicities for repetitive events. However, it is also common that users search for non-popular events, which may not exhibit temporal variations in query streams, e.g., past events recently occurred, historical events triggered by anniversaries or similar events, and future events anticipated to happen. To address the challenge of detecting dynamic classes of events, we propose a novel deep learning model to classify a given query into a predetermined set of multiple event types. Our proposed model, a Stacked Multilayer Perceptron (S-MLP) network, consists of multilayer perceptron used as a basic learning unit. We assemble stacked units to further learn complex relationships between neutrons in successive layers. To evaluate our proposed model, we conduct experiments using real-world queries and a set of manually created ground truth. Preliminary results have shown that our proposed deep learning model outperforms the state-of-the-art classification models significantly. version:1
arxiv-1606-07015 | Joint M-Best-Diverse Labelings as a Parametric Submodular Minimization | http://arxiv.org/abs/1606.07015 | id:1606.07015 author:Alexander Kirillov, Alexander Shekhovtsov, Carsten Rother, Bogdan Savchynskyy category:cs.CV  published:2016-06-22 summary:We consider the problem of jointly inferring the M-best diverse labelings for a binary (high-order) submodular energy of a graphical model. Recently, it was shown that this problem can be solved to a global optimum, for many practically interesting diversity measures. It was noted that the labelings are, so-called, nested. This nestedness property also holds for labelings of a class of parametric submodular minimization problems, where different values of the global parameter $\gamma$ give rise to different solutions. The popular example of the parametric submodular minimization is the monotonic parametric max-flow problem, which is also widely used for computing multiple labelings. As the main contribution of this work we establish a close relationship between diversity with submodular energies and the parametric submodular minimization. In particular, the joint M-best diverse labelings can be obtained by running a non-parametric submodular minimization (in the special case - max-flow) solver for M different values of $\gamma$ in parallel, for certain diversity measures. Importantly, the values for $\gamma$ can be computed in a closed form in advance, prior to any optimization. These theoretical results suggest two simple yet efficient algorithms for the joint M-best diverse problem, which outperform competitors in terms of runtime and quality of results. In particular, as we show in the paper, the new methods compute the exact M-best diverse labelings faster than a popular method of Batra et al., which in some sense only obtains approximate solutions. version:2
arxiv-1606-06368 | Unanimous Prediction for 100% Precision with Application to Learning Semantic Mappings | http://arxiv.org/abs/1606.06368 | id:1606.06368 author:Fereshte Khani, Martin Rinard, Percy Liang category:cs.LG cs.AI cs.CL I.2.7; I.2.6  published:2016-06-20 summary:Can we train a system that, on any new input, either says "don't know" or makes a prediction that is guaranteed to be correct? We answer the question in the affirmative provided our model family is well-specified. Specifically, we introduce the unanimity principle: only predict when all models consistent with the training data predict the same output. We operationalize this principle for semantic parsing, the task of mapping utterances to logical forms. We develop a simple, efficient method that reasons over the infinite set of all consistent models by only checking two of the models. We prove that our method obtains 100% precision even with a modest amount of training data from a possibly adversarial distribution. Empirically, we demonstrate the effectiveness of our approach on the standard GeoQuery dataset. version:2
arxiv-1606-07211 | Toward a Deep Neural Approach for Knowledge-Based IR | http://arxiv.org/abs/1606.07211 | id:1606.07211 author:Gia-Hung Nguyen, Lynda Tamine, Laure Soulier, Nathalie Bricon-Souf category:cs.IR cs.CL  published:2016-06-23 summary:This paper tackles the problem of the semantic gap between a document and a query within an ad-hoc information retrieval task. In this context, knowledge bases (KBs) have already been acknowledged as valuable means since they allow the representation of explicit relations between entities. However, they do not necessarily represent implicit relations that could be hidden in a corpora. This latter issue is tackled by recent works dealing with deep representation learn ing of texts. With this in mind, we argue that embedding KBs within deep neural architectures supporting documentquery matching would give rise to fine-grained latent representations of both words and their semantic relations. In this paper, we review the main approaches of neural-based document ranking as well as those approaches for latent representation of entities and relations via KBs. We then propose some avenues to incorporate KBs in deep neural approaches for document ranking. More particularly, this paper advocates that KBs can be used either to support enhanced latent representations of queries and documents based on both distributional and relational semantics or to serve as a semantic translator between their latent distributional representations. version:1
arxiv-1606-07189 | Gender and Interest Targeting for Sponsored Post Advertising at Tumblr | http://arxiv.org/abs/1606.07189 | id:1606.07189 author:Mihajlo Grbovic, Vladan Radosavljevic, Nemanja Djuric, Narayan Bhamidipati, Ananth Nagarajan category:cs.CL cs.CY cs.SI H.2.8  published:2016-06-23 summary:As one of the leading platforms for creative content, Tumblr offers advertisers a unique way of creating brand identity. Advertisers can tell their story through images, animation, text, music, video, and more, and promote that content by sponsoring it to appear as an advertisement in the streams of Tumblr users. In this paper we present a framework that enabled one of the key targeted advertising components for Tumblr, specifically gender and interest targeting. We describe the main challenges involved in development of the framework, which include creating the ground truth for training gender prediction models, as well as mapping Tumblr content to an interest taxonomy. For purposes of inferring user interests we propose a novel semi-supervised neural language model for categorization of Tumblr content (i.e., post tags and post keywords). The model was trained on a large-scale data set consisting of 6.8 billion user posts, with very limited amount of categorized keywords, and was shown to have superior performance over the bag-of-words model. We successfully deployed gender and interest targeting capability in Yahoo production systems, delivering inference for users that cover more than 90% of daily activities at Tumblr. Online performance results indicate advantages of the proposed approach, where we observed 20% lift in user engagement with sponsored posts as compared to untargeted campaigns. version:1
arxiv-1606-06812 | Link Prediction via Matrix Completion | http://arxiv.org/abs/1606.06812 | id:1606.06812 author:Ratha Pech, Dong Hao, Liming Pan, Hong Cheng, Tao Zhou category:cs.SI cs.LG physics.soc-ph  published:2016-06-22 summary:Inspired by practical importance of social networks, economic networks, biological networks and so on, studies on large and complex networks have attracted a surge of attentions in the recent years. Link prediction is a fundamental issue to understand the mechanisms by which new links are added to the networks. We introduce the method of robust principal component analysis (robust PCA) into link prediction, and estimate the missing entries of the adjacency matrix. On one hand, our algorithm is based on the sparsity and low rank property of the matrix, on the other hand, it also performs very well when the network is dense. This is because a relatively dense real network is also sparse in comparison to the complete graph. According to extensive experiments on real networks from disparate fields, when the target network is connected and sufficiently dense, whatever it is weighted or unweighted, our method is demonstrated to be very effective and with prediction accuracy being considerably improved comparing with many state-of-the-art algorithms. version:2
arxiv-1606-07166 | 3D Display Calibration by Visual Pattern Analysis | http://arxiv.org/abs/1606.07166 | id:1606.07166 author:Hyoseok Hwang, Hyun Sung Chang, Dongkyung Nam, In So Kweon category:cs.CV  published:2016-06-23 summary:Nearly all 3D displays need calibration for correct rendering. More often than not, the optical elements in a 3D display are misaligned from the designed parameter setting. As a result, 3D magic does not perform well as intended. The observed images tend to get distorted. In this paper, we propose a novel display calibration method to fix the situation. In our method, a pattern image is displayed on the panel and a camera takes its pictures twice at different positions. Then, based on a quantitative model, we extract all display parameters (i.e., pitch, slanted angle, gap or thickness, offset) from the observed patterns in the captured images. For high accuracy and robustness, our method analyzes the patterns mostly in frequency domain. We conduct two types of experiments for validation; one with optical simulation for quantitative results and the other with real-life displays for qualitative assessment. Experimental results demonstrate that our method is quite accurate, about a half order of magnitude higher than prior work; is efficient, spending less than 2 s for computation; and is robust to noise, working well in the SNR regime as low as 6 dB. version:1
arxiv-1606-07163 | Interpretable Machine Learning Models for the Digital Clock Drawing Test | http://arxiv.org/abs/1606.07163 | id:1606.07163 author:William Souillard-Mandar, Randall Davis, Cynthia Rudin, Rhoda Au, Dana Penney category:stat.ML cs.LG  published:2016-06-23 summary:The Clock Drawing Test (CDT) is a rapid, inexpensive, and popular neuropsychological screening tool for cognitive conditions. The Digital Clock Drawing Test (dCDT) uses novel software to analyze data from a digitizing ballpoint pen that reports its position with considerable spatial and temporal precision, making possible the analysis of both the drawing process and final product. We developed methodology to analyze pen stroke data from these drawings, and computed a large collection of features which were then analyzed with a variety of machine learning techniques. The resulting scoring systems were designed to be more accurate than the systems currently used by clinicians, but just as interpretable and easy to use. The systems also allow us to quantify the tradeoff between accuracy and interpretability. We created automated versions of the CDT scoring systems currently used by clinicians, allowing us to benchmark our models, which indicated that our machine learning models substantially outperformed the existing scoring systems. version:1
arxiv-1606-07153 | Fast robustness quantification with variational Bayes | http://arxiv.org/abs/1606.07153 | id:1606.07153 author:Ryan Giordano, Tamara Broderick, Rachael Meager, Jonathan Huggins, Michael Jordan category:stat.ML stat.AP stat.ME  published:2016-06-23 summary:Bayesian hierarchical models are increasing popular in economics. When using hierarchical models, it is useful not only to calculate posterior expectations, but also to measure the robustness of these expectations to reasonable alternative prior choices. We use variational Bayes and linear response methods to provide fast, accurate posterior means and robustness measures with an application to measuring the effectiveness of microcredit in the developing world. version:1
arxiv-1606-07150 | Adaptive and Scalable Android Malware Detection through Online Learning | http://arxiv.org/abs/1606.07150 | id:1606.07150 author:Annamalai Narayanan, Liu Yang, Lihui Chen, Liu Jinliang category:cs.CR cs.LG  published:2016-06-23 summary:It is well-known that malware constantly evolves so as to evade detection and this causes the entire malware population to be non-stationary. Contrary to this fact, prior works on machine learning based Android malware detection have assumed that the distribution of the observed malware characteristics (i.e., features) do not change over time. In this work, we address the problem of malware population drift and propose a novel online machine learning based framework, named DroidOL to handle it and effectively detect malware. In order to perform accurate detection, security-sensitive behaviors are captured from apps in the form of inter-procedural control-flow sub-graph features using a state-of-the-art graph kernel. In order to perform scalable detection and to adapt to the drift and evolution in malware population, an online passive-aggressive classifier is used. In a large-scale comparative analysis with more than 87,000 apps, DroidOL achieves 84.29% accuracy outperforming two state-of-the-art malware techniques by more than 20% in their typical batch learning setting and more than 3% when they are continuously re-trained. Our experimental findings strongly indicate that online learning based approaches are highly suitable for real-world malware detection. version:1
arxiv-1606-07149 | An Approach to Stable Gradient Descent Adaptation of Higher-Order Neural Units | http://arxiv.org/abs/1606.07149 | id:1606.07149 author:Ivo Bukovsky, Noriyasu Homma category:cs.NE cs.AI cs.CE cs.LG cs.SY  published:2016-06-23 summary:Stability evaluation of a weight-update system of higher-order neural units (HONUs) with polynomial aggregation of neural inputs (also known as classes of polynomial neural networks) for adaptation of both feedforward and recurrent HONUs by a gradient descent method is introduced. An essential core of the approach is based on spectral radius of a weight-update system, and it allows stability monitoring and its maintenance at every adaptation step individually. Assuring stability of the weight-update system (at every single adaptation step) naturally results in adaptation stability of the whole neural architecture that adapts to target data. As an aside, the used approach highlights the fact that the weight optimization of HONU is a linear problem, so the proposed approach can be generally extended to any neural architecture that is linear in its adaptable parameters. version:1
arxiv-1606-07137 | Automated Extraction of Number of Subjects in Randomised Controlled Trials | http://arxiv.org/abs/1606.07137 | id:1606.07137 author:Abeed Sarker category:cs.AI cs.CL cs.IR  published:2016-06-22 summary:We present a simple approach for automatically extracting the number of subjects involved in randomised controlled trials (RCT). Our approach first applies a set of rule-based techniques to extract candidate study sizes from the abstracts of the articles. Supervised classification is then performed over the candidates with support vector machines, using a small set of lexical, structural, and contextual features. With only a small annotated training set of 201 RCTs, we obtained an accuracy of 88\%. We believe that this system will aid complex medical text processing tasks such as summarisation and question answering. version:1
arxiv-1606-07129 | Explainable Restricted Boltzmann Machines for Collaborative Filtering | http://arxiv.org/abs/1606.07129 | id:1606.07129 author:Behnoush Abdollahi, Olfa Nasraoui category:stat.ML cs.LG  published:2016-06-22 summary:Most accurate recommender systems are black-box models, hiding the reasoning behind their recommendations. Yet explanations have been shown to increase the user's trust in the system in addition to providing other benefits such as scrutability, meaning the ability to verify the validity of recommendations. This gap between accuracy and transparency or explainability has generated an interest in automated explanation generation methods. Restricted Boltzmann Machines (RBM) are accurate models for CF that also lack interpretability. In this paper, we focus on RBM based collaborative filtering recommendations, and further assume the absence of any additional data source, such as item content or user attributes. We thus propose a new Explainable RBM technique that computes the top-n recommendation list from items that are explainable. Experimental results show that our method is effective in generating accurate and explainable recommendations. version:1
arxiv-1606-07112 | Visualizing Dynamics: from t-SNE to SEMI-MDPs | http://arxiv.org/abs/1606.07112 | id:1606.07112 author:Nir Ben Zrihem, Tom Zahavy, Shie Mannor category:stat.ML cs.LG  published:2016-06-22 summary:Deep Reinforcement Learning (DRL) is a trending field of research, showing great promise in many challenging problems such as playing Atari, solving Go and controlling robots. While DRL agents perform well in practice we are still missing the tools to analayze their performance and visualize the temporal abstractions that they learn. In this paper, we present a novel method that automatically discovers an internal Semi Markov Decision Process (SMDP) model in the Deep Q Network's (DQN) learned representation. We suggest a novel visualization method that represents the SMDP model by a directed graph and visualize it above a t-SNE map. We show how can we interpret the agent's policy and give evidence for the hierarchical state aggregation that DQNs are learning automatically. Our algorithm is fully automatic, does not require any domain specific knowledge and is evaluated by a novel likelihood based evaluation criteria. version:1
arxiv-1606-07104 | Manifolds' Projective Approximation Using The Moving Least-Squares (MMLS) | http://arxiv.org/abs/1606.07104 | id:1606.07104 author:Barak Sober, David Levin category:cs.GR cs.LG math.DG  published:2016-06-22 summary:In order to avoid the curse of dimensionality, frequently encountered in Big Data analysis, there was a vast development in the field of linear and non-linear dimension reduction techniques in recent years. These techniques (sometimes referred to as manifold learning) assume that the scattered input data is lying on a lower dimensional manifold, thus the high dimensionality problem can be overcome by learning the lower dimensionality behavior. However, in real life applications, data is often very noisy. In this work, we propose a method to approximate a $d$-dimensional $C^{m+1}$ smooth submanifold $\mathcal{M}$ residing in $\mathbb{R}^n$ ($d << n$) based upon scattered data points (i.e., a data cloud). We assume that the data points are located "near" the noisy lower dimensional manifold and perform a non-linear moving least-squares projection on an approximating manifold. Under some mild assumptions, the resulting approximant is shown to be infinitely smooth and of approximation order of $O(h^{m+1})$. Furthermore, the method presented here assumes no analytic knowledge of the approximated manifold and the approximation algorithm is linear in the large dimension $n$. version:1
arxiv-1606-07103 | Deep Feature Fusion Network for Answer Quality Prediction in Community Question Answering | http://arxiv.org/abs/1606.07103 | id:1606.07103 author:Sai Praneeth Suggu, Kushwanth N. Goutham, Manoj K. Chinnakotla, Manish Shrivastava category:cs.IR cs.CL  published:2016-06-22 summary:Community Question Answering (cQA) forums have become a popular medium for soliciting direct answers to specific questions of users from experts or other experienced users on a given topic. However, for a given question, users sometimes have to sift through a large number of low-quality or irrelevant answers to find out the answer which satisfies their information need. To alleviate this, the problem of Answer Quality Prediction (AQP) aims to predict the quality of an answer posted in response to a forum question. Current AQP systems either learn models using - a) various hand-crafted features (HCF) or b) use deep learning (DL) techniques which automatically learn the required feature representations. In this paper, we propose a novel approach for AQP known as - "Deep Feature Fusion Network (DFFN)" which leverages the advantages of both hand-crafted features and deep learning based systems. Given a question-answer pair along with its metadata, DFFN independently - a) learns deep features using a Convolutional Neural Network (CNN) and b) computes hand-crafted features using various external resources and then combines them using a deep neural network trained to predict the final answer quality. DFFN achieves state-of-the-art performance on the standard SemEval-2015 and SemEval-2016 benchmark datasets and outperforms baseline approaches which individually employ either HCF or DL based techniques alone. version:1
arxiv-1606-07081 | Finite Sample Prediction and Recovery Bounds for Ordinal Embedding | http://arxiv.org/abs/1606.07081 | id:1606.07081 author:Lalit Jain, Kevin Jamieson, Robert Nowak category:stat.ML cs.LG  published:2016-06-22 summary:The goal of ordinal embedding is to represent items as points in a low-dimensional Euclidean space given a set of constraints in the form of distance comparisons like "item $i$ is closer to item $j$ than item $k$". Ordinal constraints like this often come from human judgments. To account for errors and variation in judgments, we consider the noisy situation in which the given constraints are independently corrupted by reversing the correct constraint with some probability. This paper makes several new contributions to this problem. First, we derive prediction error bounds for ordinal embedding with noise by exploiting the fact that the rank of a distance matrix of points in $\mathbb{R}^d$ is at most $d+2$. These bounds characterize how well a learned embedding predicts new comparative judgments. Second, we investigate the special case of a known noise model and study the Maximum Likelihood estimator. Third, knowledge of the noise model enables us to relate prediction errors to embedding accuracy. This relationship is highly non-trivial since we show that the linear map corresponding to distance comparisons is non-invertible, but there exists a nonlinear map that is invertible. Fourth, two new algorithms for ordinal embedding are proposed and evaluated in experiments. version:1
arxiv-1606-07056 | Emulating Human Conversations using Convolutional Neural Network-based IR | http://arxiv.org/abs/1606.07056 | id:1606.07056 author:Abhay Prakash, Chris Brockett, Puneet Agrawal category:cs.AI cs.CL cs.IR H.3.3; I.2.7  published:2016-06-22 summary:Conversational agents ("bots") are beginning to be widely used in conversational interfaces. To design a system that is capable of emulating human-like interactions, a conversational layer that can serve as a fabric for chat-like interaction with the agent is needed. In this paper, we introduce a model that employs Information Retrieval by utilizing convolutional deep structured semantic neural network-based features in the ranker to present human-like responses in ongoing conversation with a user. In conversations, accounting for context is critical to the retrieval model; we show that our context-sensitive approach using a Convolutional Deep Structured Semantic Model (cDSSM) with character trigrams significantly outperforms several conventional baselines in terms of the relevance of responses retrieved. version:1
arxiv-1606-07046 | Semantic Parsing to Probabilistic Programs for Situated Question Answering | http://arxiv.org/abs/1606.07046 | id:1606.07046 author:Jayant Krishnamurthy, Oyvind Tafjord category:cs.CL  published:2016-06-22 summary:Situated question answering is the problem of answering questions about an environment such as an image. This problem requires interpreting both a question and the environment, and is challenging because the set of interpretations is large, typically superexponential in the number of environmental objects. Existing models handle this challenge by making strong -- and untrue -- independence assumptions. We present Parsing to Probabilistic Programs (P3), a novel situated question answering model that utilizes approximate inference to eliminate these independence assumptions and enable the use of global features of the question/environment interpretation. Our key insight is to treat semantic parses as probabilistic programs that execute nondeterministically and whose possible executions represent environmental uncertainty. We evaluate our approach on a new, publicly-released data set of 5000 science diagram questions, finding that our approach outperforms several competitive baselines. version:1
arxiv-1606-07043 | Toward Interpretable Topic Discovery via Anchored Correlation Explanation | http://arxiv.org/abs/1606.07043 | id:1606.07043 author:Kyle Reing, David C. Kale, Greg Ver Steeg, Aram Galstyan category:stat.ML cs.CL cs.LG  published:2016-06-22 summary:Many predictive tasks, such as diagnosing a patient based on their medical chart, are ultimately defined by the decisions of human experts. Unfortunately, encoding experts' knowledge is often time consuming and expensive. We propose a simple way to use fuzzy and informal knowledge from experts to guide discovery of interpretable latent topics in text. The underlying intuition of our approach is that latent factors should be informative about both correlations in the data and a set of relevance variables specified by an expert. Mathematically, this approach is a combination of the information bottleneck and Total Correlation Explanation (CorEx). We give a preliminary evaluation of Anchored CorEx, showing that it produces more coherent and interpretable topics on two distinct corpora. version:1
arxiv-1606-07035 | Ancestral Causal Inference | http://arxiv.org/abs/1606.07035 | id:1606.07035 author:Sara Magliacane, Tom Claassen, Joris M. Mooij category:cs.LG cs.AI stat.ML  published:2016-06-22 summary:Constraint-based causal discovery from limited data is a notoriously difficult challenge due to the many borderline independence test decisions. Several approaches to improve the reliability of the predictions by exploiting redundancy in the independence information have been proposed recently. Though promising, existing approaches can still be greatly improved in terms of accuracy and scalability. We present a novel method that reduces the combinatorial explosion of the search space by using a more coarse-grained representation of causal information, drastically reducing computation time. Additionally, we propose a method to score causal predictions based on their confidence. Crucially, our implementation also allows one to easily combine observational and interventional data and to incorporate various types of available background knowledge. We prove soundness and asymptotic consistency of our method and demonstrate that it can outperform the state-of-the-art on synthetic data, achieving a speedup of several orders of magnitude. We illustrate its practical feasibility by applying it on a challenging protein data set. version:1
arxiv-1606-07025 | Efficient Attack Graph Analysis through Approximate Inference | http://arxiv.org/abs/1606.07025 | id:1606.07025 author:Luis Muñoz-González, Daniele Sgandurra, Andrea Paudice, Emil C. Lupu category:cs.CR cs.AI stat.ML  published:2016-06-22 summary:Attack graphs provide compact representations of the attack paths that an attacker can follow to compromise network resources by analysing network vulnerabilities and topology. These representations are a powerful tool for security risk assessment. Bayesian inference on attack graphs enables the estimation of the risk of compromise to the system's components given their vulnerabilities and interconnections, and accounts for multi-step attacks spreading through the system. Whilst static analysis considers the risk posture at rest, dynamic analysis also accounts for evidence of compromise, e.g. from SIEM software or forensic investigation. However, in this context, exact Bayesian inference techniques do not scale well. In this paper we show how Loopy Belief Propagation - an approximate inference technique - can be applied to attack graphs, and that it scales linearly in the number of nodes for both static and dynamic analysis, making such analyses viable for larger networks. We experiment with different topologies and network clustering on synthetic Bayesian attack graphs with thousands of nodes to show that the algorithm's accuracy is acceptable and converge to a stable solution. We compare sequential and parallel versions of Loopy Belief Propagation with exact inference techniques for both static and dynamic analysis, showing the advantages of approximate inference techniques to scale to larger attack graphs. version:1
arxiv-1606-07006 | Using Word Embeddings in Twitter Election Classification | http://arxiv.org/abs/1606.07006 | id:1606.07006 author:Xiao Yang, Craig Macdonald, Iadh Ounis category:cs.IR cs.CL  published:2016-06-22 summary:Word embeddings and convolutional neural networks (CNN) have attracted extensive attention in various classification tasks for Twitter, e.g. sentiment classification. However, the effect of the configuration used to train and generate the word embeddings on the classification performance has not been studied in the existing literature. In this paper, using a Twitter election classification task that aims to detect election-related tweets, we investigate the impact of the background dataset used to train the embedding models, the context window size and the dimensionality of word embeddings on the classification performance. By comparing the classification results of two word embedding models, which are trained using different background corpora (e.g. Wikipedia articles and Twitter microposts), we show that the background data type should align with the Twitter classification dataset to achieve a better performance. Moreover, by evaluating the results of word embeddings models trained using various context window sizes and dimensionalities, we found that large context window and dimension sizes are preferable to improve the performance. Our experimental results also show that using word embeddings and CNN leads to statistically significant improvements over various baselines such as random, SVM with TF-IDF and SVM with word embeddings. version:1
arxiv-1606-06997 | Robust Identifiability in Sparse Dictionary Learning | http://arxiv.org/abs/1606.06997 | id:1606.06997 author:Charles J. Garfinkle, Christopher J. Hillar category:stat.ML cs.IT math.IT  published:2016-06-22 summary:Sparse coding or sparse dictionary learning methods have exposed underlying sparse structure in many kinds of natural data. Here, we generalize previous results guaranteeing when the learned dictionary and sparse codes are unique up to inherent permutation and scaling ambiguities. We show that these solutions are robust to the addition of measurement noise provided the data samples are sufficiently diverse. Central to our proofs is a useful lemma in combinatorial matrix theory which allows us to derive bounds on the number of samples necessary to guarantee uniqueness. We also provide probabilistic extensions to our robust identifiability theorem and an extension to the case where only an upper bound on the number of dictionary elements is known a priori. Our results help to inform the interpretation of sparse structure learned from data; whenever the conditions to one of our robust identifiability theorems are met, any sparsity-constrained algorithm that succeeds in approximately reconstructing the data well enough recovers the original dictionary and sparse codes up to an error commensurate with the noise. We discuss applications of this result to smoothed analysis, communication theory, and applied physics and engineering. version:1
arxiv-1606-06996 | The word entropy of natural languages | http://arxiv.org/abs/1606.06996 | id:1606.06996 author:Christian Bentz, Dimitrios Alikaniotis category:cs.CL  published:2016-06-22 summary:The average uncertainty associated with words is an information-theoretic concept at the heart of quantitative and computational linguistics. The entropy has been established as a measure of this average uncertainty - also called average information content. We here use parallel texts of 21 languages to establish the number of tokens at which word entropies converge to stable values. These convergence points are then used to select texts from a massively parallel corpus, and to estimate word entropies across more than 1000 languages. Our results help to establish quantitative language comparisons, to understand the performance of multilingual translation systems, and to normalize semantic similarity measures. version:1
arxiv-1606-07369 | Personalized Prognostic Models for Oncology: A Machine Learning Approach | http://arxiv.org/abs/1606.07369 | id:1606.07369 author:David Dooling, Angela Kim, Barbara McAneny, Jennifer Webster category:stat.AP cs.LG stat.ML  published:2016-06-22 summary:We have applied a little-known data transformation to subsets of the Surveillance, Epidemiology, and End Results (SEER) publically available data of the National Cancer Institute (NCI) to make it suitable input to standard machine learning classifiers. This transformation properly treats the right-censored data in the SEER data and the resulting Random Forest and Multi-Layer Perceptron models predict full survival curves. Treating the 6, 12, and 60 months points of the resulting survival curves as 3 binary classifiers, the 18 resulting classifiers have AUC values ranging from .765 to .885. Further evidence that the models have generalized well from the training data is provided by the extremely high levels of agreement between the random forest and neural network models predictions on the 6, 12, and 60 month binary classifiers. version:1
arxiv-1606-06991 | Toward Word Embedding for Personalized Information Retrieval | http://arxiv.org/abs/1606.06991 | id:1606.06991 author:Nawal Ould-Amer, Philippe Mulhem, Mathias Gery category:cs.IR cs.CL  published:2016-06-22 summary:This paper presents preliminary works on using Word Embedding (word2vec) for query expansion in the context of Personalized Information Retrieval. Traditionally, word embeddings are learned on a general corpus, like Wikipedia. In this work we try to personalize the word embeddings learning, by achieving the learning on the user's profile. The word embeddings are then in the same context than the user interests. Our proposal is evaluated on the CLEF Social Book Search 2016 collection. The results obtained show that some efforts should be made in the way to apply Word Embedding in the context of Personalized Information Retrieval. version:1
arxiv-1606-06061 | Fast, Compact, and High Quality LSTM-RNN Based Statistical Parametric Speech Synthesizers for Mobile Devices | http://arxiv.org/abs/1606.06061 | id:1606.06061 author:Heiga Zen, Yannis Agiomyrgiannakis, Niels Egberts, Fergus Henderson, Przemysław Szczepaniak category:cs.SD cs.CL  published:2016-06-20 summary:Acoustic models based on long short-term memory recurrent neural networks (LSTM-RNNs) were applied to statistical parametric speech synthesis (SPSS) and showed significant improvements in naturalness and latency over those based on hidden Markov models (HMMs). This paper describes further optimizations of LSTM-RNN-based SPSS for deployment on mobile devices; weight quantization, multi-frame inference, and robust inference using an {\epsilon}-contaminated Gaussian loss function. Experimental results in subjective listening tests show that these optimizations can make LSTM-RNN-based SPSS comparable to HMM-based SPSS in runtime speed while maintaining naturalness. Evaluations between LSTM-RNN- based SPSS and HMM-driven unit selection speech synthesis are also presented. version:2
arxiv-1606-06962 | Towards stationary time-vertex signal processing | http://arxiv.org/abs/1606.06962 | id:1606.06962 author:Nathanael Perraudin, Andreas Loukas, Francesco Grassi, Pierre Vandergheynst category:cs.LG cs.SI stat.ML  published:2016-06-22 summary:Graph-based methods for signal processing have shown promise for the analysis of data exhibiting irregular structure, such as those found in social, transportation, and sensor networks. Yet, though these systems are often dynamic, state-of-the-art methods for signal processing on graphs ignore the dimension of time, treating successive graph signals independently or taking a global average. To address this shortcoming, this paper considers the statistical analysis of time-varying graph signals. We introduce a novel definition of joint (time-vertex) stationarity, which generalizes the classical definition of time stationarity and the more recent definition appropriate for graphs. Joint stationarity gives rise to a scalable Wiener optimization framework for joint denoising, semi-supervised learning, or more generally inversing a linear operator, that is provably optimal. Experimental results on real weather data demonstrate that taking into account graph and time dimensions jointly can yield significant accuracy improvements in the reconstruction effort. version:1
arxiv-1606-06961 | An Approach for Parallel Genetic Algorithms in the Cloud using Software Containers | http://arxiv.org/abs/1606.06961 | id:1606.06961 author:Pasquale Salza, Filomena Ferrucci category:cs.NE cs.DC  published:2016-06-22 summary:Genetic Algorithms (GAs) are a powerful technique to address hard optimisation problems. However, scalability issues might prevent them from being applied to real-world problems. Exploiting parallel GAs in the cloud might be an affordable approach to get time efficient solutions that benefit of the appealing features of the cloud, such as scalability, reliability, fault-tolerance and cost-effectiveness. Nevertheless, distributed computation is very prone to cause considerable overhead for communication and making GAs distributed in an on-demand fashion is not trivial. Aiming to keep under control the communication overhead and support GAs developers in the construction and deployment of parallel GAs in the cloud, in this paper we propose an approach to distribute GAs using the global parallelisation model, exploiting software containers and their cloud orchestration. We also devised a conceptual workflow covering each cloud GAs distribution phase, from resources allocation to actual deployment and execution, in a DevOps fashion. version:1
arxiv-1606-06959 | Dealing with a large number of classes -- Likelihood, Discrimination or Ranking? | http://arxiv.org/abs/1606.06959 | id:1606.06959 author:David Barber, Aleksander Botev category:stat.ML  published:2016-06-22 summary:We consider training probabilistic classifiers in the case of a large number of classes. The number of classes is assumed too large to perform exact normalisation over all classes. To account for this we consider a simple approach that directly approximates the likelihood. We show that this simple approach works well on toy problems and is competitive with recently introduced alternative non-likelihood based approximations. Furthermore, we relate this approach to a simple ranking objective. This leads us to suggest a specific setting for the optimal threshold in the ranking objective. version:1
arxiv-1606-06329 | Recognizing Surgical Activities with Recurrent Neural Networks | http://arxiv.org/abs/1606.06329 | id:1606.06329 author:Robert DiPietro, Colin Lea, Anand Malpani, Narges Ahmidi, S. Swaroop Vedula, Gyusung I. Lee, Mija R. Lee, Gregory D. Hager category:cs.CV  published:2016-06-20 summary:We apply recurrent neural networks to the task of recognizing surgical activities from robot kinematics. Prior work in this area focuses on recognizing short, low-level activities, or gestures, and has been based on variants of hidden Markov models and conditional random fields. In contrast, we work on recognizing both gestures and longer, higher-level activites, or maneuvers, and we model the mapping from kinematics to gestures/maneuvers with recurrent neural networks. To our knowledge, we are the first to apply recurrent neural networks to this task. Using a single model and a single set of hyperparameters, we match state-of-the-art performance for gesture recognition and advance state-of-the-art performance for maneuver recognition, in terms of both accuracy and edit distance. Code is available at https://github.com/rdipietro/miccai-2016-surgical-activity-rec . version:2
arxiv-1606-06950 | A segmental framework for fully-unsupervised large-vocabulary speech recognition | http://arxiv.org/abs/1606.06950 | id:1606.06950 author:Herman Kamper, Aren Jansen, Sharon Goldwater category:cs.CL cs.LG  published:2016-06-22 summary:Zero-resource speech technology is a growing research area that aims to develop methods for speech processing in the absence of transcriptions, lexicons, or language modelling text. Early systems focused on identifying isolated recurring terms in a corpus, while more recent full-coverage systems attempt to completely segment and cluster the audio into word-like units---effectively performing unsupervised speech recognition. To our knowledge, this article presents the first such system evaluated on large-vocabulary multi-speaker data. The system uses a Bayesian modelling framework with segmental word representations: each word segment is represented as a fixed-dimensional acoustic embedding obtained by mapping the sequence of feature frames to a single embedding vector. We compare our system on English and Xitsonga datasets to state-of-the-art baselines, using a variety of measures including word error rate (obtained by mapping the unsupervised output to ground truth transcriptions). We show that by imposing a consistent top-down segmentation while also using bottom-up knowledge from detected syllable boundaries, both single-speaker and multi-speaker versions of our system outperform a purely bottom-up single-speaker syllable-based approach. We also show that the discovered clusters can be made less speaker- and gender-specific by using an unsupervised autoencoder-like feature extractor to learn better frame-level features (prior to embedding). Our system's discovered clusters are still less pure than those of two multi-speaker term discovery systems, but provide far greater coverage. version:1
arxiv-1606-06905 | Learning text representation using recurrent convolutional neural network with highway layers | http://arxiv.org/abs/1606.06905 | id:1606.06905 author:Ying Wen, Weinan Zhang, Rui Luo, Jun Wang category:cs.CL cs.IR  published:2016-06-22 summary:Recently, the rapid development of word embedding and neural networks has brought new inspiration to various NLP and IR tasks. In this paper, we describe a staged hybrid model combining Recurrent Convolutional Neural Networks (RCNN) with highway layers. The highway network module is incorporated in the middle takes the output of the bi-directional Recurrent Neural Network (Bi-RNN) module in the first stage and provides the Convolutional Neural Network (CNN) module in the last stage with the input. The experiment shows that our model outperforms common neural network models (CNN, RNN, Bi-RNN) on a sentiment analysis task. Besides, the analysis of how sequence length influences the RCNN with highway layers shows that our model could learn good representation for the long text. version:1
arxiv-1606-06900 | Inferring Logical Forms From Denotations | http://arxiv.org/abs/1606.06900 | id:1606.06900 author:Panupong Pasupat, Percy Liang category:cs.CL cs.AI  published:2016-06-22 summary:A core problem in learning semantic parsers from denotations is picking out consistent logical forms--those that yield the correct denotation--from a combinatorially large space. To control the search space, previous work relied on restricted set of rules, which limits expressivity. In this paper, we consider a much more expressive class of logical forms, and show how to use dynamic programming to efficiently represent the complete set of consistent logical forms. Expressivity also introduces many more spurious logical forms which are consistent with the correct denotation but do not represent the meaning of the utterance. To address this, we generate fictitious worlds and use crowdsourced denotations on these worlds to filter out spurious logical forms. On the WikiTableQuestions dataset, we increase the coverage of answerable questions from 53.5% to 76%, and the additional crowdsourced supervision lets us rule out 92.1% of spurious logical forms. version:1
arxiv-1606-05415 | Multi-feature combined cloud and cloud shadow detection in GF-1 WFV imagery | http://arxiv.org/abs/1606.05415 | id:1606.05415 author:Zhiwei Li, Huanfeng Shen, Huifang Li, Guisong Xia, Paolo Gamba, Liangpei Zhang category:cs.CV  published:2016-06-17 summary:The wide field of view (WFV) imaging system onboard the Chinese GF-1 optical satellite has a 16-m resolution and four-day revisit cycle for large-scale Earth observation. The advantages of the high temporal-spatial resolution and the wide field of view make the GF-1 WFV imagery very popular. However, cloud cover is a common problem in GF-1 WFV imagery which influences its precise application. Cloud and cloud shadow detection in GF-1 WFV imagery is quite difficult due to the fact that there are only four visible and near-infrared bands. In this paper, an automatic multi-feature combined (MFC) method is proposed for cloud and cloud shadow detection in GF-1 WFV imagery. The MFC method first implements threshold segmentation based on the spectral features, and guided filtering to generate a preliminary cloud mask. The geometric features are then used in combination with texture features to improve the cloud detection results and produce the final cloud mask. Finally, the cloud shadow mask can be acquired by means of the cloud and shadow matching and follow-up correction process. The method was validated on 16 scenes randomly selected from different areas of China. The results indicate that MFC performs well under different conditions, and the average cloud classification accuracy of MFC is as high as 98.3%. When relatively compared to Fmask, MFC achieved almost the same accuracy of the cloud and cloud shadow in GF-1 WFV imagery with less spectral bands. The method proposed in this paper is developed with the goal of implementing fast and high-precision cloud and cloud shadow detection, and it will be applied to the land cover remote sensing monitoring project on a national scale. version:2
arxiv-1606-06871 | A Comprehensive Study of Deep Bidirectional LSTM RNNs for Acoustic Modeling in Speech Recognition | http://arxiv.org/abs/1606.06871 | id:1606.06871 author:Albert Zeyer, Patrick Doetsch, Paul Voigtlaender, Ralf Schlüter, Hermann Ney category:cs.NE cs.CL cs.LG cs.SD  published:2016-06-22 summary:We present a comprehensive study of deep bidirectional long short-term memory (LSTM) recurrent neural network (RNN) based acoustic models for automatic speech recognition (ASR). We study the effect of size and depth and train models of up to 8 layers. We investigate the training aspect and study different variants of optimization methods, batching, truncated backpropagation, different regularization techniques such as dropout and $L_2$ regularization, and different gradient clipping variants. The major part of the experimental analysis was performed on the Quaero corpus. Additional experiments also were performed on the Switchboard corpus. Our best LSTM model has a relative improvement in word error rate of over 14\% compared to our best feed-forward neural network (FFNN) baseline on the Quaero task. On this task, we get our best result with an 8 layer bidirectional LSTM and we show that a pretraining scheme with layer-wise construction helps for deep LSTMs. Finally we compare the training calculation time of many of the presented experiments in relation with recognition performance. All the experiments were done with RETURNN, the RWTH extensible training framework for universal recurrent neural networks in combination with RASR, the RWTH ASR toolkit. version:1
arxiv-1606-06864 | A Curriculum Learning Method for Improved Noise Robustness in Automatic Speech Recognition | http://arxiv.org/abs/1606.06864 | id:1606.06864 author:Stefan Braun, Daniel Neil, Shih-Chii Liu category:cs.CL cs.LG cs.SD  published:2016-06-22 summary:The performance of automatic speech recognition systems under noisy environments still leaves room for improvement. Speech enhancement or feature enhancement techniques for increasing noise robustness of these systems usually add components to the recognition system that need careful optimization. In this work, we propose the use of a relatively simple training method called accordion annealing which is inspired by curriculum learning. It uses a multi-stage training schedule where samples at SNR values as low as -15 dB are first added and subsequently samples at increasing higher SNR values are gradually added up to an SNR value of 50 dB. Because of the necessity of providing many different SNR valued samples, we additionally use a method called per-epoch noise mixing (PEM) to generate the noisy training samples online during training. Both the accordion annealing and the PEM methods are used during training of a recurrent neural network which is then evaluated on three databases. Accordion annealing improves the relative average accuracy of this network by 2 % when tested in a high SNR range (50 dB to 0 dB) and by 42 % in a low SNR range(-20 dB to 0 dB) on the Grid Corpus database. version:1
arxiv-1606-06854 | Model-based Deep Hand Pose Estimation | http://arxiv.org/abs/1606.06854 | id:1606.06854 author:Xingyi Zhou, Qingfu Wan, Wei Zhang, Xiangyang Xue, Yichen Wei category:cs.CV  published:2016-06-22 summary:Previous learning based hand pose estimation methods does not fully exploit the prior information in hand model geometry. Instead, they usually rely a separate model fitting step to generate valid hand poses. Such a post processing is inconvenient and sub-optimal. In this work, we propose a model based deep learning approach that adopts a forward kinematics based layer to ensure the geometric validity of estimated poses. For the first time, we show that embedding such a non-linear generative process in deep learning is feasible for hand pose estimation. Our approach is verified on challenging public datasets and achieves state-of-the-art performance. version:1
arxiv-1606-06820 | Divergent Discourse Between Protests and Counter-Protests: #BlackLivesMatter and #AllLivesMatter | http://arxiv.org/abs/1606.06820 | id:1606.06820 author:Ryan Gallagher, Andrew Reagan, Christopher M. Danforth, Peter Sheridan Dodds category:cs.CL cs.CY cs.SI  published:2016-06-22 summary:Since the shooting of Black teenager Michael Brown by White police officer Darren Wison in Ferguson, Missouri, the protest hashtag #BlackLivesMatter has amplified critiques of extrajudicial killings of Black Americans. In response to #BlackLivesMatter, other Twitter users have adopted #AllLivesMatter, a counter-protest hashtag whose content argues that equal attention should be given to all lives regardless of race. Through a multi-level analysis, we study how these protests and counter-protests diverge by quantifying aspects of their discourse. In particular, we introduce methodology that not only quantifies these divergences, but also reveals whether they are from widespread discussion or a few popular retweets within these groups. We find that #BlackLivesMatter exhibits many informationally rich conversations, while those within #AllLivesMatter are more muted and susceptible to hijacking. We also show that the discussion within #BlackLivesMatter is more likely to center around the deaths of Black Americans, while that of #AllLivesMatter is more likely to sympathize with the lives of police officers and express politically conservative views. version:1
arxiv-1606-06818 | Evolutionary computation for multicomponent problems: opportunities and future directions | http://arxiv.org/abs/1606.06818 | id:1606.06818 author:Mohammad Reza Bonyadi, Zbigniew Michalewicz, Frank Neumann, Markus Wagner category:cs.NE  published:2016-06-22 summary:Over the past 30 years many researchers in the field of evolutionary computation have put a lot of effort to introduce various approaches for solving hard problems. Most of these problems have been inspired by major industries so that solving them, by providing either optimal or near optimal solution, was of major significance. Indeed, this was a very promising trajectory as advances in these problem-solving approaches could result in adding values to major industries. In this paper we revisit this trajectory to find out whether the attempts that started three decades ago are still aligned with the same goal, as complexities of real-world problems increased significantly. We present some examples of modern real-world problems, discuss why they might be difficult to solve, and whether there is any mismatch between these examples and the problems that are investigated in the evolutionary computation area. version:1
arxiv-1606-05409 | Sense Embedding Learning for Word Sense Induction | http://arxiv.org/abs/1606.05409 | id:1606.05409 author:Linfeng Song, Zhiguo Wang, Haitao Mi, Daniel Gildea category:cs.CL  published:2016-06-17 summary:Conventional word sense induction (WSI) methods usually represent each instance with discrete linguistic features or cooccurrence features, and train a model for each polysemous word individually. In this work, we propose to learn sense embeddings for the WSI task. In the training stage, our method induces several sense centroids (embedding) for each polysemous word. In the testing stage, our method represents each instance as a contextual vector, and induces its sense by finding the nearest sense centroid in the embedding space. The advantages of our method are (1) distributed sense vectors are taken as the knowledge representations which are trained discriminatively, and usually have better performance than traditional count-based distributional models, and (2) a general model for the whole vocabulary is jointly trained to induce sense centroids under the mutlitask learning framework. Evaluated on SemEval-2010 WSI dataset, our method outperforms all participants and most of the recent state-of-the-art methods. We further verify the two advantages by comparing with carefully designed baselines. version:2
arxiv-1606-06811 | Where to Focus: Query Adaptive Matching for Instance Retrieval Using Convolutional Feature Maps | http://arxiv.org/abs/1606.06811 | id:1606.06811 author:Jiewei Cao, Lingqiao Liu, Peng Wang, Zi Huang, Chunhua Shen, Heng Tao Shen category:cs.CV H.3.3; I.4.8  published:2016-06-22 summary:Instance retrieval requires one to search for images that contain a particular object within a large corpus. Recent studies show that using image features generated by pooling convolutional layer feature maps (CFMs) of a pretrained convolutional neural network (CNN) leads to promising performance for this task. However, due to the global pooling strategy adopted in those works, the generated image feature is less robust to image clutter and tends to be contaminated by the irrelevant image patterns. In this article, we alleviate this drawback by proposing a novel reranking algorithm using CFMs to refine the retrieval result obtained by existing methods. Our key idea, called query adaptive matching (QAM), is to first represent the CFMs of each image by a set of base regions which can be freely combined into larger regions-of-interest. Then the similarity between the query and a candidate image is measured by the best similarity score that can be attained by comparing the query feature and the feature pooled from a combined region. We show that the above procedure can be cast as an optimization problem and it can be solved efficiently with an off-the-shelf solver. Besides this general framework, we also propose two practical ways to create the base regions. One is based on the property of the CFM and the other one is based on a multi-scale spatial pyramid scheme. Through extensive experiments, we show that our reranking approaches bring substantial performance improvement and by applying them we can outperform the state of the art on several instance retrieval benchmarks. version:1
arxiv-1606-06793 | Scalable Support Vector Machine for Semi-supervised Learning | http://arxiv.org/abs/1606.06793 | id:1606.06793 author:Trung Le, Khanh Nguyen, Van Nguyen, Vu Nguyen, Dinh Phung category:cs.LG  published:2016-06-22 summary:Owing to the prevalence of unlabeled data, semisupervised learning has recently drawn significant attention and has found applicable in many real-world applications. In this paper, we present the so-called Graph-based Semi-supervised Support Vector Machine (gS3VM), a method that leverages the excellent generalization ability of kernel-based method with the geometrical and distributive information carried in a spectral graph for semi-supervised learning purpose. The proposed gS3VM can be solved directly in the primal form using the Stochastic Gradient Descent method with the ideal convergence rate $O(\frac{1}{T})$. Besides, our gS3VM allows the combinations of a wide spectrum of loss functions (e.g., Hinge, smooth Hinge, Logistic, L1, and {\epsilon}-insensitive) and smoothness functions (i.e., $l_p(t) = t ^p$ with $p\ge1$). We note that the well-known Laplacian Support Vector Machine falls into the spectrum of gS3VM corresponding to the combination of the Hinge loss and the smoothness function $l_2(.)$. We further validate our proposed method on several benchmark datasets to demonstrate that gS3VM is appropriate for the large-scale datasets since it is optimal in memory used and yields superior classification accuracy whilst simultaneously achieving a significant computation speedup in comparison with the state-of-the-art baselines. version:1
arxiv-1606-06771 | A Stackelberg Game Perspective on the Conflict Between Machine Learning and Data Obfuscation | http://arxiv.org/abs/1606.06771 | id:1606.06771 author:Jeffrey Pawlick, Quanyan Zhu category:cs.CR cs.LG  published:2016-06-21 summary:Data is the new oil; this refrain is repeated extensively in the age of internet tracking, machine learning, and data analytics. Social network analysis, cookie-based advertising, and government surveillance are all evidence of the use of data for commercial and national interests. Public pressure, however, is mounting for the protection of privacy. Frameworks such as differential privacy offer machine learning algorithms methods to guarantee limits to information disclosure, but they are seldom implemented. Recently, however, developers have made significant efforts to undermine tracking through obfuscation tools that hide user characteristics in a sea of noise. These services highlight an emerging clash between tracking and data obfuscation. In this paper, we conceptualize this conflict through a dynamic game between users and a machine learning algorithm that uses empirical risk minimization. First, a machine learner declares a privacy protection level, and then users respond by choosing their own perturbation amounts. We study the interaction between the users and the learner using a Stackelberg game. The utility functions quantify accuracy using expected loss and privacy in terms of the bounds of differential privacy. In equilibrium, we find selfish users tend to cause significant utility loss to trackers by perturbing heavily, in a phenomenon reminiscent of public good games. Trackers, however, can improve the balance by proactively perturbing the data themselves. While other work in this area has studied privacy markets and mechanism design for truthful reporting of user information, we take a different viewpoint by considering both user and learner perturbation. version:1
arxiv-1606-05611 | Data-driven HR - Résumé Analysis Based on Natural Language Processing and Machine Learning | http://arxiv.org/abs/1606.05611 | id:1606.05611 author:Tim Zimmermann, Leo Kotschenreuther, Karsten Schmidt category:cs.CL cs.AI  published:2016-06-17 summary:Recruiters usually spend less than a minute looking at each r\'esum\'e when deciding whether it's worth continuing the recruitment process with the candidate. Recruiters focus on keywords, and it's almost impossible to guarantee a fair process of candidate selection. The main scope of this paper is to tackle this issue by introducing a data-driven approach that shows how to process r\'esum\'es automatically and give recruiters more time to only examine promising candidates. Furthermore, we show how to leverage Machine Learning and Natural Language Processing in order to extract all required information from the r\'esum\'es. Once the information is extracted, a ranking score is calculated. The score describes how well the candidates fit based on their education, work experience and skills. Later this paper illustrates a prototype application that shows how this novel approach can increase the productivity of recruiters. The application enables them to filter and rank candidates based on predefined job descriptions. Guided by the ranking, recruiters can get deeper insights from candidate profiles and validate why and how the application ranked them. This application shows how to improve the hiring process by giving an unbiased hiring decision support. version:2
arxiv-1606-06737 | Critical Behavior from Deep Dynamics: A Hidden Dimension in Natural Language | http://arxiv.org/abs/1606.06737 | id:1606.06737 author:Henry Lin, Max Tegmark category:cond-mat.dis-nn cs.CL  published:2016-06-21 summary:We show that although many important data sequences - from texts in different languages to melodies and genomes - exhibit critical behavior, where the mutual information between symbols decays roughly like a power law with separation, Markov processes generically do not, their mutual information instead decaying exponentially. This explains why natural languages are very poorly approximated by Markov processes. We also present a broad class of models that naturally produce critical behavior. They all involve deep dynamics of a recursive nature, as can be implemented by tree-like or recurrent deep neural networks. This model class captures the essence of recursive universal grammar as well as recursive self-reproduction in physical phenomena such as turbulence and cosmological inflation. We derive an analytic formula for the asymptotic power law and elucidate our results in a statistical physics context: 1-dimensional models (such as a Markov models) will always fail to model natural language, because they cannot exhibit phase transitions, whereas models with one or more "hidden" dimensions representing levels of abstraction or scale can potentially succeed. version:1
arxiv-1606-06724 | Tagger: Deep Unsupervised Perceptual Grouping | http://arxiv.org/abs/1606.06724 | id:1606.06724 author:Klaus Greff, Antti Rasmus, Mathias Berglund, Tele Hotloo Hao, Jürgen Schmidhuber, Harri Valpola category:cs.CV cs.NE 97R40  published:2016-06-21 summary:We present a framework for efficient perceptual inference that explicitly reasons about the segmentation of its inputs and features. Rather than being trained for any specific segmentation, our framework learns the grouping process in an unsupervised manner or alongside any supervised task. By enriching the representations of a neural network, we enable it to group the representations of different objects in an iterative manner. By allowing the system to amortize the iterative inference of the groupings, we achieve very fast convergence. In contrast to many other recently proposed methods for addressing multi-object scenes, our system does not assume the inputs to be images and can therefore directly handle other modalities. For multi-digit classification of very cluttered images that require texture segmentation, our method offers improved classification performance over convolutional networks despite being fully connected. Furthermore, we observe that our system greatly improves on the semi-supervised result of a baseline Ladder network on our dataset, indicating that segmentation can also improve sample efficiency. version:1
arxiv-1606-06710 | Correlation-based Intrinsic Evaluation of Word Vector Representations | http://arxiv.org/abs/1606.06710 | id:1606.06710 author:Yulia Tsvetkov, Manaal Faruqui, Chris Dyer category:cs.CL  published:2016-06-21 summary:We introduce QVEC-CCA--an intrinsic evaluation metric for word vector representations based on correlations of learned vectors with features extracted from linguistic resources. We show that QVEC-CCA scores are an effective proxy for a range of extrinsic semantic and syntactic tasks. We also show that the proposed evaluation obtains higher and more consistent correlations with downstream tasks, compared to existing approaches to intrinsic evaluation of word vectors that are based on word similarity. version:1
arxiv-1606-05685 | Using Visual Analytics to Interpret Predictive Machine Learning Models | http://arxiv.org/abs/1606.05685 | id:1606.05685 author:Josua Krause, Adam Perer, Enrico Bertini category:stat.ML cs.LG  published:2016-06-17 summary:It is commonly believed that increasing the interpretability of a machine learning model may decrease its predictive power. However, inspecting input-output relationships of those models using visual analytics, while treating them as black-box, can help to understand the reasoning behind outcomes without sacrificing predictive quality. We identify a space of possible solutions and provide two examples of where such techniques have been successfully used in practice. version:2
arxiv-1606-06681 | Crowdsourcing scoring of immunohistochemistry images: Evaluating Performance of the Crowd and an Automated Computational Method | http://arxiv.org/abs/1606.06681 | id:1606.06681 author:Humayun Irshad, Eun-Yeong Oh, Daniel Schmolze, Liza M Quintana, Laura Collins, Rulla M. Tamimi, Andrew H. Beck category:cs.CV  published:2016-06-21 summary:The assessment of protein expression in immunohistochemistry (IHC) images provides important diagnostic, prognostic and predictive information for guiding cancer diagnosis and therapy. Manual scoring of IHC images represents a logistical challenge, as the process is labor intensive and time consuming. Since the last decade, computational methods have been developed to enable the application of quantitative methods for the analysis and interpretation of protein expression in IHC images. These methods have not yet replaced manual scoring for the assessment of IHC in the majority of diagnostic laboratories and in many large-scale research studies. An alternative approach is crowdsourcing the quantification of IHC images to an undefined crowd. The aim of this study is to quantify IHC images for labeling of ER status with two different crowdsourcing approaches, image labeling and nuclei labeling, and compare their performance with automated methods. Crowdsourcing-derived scores obtained greater concordance with the pathologist interpretations for both image labeling and nuclei labeling tasks (83% and 87%), as compared to the pathologist concordance achieved by the automated method (81%) on 5,483 TMA images from 1,909 breast cancer patients. This analysis shows that crowdsourcing the scoring of protein expression in IHC images is a promising new approach for large scale cancer molecular pathology studies. version:1
arxiv-1606-06653 | Tracking Time-Vertex Propagation using Dynamic Graph Wavelets | http://arxiv.org/abs/1606.06653 | id:1606.06653 author:Francesco Grassi, Nathanael Perraudin, Benjamin Ricaud category:cs.LG  published:2016-06-21 summary:Graph Signal Processing generalizes classical signal processing to signal or data indexed by the vertices of a weighted graph. So far, the research efforts have been focused on static graph signals. However numerous applications involve graph signals evolving in time, such as spreading or propagation of waves on a network. The analysis of this type of data requires a new set of methods that fully takes into account the time and graph dimensions. We propose a novel class of wavelet frames named Dynamic Graph Wavelets, whose time-vertex evolution follows a dynamic process. We demonstrate that this set of functions can be combined with sparsity based approaches such as compressive sensing to reveal information on the dynamic processes occurring on a graph. Experiments on real seismological data show the efficiency of the technique, allowing to estimate the epicenter of earthquake events recorded by a seismic network. version:1
arxiv-1606-06650 | 3D U-Net: Learning Dense Volumetric Segmentation from Sparse Annotation | http://arxiv.org/abs/1606.06650 | id:1606.06650 author:Özgün Çiçek, Ahmed Abdulkadir, Soeren S. Lienkamp, Thomas Brox, Olaf Ronneberger category:cs.CV  published:2016-06-21 summary:This paper introduces a network for volumetric segmentation that learns from sparsely annotated volumetric images. We outline two attractive use cases of this method: (1) In a semi-automated setup, the user annotates some slices in the volume to be segmented. The network learns from these sparse annotations and provides a dense 3D segmentation. (2) In a fully-automated setup, we assume that a representative, sparsely annotated training set exists. Trained on this data set, the network densely segments new volumetric images. The proposed network extends the previous u-net architecture from Ronneberger et al. by replacing all 2D operations with their 3D counterparts. The implementation performs on-the-fly elastic deformations for efficient data augmentation during training. It is trained end-to-end from scratch, i.e., no pre-trained network is required. We test the performance of the proposed method on a complex, highly variable 3D structure, the Xenopus kidney, and achieve good results for both use cases. version:1
arxiv-1606-06640 | Neural Morphological Tagging from Characters for Morphologically Rich Languages | http://arxiv.org/abs/1606.06640 | id:1606.06640 author:Georg Heigold, Guenter Neumann, Josef van Genabith category:cs.CL  published:2016-06-21 summary:This paper investigates neural character-based morphological tagging for languages with complex morphology and large tag sets. We systematically explore a variety of neural architectures (DNN, CNN, CNNHighway, LSTM, BLSTM) to obtain character-based word vectors combined with bidirectional LSTMs to model across-word context in an end-to-end setting. We explore supplementary use of word-based vectors trained on large amounts of unlabeled data. Our experiments for morphological tagging suggest that for "simple" model configurations, the choice of the network architecture (CNN vs. CNNHighway vs. LSTM vs. BLSTM) or the augmentation with pre-trained word embeddings can be important and clearly impact the accuracy. Increasing the model capacity by adding depth, for example, and carefully optimizing the neural networks can lead to substantial improvements, and the differences in accuracy (but not training time) become much smaller or even negligible. Overall, our best morphological taggers for German and Czech outperform the best results reported in the literature by a large margin. version:1
arxiv-1606-06630 | On Multiplicative Integration with Recurrent Neural Networks | http://arxiv.org/abs/1606.06630 | id:1606.06630 author:Yuhuai Wu, Saizheng Zhang, Ying Zhang, Yoshua Bengio, Ruslan Salakhutdinov category:cs.LG  published:2016-06-21 summary:We introduce a general and simple structural design called Multiplicative Integration (MI) to improve recurrent neural networks (RNNs). MI changes the way in which information from difference sources flows and is integrated in the computational building block of an RNN, while introducing almost no extra parameters. The new structure can be easily embedded into many popular RNN models, including LSTMs and GRUs. We empirically analyze its learning behaviour and conduct evaluations on several tasks using different RNN models. Our experimental results demonstrate that Multiplicative Integration can provide a substantial performance boost over many of the existing RNN models. version:1
arxiv-1606-06623 | An empirical study on large scale text classification with skip-gram embeddings | http://arxiv.org/abs/1606.06623 | id:1606.06623 author:Georgios Balikas, Massih-Reza Amini category:cs.CL cs.IR  published:2016-06-21 summary:We investigate the integration of word embeddings as classification features in the setting of large scale text classification. Such representations have been used in a plethora of tasks, however their application in classification scenarios with thousands of classes has not been extensively researched, partially due to hardware limitations. In this work, we examine efficient composition functions to obtain document-level from word-level embeddings and we subsequently investigate their combination with the traditional one-hot-encoding representations. By presenting empirical evidence on large, multi-class, multi-label classification problems, we demonstrate the efficiency and the performance benefits of this combination. version:1
arxiv-1606-06622 | Question Relevance in VQA: Identifying Non-Visual And False-Premise Questions | http://arxiv.org/abs/1606.06622 | id:1606.06622 author:Arijit Ray, Gordon Christie, Mohit Bansal, Dhruv Batra, Devi Parikh category:cs.CV cs.CL cs.LG  published:2016-06-21 summary:Visual Question Answering (VQA) is the task of answering natural-language questions about images. We introduce the novel problem of determining the relevance of questions to images in VQA. Current VQA models do not reason about whether a question is even related to the given image (e.g. What is the capital of Argentina?) or if it requires information from external resources to answer correctly. This can break the continuity of a dialogue in human-machine interaction. Our approaches for determining relevance are composed of two stages. Given an image and a question, (1) we first determine whether the question is visual or not, (2) if visual, we determine whether the question is relevant to the given image or not. Our approaches, based on LSTM-RNNs, VQA model uncertainty, and caption-question similarity, are able to outperform strong baselines on both relevance tasks. We also present human studies showing that VQA models augmented with such question relevance reasoning are perceived as more intelligent, reasonable, and human-like. version:1
arxiv-1606-06588 | ML-based tactile sensor calibration: A universal approach | http://arxiv.org/abs/1606.06588 | id:1606.06588 author:Maximilian Karl, Artur Lohrer, Dhananjay Shah, Frederik Diehl, Max Fiedler, Saahil Ognawala, Justin Bayer, Patrick van der Smagt category:cs.RO cs.LG  published:2016-06-21 summary:We study the responses of two tactile sensors, the fingertip sensor from the iCub and the BioTac under different external stimuli. The question of interest is to which degree both sensors i) allow the estimation of force exerted on the sensor and ii) enable the recognition of differing degrees of curvature. Making use of a force controlled linear motor affecting the tactile sensors we acquire several high-quality data sets allowing the study of both sensors under exactly the same conditions. We also examined the structure of the representation of tactile stimuli in the recorded tactile sensor data using t-SNE embeddings. The experiments show that both the iCub and the BioTac excel in different settings. version:1
arxiv-1606-06582 | Augmenting Supervised Neural Networks with Unsupervised Objectives for Large-scale Image Classification | http://arxiv.org/abs/1606.06582 | id:1606.06582 author:Yuting Zhang, Kibok Lee, Honglak Lee category:cs.LG cs.CV  published:2016-06-21 summary:Unsupervised learning and supervised learning are key research topics in deep learning. However, as high-capacity supervised neural networks trained with a large amount of labels have achieved remarkable success in many computer vision tasks, the availability of large-scale labeled images reduced the significance of unsupervised learning. Inspired by the recent trend toward revisiting the importance of unsupervised learning, we investigate joint supervised and unsupervised learning in a large-scale setting by augmenting existing neural networks with decoding pathways for reconstruction. First, we demonstrate that the intermediate activations of pretrained large-scale classification networks preserve almost all the information of input images except a portion of local spatial details. Then, by end-to-end training of the entire augmented architecture with the reconstructive objective, we show improvement of the network performance for supervised tasks. We evaluate several variants of autoencoders, including the recently proposed "what-where" autoencoder that uses the encoder pooling switches, to study the importance of the architecture design. Taking the 16-layer VGGNet trained under the ImageNet ILSVRC 2012 protocol as a strong baseline for image classification, our methods improve the validation-set accuracy by a noticeable margin. version:1
arxiv-1606-06565 | Concrete Problems in AI Safety | http://arxiv.org/abs/1606.06565 | id:1606.06565 author:Dario Amodei, Chris Olah, Jacob Steinhardt, Paul Christiano, John Schulman, Dan Mané category:cs.AI cs.LG  published:2016-06-21 summary:Rapid progress in machine learning and artificial intelligence (AI) has brought increasing attention to the potential impacts of AI technologies on society. In this paper we discuss one such potential impact: the problem of accidents in machine learning systems, defined as unintended and harmful behavior that may emerge from poor design of real-world AI systems. We present a list of five practical research problems related to accident risk, categorized according to whether the problem originates from having the wrong objective function ("avoiding side effects" and "avoiding reward hacking"), an objective function that is too expensive to evaluate frequently ("scalable supervision"), or undesirable behavior during the learning process ("safe exploration" and "distributional shift"). We review previous work in these areas as well as suggesting research directions with a focus on relevance to cutting-edge AI systems. Finally, we consider the high-level question of how to think most productively about the safety of forward-looking applications of AI. version:1
arxiv-1606-06564 | An artificial neural network to find correlation patterns among an arbitrary number of variables | http://arxiv.org/abs/1606.06564 | id:1606.06564 author:Alessandro Fontana category:cs.LG q-bio.NC stat.ML  published:2016-06-21 summary:Methods to find correlation among variables are of interest to many disciplines, including statistics, machine learning, (big) data mining and neurosciences. Parameters that measure correlation between two variables are of limited utility when used with multiple variables. In this work, I propose a simple criterion to measure correlation among an arbitrary number of variables, based on a data set. The central idea is to i) design a function of the variables that can take different forms depending on a set of parameters, ii) calculate the difference between a statistics associated to the function computed on the data set and the same statistics computed on a randomised version of the data set, called "scrambled" data set, and iii) optimise the parameters to maximise this difference. Many such functions can be organised in layers, which can in turn be stacked one on top of the other, forming a neural network. The function parameters are searched with an enhanced genetic algortihm called POET and the resulting method is tested on a cancer gene data set. The method may have potential implications for some issues that affect the field of neural networks, such as overfitting, the need to process huge amounts of data for training and the presence of "adversarial examples". version:1
arxiv-1606-06539 | Drawing and Recognizing Chinese Characters with Recurrent Neural Network | http://arxiv.org/abs/1606.06539 | id:1606.06539 author:Xu-Yao Zhang, Fei Yin, Yan-Ming Zhang, Cheng-Lin Liu, Yoshua Bengio category:cs.CV  published:2016-06-21 summary:Recent deep learning based approaches have achieved great success on handwriting recognition. Chinese characters are among the most widely adopted writing systems in the world. Previous research has mainly focused on recognizing handwritten Chinese characters. However, recognition is only one aspect for understanding a language, another challenging and interesting task is to teach a machine to automatically write (pictographic) Chinese characters. In this paper, we propose a framework by using the recurrent neural network (RNN) as both a discriminative model for recognizing Chinese characters and a generative model for drawing (generating) Chinese characters. To recognize Chinese characters, previous methods usually adopt the convolutional neural network (CNN) models which require transforming the online handwriting trajectory into image-like representations. Instead, our RNN based approach is an end-to-end system which directly deals with the sequential structure and does not require any domain-specific knowledge. With the RNN system (combining an LSTM and GRU), state-of-the-art performance can be achieved on the ICDAR-2013 competition database. Furthermore, under the RNN framework, a conditional generative model with character embedding is proposed for automatically drawing recognizable Chinese characters. The generated characters (in vector format) are human-readable and also can be recognized by the discriminative RNN model with high accuracy. Experimental results verify the effectiveness of using RNNs as both generative and discriminative models for the tasks of drawing and recognizing Chinese characters. version:1
arxiv-1606-06472 | DeepWriter: A Multi-Stream Deep CNN for Text-independent Writer Identification | http://arxiv.org/abs/1606.06472 | id:1606.06472 author:Linjie Xing, Yu Qiao category:cs.CV  published:2016-06-21 summary:Text-independent writer identification is challenging due to the huge variation of written contents and the ambiguous written styles of different writers. This paper proposes DeepWriter, a deep multi-stream CNN to learn deep powerful representation for recognizing writers. DeepWriter takes local handwritten patches as input and is trained with softmax classification loss. The main contributions are: 1) we design and optimize multi-stream structure for writer identification task; 2) we introduce data augmentation learning to enhance the performance of DeepWriter; 3) we introduce a patch scanning strategy to handle text image with different lengths. In addition, we find that different languages such as English and Chinese may share common features for writer identification, and joint training can yield better performance. Experimental results on IAM and HWDB datasets show that our models achieve high identification accuracy: 99.01% on 301 writers and 97.03% on 657 writers with one English sentence input, 93.85% on 300 writers with one Chinese character input, which outperform previous methods with a large margin. Moreover, our models obtain accuracy of 98.01% on 301 writers with only 4 English alphabets as input. version:1
arxiv-1606-06461 | Neighborhood Mixture Model for Knowledge Base Completion | http://arxiv.org/abs/1606.06461 | id:1606.06461 author:Dat Quoc Nguyen, Kairit Sirts, Lizhen Qu, Mark Johnson category:cs.CL cs.AI  published:2016-06-21 summary:Knowledge bases are useful resources for many natural language processing tasks, however, they are far from complete. In this paper, we define a novel entity representation as a mixture of its neighborhood in the knowledge base and apply this technique on TransE-a well-known embedding model for knowledge base completion. Experimental results show that the neighborhood information significantly helps to improve the results of the TransE, leading to better performance than obtained by other state-of-the-art embedding models on three benchmark datasets for triple classification, entity prediction and relation prediction tasks. version:1
arxiv-1606-06443 | An active efficient coding model of the optokinetic nystagmus | http://arxiv.org/abs/1606.06443 | id:1606.06443 author:Chong Zhang, Jochen Triesch, Bertram E. Shi category:q-bio.NC cs.NE  published:2016-06-21 summary:Optokinetic nystagmus (OKN) is an involuntary eye movement responsible for stabilizing retinal images in the presence of relative motion between an observer and the environment. Fully understanding the development of optokinetic nystagmus requires a neurally plausible computational model that accounts for the neural development and the behavior. To date, work in this area has been limited. We propose a neurally plausible framework for the joint development of disparity and motion tuning in the visual cortex, the optokinetic and vergence eye movements. This framework models the joint emergence of both perception and behavior, and accounts for the importance of the development of normal vergence control and binocular vision in achieving normal monocular OKN (mOKN) behaviors. Because the model includes behavior, we can simulate the same perturbations as performed in past experiments, such as artificially induced strabismus. The proposed model agrees both qualitatively and quantitatively with a number of findings from the literature on both binocular vision as well as the optokinetic reflex. Finally, our model also makes quantitative predictions about the OKN behavior using the same methods used to characterize the OKN in the experimental literature. version:1
arxiv-1606-06439 | Social-sparsity brain decoders: faster spatial sparsity | http://arxiv.org/abs/1606.06439 | id:1606.06439 author:Gaël Varoquaux, Matthieu Kowalski, Bertrand Thirion category:stat.ML cs.CV q-bio.NC  published:2016-06-21 summary:Spatially-sparse predictors are good models for brain decoding: they give accurate predictions and their weight maps are interpretable as they focus on a small number of regions. However, the state of the art, based on total variation or graph-net, is computationally costly. Here we introduce sparsity in the local neighborhood of each voxel with social-sparsity, a structured shrinkage operator. We find that, on brain imaging classification problems, social-sparsity performs almost as well as total-variation models and better than graph-net, for a fraction of the computational cost. It also very clearly outlines predictive regions. We give details of the model and the algorithm. version:1
arxiv-1606-06437 | Efficient 2D and 3D Facade Segmentation using Auto-Context | http://arxiv.org/abs/1606.06437 | id:1606.06437 author:Raghudeep Gadde, Varun Jampani, Renaud Marlet, Peter V. Gehler category:cs.CV  published:2016-06-21 summary:This paper introduces a fast and efficient segmentation technique for 2D images and 3D point clouds of building facades. Facades of buildings are highly structured and consequently most methods that have been proposed for this problem aim to make use of this strong prior information. Contrary to most prior work, we are describing a system that is almost domain independent and consists of standard segmentation methods. We train a sequence of boosted decision trees using auto-context features. This is learned using stacked generalization. We find that this technique performs better, or comparable with all previous published methods and present empirical results on all available 2D and 3D facade benchmark datasets. The proposed method is simple to implement, easy to extend, and very efficient at test-time inference. version:1
arxiv-1606-06424 | A Novel Framework to Expedite Systematic Reviews by Automatically Building Information Extraction Training Corpora | http://arxiv.org/abs/1606.06424 | id:1606.06424 author:Tanmay Basu, Shraman Kumar, Abhishek Kalyan, Priyanka Jayaswal, Pawan Goyal, Stephen Pettifer, Siddhartha R. Jonnalagadda category:cs.IR cs.CL cs.LG  published:2016-06-21 summary:A systematic review identifies and collates various clinical studies and compares data elements and results in order to provide an evidence based answer for a particular clinical question. The process is manual and involves lot of time. A tool to automate this process is lacking. The aim of this work is to develop a framework using natural language processing and machine learning to build information extraction algorithms to identify data elements in a new primary publication, without having to go through the expensive task of manual annotation to build gold standards for each data element type. The system is developed in two stages. Initially, it uses information contained in existing systematic reviews to identify the sentences from the PDF files of the included references that contain specific data elements of interest using a modified Jaccard similarity measure. These sentences have been treated as labeled data.A Support Vector Machine (SVM) classifier is trained on this labeled data to extract data elements of interests from a new article. We conducted experiments on Cochrane Database systematic reviews related to congestive heart failure using inclusion criteria as an example data element. The empirical results show that the proposed system automatically identifies sentences containing the data element of interest with a high recall (93.75%) and reasonable precision (27.05% - which means the reviewers have to read only 3.7 sentences on average). The empirical results suggest that the tool is retrieving valuable information from the reference articles, even when it is time-consuming to identify them manually. Thus we hope that the tool will be useful for automatic data extraction from biomedical research publications. The future scope of this work is to generalize this information framework for all types of systematic reviews. version:1
arxiv-1606-06406 | Incremental Parsing with Minimal Features Using Bi-Directional LSTM | http://arxiv.org/abs/1606.06406 | id:1606.06406 author:James Cross, Liang Huang category:cs.CL  published:2016-06-21 summary:Recently, neural network approaches for parsing have largely automated the combination of individual features, but still rely on (often a larger number of) atomic features created from human linguistic intuition, and potentially omitting important global context. To further reduce feature engineering to the bare minimum, we use bi-directional LSTM sentence representations to model a parser state with only three sentence positions, which automatically identifies important aspects of the entire sentence. This model achieves state-of-the-art results among greedy dependency parsers for English. We also introduce a novel transition system for constituency parsing which does not require binarization, and together with the above architecture, achieves state-of-the-art results among greedy parsers for both English and Chinese. version:1
arxiv-1606-05854 | Full-Time Supervision based Bidirectional RNN for Factoid Question Answering | http://arxiv.org/abs/1606.05854 | id:1606.05854 author:Dong Xu, Wu-Jun Li category:cs.CL  published:2016-06-19 summary:Recently, bidirectional recurrent neural network (BRNN) has been widely used for question answering (QA) tasks with promising performance. However, most existing BRNN models extract the information of questions and answers by directly using a pooling operation to generate the representation for loss or similarity calculation. Hence, these existing models don't put supervision (loss or similarity calculation) at every time step, which will lose some useful information. In this paper, we propose a novel BRNN model called full-time supervision based BRNN (FTS-BRNN), which can put supervision at every time step. Experiments on the factoid QA task show that our FTS-BRNN can outperform other baselines to achieve the state-of-the-art accuracy. version:2
arxiv-1606-06377 | Kernel-based Generative Learning in Distortion Feature Space | http://arxiv.org/abs/1606.06377 | id:1606.06377 author:Bo Tang, Paul M. Baggenstoss, Haibo He category:stat.ML cs.LG  published:2016-06-21 summary:This paper presents a novel kernel-based generative classifier which is defined in a distortion subspace using polynomial series expansion, named Kernel-Distortion (KD) classifier. An iterative kernel selection algorithm is developed to steadily improve classification performance by repeatedly removing and adding kernels. The experimental results on character recognition application not only show that the proposed generative classifier performs better than many existing classifiers, but also illustrate that it has different recognition capability compared to the state-of-the-art discriminative classifier - deep belief network. The recognition diversity indicates that a hybrid combination of the proposed generative classifier and the discriminative classifier could further improve the classification performance. Two hybrid combination methods, cascading and stacking, have been implemented to verify the diversity and the improvement of the proposed classifier. version:1
arxiv-1606-06369 | Contextual Weisfeiler-Lehman Graph Kernel For Malware Detection | http://arxiv.org/abs/1606.06369 | id:1606.06369 author:Annamalai Narayanan, Guozhu Meng, Liu Yang, Jinliang Liu, Lihui Chen category:cs.CR cs.LG  published:2016-06-21 summary:In this paper, we propose a novel graph kernel specifically to address a challenging problem in the field of cyber-security, namely, malware detection. Previous research has revealed the following: (1) Graph representations of programs are ideally suited for malware detection as they are robust against several attacks, (2) Besides capturing topological neighbourhoods (i.e., structural information) from these graphs it is important to capture the context under which the neighbourhoods are reachable to accurately detect malicious neighbourhoods. We observe that state-of-the-art graph kernels, such as Weisfeiler-Lehman kernel (WLK) capture the structural information well but fail to capture contextual information. To address this, we develop the Contextual Weisfeiler-Lehman kernel (CWLK) which is capable of capturing both these types of information. We show that for the malware detection problem, CWLK is more expressive and hence more accurate than WLK while maintaining comparable efficiency. Through our large-scale experiments with more than 50,000 real-world Android apps, we demonstrate that CWLK outperforms two state-of-the-art graph kernels (including WLK) and three malware detection techniques by more than 5.27% and 4.87% F-measure, respectively, while maintaining high efficiency. This high accuracy and efficiency make CWLK suitable for large-scale real-world malware detection. version:1
arxiv-1606-06366 | FSMJ: Feature Selection with Maximum Jensen-Shannon Divergence for Text Categorization | http://arxiv.org/abs/1606.06366 | id:1606.06366 author:Bo Tang, Haibo He category:stat.ML cs.LG  published:2016-06-20 summary:In this paper, we present a new wrapper feature selection approach based on Jensen-Shannon (JS) divergence, termed feature selection with maximum JS-divergence (FSMJ), for text categorization. Unlike most existing feature selection approaches, the proposed FSMJ approach is based on real-valued features which provide more information for discrimination than binary-valued features used in conventional approaches. We show that the FSMJ is a greedy approach and the JS-divergence monotonically increases when more features are selected. We conduct several experiments on real-life data sets, compared with the state-of-the-art feature selection approaches for text categorization. The superior performance of the proposed FSMJ approach demonstrates its effectiveness and further indicates its wide potential applications on data mining. version:1
arxiv-1606-06364 | Predicting Student Dropout in Higher Education | http://arxiv.org/abs/1606.06364 | id:1606.06364 author:Lovenoor Aulck, Nishant Velagapudi, Joshua Blumenstock, Jevin West category:stat.ML cs.CY  published:2016-06-20 summary:Each year, roughly 30% of first-year students at US baccalaureate institutions do not return for their second year and over $9 billion is spent educating these students. Yet, little quantitative research has analyzed the causes and possible remedies for student attrition. Here, we describe initial efforts to model student dropout using the largest known dataset on higher education attrition, which tracks over 32,500 students' demographics and transcript records at one of the nation's largest public universities. Our results highlight several early indicators of student attrition and show that dropout can be accurately predicted even when predictions are based on a single term of academic transcript data. These results highlight the potential for machine learning to have an impact on student retention and success while pointing to several promising directions for future work. version:1
arxiv-1606-06361 | A Probabilistic Generative Grammar for Semantic Parsing | http://arxiv.org/abs/1606.06361 | id:1606.06361 author:Abulhair Saparov, Tom M. Mitchell category:cs.CL cs.LG stat.ML  published:2016-06-20 summary:We present a framework that couples the syntax and semantics of natural language sentences in a generative model, in order to develop a semantic parser that jointly infers the syntactic, morphological, and semantic representations of a given sentence under the guidance of background knowledge. To generate a sentence in our framework, a semantic statement is first sampled from a prior, such as from a set of beliefs in a knowledge base. Given this semantic statement, a grammar probabilistically generates the output sentence. A joint semantic-syntactic parser is derived that returns the $k$-best semantic and syntactic parses for a given sentence. The semantic prior is flexible, and can be used to incorporate background knowledge during parsing, in ways unlike previous semantic parsing approaches. For example, semantic statements corresponding to beliefs in a knowledge base can be given higher prior probability, type-correct statements can be given somewhat lower probability, and beliefs outside the knowledge base can be given lower probability. The construction of our grammar invokes a novel application of hierarchical Dirichlet processes (HDPs), which in turn, requires a novel and efficient inference approach. We present experimental results showing, for a simple grammar, that our parser outperforms a state-of-the-art CCG semantic parser and scales to knowledge bases with millions of beliefs. version:1
arxiv-1606-06357 | Complex Embeddings for Simple Link Prediction | http://arxiv.org/abs/1606.06357 | id:1606.06357 author:Théo Trouillon, Johannes Welbl, Sebastian Riedel, Éric Gaussier, Guillaume Bouchard category:cs.AI cs.LG stat.ML  published:2016-06-20 summary:In statistical relational learning, the link prediction problem is key to automatically understand the structure of large knowledge bases. As in previous studies, we propose to solve this problem through latent factorization. However, here we make use of complex valued embeddings. The composition of complex embeddings can handle a large variety of binary relations, among them symmetric and antisymmetric relations. Compared to state-of-the-art models such as Neural Tensor Network and Holographic Embeddings, our approach based on complex embeddings is arguably simpler, as it only uses the Hermitian dot product, the complex counterpart of the standard dot product between real vectors. Our approach is scalable to large datasets as it remains linear in both space and time, while consistently outperforming alternative approaches on standard link prediction benchmarks. version:1
arxiv-1606-06354 | Multiple Instance Hyperspectral Target Characterization | http://arxiv.org/abs/1606.06354 | id:1606.06354 author:Alina Zare, Changzhe Jiao, Taylor Glenn category:cs.CV  published:2016-06-20 summary:In this paper, two methods for multiple instance target characterization, MI-SMF and MI-ACE, are presented. MI-SMF and MI-ACE estimate a discriminative target signature from imprecisely-labeled and mixed training data. In many applications, such as sub-pixel target detection in remotely-sensed hyperspectral imagery, accurate pixel-level labels on training data is often unavailable and infeasible to obtain. Furthermore, since sub-pixel targets are smaller in size than the resolution of a single pixel, training data is comprised only of mixed data points (in which target training points are mixtures of responses from both target and non-target classes). Results show improved, consistent performance over existing multiple instance concept learning methods on several hyperspectral sub-pixel target detection problems. version:1
arxiv-1606-06352 | Visualizing textual models with in-text and word-as-pixel highlighting | http://arxiv.org/abs/1606.06352 | id:1606.06352 author:Abram Handler, Su Lin Blodgett, Brendan O'Connor category:stat.ML cs.CL cs.LG  published:2016-06-20 summary:We explore two techniques which use color to make sense of statistical text models. One method uses in-text annotations to illustrate a model's view of particular tokens in particular documents. Another uses a high-level, "words-as-pixels" graphic to display an entire corpus. Together, these methods offer both zoomed-in and zoomed-out perspectives into a model's understanding of text. We show how these interconnected methods help diagnose a classifier's poor performance on Twitter slang, and make sense of a topic model on historical political texts. version:1
arxiv-1606-06343 | Twitter as a Source of Global Mobility Patterns for Social Good | http://arxiv.org/abs/1606.06343 | id:1606.06343 author:Mark Dredze, Manuel García-Herranz, Alex Rutherford, Gideon Mann category:cs.SI physics.soc-ph stat.ML  published:2016-06-20 summary:Data on human spatial distribution and movement is essential for understanding and analyzing social systems. However existing sources for this data are lacking in various ways; difficult to access, biased, have poor geographical or temporal resolution, or are significantly delayed. In this paper, we describe how geolocation data from Twitter can be used to estimate global mobility patterns and address these shortcomings. These findings will inform how this novel data source can be harnessed to address humanitarian and development efforts. version:1
arxiv-1606-06314 | Colorization for Image Compression | http://arxiv.org/abs/1606.06314 | id:1606.06314 author:Mohammad Haris Baig, Lorenzo Torresani category:cs.CV  published:2016-06-20 summary:In this work we focus on the problem of colorization for image compression. Since color information occupies a large proportion of the total storage size of an image, a method that can predict accurate color from its grayscale version can produce dramatic reduction in image file size. But colorization for compression poses several challenges. First, while colorization for artistic purposes simply involves predicting plausible chroma, colorization for compression requires generating output colors that are as close as possible to the ground truth. Second, many objects in the real world exhibit multiple possible colors. Thus, to disambiguate the colorization problem some additional information must be stored to reproduce the true colors with good accuracy. To account for the multimodal color distribution of objects we propose a deep tree-structured network that generates multiple color hypotheses for every pixel from a grayscale picture (as opposed to a single color produced by most prior colorization approaches). We show how to leverage the multimodal output of our model to reproduce with high fidelity the true colors of an image by storing very little additional information. In the experiments we show that our proposed method outperforms traditional JPEG color coding by a large margin, producing colors that are nearly indistinguishable from the ground truth at the storage cost of just a few hundred bytes for high-resolution pictures! version:1
arxiv-1606-06274 | A Data-Driven Approach for Semantic Role Labeling from Induced Grammar Structures in Language | http://arxiv.org/abs/1606.06274 | id:1606.06274 author:Vivek Datla, David Lin, Max Louwerse, Abhinav Vishnu category:cs.CL  published:2016-06-20 summary:Semantic roles play an important role in extracting knowledge from text. Current unsupervised approaches utilize features from grammar structures, to induce semantic roles. The dependence on these grammars, however, makes it difficult to adapt to noisy and new languages. In this paper we develop a data-driven approach to identifying semantic roles, the approach is entirely unsupervised up to the point where rules need to be learned to identify the position the semantic role occurs. Specifically we develop a modified-ADIOS algorithm based on ADIOS Solan et al. (2005) to learn grammar structures, and use these grammar structures to learn the rules for identifying the semantic roles based on the context in which the grammar structures appeared. The results obtained are comparable with the current state-of-art models that are inherently dependent on human annotated data. version:1
arxiv-1606-06266 | Detection and Tracking of Liquids with Fully Convolutional Networks | http://arxiv.org/abs/1606.06266 | id:1606.06266 author:Connor Schenck, Dieter Fox category:cs.CV cs.RO  published:2016-06-20 summary:Recent advances in AI and robotics have claimed many incredible results with deep learning, yet no work to date has applied deep learning to the problem of liquid perception and reasoning. In this paper, we apply fully-convolutional deep neural networks to the tasks of detecting and tracking liquids. We evaluate three models: a single-frame network, multi-frame network, and a LSTM recurrent network. Our results show that the best liquid detection results are achieved when aggregating data over multiple frames, in contrast to standard image segmentation. They also show that the LSTM network outperforms the other two in both tasks. This suggests that LSTM-based neural networks have the potential to be a key component for enabling robots to handle liquids using robust, closed-loop controllers. version:1
arxiv-1606-06259 | MOSI: Multimodal Corpus of Sentiment Intensity and Subjectivity Analysis in Online Opinion Videos | http://arxiv.org/abs/1606.06259 | id:1606.06259 author:Amir Zadeh, Rowan Zellers, Eli Pincus, Louis-Philippe Morency category:cs.CL cs.MM  published:2016-06-20 summary:People are sharing their opinions, stories and reviews through online video sharing websites every day. Studying sentiment and subjectivity in these opinion videos is experiencing a growing attention from academia and industry. While sentiment analysis has been successful for text, it is an understudied research question for videos and multimedia content. The biggest setbacks for studies in this direction are lack of a proper dataset, methodology, baselines and statistical analysis of how information from different modality sources relate to each other. This paper introduces to the scientific community the first opinion-level annotated corpus of sentiment and subjectivity analysis in online videos called Multimodal Opinion-level Sentiment Intensity dataset (MOSI). The dataset is rigorously annotated with labels for subjectivity, sentiment intensity, per-frame and per-opinion annotated visual features, and per-milliseconds annotated audio features. Furthermore, we present baselines for future studies in this direction as well as a new multimodal fusion approach that jointly models spoken words and visual gestures. version:1
arxiv-1606-06250 | An Empirical Comparison of Sampling Quality Metrics: A Case Study for Bayesian Nonnegative Matrix Factorization | http://arxiv.org/abs/1606.06250 | id:1606.06250 author:Arjumand Masood, Weiwei Pan, Finale Doshi-Velez category:cs.LG stat.ML  published:2016-06-20 summary:In this work, we empirically explore the question: how can we assess the quality of samples from some target distribution? We assume that the samples are provided by some valid Monte Carlo procedure, so we are guaranteed that the collection of samples will asymptotically approximate the true distribution. Most current evaluation approaches focus on two questions: (1) Has the chain mixed, that is, is it sampling from the distribution? and (2) How independent are the samples (as MCMC procedures produce correlated samples)? Focusing on the case of Bayesian nonnegative matrix factorization, we empirically evaluate standard metrics of sampler quality as well as propose new metrics to capture aspects that these measures fail to expose. The aspect of sampling that is of particular interest to us is the ability (or inability) of sampling methods to move between multiple optima in NMF problems. As a proxy, we propose and study a number of metrics that might quantify the diversity of a set of NMF factorizations obtained by a sampler through quantifying the coverage of the posterior distribution. We compare the performance of a number of standard sampling methods for NMF in terms of these new metrics. version:1
arxiv-1606-06244 | Fast Convergence of Common Learning Algorithms in Games | http://arxiv.org/abs/1606.06244 | id:1606.06244 author:Dylan J. Foster, Zhiyuan Li, Thodoris Lykouris, Karthik Sridharan, Eva Tardos category:cs.GT cs.LG  published:2016-06-20 summary:We show that learning algorithms satisfying a $\textit{low approximate regret}$ property experience fast convergence to approximate optimality in a large class of repeated games. Our property, which simply requires that each learner has small regret compared to a $(1+\epsilon)$-multiplicative approximation to the best action in hindsight, is ubiquitous among learning algorithms - it is satisfied even by the vanilla Hedge forecaster. Our results improve upon recent work of Syrgkanis et al. [SALS15] in a number of ways. We improve upon the speed of convergence by a factor of n, the number of players, and require only that the players observe payoffs under other players' realized actions, as opposed to expected payoffs. We further show that convergence occurs with high probability, and under certain conditions show convergence under bandit feedback. Both the scope of settings and the class of algorithms for which our analysis provides fast convergence are considerably broader than in previous work. Our framework applies to dynamic population games via a low approximate regret property for shifting experts. Here we strengthen the results of Lykouris et al. [LST16] in two ways: We allow players to select learning algorithms from a larger class, which includes a minor variant of the basic Hedge algorithm, and we increase the maximum churn in players for which approximate optimality is achieved. In the bandit setting we present a novel algorithm which provides a "small loss"-type bound with improved dependence on the number of actions and is both simple and efficient. This result may be of independent interest. version:1
arxiv-1606-06237 | Online and Differentially-Private Tensor Decomposition | http://arxiv.org/abs/1606.06237 | id:1606.06237 author:Yining Wang, Animashree Anandkumar category:stat.ML cs.LG  published:2016-06-20 summary:Tensor decomposition is positioned to be a pervasive tool in the era of big data. In this paper, we resolve many of the key algorithmic questions regarding robustness, memory efficiency, and differential privacy of tensor decomposition. We propose simple variants of the tensor power method which enjoy these strong properties. We present the first guarantees for online tensor power method which has a linear memory requirement. Moreover, we present a noise calibrated tensor power method with efficient privacy guarantees. At the heart of all these guarantees lies a careful perturbation analysis derived in this paper which improves up on the existing results significantly. version:1
arxiv-1606-06234 | CNNLab: a Novel Parallel Framework for Neural Networks using GPU and FPGA-a Practical Study with Trade-off Analysis | http://arxiv.org/abs/1606.06234 | id:1606.06234 author:Maohua Zhu, Liu Liu, Chao Wang, Yuan Xie category:cs.LG cs.DC  published:2016-06-20 summary:Designing and implementing efficient, provably correct parallel neural network processing is challenging. Existing high-level parallel abstractions like MapReduce are insufficiently expressive while low-level tools like MPI and Pthreads leave ML experts repeatedly solving the same design challenges. However, the diversity and large-scale data size have posed a significant challenge to construct a flexible and high-performance implementation of deep learning neural networks. To improve the performance and maintain the scalability, we present CNNLab, a novel deep learning framework using GPU and FPGA-based accelerators. CNNLab provides a uniform programming model to users so that the hardware implementation and the scheduling are invisible to the programmers. At runtime, CNNLab leverages the trade-offs between GPU and FPGA before offloading the tasks to the accelerators. Experimental results on the state-of-the-art Nvidia K40 GPU and Altera DE5 FPGA board demonstrate that the CNNLab can provide a universal framework with efficient support for diverse applications without increasing the burden of the programmers. Moreover, we analyze the detailed quantitative performance, throughput, power, energy, and performance density for both approaches. Experimental results leverage the trade-offs between GPU and FPGA and provide useful practical experiences for the deep learning research community. version:1
arxiv-1606-06216 | Neural networks with differentiable structure | http://arxiv.org/abs/1606.06216 | id:1606.06216 author:Thomas Miconi category:cs.NE  published:2016-06-20 summary:While gradient descent has proven highly successful in learning connection weights for neural networks, the actual structure of these networks is usually determined by hand, or by other optimization algorithms. Here we describe a simple method to make network structure differentiable, and therefore accessible to gradient descent. We test this method on recurrent neural networks applied to simple sequence prediction problems. Starting with initial networks containing only one node, the method automatically builds networks that successfully solve the tasks. The number of nodes in the final network correlates with task difficulty. The method can dynamically increase network size in response to an abrupt complexification in the task; however, reduction in network size in response to task simplification is not evident for reasonable meta-parameters. The method does not penalize network performance for these test tasks: variable-size networks actually reach better performance than fixed-size networks of higher, lower or identical size. We conclude by discussing how this method could be applied to more complex networks, such as feedforward layered networks, or multiple-area networks of arbitrary shape. version:1
arxiv-1606-06179 | On the prediction loss of the lasso in the partially labeled setting | http://arxiv.org/abs/1606.06179 | id:1606.06179 author:Pierre C. Bellec, Arnak S. Dalalyan, Edwin Grappin, Quentin Paris category:math.ST stat.ML stat.TH  published:2016-06-20 summary:In this paper we revisit the risk bounds of the lasso estimator in the context of transductive and semi-supervised learning. In other terms, the setting under consideration is that of regression with random design under partial labeling. The main goal is to obtain user-friendly bounds on the off-sample prediction risk. To this end, the simple setting of bounded response variable and bounded (high-dimensional) covariates is considered. We propose some new adaptations of the lasso to these settings and establish oracle inequalities both in expectation and in deviation. These results provide non-asymptotic upper bounds on the risk that highlight the interplay between the bias due to the mis-specification of the linear model, the bias due to the approximate sparsity and the variance. They also demonstrate that the presence of a large number of unlabeled features may have significant positive impact in the situations where the restricted eigenvalue of the design matrix vanishes or is very small. version:1
arxiv-1606-06164 | Pragmatic factors in image description: the case of negations | http://arxiv.org/abs/1606.06164 | id:1606.06164 author:Emiel van Miltenburg, Roser Morante, Desmond Elliott category:cs.CL cs.CV  published:2016-06-20 summary:We provide a qualitative analysis of the descriptions containing negations (no, not, n't, nobody, etc) in the Flickr30K corpus, and a categorization of negation uses. Based on this analysis, we provide a set of requirements that an image description system should have in order to generate negation sentences. As a pilot experiment, we used our categorization to manually annotate sentences containing negations in the Flickr30K corpus, with an agreement score of K=0.67. With this paper, we hope to open up a broader discussion of subjective language in image descriptions. version:1
arxiv-1606-06160 | DoReFa-Net: Training Low Bitwidth Convolutional Neural Networks with Low Bitwidth Gradients | http://arxiv.org/abs/1606.06160 | id:1606.06160 author:Shuchang Zhou, Zekun Ni, Xinyu Zhou, He Wen, Yuxin Wu, Yuheng Zou category:cs.NE cs.LG  published:2016-06-20 summary:We propose DoReFa-Net, a method to train convolutional neural networks that have low bitwidth weights and activations using low bitwidth parameter gradients. In particular, during backward pass, parameter gradients are stochastically quantized to low bitwidth numbers before being propagated to convolutional layers. As convolutions during forward/backward passes can now operate on low bitwidth weights and activations/gradients respectively, DoReFa-Net can use bit convolution kernels to accelerate both training and inference. Moreover, as bit convolutions can be efficiently implemented on CPU, FPGA, ASIC and GPU, DoReFatNet opens the way to accelerate training of low bitwidth neural network on these hardware. Our experiments on SVHN and ImageNet datasets prove that DoReFa-Net can achieve comparable prediction accuracy as 32-bit counterparts. For example, a DoReFa-Net derived from AlexNet that has 1-bit weights, 2-bit activations, can be trained from scratch using 4-bit gradients to get 47\% top-1 accuracy on ImageNet validation set. The DoReFa-Net AlexNet model is released publicly. version:1
arxiv-1606-06142 | Comparing the hierarchy of keywords in on-line news portals | http://arxiv.org/abs/1606.06142 | id:1606.06142 author:Gergely Tibély, David Sousa-Rodrigues, Péter Pollner, Gergely Palla category:physics.soc-ph cs.CL cs.SI  published:2016-06-20 summary:The tagging of on-line content with informative keywords is a widespread phenomenon from scientific article repositories through blogs to on-line news portals. In most of the cases, the tags on a given item are free words chosen by the authors independently. Therefore, relations among keywords in a collection of news items is unknown. However, in most cases the topics and concepts described by these keywords are forming a latent hierarchy, with the more general topics and categories at the top, and more specialised ones at the bottom. Here we apply a recent, cooccurrence-based tag hierarchy extraction method to sets of keywords obtained from four different on-line news portals. The resulting hierarchies show substantial differences not just in the topics rendered as important (being at the top of the hierarchy) or of less interest (categorised low in the hierarchy), but also in the underlying network structure. This reveals discrepancies between the plausible keyword association frameworks in the studied news portals. version:1
arxiv-1606-06137 | LSTM-Based Predictions for Proactive Information Retrieval | http://arxiv.org/abs/1606.06137 | id:1606.06137 author:Petri Luukkonen, Markus Koskela, Patrik Floréen category:cs.IR cs.CL cs.NE  published:2016-06-20 summary:We describe a method for proactive information retrieval targeted at retrieving relevant information during a writing task. In our method, the current task and the needs of the user are estimated, and the potential next steps are unobtrusively predicted based on the user's past actions. We focus on the task of writing, in which the user is coalescing previously collected information into a text. Our proactive system automatically recommends the user relevant background information. The proposed system incorporates text input prediction using a long short-term memory (LSTM) network. We present simulations, which show that the system is able to reach higher precision values in an exploratory search setting compared to both a baseline and a comparison system. version:1
arxiv-1606-06135 | The Minimum Cost Connected Subgraph Problem in Medical Image Analysis | http://arxiv.org/abs/1606.06135 | id:1606.06135 author:Markus Rempfler, Bjoern Andres, Bjoern H. Menze category:cs.CV  published:2016-06-20 summary:Several important tasks in medical image analysis can be stated in the form of an optimization problem whose feasible solutions are connected subgraphs. Examples include the reconstruction of neural or vascular structures under connectedness constraints. We discuss the minimum cost connected subgraph (MCCS) problem and its approximations from the perspective of medical applications. We propose a) objective-dependent constraints and b) novel constraint generation schemes to solve this optimization problem exactly by means of a branch-and-cut algorithm. These are shown to improve scalability and allow us to solve instances of two medical benchmark datasets to optimality for the first time. This enables us to perform a quantitative comparison between exact and approximative algorithms, where we identify the geodesic tree algorithm as an excellent alternative to exact inference on the examined datasets. version:1
arxiv-1606-06127 | Cutting out the middleman: measuring nuclear area in histopathology slides without segmentation | http://arxiv.org/abs/1606.06127 | id:1606.06127 author:Mitko Veta, Paul J. van Diest, Josien P. W. Pluim category:cs.CV  published:2016-06-20 summary:The size of nuclei in histological preparations from excised breast tumors is predictive of patient outcome (large nuclei indicate poor outcome). Pathologists take into account nuclear size when performing breast cancer grading. In addition, the mean nuclear area (MNA) has been shown to have independent prognostic value. The straightforward approach to measuring nuclear size is by performing nuclei segmentation. We hypothesize that given an image of a tumor region with known nuclei locations, the area of the individual nuclei and region statistics such as the MNA can be reliably computed directly from the image data by employing a machine learning model, without the intermediate step of nuclei segmentation. Towards this goal, we train a deep convolutional neural network model that is applied locally at each nucleus location, and can reliably measure the area of the individual nuclei and the MNA. Furthermore, we show how such an approach can be extended to perform combined nuclei detection and measurement, which is reminiscent of granulometry. version:1
arxiv-1606-06126 | High Confidence Off-Policy Evaluation with Models | http://arxiv.org/abs/1606.06126 | id:1606.06126 author:Josiah P. Hanna, Peter Stone, Scott Niekum category:cs.AI cs.LG stat.ML  published:2016-06-20 summary:In many reinforcement learning applications executing a poor policy may be costly or even dangerous. Thus, it is desirable to determine confidence interval lower bounds on the performance of any given policy without executing said policy. Current methods for high confidence off-policy evaluation require a substantial amount of data to achieve a tight lower bound, while existing model-based methods only address the problem in discrete state spaces. We propose two bootstrapping approaches combined with learned MDP transition models in order to efficiently estimate lower confidence bounds on policy performance with limited data in both continuous and discrete state spaces. Since direct use of a model may introduce bias, we derive a theoretical upper bound on model bias when we estimate the model transitions with i.i.d. sampled trajectories. This bound can be used to guide selection between the two methods. Finally, we empirically validate the data-efficiency of our proposed methods across three domains and analyze the settings where one method is preferable to the other. version:1
arxiv-1606-06125 | Introducing a Calculus of Effects and Handlers for Natural Language Semantics | http://arxiv.org/abs/1606.06125 | id:1606.06125 author:Jirka Maršík, Maxime Amblard category:cs.CL cs.PL  published:2016-06-20 summary:In compositional model-theoretic semantics, researchers assemble truth-conditions or other kinds of denotations using the lambda calculus. It was previously observed that the lambda terms and/or the denotations studied tend to follow the same pattern: they are instances of a monad. In this paper, we present an extension of the simply-typed lambda calculus that exploits this uniformity using the recently discovered technique of effect handlers. We prove that our calculus exhibits some of the key formal properties of the lambda calculus and we use it to construct a modular semantics for a small fragment that involves multiple distinct semantic phenomena. version:1
arxiv-1606-06121 | Quantifying and Reducing Stereotypes in Word Embeddings | http://arxiv.org/abs/1606.06121 | id:1606.06121 author:Tolga Bolukbasi, Kai-Wei Chang, James Zou, Venkatesh Saligrama, Adam Kalai category:cs.CL cs.LG stat.ML  published:2016-06-20 summary:Machine learning algorithms are optimized to model statistical properties of the training data. If the input data reflects stereotypes and biases of the broader society, then the output of the learning algorithm also captures these stereotypes. In this paper, we initiate the study of gender stereotypes in {\em word embedding}, a popular framework to represent text data. As their use becomes increasingly common, applications can inadvertently amplify unwanted stereotypes. We show across multiple datasets that the embeddings contain significant gender stereotypes, especially with regard to professions. We created a novel gender analogy task and combined it with crowdsourcing to systematically quantify the gender bias in a given embedding. We developed an efficient algorithm that reduces gender stereotype using just a handful of training examples while preserving the useful geometric properties of the embedding. We evaluated our algorithm on several metrics. While we focus on male/female stereotypes, our framework may be applicable to other types of embedding biases. version:1
arxiv-1606-06108 | DualNet: Domain-Invariant Network for Visual Question Answering | http://arxiv.org/abs/1606.06108 | id:1606.06108 author:Kuniaki Saito, Andrew Shin, Yoshitaka Ushiku, Tatsuya Harada category:cs.CV  published:2016-06-20 summary:Visual question answering (VQA) task not only bridges the gap between images and language, but also requires that specific contents within the image are understood as indicated by linguistic context of the question, in order to generate the accurate answers. Thus, it is critical to build an efficient embedding of images and texts. We implement DualNet, which fully takes advantage of discriminative power of both image and textual features by separately performing two operations. Building an ensemble of DualNet further boosts the performance. Contrary to common belief, our method proved effective in both real images and abstract scenes, in spite of significantly different properties of respective domain. Our method was able to outperform previous state-of-the-art methods in real images category even without explicitly employing attention mechanism, and also outperformed our own state-of-the-art method in abstract scenes category, which recently won the first place in VQA Challenge 2016. version:1
arxiv-1606-06086 | Uncertainty in Neural Network Word Embedding: Exploration of Threshold for Similarity | http://arxiv.org/abs/1606.06086 | id:1606.06086 author:Navid Rekabsaz, Mihai Lupu, Allan Hanbury category:cs.CL cs.IR  published:2016-06-20 summary:Word embedding, specially with its recent developments, promises a quantification of the similarity between terms. However, it is not clear to which extent this similarity value can be genuinely meaningful and useful for subsequent tasks. We explore how the similarity score obtained from the models is really indicative of term relatedness. We first observe and quantify the uncertainty factor of the word embedding models regarding to the similarity value. Based on this factor, we introduce a general threshold on various dimensions which effectively filters the highly related terms. Our evaluation on four information retrieval collections supports the effectiveness of our approach as the results of the introduced threshold are significantly better than the baseline while being equal to or statistically indistinguishable from the optimal results. version:1
arxiv-1606-06083 | Product Classification in E-Commerce using Distributional Semantics | http://arxiv.org/abs/1606.06083 | id:1606.06083 author:Vivek Gupta, Harish Karnick, Ashendra Bansal, Pradhuman Jhala category:cs.AI cs.CL cs.IR  published:2016-06-20 summary:Product classification is the task of automatically predicting a taxonomy path for a product in a predefined taxonomy hierarchy given a textual product description or title. For efficient product classification we require a suitable representation for a document (the textual description of a product) feature vector and efficient and fast algorithms for prediction. To address the above challenges, we propose a new distributional semantics representation for document vector formation. We also develop a new two-level ensemble approach utilizing (with respect to the taxonomy tree) a path-wise, node-wise and depth-wise classifiers for error reduction in the final product classification. Our experiments show the effectiveness of the distributional representation and the ensemble approach on data sets from a leading e-commerce platform and achieve better results on various evaluation metrics compared to earlier approaches. version:1
arxiv-1606-06069 | Relative Natural Gradient for Learning Large Complex Models | http://arxiv.org/abs/1606.06069 | id:1606.06069 author:Ke Sun, Frank Nielsen category:cs.LG  published:2016-06-20 summary:Fisher information and natural gradient provided deep insights and powerful tools to artificial neural networks. However related analysis becomes more and more difficult as the learner's structure turns large and complex. This paper makes a preliminary step towards a new direction. We extract a local component of a large neuron system, and defines its relative Fisher information metric that describes accurately this small component, and is invariant to the other parts of the system. This concept is important because the geometry structure is much simplified and it can be easily applied to guide the learning of neural networks. We provide an analysis on a list of commonly used components, and demonstrate how to use this concept to further improve optimization. version:1
arxiv-1606-06066 | Mining Local Process Models | http://arxiv.org/abs/1606.06066 | id:1606.06066 author:Niek Tax, Natalia Sidorova, Reinder Haakma, Wil M. P. van der Aalst category:cs.DB cs.LG  published:2016-06-20 summary:In this paper we describe a method to discover frequent behavioral patterns in event logs. We express these patterns as \emph{local process models}. Local process model mining can be positioned in-between process discovery and episode / sequential pattern mining. The technique presented in this paper is able to learn behavioral patterns involving sequential composition, concurrency, choice and loop, like in process mining. However, we do not look at start-to-end models, which distinguishes our approach from process discovery and creates a link to episode / sequential pattern mining. We propose an incremental procedure for building local process models capturing frequent patterns based on so-called process trees. We propose five quality dimensions and corresponding metrics for local process models, given an event log. We show monotonicity properties for some quality dimensions, enabling a speedup of local process model discovery through pruning. We demonstrate through a real life case study that mining local patterns allows us to get insights in processes where regular start-to-end process discovery techniques are only able to learn unstructured, flower-like, models. version:1
arxiv-1606-06047 | Contravening Esotery: Cryptanalysis of Knapsack Cipher using Genetic Algorithms | http://arxiv.org/abs/1606.06047 | id:1606.06047 author:Harmeet Singh category:cs.CR cs.NE  published:2016-06-20 summary:Cryptanalysis of knapsack cipher is a fascinating problem which has eluded the computing fraternity for decades. However, in most of the cases either the time complexity of the proposed algorithm is colossal or an insufficient number of samples have been taken for verification. The present work proposes a Genetic Algorithm based technique for cryptanalysis of knapsack cipher. The experiments conducted prove the validity of the technique. The results prove that the technique is better than the existing techniques. An extensive review has been carried out in order to find the gaps in the existing techniques. The work paves the way of the application of computational intelligence techniques to the discipline of cryptanalysis. version:1
arxiv-1606-06041 | Bandit-Based Random Mutation Hill-Climbing | http://arxiv.org/abs/1606.06041 | id:1606.06041 author:Jialin Liu, Diego Peŕez-Liebana, Simon M. Lucas category:cs.AI cs.NE I.2.8  published:2016-06-20 summary:The Random Mutation Hill-Climbing algorithm is a direct search technique mostly used in discrete domains. It repeats the process of randomly selecting a neighbour of a best-so-far solution and accepts the neighbour if it is better than or equal to it. In this work, we propose to use a novel method to select the neighbour solution using a set of independent multi- armed bandit-style selection units which results in a bandit-based Random Mutation Hill-Climbing algorithm. The new algorithm significantly outperforms Random Mutation Hill-Climbing in both OneMax (in noise-free and noisy cases) and Royal Road problems (in the noise-free case). The algorithm shows particular promise for discrete optimisation problems where each fitness evaluation is expensive. version:1
arxiv-1606-06031 | The LAMBADA dataset: Word prediction requiring a broad discourse context | http://arxiv.org/abs/1606.06031 | id:1606.06031 author:Denis Paperno, Germán Kruszewski, Angeliki Lazaridou, Quan Ngoc Pham, Raffaella Bernardi, Sandro Pezzelle, Marco Baroni, Gemma Boleda, Raquel Fernández category:cs.CL cs.AI cs.LG  published:2016-06-20 summary:We introduce LAMBADA, a dataset to evaluate the capabilities of computational models for text understanding by means of a word prediction task. LAMBADA is a collection of narrative passages sharing the characteristic that human subjects are able to guess their last word if they are exposed to the whole passage, but not if they only see the last sentence preceding the target word. To succeed on LAMBADA, computational models cannot simply rely on local context, but must be able to keep track of information in the broader discourse. We show that LAMBADA exemplifies a wide range of linguistic phenomena, and that none of several state-of-the-art language models reaches accuracy above 1% on this novel benchmark. We thus propose LAMBADA as a challenging test set, meant to encourage the development of new models capable of genuine understanding of broad context in natural language text. version:1
arxiv-1606-06007 | Perfect Fingerprint Orientation Fields by Locally Adaptive Global Models | http://arxiv.org/abs/1606.06007 | id:1606.06007 author:Carsten Gottschlich, Benjamin Tams, Stephan Huckemann category:cs.CV  published:2016-06-20 summary:Fingerprint recognition is widely used for verification and identification in many commercial, governmental and forensic applications. The orientation field (OF) plays an important role at various processing stages in fingerprint recognition systems. OFs are used for image enhancement, fingerprint alignment, for fingerprint liveness detection, fingerprint alteration detection and fingerprint matching. In this paper, a novel approach is presented to globally model an OF combined with locally adaptive methods. We show that this model adapts perfectly to the 'true OF' in the limit. This perfect OF is described by a small number of parameters with straightforward geometric interpretation. Applications are manifold: Quick expert marking of very poor quality (for instance latent) OFs, high fidelity low parameter OF compression and a direct road to ground truth OFs markings for large databases, say. In this contribution we describe an algorithm to perfectly estimate OF parameters automatically or semi-automatically, depending on image quality, and we establish the main underlying claim of high fidelity low parameter OF compression. version:1
arxiv-1606-05994 | The Role of CNL and AMR in Scalable Abstractive Summarization for Multilingual Media Monitoring | http://arxiv.org/abs/1606.05994 | id:1606.05994 author:Normunds Gruzitis, Guntis Barzdins category:cs.CL  published:2016-06-20 summary:In the era of Big Data and Deep Learning, there is a common view that machine learning approaches are the only way to cope with the robust and scalable information extraction and summarization. It has been recently proposed that the CNL approach could be scaled up, building on the concept of embedded CNL and, thus, allowing for CNL-based information extraction from e.g. normative or medical texts that are rather controlled by nature but still infringe the boundaries of CNL. Although it is arguable if CNL can be exploited to approach the robust wide-coverage semantic parsing for use cases like media monitoring, its potential becomes much more obvious in the opposite direction: generation of story highlights from the summarized AMR graphs, which is in the focus of this position paper. version:1
arxiv-1606-05990 | A New Training Method for Feedforward Neural Networks Based on Geometric Contraction Property of Activation Functions | http://arxiv.org/abs/1606.05990 | id:1606.05990 author:Petre Birtea, Cosmin Cernazanu-Glavan, Alexandru Sisu category:cs.NE cs.LG 92B20  68T05  published:2016-06-20 summary:We propose a new training method for a feedforward neural network having the activation functions with the geometric contraction property. The method consists of constructing a new functional that is less nonlinear in comparison with the classical functional by removing the nonlinearity of the activation functions from the output layer. We validate this new method by a series of experiments that show an improved learning speed and also a better classification error. version:1
arxiv-1606-05988 | Continuum directions for supervised dimension reduction | http://arxiv.org/abs/1606.05988 | id:1606.05988 author:Sungkyu Jung category:stat.ME cs.LG stat.ML  published:2016-06-20 summary:We consider dimension reduction of multivariate data under the existence of various types of auxiliary information. We propose a criterion that provides a series of orthogonal directional vectors, that form a basis for dimension reduction. The proposed method can be thought of as an extension from the continuum regression, and the resulting basis is called continuum directions. We show that these directions continuously bridge the principal component, mean difference and linear discriminant directions, thus ranging from unsupervised to fully supervised dimension reduction. With a presence of binary supervision data, the proposed directions can be directly used for a two-group classification. Numerical studies show that the proposed method works well in high-dimensional settings where the variance of the first principal component is much larger than the rest. version:1
arxiv-1606-05973 | A New Parallel Algorithm for Two-Pass Connected Component Labeling | http://arxiv.org/abs/1606.05973 | id:1606.05973 author:Siddharth Gupta, Diana Palsetia, Md. Mostofa Ali Patwary, Ankit Agrawal, Alok Choudhary category:cs.DS cs.CV cs.PF  published:2016-06-20 summary:Connected Component Labeling (CCL) is an important step in pattern recognition and image processing. It assigns labels to the pixels such that adjacent pixels sharing the same features are assigned the same label. Typically, CCL requires several passes over the data. We focus on two-pass technique where each pixel is given a provisional label in the first pass whereas an actual label is assigned in the second pass. We present a scalable parallel two-pass CCL algorithm, called PAREMSP, which employs a scan strategy and the best union-find technique called REMSP, which uses REM's algorithm for storing label equivalence information of pixels in a 2-D image. In the first pass, we divide the image among threads and each thread runs the scan phase along with REMSP simultaneously. In the second phase, we assign the final labels to the pixels. As REMSP is easily parallelizable, we use the parallel version of REMSP for merging the pixels on the boundary. Our experiments show the scalability of PAREMSP achieving speedups up to $20.1$ using $24$ cores on shared memory architecture using OpenMP for an image of size $465.20$ MB. We find that our proposed parallel algorithm achieves linear scaling for a large resolution fixed problem size as the number of processing elements are increased. Additionally, the parallel algorithm does not make use of any hardware specific routines, and thus is highly portable. version:1
arxiv-1606-05967 | A Nonparametric Bayesian Approach for Spoken Term detection by Example Query | http://arxiv.org/abs/1606.05967 | id:1606.05967 author:Amir Hossein Harati Nejad Torbati, Joseph Picone category:cs.CL  published:2016-06-20 summary:State of the art speech recognition systems use data-intensive context-dependent phonemes as acoustic units. However, these approaches do not translate well to low resourced languages where large amounts of training data is not available. For such languages, automatic discovery of acoustic units is critical. In this paper, we demonstrate the application of nonparametric Bayesian models to acoustic unit discovery. We show that the discovered units are correlated with phonemes and therefore are linguistically meaningful. We also present a spoken term detection (STD) by example query algorithm based on these automatically learned units. We show that our proposed system produces a P@N of 61.2% and an EER of 13.95% on the TIMIT dataset. The improvement in the EER is 5% while P@N is only slightly lower than the best reported system in the literature. version:1
arxiv-1606-05934 | Adapting ELM to Time Series Classification: A Novel Diversified Top-k Shapelets Extraction Method | http://arxiv.org/abs/1606.05934 | id:1606.05934 author:Qiuyan Yan, Qifa Sun, Xinming Yan category:cs.LG  published:2016-06-20 summary:ELM (Extreme Learning Machine) is a single hidden layer feed-forward network, where the weights between input and hidden layer are initialized randomly. ELM is efficient due to its utilization of the analytical approach to compute weights between hidden and output layer. However, ELM still fails to output the semantic classification outcome. To address such limitation, in this paper, we propose a diversified top-k shapelets transform framework, where the shapelets are the subsequences i.e., the best representative and interpretative features of each class. As we identified, the most challenge problems are how to extract the best k shapelets in original candidate sets and how to automatically determine the k value. Specifically, we first define the similar shapelets and diversified top-k shapelets to construct diversity shapelets graph. Then, a novel diversity graph based top-k shapelets extraction algorithm named as \textbf{DivTopkshapelets}\ is proposed to search top-k diversified shapelets. Finally, we propose a shapelets transformed ELM algorithm named as \textbf{DivShapELM} to automatically determine the k value, which is further utilized for time series classification. The experimental results over public data sets demonstrate that the proposed approach significantly outperforms traditional ELM algorithm in terms of effectiveness and efficiency. version:1
arxiv-1606-05929 | Learning Convolutional Neural Networks using Hybrid Orthogonal Projection and Estimation | http://arxiv.org/abs/1606.05929 | id:1606.05929 author:Hengyue Pan, Hui Jiang category:cs.NE cs.CV  published:2016-06-20 summary:Convolutional neural networks (CNNs) have yielded the excellent performance in a variety of computer vision tasks, where CNNs typically adopt a similar structure consisting of convolution layers, pooling layers and fully connected layers. In this paper, we propose to apply a novel method, namely Hybrid Orthogonal Projection and Estimation (HOPE), to CNNs in order to introduce orthogonality into the CNN structure. The HOPE model can be viewed as a hybrid model to combine feature extraction using orthogonal linear projection with mixture models. It is an effective model to extract useful information from the original high-dimension feature vectors and meanwhile filter out irrelevant noises. In this work, we present two different ways to apply the HOPE models to CNNs, i.e., {\em HOPE-Input} and {\em HOPE-Pooling}. For {\em HOPE-Input}, a HOPE layer is directly used right after the input to de-correlate high-dimension input feature vectors. Alternatively, in {\em HOPE-Pooling}, a HOPE layer is used to replace the regular pooling layer in CNNs. The experimental results on both CIFAR-10 and CIFAR-100 data sets have shown that the orthogonal contraints imposed by the HOPE layers can significantly improve the performance of CNNs in these image classification tasks (we have achieved top-3 performance when image augmentation has not been applied). version:1
arxiv-1606-05927 | Minimum cost polygon overlay with rectangular shape stock panels | http://arxiv.org/abs/1606.05927 | id:1606.05927 author:Wilson S. Siringoringo, Andy M. Connor, Nick Clements, Nick Alexander category:cs.NE cs.CG cs.DS  published:2016-06-19 summary:Minimum Cost Polygon Overlay (MCPO) is a unique two-dimensional optimization problem that involves the task of covering a polygon shaped area with a series of rectangular shaped panels. This has a number of applications in the construction industry. This work examines the MCPO problem in order to construct a model that captures essential parameters of the problem to be solved automatically using numerical optimization algorithms. Three algorithms have been implemented of the actual optimization task: the greedy search, the Monte Carlo (MC) method, and the Genetic Algorithm (GA). Results are presented to show the relative effectiveness of the algorithms. This is followed by critical analysis of various findings of this research. version:1
arxiv-1606-05925 | Graph based manifold regularized deep neural networks for automatic speech recognition | http://arxiv.org/abs/1606.05925 | id:1606.05925 author:Vikrant Singh Tomar, Richard C. Rose category:stat.ML cs.CL cs.LG  published:2016-06-19 summary:Deep neural networks (DNNs) have been successfully applied to a wide variety of acoustic modeling tasks in recent years. These include the applications of DNNs either in a discriminative feature extraction or in a hybrid acoustic modeling scenario. Despite the rapid progress in this area, a number of challenges remain in training DNNs. This paper presents an effective way of training DNNs using a manifold learning based regularization framework. In this framework, the parameters of the network are optimized to preserve underlying manifold based relationships between speech feature vectors while minimizing a measure of loss between network outputs and targets. This is achieved by incorporating manifold based locality constraints in the objective criterion of DNNs. Empirical evidence is provided to demonstrate that training a network with manifold constraints preserves structural compactness in the hidden layers of the network. Manifold regularization is applied to train bottleneck DNNs for feature extraction in hidden Markov model (HMM) based speech recognition. The experiments in this work are conducted on the Aurora-2 spoken digits and the Aurora-4 read news large vocabulary continuous speech recognition tasks. The performance is measured in terms of word error rate (WER) on these tasks. It is shown that the manifold regularized DNNs result in up to 37% reduction in WER relative to standard DNNs. version:1
arxiv-1606-05918 | Slack and Margin Rescaling as Convex Extensions of Supermodular Functions | http://arxiv.org/abs/1606.05918 | id:1606.05918 author:Matthew B. Blaschko category:cs.LG cs.DM  published:2016-06-19 summary:Slack and margin rescaling are variants of the structured output SVM. They define convex surrogates to task specific loss functions, which, when specialized to non-additive loss functions for multi-label problems, yield extensions to increasing set functions. We demonstrate in this paper that we may use these concepts to define polynomial time convex extensions of arbitrary supermodular functions. We further show that slack and margin rescaling can be interpreted as dominating convex extensions over multiplicative and additive families, and that margin rescaling is strictly dominated by slack rescaling. However, we also demonstrate that, while the function value and gradient for margin rescaling can be computed in polynomial time, the same for slack rescaling corresponds to a non-supermodular maximization problem. version:1
arxiv-1606-05908 | Tutorial on Variational Autoencoders | http://arxiv.org/abs/1606.05908 | id:1606.05908 author:Carl Doersch category:stat.ML cs.LG  published:2016-06-19 summary:In just three years, Variational Autoencoders (VAEs) have emerged as one of the most popular approaches to unsupervised learning of complicated distributions. VAEs are appealing because they are built on top of standard function approximators (neural networks), and can be trained with stochastic gradient descent. VAEs have already shown promise in generating many kinds of complicated data, including handwritten digits, faces, house numbers, CIFAR images, physical models of scenes, segmentation, and predicting the future from static images. This tutorial introduces the intuitions behind VAEs, explains the mathematics behind them, and describes some empirical behavior. No prior knowledge of variational Bayesian methods is assumed. version:1
arxiv-1606-05897 | Preserving Color in Neural Artistic Style Transfer | http://arxiv.org/abs/1606.05897 | id:1606.05897 author:Leon A. Gatys, Matthias Bethge, Aaron Hertzmann, Eli Shechtman category:cs.CV  published:2016-06-19 summary:This note presents an extension to the neural artistic style transfer algorithm (Gatys et al.). The original algorithm transforms an image to have the style of another given image. For example, a photograph can be transformed to have the style of a famous painting. Here we address a potential shortcoming of the original method: the algorithm transfers the colors of the original painting, which can alter the appearance of the scene in undesirable ways. We describe simple linear methods for transferring style while preserving colors. version:1
arxiv-1606-05896 | Clustering with a Reject Option: Interactive Clustering as Bayesian Prior Elicitation | http://arxiv.org/abs/1606.05896 | id:1606.05896 author:Akash Srivastava, James Zou, Ryan P. Adams, Charles Sutton category:stat.ML cs.LG  published:2016-06-19 summary:A good clustering can help a data analyst to explore and understand a data set, but what constitutes a good clustering may depend on domain-specific and application-specific criteria. These criteria can be difficult to formalize, even when it is easy for an analyst to know a good clustering when they see one. We present a new approach to interactive clustering for data exploration called TINDER, based on a particularly simple feedback mechanism, in which an analyst can reject a given clustering and request a new one, which is chosen to be different from the previous clustering while fitting the data well. We formalize this interaction in a Bayesian framework as a method for prior elicitation, in which each different clustering is produced by a prior distribution that is modified to discourage previously rejected clusterings. We show that TINDER successfully produces a diverse set of clusterings, each of equivalent quality, that are much more diverse than would be obtained by randomized restarts. version:1
arxiv-1606-05889 | Tight Performance Bounds for Compressed Sensing With Group Sparsity | http://arxiv.org/abs/1606.05889 | id:1606.05889 author:Shashank Ranjan, Mathukumalli Vidyasagar category:stat.ML  published:2016-06-19 summary:Compressed sensing refers to the recovery of a high-dimensional but sparse vector using a small number of linear measurements. Minimizing the $\ell_1$-norm is among the more popular approaches for compressed sensing. A recent paper by Cai and Zhang has provided the "best possible" bounds for $\ell_1$-norm minimization to achieve robust sparse recovery (a formal statement of compressed sensing). In some applications, "group sparsity" is more natural than conventional sparsity. In this paper we present sufficient conditions for $\ell_1$-norm minimization to achieve robust group sparse recovery. When specialized to conventional sparsity, these conditions reduce to the known "best possible" bounds proved earlier by Cai and Zhang. This is achieved by stating and proving a group robust null space property, which is a new result even for conventional sparsity. We also derive bounds for the $\ell_p$-norm of the residual error between the true vector and its approximation, for all $p \in [1,2]$. These bounds are new even for conventional sparsity and of course also for group sparsity, because previously error bounds were available only for the $\ell_2$-norm. version:1
arxiv-1606-05850 | Guaranteed bounds on the Kullback-Leibler divergence of univariate mixtures using piecewise log-sum-exp inequalities | http://arxiv.org/abs/1606.05850 | id:1606.05850 author:Frank Nielsen, Ke Sun category:cs.LG cs.IT math.IT stat.ML  published:2016-06-19 summary:The Kullback-Leibler divergence between two mixture models is a core primitive in many signal processing tasks. Since the Kullback-Leibler divergence of mixtures does not admit closed-form formula, it is in practice either estimated using costly Monte-Carlo stochastic integration or approximated using various techniques. We present a fast and generic method that builds algorithmically closed-form lower and upper bounds on the entropy, the cross-entropy and the Kullback-Leibler divergence of mixtures. We illustrate the versatile method by reporting on our experiments for approximating the Kullback-Leibler divergence between univariate exponential mixtures, Gaussian mixtures and Rayleigh mixtures. version:1
arxiv-1606-05844 | Statistical Parametric Speech Synthesis Using Bottleneck Representation From Sequence Auto-encoder | http://arxiv.org/abs/1606.05844 | id:1606.05844 author:Sivanand Achanta, KNRK Raju Alluri, Suryakanth V Gangashetty category:cs.SD cs.LG  published:2016-06-19 summary:In this paper, we describe a statistical parametric speech synthesis approach with unit-level acoustic representation. In conventional deep neural network based speech synthesis, the input text features are repeated for the entire duration of phoneme for mapping text and speech parameters. This mapping is learnt at the frame-level which is the de-facto acoustic representation. However much of this computational requirement can be drastically reduced if every unit can be represented with a fixed-dimensional representation. Using recurrent neural network based auto-encoder, we show that it is indeed possible to map units of varying duration to a single vector. We then use this acoustic representation at unit-level to synthesize speech using deep neural network based statistical parametric speech synthesis technique. Results show that the proposed approach is able to synthesize at the same quality as the conventional frame based approach at a highly reduced computational cost. version:1
arxiv-1606-05829 | Can Machine Generate Traditional Chinese Poetry? A Feigenbaum Test | http://arxiv.org/abs/1606.05829 | id:1606.05829 author:Qixin Wang, Tianyi Luo, Dong Wang category:cs.CL  published:2016-06-19 summary:Recent progress in neural learning demonstrated that machines can do well in regularized tasks, e.g., the game of Go. However, artistic activities such as poem generation are still widely regarded as human's special capability. In this paper, we demonstrate that a simple neural model can imitate human in some tasks of art generation. We particularly focus on traditional Chinese poetry, and show that machines can do as well as many contemporary poets and weakly pass the Feigenbaum Test, a variant of Turing test in professional domains. Our method is based on an attention-based recurrent neural network, which accepts a set of keywords as the theme and generates poems by looking at each keyword during the generation. A number of techniques are proposed to improve the model, including character vector initialization, attention to input and hybrid-style training. Compared to existing poetry generation methods, our model can generate much more theme-consistent and semantic-rich poems. version:1
arxiv-1606-05819 | Building an Interpretable Recommender via Loss-Preserving Transformation | http://arxiv.org/abs/1606.05819 | id:1606.05819 author:Amit Dhurandhar, Sechan Oh, Marek Petrik category:stat.ML cs.LG  published:2016-06-19 summary:We propose a method for building an interpretable recommender system for personalizing online content and promotions. Historical data available for the system consists of customer features, provided content (promotions), and user responses. Unlike in a standard multi-class classification setting, misclassification costs depend on both recommended actions and customers. Our method transforms such a data set to a new set which can be used with standard interpretable multi-class classification algorithms. The transformation has the desirable property that minimizing the standard misclassification penalty in this new space is equivalent to minimizing the custom cost function. version:1
arxiv-1606-05814 | Eye Tracking for Everyone | http://arxiv.org/abs/1606.05814 | id:1606.05814 author:Kyle Krafka, Aditya Khosla, Petr Kellnhofer, Harini Kannan, Suchendra Bhandarkar, Wojciech Matusik, Antonio Torralba category:cs.CV  published:2016-06-18 summary:From scientific research to commercial applications, eye tracking is an important tool across many domains. Despite its range of applications, eye tracking has yet to become a pervasive technology. We believe that we can put the power of eye tracking in everyone's palm by building eye tracking software that works on commodity hardware such as mobile phones and tablets, without the need for additional sensors or devices. We tackle this problem by introducing GazeCapture, the first large-scale dataset for eye tracking, containing data from over 1450 people consisting of almost 2.5M frames. Using GazeCapture, we train iTracker, a convolutional neural network for eye tracking, which achieves a significant reduction in error over previous approaches while running in real time (10-15fps) on a modern mobile device. Our model achieves a prediction error of 1.71cm and 2.53cm without calibration on mobile phones and tablets respectively. With calibration, this is reduced to 1.34cm and 2.12cm. Further, we demonstrate that the features learned by iTracker generalize well to other datasets, achieving state-of-the-art results. The code, data, and models are available at http://gazecapture.csail.mit.edu. version:1
arxiv-1606-05804 | Generalizing to Unseen Entities and Entity Pairs with Row-less Universal Schema | http://arxiv.org/abs/1606.05804 | id:1606.05804 author:Patrick Verga, Arvind Neelakantan, Andrew McCallum category:cs.CL  published:2016-06-18 summary:Universal schema predicts the types of entities and relations in a knowledge base (KB) by jointly embedding the union of all available schema types---not only types from multiple structured databases (such as Freebase or Wikipedia infoboxes), but also types expressed as textual patterns from raw text. This prediction is typically modeled as a matrix completion problem, with one type per column, and either one or two entities per row (in the case of entity types or binary relation types, respectively). Factorizing this sparsely observed matrix yields a learned vector embedding for each row and each column. In this paper we explore the problem of making predictions for entities or entity-pairs unseen at training time (and hence without a pre-learned row embedding). We propose an approach having no per-row parameters at all; rather we produce a row vector on the fly using a learned aggregation function of the vectors of the observed columns for that row. We experiment with various aggregation functions, including neural network attention models. Our approach can be understood as a natural language database, in that questions about KB entities are answered by attending to textual or database evidence. In experiments predicting both relations and entity types, we demonstrate that despite having an order of magnitude fewer parameters than traditional universal schema, we can match the accuracy of the traditional model, and more importantly, we can now make predictions about unseen rows with nearly the same accuracy as rows available at training time. version:1
arxiv-1606-05798 | Interpretable Two-level Boolean Rule Learning for Classification | http://arxiv.org/abs/1606.05798 | id:1606.05798 author:Guolong Su, Dennis Wei, Kush R. Varshney, Dmitry M. Malioutov category:stat.ML cs.LG  published:2016-06-18 summary:As a contribution to interpretable machine learning research, we develop a novel optimization framework for learning accurate and sparse two-level Boolean rules. We consider rules in both conjunctive normal form (AND-of-ORs) and disjunctive normal form (OR-of-ANDs). A principled objective function is proposed to trade classification accuracy and interpretability, where we use Hamming loss to characterize accuracy and sparsity to characterize interpretability. We propose efficient procedures to optimize these objectives based on linear programming (LP) relaxation, block coordinate descent, and alternating minimization. Experiments show that our new algorithms provide very good tradeoffs between accuracy and interpretability. version:1
arxiv-1606-05785 | Automatic 3D Reconstruction for Symmetric Shapes | http://arxiv.org/abs/1606.05785 | id:1606.05785 author:Atishay Jain category:cs.CV cs.GR  published:2016-06-18 summary:Generic 3D reconstruction from a single image is a difficult problem. A lot of data loss occurs in the projection. A domain based approach to reconstruction where we solve a smaller set of problems for a particular use case lead to greater returns. The project provides a way to automatically generate full 3-D renditions of actual symmetric images that have some prior information provided in the pipeline by a recognition algorithm. We provide a critical analysis on how this can be enhanced and improved to provide a general reconstruction framework for automatic reconstruction for any symmetric shape. version:1
arxiv-1606-05784 | Hitting times of local and global optima in genetic algorithms with very high selection pressure | http://arxiv.org/abs/1606.05784 | id:1606.05784 author:Anton Eremeev category:cs.NE  published:2016-06-18 summary:The paper is devoted to upper bounds on expected first hitting times of the sets of local or global optima for non-elitist genetic algorithms with very high selection pressure. The obtained results extend the range of situations where the upper bounds on the expected runtime are known for genetic algorithms and apply, in particular, to Canonical Genetic Algorithm. version:1
arxiv-1606-05763 | Online and Offline Handwritten Chinese Character Recognition: A Comprehensive Study and New Benchmark | http://arxiv.org/abs/1606.05763 | id:1606.05763 author:Xu-Yao Zhang, Yoshua Bengio, Cheng-Lin Liu category:cs.CV  published:2016-06-18 summary:Recent deep learning based methods have achieved the state-of-the-art performance for handwritten Chinese character recognition (HCCR) by learning discriminative representations directly from raw data. Nevertheless, we believe that the long-and-well investigated domain-specific knowledge should still help to boost the performance of HCCR. By integrating the traditional normalization-cooperated direction-decomposed feature map (directMap) with the deep convolutional neural network (convNet), we are able to obtain new highest accuracies for both online and offline HCCR on the ICDAR-2013 competition database. With this new framework, we can eliminate the needs for data augmentation and model ensemble, which are widely used in other systems to achieve their best results. This makes our framework to be efficient and effective for both training and testing. Furthermore, although directMap+convNet can achieve the best results and surpass human-level performance, we show that writer adaptation in this case is still effective. A new adaptation layer is proposed to reduce the mismatch between training and test data on a particular source layer. The adaptation process can be efficiently and effectively implemented in an unsupervised manner. By adding the adaptation layer into the pre-trained convNet, it can adapt to the new handwriting styles of particular writers, and the recognition accuracy can be further improved consistently and significantly. This paper gives an overview and comparison of recent deep learning based approaches for HCCR, and also sets new benchmarks for both online and offline HCCR. version:1
arxiv-1606-05759 | Egyptian Arabic to English Statistical Machine Translation System for NIST OpenMT'2015 | http://arxiv.org/abs/1606.05759 | id:1606.05759 author:Hassan Sajjad, Nadir Durrani, Francisco Guzman, Preslav Nakov, Ahmed Abdelali, Stephan Vogel, Wael Salloum, Ahmed El Kholy, Nizar Habash category:cs.CL  published:2016-06-18 summary:The paper describes the Egyptian Arabic-to-English statistical machine translation (SMT) system that the QCRI-Columbia-NYUAD (QCN) group submitted to the NIST OpenMT'2015 competition. The competition focused on informal dialectal Arabic, as used in SMS, chat, and speech. Thus, our efforts focused on processing and standardizing Arabic, e.g., using tools such as 3arrib and MADAMIRA. We further trained a phrase-based SMT system using state-of-the-art features and components such as operation sequence model, class-based language model, sparse features, neural network joint model, genre-based hierarchically-interpolated language model, unsupervised transliteration mining, phrase-table merging, and hypothesis combination. Our system ranked second on all three genres. version:1
arxiv-1606-05735 | Student performance prediction using classification data mining techniques | http://arxiv.org/abs/1606.05735 | id:1606.05735 author:Muhammed Salman Shamsi, Jhansi Lakshmi category:cs.LG cs.AI cs.CY  published:2016-06-18 summary:Students opting engineering as their disciple is increasing rapidly. But due to various factors and inappropriate primary education in India dropout rates are high. Students are unable to excel in core engineering subjects which are complex and mathematical, hence mostly get drop / keep term (kt) in that subject. With the help of data mining techniques we can predict the performance of students in terms of grades and dropout for a subject. This paper compares various techniques such as na\"ive Bayes, LibSVM, J48, random forest, and JRip and try to choose one of them as per our needs and their accuracy. Based on the rules obtained from this technique(s), we derive the key factors influencing student performance. version:1
arxiv-1606-05729 | RRV: A Spatiotemporal Descriptor for Rigid Body Motion Recognition | http://arxiv.org/abs/1606.05729 | id:1606.05729 author:Yao Guo, Youfu Li, Zhanpeng Shao category:cs.RO cs.CV  published:2016-06-18 summary:Motion behaviors of a rigid body can be characterized by a 6-dimensional motion trajectory, which contains position vectors of a reference point on the rigid body and rotations of this rigid body over time. This paper devises a Rotation and Relative Velocity (RRV) descriptor by exploring the local translational and rotational invariants of motion trajectories of rigid bodies, which is insensitive to noise, invariant to rigid transformation and scaling. A flexible metric is also introduced to measure the distance between two RRV descriptors. The RRV descriptor is then applied to characterize motions of a human body skeleton modeled as articulated interconnections of multiple rigid bodies. To illustrate the descriptive ability of the RRV descriptor, we explore it for different rigid body motion recognition tasks. The experimental results on benchmark datasets demonstrate that this simple RRV descriptor outperforms the previous ones regarding recognition accuracy without increasing computational cost. version:1
arxiv-1606-05725 | An Efficient Large-scale Semi-supervised Multi-label Classifier Capable of Handling Missing labels | http://arxiv.org/abs/1606.05725 | id:1606.05725 author:Amirhossein Akbarnejad, Mahdieh Soleymani Baghshah category:cs.LG cs.AI stat.ML  published:2016-06-18 summary:Multi-label classification has received considerable interest in recent years. Multi-label classifiers have to address many problems including: handling large-scale datasets with many instances and a large set of labels, compensating missing label assignments in the training set, considering correlations between labels, as well as exploiting unlabeled data to improve prediction performance. To tackle datasets with a large set of labels, embedding-based methods have been proposed which seek to represent the label assignments in a low-dimensional space. Many state-of-the-art embedding-based methods use a linear dimensionality reduction to represent the label assignments in a low-dimensional space. However, by doing so, these methods actually neglect the tail labels - labels that are infrequently assigned to instances. We propose an embedding-based method that non-linearly embeds the label vectors using an stochastic approach, thereby predicting the tail labels more accurately. Moreover, the proposed method have excellent mechanisms for handling missing labels, dealing with large-scale datasets, as well as exploiting unlabeled data. With the best of our knowledge, our proposed method is the first multi-label classifier that simultaneously addresses all of the mentioned challenges. Experiments on real-world datasets show that our method outperforms stateof-the-art multi-label classifiers by a large margin, in terms of prediction performance, as well as training time. version:1
arxiv-1606-05718 | Deep Learning for Identifying Metastatic Breast Cancer | http://arxiv.org/abs/1606.05718 | id:1606.05718 author:Dayong Wang, Aditya Khosla, Rishab Gargeya, Humayun Irshad, Andrew H. Beck category:q-bio.QM cs.CV  published:2016-06-18 summary:The International Symposium on Biomedical Imaging (ISBI) held a grand challenge to evaluate computational systems for the automated detection of metastatic breast cancer in whole slide images of sentinel lymph node biopsies. Our team won both competitions in the grand challenge, obtaining an area under the receiver operating curve (AUC) of 0.925 for the task of whole slide image classification and a score of 0.7051 for the tumor localization task. A pathologist independently reviewed the same images, obtaining a whole slide image classification AUC of 0.966 and a tumor localization score of 0.733. Combining our deep learning system's predictions with the human pathologist's diagnoses increased the pathologist's AUC to 0.995, representing an approximately 85 percent reduction in human error rate. These results demonstrate the power of using deep learning to produce significant improvements in the accuracy of pathological diagnoses. version:1
arxiv-1606-05706 | Improving Agreement and Disagreement Identification in Online Discussions with A Socially-Tuned Sentiment Lexicon | http://arxiv.org/abs/1606.05706 | id:1606.05706 author:Lu Wang, Claire Cardie category:cs.CL  published:2016-06-17 summary:We study the problem of agreement and disagreement detection in online discussions. An isotonic Conditional Random Fields (isotonic CRF) based sequential model is proposed to make predictions on sentence- or segment-level. We automatically construct a socially-tuned lexicon that is bootstrapped from existing general-purpose sentiment lexicons to further improve the performance. We evaluate our agreement and disagreement tagging model on two disparate online discussion corpora -- Wikipedia Talk pages and online debates. Our model is shown to outperform the state-of-the-art approaches in both datasets. For example, the isotonic CRF model achieves F1 scores of 0.74 and 0.67 for agreement and disagreement detection, when a linear chain CRF obtains 0.58 and 0.56 for the discussions on Wikipedia Talk pages. version:1
arxiv-1606-05705 | Strategies for Searching Video Content with Text Queries or Video Examples | http://arxiv.org/abs/1606.05705 | id:1606.05705 author:Shoou-I Yu, Yi Yang, Zhongwen Xu, Shicheng Xu, Deyu Meng, Zexi Mao, Zhigang Ma, Ming Lin, Xuanchong Li, Huan Li, Zhenzhong Lan, Lu Jiang, Alexander G. Hauptmann, Chuang Gan, Xingzhong Du, Xiaojun Chang category:cs.IR cs.CV cs.MM  published:2016-06-17 summary:The large number of user-generated videos uploaded on to the Internet everyday has led to many commercial video search engines, which mainly rely on text metadata for search. However, metadata is often lacking for user-generated videos, thus these videos are unsearchable by current search engines. Therefore, content-based video retrieval (CBVR) tackles this metadata-scarcity problem by directly analyzing the visual and audio streams of each video. CBVR encompasses multiple research topics, including low-level feature design, feature fusion, semantic detector training and video search/reranking. We present novel strategies in these topics to enhance CBVR in both accuracy and speed under different query inputs, including pure textual queries and query by video examples. Our proposed strategies have been incorporated into our submission for the TRECVID 2014 Multimedia Event Detection evaluation, where our system outperformed other submissions in both text queries and video example queries, thus demonstrating the effectiveness of our proposed approaches. version:1
arxiv-1606-05704 | A Piece of My Mind: A Sentiment Analysis Approach for Online Dispute Detection | http://arxiv.org/abs/1606.05704 | id:1606.05704 author:Lu Wang, Claire Cardie category:cs.CL  published:2016-06-17 summary:We investigate the novel task of online dispute detection and propose a sentiment analysis solution to the problem: we aim to identify the sequence of sentence-level sentiments expressed during a discussion and to use them as features in a classifier that predicts the DISPUTE/NON-DISPUTE label for the discussion as a whole. We evaluate dispute detection approaches on a newly created corpus of Wikipedia Talk page disputes and find that classifiers that rely on our sentiment tagging features outperform those that do not. The best model achieves a very promising F1 score of 0.78 and an accuracy of 0.80. version:1
arxiv-1606-05703 | A Survey of Pansharpening Methods with A New Band-Decoupled Variational Model | http://arxiv.org/abs/1606.05703 | id:1606.05703 author:Joan Duran, Antoni Buades, Bartomeu Coll, Catalina Sbert, Gwendoline Blanchet category:cs.CV math.OC  published:2016-06-17 summary:Most satellites decouple the acquisition of a panchromatic image at high spatial resolution from the acquisition of a multispectral image at lower spatial resolution. Pansharpening is a fusion technique used to increase the spatial resolution of the multispectral data while simultaneously preserving its spectral information. In this paper, we consider pansharpening as an optimization problem minimizing a cost function with a nonlocal regularization term. The energy functional which is to be minimized decouples for each band, thus permitting the application to misregistered spectral components. This requirement is achieved by dropping the, commonly used, assumption that relates the spectral and panchromatic modalities by a linear transformation. Instead, a new constraint that preserves the radiometric ratio between the panchromatic and each spectral component is introduced. An exhaustive performance comparison of the proposed fusion method with several classical and state-of-the-art pansharpening techniques illustrates its superiority in preserving spatial details, reducing color distortions, and avoiding the creation of aliasing artifacts. version:1
arxiv-1606-05702 | Query-Focused Opinion Summarization for User-Generated Content | http://arxiv.org/abs/1606.05702 | id:1606.05702 author:Lu Wang, Hema Raghavan, Claire Cardie, Vittorio Castelli category:cs.CL  published:2016-06-17 summary:We present a submodular function-based framework for query-focused opinion summarization. Within our framework, relevance ordering produced by a statistical ranker, and information coverage with respect to topic distribution and diverse viewpoints are both encoded as submodular functions. Dispersion functions are utilized to minimize the redundancy. We are the first to evaluate different metrics of text similarity for submodularity-based summarization methods. By experimenting on community QA and blog summarization, we show that our system outperforms state-of-the-art approaches in both automatic evaluation and human evaluation. A human evaluation task is conducted on Amazon Mechanical Turk with scale, and shows that our systems are able to generate summaries of high overall quality and information diversity. version:1
arxiv-1606-05699 | Socially-Informed Timeline Generation for Complex Events | http://arxiv.org/abs/1606.05699 | id:1606.05699 author:Lu Wang, Claire Cardie, Galen Marchetti category:cs.CL  published:2016-06-17 summary:Existing timeline generation systems for complex events consider only information from traditional media, ignoring the rich social context provided by user-generated content that reveals representative public interests or insightful opinions. We instead aim to generate socially-informed timelines that contain both news article summaries and selected user comments. We present an optimization framework designed to balance topical cohesion between the article and comment summaries along with their informativeness and coverage of the event. Automatic evaluations on real-world datasets that cover four complex events show that our system produces more informative timelines than state-of-the-art systems. In human evaluation, the associated comment summaries are furthermore rated more insightful than editor's picks and comments ranked highly by users. version:1
arxiv-1606-05694 | DeepStance at SemEval-2016 Task 6: Detecting Stance in Tweets Using Character and Word-Level CNNs | http://arxiv.org/abs/1606.05694 | id:1606.05694 author:Prashanth Vijayaraghavan, Ivan Sysoev, Soroush Vosoughi, Deb Roy category:cs.CL cs.SI  published:2016-06-17 summary:This paper describes our approach for the Detecting Stance in Tweets task (SemEval-2016 Task 6). We utilized recent advances in short text categorization using deep learning to create word-level and character-level models. The choice between word-level and character-level models in each particular case was informed through validation performance. Our final system is a combination of classifiers using word-level or character-level models. We also employed novel data augmentation techniques to expand and diversify our training dataset, thus making our system more robust. Our system achieved a macro-average precision, recall and F1-scores of 0.67, 0.61 and 0.635 respectively. version:1
arxiv-1606-05693 | Structured Stochastic Linear Bandits | http://arxiv.org/abs/1606.05693 | id:1606.05693 author:Nicholas Johnson, Vidyashankar Sivakumar, Arindam Banerjee category:stat.ML cs.LG  published:2016-06-17 summary:The stochastic linear bandit problem proceeds in rounds where at each round the algorithm selects a vector from a decision set after which it receives a noisy linear loss parameterized by an unknown vector. The goal in such a problem is to minimize the (pseudo) regret which is the difference between the total expected loss of the algorithm and the total expected loss of the best fixed vector in hindsight. In this paper, we consider settings where the unknown parameter has structure, e.g., sparse, group sparse, low-rank, which can be captured by a norm, e.g., $L_1$, $L_{(1,2)}$, nuclear norm. We focus on constructing confidence ellipsoids which contain the unknown parameter across all rounds with high-probability. We show the radius of such ellipsoids depend on the Gaussian width of sets associated with the norm capturing the structure. Such characterization leads to tighter confidence ellipsoids and, therefore, sharper regret bounds compared to bounds in the existing literature which are based on the ambient dimensionality. version:1
arxiv-1606-05688 | ZNNi - Maximizing the Inference Throughput of 3D Convolutional Networks on Multi-Core CPUs and GPUs | http://arxiv.org/abs/1606.05688 | id:1606.05688 author:Aleksandar Zlateski, Kisuk Lee, H. Sebastian Seung category:cs.DC cs.LG  published:2016-06-17 summary:Sliding window convolutional networks (ConvNets) have become a popular approach to computer vision problems such as image segmentation, and object detection and localization. Here we consider the problem of inference, the application of a previously trained ConvNet, with emphasis on 3D images. Our goal is to maximize throughput, defined as average number of output voxels computed per unit time. Other things being equal, processing a larger image tends to increase throughput, because fractionally less computation is wasted on the borders of the image. It follows that an apparently slower algorithm may end up having higher throughput if it can process a larger image within the constraint of the available RAM. We introduce novel CPU and GPU primitives for convolutional and pooling layers, which are designed to minimize memory overhead. The primitives include convolution based on highly efficient pruned FFTs. Our theoretical analyses and empirical tests reveal a number of interesting findings. For some ConvNet architectures, cuDNN is outperformed by our FFT-based GPU primitives, and these in turn can be outperformed by our CPU primitives. The CPU manages to achieve higher throughput because of its fast access to more RAM. A novel primitive in which the GPU accesses host RAM can significantly increase GPU throughput. Finally, a CPU-GPU algorithm achieves the greatest throughput of all, 10x or more than other publicly available implementations of sliding window 3D ConvNets. All of our code has been made available as open source project. version:1
arxiv-1606-05681 | Generating Object Cluster Hierarchies for Benchmarking | http://arxiv.org/abs/1606.05681 | id:1606.05681 author:Michał Spytkowski, Łukasz P. Olech, Halina Kwasnicka category:cs.CV  published:2016-06-17 summary:The field of Machine Learning and the topic of clustering within it is still widely researched. Recently, researchers became interested in a new variant of hierarchical clustering, where hierarchical (partial order) relationships exist not only between clusters but also objects. In this variant of clustering, objects can be assigned not only to leave, but other properties are also defined. Although examples of this approach already exist in literature, the authors have encountered a problem with the analysis and comparison of obtained results. The problem is twofold. Firstly, there is a lack of evaluation methods. Secondly, there is a lack of available benchmark data, at least the authors failed to find them. The aim of this work is to fill the second gap. The main contribution of this paper is a new method of generating hierarchical structures of data. Additionally, the paper includes a theoretical analysis of the generation parameters and their influence on the results. Comprehensive experiments are presented and discussed. The dataset generator and visualiser tools developed are publicly available for use (http://kio.pwr.edu.pl/?page_id=396). version:1
arxiv-1606-05679 | Two Discourse Driven Language Models for Semantics | http://arxiv.org/abs/1606.05679 | id:1606.05679 author:Haoruo Peng, Dan Roth category:cs.CL  published:2016-06-17 summary:Natural language understanding often requires deep semantic knowledge. Expanding on previous proposals, we suggest that some important aspects of semantic knowledge can be modeled as a language model if done at an appropriate level of abstraction. We develop two distinct models that capture semantic frame chains and discourse information while abstracting over the specific mentions of predicates and entities. For each model, we investigate four implementations: a "standard" N-gram language model and three discriminatively trained "neural" language models that generate embeddings for semantic frames. The quality of the semantic language models (SemLM) is evaluated both intrinsically, using perplexity and a narrative cloze test and extrinsically - we show that our SemLM helps improve performance on semantic natural language processing tasks such as co-reference resolution and discourse parsing. version:1
arxiv-1606-05675 | DeepFood: Deep Learning-Based Food Image Recognition for Computer-Aided Dietary Assessment | http://arxiv.org/abs/1606.05675 | id:1606.05675 author:Chang Liu, Yu Cao, Yan Luo, Guanling Chen, Vinod Vokkarane, Yunsheng Ma category:cs.CV  published:2016-06-17 summary:Worldwide, in 2014, more than 1.9 billion adults, 18 years and older, were overweight. Of these, over 600 million were obese. Accurately documenting dietary caloric intake is crucial to manage weight loss, but also presents challenges because most of the current methods for dietary assessment must rely on memory to recall foods eaten. The ultimate goal of our research is to develop computer-aided technical solutions to enhance and improve the accuracy of current measurements of dietary intake. Our proposed system in this paper aims to improve the accuracy of dietary assessment by analyzing the food images captured by mobile devices (e.g., smartphone). The key technique innovation in this paper is the deep learning-based food image recognition algorithms. Substantial research has demonstrated that digital imaging accurately estimates dietary intake in many environments and it has many advantages over other methods. However, how to derive the food information (e.g., food type and portion size) from food image effectively and efficiently remains a challenging and open research problem. We propose a new Convolutional Neural Network (CNN)-based food image recognition algorithm to address this problem. We applied our proposed approach to two real-world food image data sets (UEC-256 and Food-101) and achieved impressive results. To the best of our knowledge, these results outperformed all other reported work using these two data sets. Our experiments have demonstrated that the proposed approach is a promising solution for addressing the food image recognition problem. Our future work includes further improving the performance of the algorithms and integrating our system into a real-world mobile and cloud computing-based system to enhance the accuracy of current measurements of dietary intake. version:1
arxiv-1606-05672 | Interpretability in Linear Brain Decoding | http://arxiv.org/abs/1606.05672 | id:1606.05672 author:Seyed Mostafa Kia, Andrea Passerini category:stat.ML  published:2016-06-17 summary:Improving the interpretability of brain decoding approaches is of primary interest in many neuroimaging studies. Despite extensive studies of this type, at present, there is no formal definition for interpretability of brain decoding models. As a consequence, there is no quantitative measure for evaluating the interpretability of different brain decoding methods. In this paper, we present a simple definition for interpretability of linear brain decoding models. Then, we propose to combine the interpretability and the performance of the brain decoding into a new multi-objective criterion for model selection. Our preliminary results on the toy data show that optimizing the hyper-parameters of the regularized linear classifier based on the proposed criterion results in more informative linear models. The presented definition provides the theoretical background for quantitative evaluation of interpretability in linear brain decoding. version:1
arxiv-1606-05647 | Decision Dynamics in Group Evacuation | http://arxiv.org/abs/1606.05647 | id:1606.05647 author:Fangqiu Han, Chantal Nguyen, Kimberly J. Schlesinger, Izzeddin Gür, Jean M. Carlson category:physics.soc-ph cs.NE cs.SI  published:2016-06-17 summary:Identifying factors that affect human decision making and quantifying their influence remain essential and challenging tasks for the design and implementation of social and technological communication systems. We report results of a behavioral experiment involving decision making in the face of an impending natural disaster. In a controlled laboratory setting, we characterize individual and group evacuation decision making influenced by several key factors, including the likelihood of the disaster, available shelter capacity, group size, and group decision protocol. Our results show that success in individual decision making is not a strong predictor of group performance. We use an artificial neural network trained on the collective behavior of subjects to predict individual and group outcomes. Overall model accuracy increases with the inclusion of a subject-specific performance parameter based on laboratory trials that captures individual differences. In parallel, we demonstrate that the social media activity of individual subjects, specifically their Facebook use, can be used to generate an alternative individual personality profile that leads to comparable model accuracy. Quantitative characterization and prediction of collective decision making is crucial for the development of effective policies to guide the action of populations in the face of threat or uncertainty. version:1
arxiv-1606-05642 | Balancing New Against Old Information: The Role of Surprise | http://arxiv.org/abs/1606.05642 | id:1606.05642 author:Mohammad Javad Faraji, Kerstin Preuschoff, Wulfram Gerstner category:stat.ML cs.LG q-bio.NC  published:2016-06-17 summary:Surprise is a ubiquitous concept describing a wide range of phenomena from unexpected events to behavioral responses. We propose a measure of surprise, to arrive at a new framework for surprise-driven learning. There are two components to this framework: (i) a confidence-adjusted surprise measure to capture environmental statistics as well as subjective beliefs, (ii) a surprise-minimization learning rule, or SMiLe-rule, which dynamically adjusts the balance between new and old information without making prior assumptions about the temporal statistics in the environment. We apply our framework to a dynamic decision making task and a maze exploration task to demonstrate that it is suitable for learning in complex environments, even if the environment undergoes gradual or sudden changes. Our proposed surprise-modulated belief update algorithm provides a framework to study the behavior of humans and animals encountering surprising events. version:1
arxiv-1606-05615 | Guaranteed Non-convex Optimization: Submodular Maximization over Continuous Domains | http://arxiv.org/abs/1606.05615 | id:1606.05615 author:Yatao Bian, Baharan Mirzasoleiman, Joachim M. Buhmann, Andreas Krause category:cs.LG cs.DS  published:2016-06-17 summary:\textit{Submodular continuous functions} are a category of (generally) non-convex/non-concave functions with a wide spectrum of applications. We characterize these functions and demonstrate that they can be maximized efficiently with approximation guarantees. Specifically, I) for monotone submodular continuous functions with an additional diminishing returns property, we propose a \texttt{Frank-Wolfe} style algorithm with $(1-1/e)$-approximation, and sub-linear convergence rate; II) for general non-monotone submodular continuous functions, we propose a \texttt{DoubleGreedy} algorithm with $1/3$-approximation. Submodular continuous functions naturally find applications in various real-world settings, including influence and revenue maximization with continuous assignments, sensor energy management, multi-resolution data summarization, facility location, etc. Experimental results show that the proposed algorithms efficiently generate superior solutions in terms of empirical objectives compared to baseline algorithms. version:1
arxiv-1606-05614 | High-resolution LIDAR-based Depth Mapping using Bilateral Filter | http://arxiv.org/abs/1606.05614 | id:1606.05614 author:C. Premebida, L. Garrote, A. Asvadi, A. Pedro Ribeiro, U. Nunes category:cs.CV  published:2016-06-17 summary:High resolution depth-maps, obtained by upsampling sparse range data from a 3D-LIDAR, find applications in many fields ranging from sensory perception to semantic segmentation and object detection. Upsampling is often based on combining data from a monocular camera to compensate the low-resolution of a LIDAR. This paper, on the other hand, introduces a novel framework to obtain dense depth-map solely from a single LIDAR point cloud; which is a research direction that has been barely explored. The formulation behind the proposed depth-mapping process relies on local spatial interpolation, using sliding-window (mask) technique, and on the Bilateral Filter (BF) where the variable of interest, the distance from the sensor, is considered in the interpolation problem. In particular, the BF is conveniently modified to perform depth-map upsampling such that the edges (foreground-background discontinuities) are better preserved by means of a proposed method which influences the range-based weighting term. Other methods for spatial upsampling are discussed, evaluated and compared in terms of different error measures. This paper also researches the role of the mask's size in the performance of the implemented methods. Quantitative and qualitative results from experiments on the KITTI Database, using LIDAR point clouds only, show very satisfactory performance of the approach introduced in this work. version:1
arxiv-1606-05596 | Ground Truth Bias in External Cluster Validity Indices | http://arxiv.org/abs/1606.05596 | id:1606.05596 author:Yang Lei, James C. Bezdek, Simone Romano, Nguyen Xuan Vinh, Jeffrey Chan, James Bailey category:stat.ML cs.LG  published:2016-06-17 summary:It has been noticed that some external CVIs exhibit a preferential bias towards a larger or smaller number of clusters which is monotonic (directly or inversely) in the number of clusters in candidate partitions. This type of bias is caused by the functional form of the CVI model. For example, the popular Rand index (RI) exhibits a monotone increasing (NCinc) bias, while the Jaccard Index (JI) index suffers from a monotone decreasing (NCdec) bias. This type of bias has been previously recognized in the literature. In this work, we identify a new type of bias arising from the distribution of the ground truth (reference) partition against which candidate partitions are compared. We call this new type of bias ground truth (GT) bias. This type of bias occurs if a change in the reference partition causes a change in the bias status (e.g., NCinc, NCdec) of a CVI. For example, NCinc bias in the RI can be changed to NCdec bias by skewing the distribution of clusters in the ground truth partition. It is important for users to be aware of this new type of biased behaviour, since it may affect the interpretations of CVI results. The objective of this article is to study the empirical and theoretical implications of GT bias. To the best of our knowledge, this is the first extensive study of such a property for external cluster validity indices. version:1
arxiv-1606-05589 | Human Attention in Visual Question Answering: Do Humans and Deep Networks Look at the Same Regions? | http://arxiv.org/abs/1606.05589 | id:1606.05589 author:Abhishek Das, Harsh Agrawal, C. Lawrence Zitnick, Devi Parikh, Dhruv Batra category:stat.ML cs.CV  published:2016-06-17 summary:We conduct large-scale studies on `human attention' in Visual Question Answering (VQA) to understand where humans choose to look to answer questions about images. We design and test multiple game-inspired novel attention-annotation interfaces that require the subject to sharpen regions of a blurred image to answer a question. Thus, we introduce the VQA-HAT (Human ATtention) dataset. We evaluate attention maps generated by state-of-the-art VQA models against human attention both qualitatively (via visualizations) and quantitatively (via rank-order correlation). Overall, our experiments show that current attention models in VQA do not seem to be looking at the same regions as humans. version:1
arxiv-1606-05579 | Early Visual Concept Learning with Unsupervised Deep Learning | http://arxiv.org/abs/1606.05579 | id:1606.05579 author:Irina Higgins, Loic Matthey, Xavier Glorot, Arka Pal, Benigno Uria, Charles Blundell, Shakir Mohamed, Alexander Lerchner category:stat.ML cs.LG q-bio.NC  published:2016-06-17 summary:Automated discovery of early visual concepts from raw image data is a major open challenge in AI research. Addressing this problem, we propose an unsupervised approach for learning disentangled representations of the underlying factors of variation. We draw inspiration from neuroscience, and show how this can be achieved in an unsupervised generative model by applying the same learning pressures as have been suggested to act in the ventral visual stream in the brain. By enforcing redundancy reduction, encouraging statistical independence, and exposure to data with transform continuities analogous to those to which human infants are exposed, we obtain a variational autoencoder (VAE) framework capable of learning disentangled factors. Our approach makes few assumptions and works well across a wide variety of datasets. Furthermore, our solution has useful emergent properties, such as zero-shot inference and an intuitive understanding of "objectness". version:1
arxiv-1606-05572 | Learning Interpretable Musical Compositional Rules and Traces | http://arxiv.org/abs/1606.05572 | id:1606.05572 author:Haizi Yu, Lav R. Varshney, Guy E. Garnett, Ranjitha Kumar category:stat.ML cs.LG  published:2016-06-17 summary:Throughout music history, theorists have identified and documented interpretable rules that capture the decisions of composers. This paper asks, "Can a machine behave like a music theorist?" It presents MUS-ROVER, a self-learning system for automatically discovering rules from symbolic music. MUS-ROVER performs feature learning via $n$-gram models to extract compositional rules --- statistical patterns over the resulting features. We evaluate MUS-ROVER on Bach's (SATB) chorales, demonstrating that it can recover known rules, as well as identify new, characteristic patterns for further study. We discuss how the extracted rules can be used in both machine and human composition. version:1
arxiv-1606-05554 | SMS Spam Filtering using Probabilistic Topic Modelling and Stacked Denoising Autoencoder | http://arxiv.org/abs/1606.05554 | id:1606.05554 author:Noura Al Moubayed, Toby Breckon, Peter Matthews, A. Stephen McGough category:cs.CL cs.LG cs.NE  published:2016-06-17 summary:In This paper we present a novel approach to spam filtering and demonstrate its applicability with respect to SMS messages. Our approach requires minimum features engineering and a small set of la- belled data samples. Features are extracted using topic modelling based on latent Dirichlet allocation, and then a comprehensive data model is created using a Stacked Denoising Autoencoder (SDA). Topic modelling summarises the data providing ease of use and high interpretability by visualising the topics using word clouds. Given that the SMS messages can be regarded as either spam (unwanted) or ham (wanted), the SDA is able to model the messages and accurately discriminate between the two classes without the need for a pre-labelled training set. The results are compared against the state-of-the-art spam detection algorithms with our proposed approach achieving over 97% accuracy which compares favourably to the best reported algorithms presented in the literature. version:1
arxiv-1606-05551 | Self-adaptation of Mutation Rates in Non-elitist Populations | http://arxiv.org/abs/1606.05551 | id:1606.05551 author:Duc-Cuong Dang, Per Kristian Lehre category:cs.NE q-bio.PE  published:2016-06-17 summary:The runtime of evolutionary algorithms (EAs) depends critically on their parameter settings, which are often problem-specific. Automated schemes for parameter tuning have been developed to alleviate the high costs of manual parameter tuning. Experimental results indicate that self-adaptation, where parameter settings are encoded in the genomes of individuals, can be effective in continuous optimisation. However, results in discrete optimisation have been less conclusive. Furthermore, a rigorous runtime analysis that explains how self-adaptation can lead to asymptotic speedups has been missing. This paper provides the first such analysis for discrete, population-based EAs. We apply level-based analysis to show how a self-adaptive EA is capable of fine-tuning its mutation rate, leading to exponential speedups over EAs using fixed mutation rates. version:1
arxiv-1606-05545 | Universal, Unsupervised, Uncovered Sentiment Analysis | http://arxiv.org/abs/1606.05545 | id:1606.05545 author:David Vilares, Carlos Gómez-Rodríguez, Miguel A. Alonso category:cs.CL  published:2016-06-17 summary:We present a novel unsupervised approach for multilingual sentiment analysis driven by compositional syntax-based rules. On the one hand, we exploit some of the main advantages of unsupervised algorithms: (1) the interpretability of their output, in contrast with most supervised models, which behave as a black box and (2) their robustness across different corpora and domains. On the other hand, by introducing the concept of compositional operations and exploiting syntactic information in the form of universal dependencies, we tackle one of their main drawbacks: their rigidity on data that are differently structured depending on the language. Experiments show an improvement both over existing unsupervised methods, and over state-of-the-art supervised models when evaluating outside their corpus of origin. The system is freely available. version:1
arxiv-1606-05535 | Tensor Ring Decomposition | http://arxiv.org/abs/1606.05535 | id:1606.05535 author:Qibin Zhao, Guoxu Zhou, Shengli Xie, Liqing Zhang, Andrzej Cichocki category:cs.NA cs.CV cs.DS  published:2016-06-17 summary:Tensor networks have in recent years emerged as the powerful tools for solving the large-scale optimization problems. One of the most popular tensor network is tensor train (TT) decomposition that acts as the building blocks for the complicated tensor networks. However, the TT decomposition highly depends on permutations of tensor dimensions, due to its strictly sequential multilinear products over latent cores, which leads to difficulties in finding the optimal TT representation. In this paper, we introduce a fundamental tensor decomposition model to represent a large dimensional tensor by a circular multilinear products over a sequence of low dimensional cores, which can be graphically interpreted as a cyclic interconnection of 3rd-order tensors, and thus termed as tensor ring (TR) decomposition. The key advantage of TR model is the circular dimensional permutation invariance which is gained by employing the trace operation and treating the latent cores equivalently. TR model can be viewed as a linear combination of TT decompositions, thus obtaining the powerful and generalized representation abilities. For optimization of latent cores, we present four different algorithms based on the sequential SVDs, ALS scheme, and block-wise ALS techniques. Furthermore, the mathematical properties of TR model are investigated, which shows that the basic multilinear algebra can be performed efficiently by using TR representaions and the classical tensor decompositions can be conveniently transformed into the TR representation. Finally, the experiments on both synthetic signals and real-world datasets were conducted to evaluate the performance of different algorithms. version:1
arxiv-1606-05506 | Learning Abstract Classes using Deep Learning | http://arxiv.org/abs/1606.05506 | id:1606.05506 author:Sebastian Stabinger, Antonio Rodriguez-Sanchez, Justus Piater category:cs.CV cs.AI  published:2016-06-17 summary:Humans are generally good at learning abstract concepts about objects and scenes (e.g.\ spatial orientation, relative sizes, etc.). Over the last years convolutional neural networks have achieved almost human performance in recognizing concrete classes (i.e.\ specific object categories). This paper tests the performance of a current CNN (GoogLeNet) on the task of differentiating between abstract classes which are trivially differentiable for humans. We trained and tested the CNN on the two abstract classes of horizontal and vertical orientation and determined how well the network is able to transfer the learned classes to other, previously unseen objects. version:1
arxiv-1606-05492 | PSF : Introduction to R Package for Pattern Sequence Based Forecasting Algorithm | http://arxiv.org/abs/1606.05492 | id:1606.05492 author:Neeraj Bokde, Kishore Kulat category:stat.ML  published:2016-06-17 summary:This paper discusses about PSF, an R package for Pattern Sequence based Forecasting (PSF) algorithm used for univariate time series future prediction. The PSF algorithm consists of two major parts: clustering and prediction techniques. Clustering part includes selection of cluster size and then labeling of time series data with reference to various clusters. Whereas, the prediction part include functions like optimum window size selection for specific patterns and prediction of future values with reference to past pattern sequences. The PSF package consists of various functions to implement PSF algorithm. It also contains a function, which automates all other functions to obtain optimum prediction results. The aim of this package is to promote PSF algorithm and to ease its implementation with minimum efforts. This paper describe all the functions in PSF package with their syntax and simple examples. Finally, the usefulness of this package is discussed by comparing it with auto.arima, a well known time series forecasting function available on CRAN repository. version:1
arxiv-1606-05491 | Sequence-to-Sequence Generation for Spoken Dialogue via Deep Syntax Trees and Strings | http://arxiv.org/abs/1606.05491 | id:1606.05491 author:Ondřej Dušek, Filip Jurčíček category:cs.CL I.2.7  published:2016-06-17 summary:We present a natural language generator based on the sequence-to-sequence approach that can be trained to produce natural language strings as well as deep syntax dependency trees from input dialogue acts, and we use it to directly compare two-step generation with separate sentence planning and surface realization stages to a joint, one-step approach. We were able to train both setups successfully using very little training data. The joint setup offers better performance, surpassing state-of-the-art with regards to n-gram-based scores while providing more relevant outputs. version:1
arxiv-1606-05487 | YodaNN: An Ultra-Low Power Convolutional Neural Network Accelerator Based on Binary Weights | http://arxiv.org/abs/1606.05487 | id:1606.05487 author:Renzo Andri, Lukas Cavigelli, Davide Rossi, Luca Benini category:cs.AR cs.CV cs.NE  published:2016-06-17 summary:Convolutional Neural Networks (CNNs) have revolutionized the world of image classification over the last few years, pushing the computer vision close beyond human accuracy. The required computational effort of CNNs today requires power-hungry parallel processors and GP-GPUs. Recent efforts in designing CNN Application-Specific Integrated Circuits (ASICs) and accelerators for System-On-Chip (SoC) integration have achieved very promising results. Unfortunately, even these highly optimized engines are still above the power envelope imposed by mobile and deeply embedded applications and face hard limitations caused by CNN weight I/O and storage. On the algorithmic side, highly competitive classification accuracy can be achieved by properly training CNNs with binary weights. This novel algorithm approach brings major optimization opportunities in the arithmetic core by removing the need for the expensive multiplications as well as in the weight storage and I/O costs. In this work, we present a HW accelerator optimized for BinaryConnect CNNs that achieves 1510 GOp/s on a core area of only 1.33 MGE and with a power dissipation of 153 mW in UMC 65 nm technology at 1.2 V. Our accelerator outperforms state-of-the-art performance in terms of ASIC energy efficiency as well as area efficiency with 61.2 TOp/s/W and 1135 GOp/s/MGE, respectively. version:1
arxiv-1606-05467 | Gender Inference using Statistical Name Characteristics in Twitter | http://arxiv.org/abs/1606.05467 | id:1606.05467 author:Juergen Mueller, Gerd Stumme category:cs.CL cs.SI  published:2016-06-17 summary:Much attention has been given to the task of gender inference of Twitter users. Although names are strong gender indicators, the names of Twitter users are rarely used as a feature; probably due to the high number of ill-formed names, which cannot be found in any name dictionary. Instead of relying solely on a name database, we propose a novel name classifier. Our approach extracts characteristics from the user names and uses those in order to assign the names to a gender. This enables us to classify international first names as well as ill-formed names. version:1
arxiv-1606-05464 | Stance Detection with Bidirectional Conditional Encoding | http://arxiv.org/abs/1606.05464 | id:1606.05464 author:Isabelle Augenstein, Tim Rocktäschel, Andreas Vlachos, Kalina Bontcheva category:cs.CL cs.LG cs.NE  published:2016-06-17 summary:Stance detection is the task of classifying the attitude expressed in a text towards a target such as "Climate Change is a Real Concern" to be "positive", "negative" or "neutral". Previous work has assumed that either the target is mentioned in the text or that training data for every target is given. This paper considers the more challenging version of this task, where targets are not always mentioned and no training data is available for the test targets. We experiment with conditional LSTM encoding, which builds a representation of the tweet that is dependent on the target, and demonstrate that it outperforms the independent encoding of tweet and target. Performance improves even further when the conditional model is augmented with bidirectional encoding. The method is evaluated on the SemEval 2016 Task 6 Twitter Stance Detection corpus and achieves performance second best only to a system trained on semi-automatically labelled tweets for the test target. When such weak supervision is added, our approach achieves state-of-the-art results. version:1
arxiv-1606-05433 | FVQA: Fact-based Visual Question Answering | http://arxiv.org/abs/1606.05433 | id:1606.05433 author:Peng Wang, Qi Wu, Chunhua Shen, Anton van den Hengel, Anthony Dick category:cs.CV  published:2016-06-17 summary:Visual Question Answering (VQA) has attracted a lot of attention in both Computer Vision and Natural Language Processing communities, not least because it off?ers insight into the relationships between two important sources of information. Current datasets, and the models built upon them, have focused on questions which are answerable by direct analysis of the question and image alone. The set of such questions that require no external information to answer is interesting, but very limited. It excludes questions which require common sense, or basic factual knowledge to answer, for example. Here we introduce FVQA, a VQA dataset which requires, and supports, much deeper reasoning. FVQA only contains questions which require external information to answer. We thus extend a conventional visual question answering dataset, which contains image-question-answerg triplets, through additional image-question-answer-supporting fact tuples. The supporting fact is represented as a structural triplet, such as <Cat,CapableOf,ClimbingTrees>. We evaluate several baseline models on the FVQA dataset, and describe a novel model which is capable of reasoning about an image on the basis of supporting facts. version:1
arxiv-1606-05427 | Proceedings First International Workshop on Hammers for Type Theories | http://arxiv.org/abs/1606.05427 | id:1606.05427 author:Jasmin Christian Blanchette, Cezary Kaliszyk category:cs.LO cs.AI cs.LG  published:2016-06-17 summary:This volume of EPTCS contains the proceedings of the First Workshop on Hammers for Type Theories (HaTT 2016), held on 1 July 2016 as part of the International Joint Conference on Automated Reasoning (IJCAR 2016) in Coimbra, Portugal. The proceedings contain four regular papers, as well as abstracts of the two invited talks by Pierre Corbineau (Verimag, France) and Aleksy Schubert (University of Warsaw, Poland). version:1
arxiv-1606-05426 | DecomposeMe: Simplifying ConvNets for End-to-End Learning | http://arxiv.org/abs/1606.05426 | id:1606.05426 author:Jose Alvarez, Lars Petersson category:cs.CV  published:2016-06-17 summary:Deep learning and convolutional neural networks (ConvNets) have been successfully applied to most relevant tasks in the computer vision community. However, these networks are computationally demanding and not suitable for embedded devices where memory and time consumption are relevant. In this paper, we propose DecomposeMe, a simple but effective technique to learn features using 1D convolutions. The proposed architecture enables both simplicity and filter sharing leading to increased learning capacity. A comprehensive set of large-scale experiments on ImageNet and Places2 demonstrates the ability of our method to improve performance while significantly reducing the number of parameters required. Notably, on Places2, we obtain an improvement in relative top-1 classification accuracy of 7.7\% with an architecture that requires 92% fewer parameters compared to VGG-B. The proposed network is also demonstrated to generalize to other tasks by converting existing networks. version:1
arxiv-1606-05413 | CMS-RCNN: Contextual Multi-Scale Region-based CNN for Unconstrained Face Detection | http://arxiv.org/abs/1606.05413 | id:1606.05413 author:Chenchen Zhu, Yutong Zheng, Khoa Luu, Marios Savvides category:cs.CV  published:2016-06-17 summary:Robust face detection in the wild is one of the ultimate components to support various facial related problems, i.e. unconstrained face recognition, facial periocular recognition, facial landmarking and pose estimation, facial expression recognition, 3D facial model construction, etc. Although the face detection problem has been intensely studied for decades with various commercial applications, it still meets problems in some real-world scenarios due to numerous challenges, e.g. heavy facial occlusions, extremely low resolutions, strong illumination, exceptionally pose variations, image or video compression artifacts, etc. In this paper, we present a face detection approach named Contextual Multi-Scale Region-based Convolution Neural Network (CMS-RCNN) to robustly solve the problems mentioned above. Similar to the region-based CNNs, our proposed network consists of the region proposal component and the region-of-interest (RoI) detection component. However, far apart of that network, there are two main contributions in our proposed network that play a significant role to achieve the state-of-the-art performance in face detection. Firstly, the multi-scale information is grouped both in region proposal and RoI detection to deal with tiny face regions. Secondly, our proposed network allows explicit body contextual reasoning in the network inspired from the intuition of human vision system. The proposed approach is benchmarked on two recent challenging face detection databases, i.e. the WIDER FACE Dataset which contains high degree of variability, as well as the Face Detection Dataset and Benchmark (FDDB). The experimental results show that our proposed approach trained on WIDER FACE Dataset outperforms strong baselines on WIDER FACE Dataset by a large margin, and consistently achieves competitive results on FDDB against the recent state-of-the-art face detection methods. version:1
arxiv-1606-05400 | Complex systems: features, similarity and connectivity | http://arxiv.org/abs/1606.05400 | id:1606.05400 author:Cesar H. Comin, Thomas K. DM. Peron, Filipi N. Silva, Diego R. Amancio, Francisco A. Rodrigues, Luciano da F. Costa category:physics.soc-ph physics.data-an stat.ML  published:2016-06-17 summary:The increasing interest in complex networks research has been a consequence of several intrinsic features of this area, such as the generality of the approach to represent and model virtually any discrete system, and the incorporation of concepts and methods deriving from many areas, from statistical physics to sociology, which are often used in an independent way. Yet, for this same reason, it would be desirable to integrate these various aspects into a more coherent and organic framework, which would imply in several benefits normally allowed by the systematization in science, including the identification of new types of problems and the cross-fertilization between fields. More specifically, the identification of the main areas to which the concepts frequently used in complex networks can be applied paves the way to adopting and applying a larger set of concepts and methods deriving from those respective areas. Among the several areas that have been used in complex networks research, pattern recognition, optimization, linear algebra, and time series analysis seem to play a more basic and recurrent role. In the present manuscript, we propose a systematic way to integrate the concepts from these diverse areas regarding complex networks research. In order to do so, we start by grouping the multidisciplinary concepts into three main groups, namely features, similarity, and network connectivity. Then we show that several of the analysis and modeling approaches to complex networks can be thought as a composition of maps between these three groups, with emphasis on nine main types of mappings, which are presented and illustrated. Such a systematization of principles and approaches also provides an opportunity to review some of the most closely related works in the literature, which is also developed in this article. version:1
arxiv-1606-05390 | Making Tree Ensembles Interpretable | http://arxiv.org/abs/1606.05390 | id:1606.05390 author:Satoshi Hara, Kohei Hayashi category:stat.ML  published:2016-06-17 summary:Tree ensembles, such as random forest and boosted trees, are renowned for their high prediction performance, whereas their interpretability is critically limited. In this paper, we propose a post processing method that improves the model interpretability of tree ensembles. After learning a complex tree ensembles in a standard way, we approximate it by a simpler model that is interpretable for human. To obtain the simpler model, we derive the EM algorithm minimizing the KL divergence from the complex ensemble. A synthetic experiment showed that a complicated tree ensemble was approximated reasonably as interpretable. version:1
arxiv-1606-05386 | Model-Agnostic Interpretability of Machine Learning | http://arxiv.org/abs/1606.05386 | id:1606.05386 author:Marco Tulio Ribeiro, Sameer Singh, Carlos Guestrin category:stat.ML cs.LG  published:2016-06-16 summary:Understanding why machine learning models behave the way they do empowers both system designers and end-users in many ways: in model selection, feature engineering, in order to trust and act upon the predictions, and in more intuitive user interfaces. Thus, interpretability has become a vital concern in machine learning, and work in the area of interpretable models has found renewed interest. In some applications, such models are as accurate as non-interpretable ones, and thus are preferred for their transparency. Even when they are not accurate, they may still be preferred when interpretability is of paramount importance. However, restricting machine learning to interpretable models is often a severe limitation. In this paper we argue for explaining machine learning predictions using model-agnostic approaches. By treating the machine learning models as black-box functions, these approaches provide crucial flexibility in the choice of models, explanations, and representations, improving debugging, comparison, and interfaces for a variety of users and models. We also outline the main challenges for such methods, and review a recently-introduced model-agnostic explanation approach (LIME) that addresses these challenges. version:1
arxiv-1606-05382 | Sampling Method for Fast Training of Support Vector Data Description | http://arxiv.org/abs/1606.05382 | id:1606.05382 author:Arin Chaudhuri, Deovrat Kakde, Wei Xiao, Maria Jahja, Wei Xiao, Hansi Jiang, Seunghyun Kong, Sergiy Peredriy category:cs.LG  published:2016-06-16 summary:Support Vector Data Description (SVDD) is a machine learning technique used for single class classification and outlier detection. The SVDD model for normal data description builds a minimum radius hypersphere around the training data. A flexible description can be obtained by use of Kernel functions. The data description is defined by the support vectors obtained by solving quadratic optimization problem which minimizes the volume enclosed by the hypersphere. The time required to solve the quadratic programming problem is directly related to the number of observations in the training data set. This leads to very high computing time for large training datasets. In this paper we propose a new iterative sampling-based method for SVDD training. The method incrementally learns the training data set description at each iteration by computing SVDD on an independent random sample selected with replacement from the training data set. The experimental results indicate that the proposed method is extremely fast and provides near-identical data description as compared to training using the entire data set in one iteration. Proposed method can be easily implemented as a wrapper code around the core module for SVDD training computations either in a single machine or a multi-machine distributed environment. version:1
arxiv-1606-05381 | Deep Image Set Hashing | http://arxiv.org/abs/1606.05381 | id:1606.05381 author:Jie Feng, Svebor Karaman, Shih-Fu Chang category:cs.CV  published:2016-06-16 summary:In applications involving matching of image sets, the information from multiple images must be effectively exploited to represent each set. State-of-the-art methods use probabilistic distribution or subspace to model a set and use specific distance measure to compare two sets. These methods are slow to compute and not compact to use in a large scale scenario. Learning-based hashing is often used in large scale image retrieval as they provide a compact representation of each sample and the Hamming distance can be used to efficiently compare two samples. However, most hashing methods encode each image separately and discard knowledge that multiple images in the same set represent the same object or person. We investigate the set hashing problem by combining both set representation and hashing in a single deep neural network. An image set is first passed to a CNN module to extract image features, then these features are aggregated using two types of set feature to capture both set specific and database-wide distribution information. The computed set feature is then fed into a multilayer perceptron to learn a compact binary embedding. Triplet loss is used to train the network by forming set similarity relations using class labels. We extensively evaluate our approach on datasets used for image matching and show highly competitive performance compared to state-of-the-art methods. version:1
arxiv-1606-05378 | Simpler Context-Dependent Logical Forms via Model Projections | http://arxiv.org/abs/1606.05378 | id:1606.05378 author:Reginald Long, Panupong Pasupat, Percy Liang category:cs.CL I.2.6; I.2.7  published:2016-06-16 summary:We consider the task of learning a context-dependent mapping from utterances to denotations. With only denotations at training time, we must search over a combinatorially large space of logical forms, which is even larger with context-dependent utterances. To cope with this challenge, we perform successive projections of the full model onto simpler models that operate over equivalence classes of logical forms. Though less expressive, we find that these simpler models are much faster and can be surprisingly effective. Moreover, they can be used to bootstrap the full model. Finally, we collected three new context-dependent semantic parsing datasets, and develop a new left-to-right parser. version:1
arxiv-1606-05374 | Avoiding Imposters and Delinquents: Adversarial Crowdsourcing and Peer Prediction | http://arxiv.org/abs/1606.05374 | id:1606.05374 author:Jacob Steinhardt, Gregory Valiant, Moses Charikar category:cs.HC cs.CR cs.DS cs.GT cs.LG  published:2016-06-16 summary:We consider a crowdsourcing model in which $n$ workers are asked to rate the quality of $n$ items previously generated by other workers. An unknown set of $\alpha n$ workers generate reliable ratings, while the remaining workers may behave arbitrarily and possibly adversarially. The manager of the experiment can also manually evaluate the quality of a small number of items, and wishes to curate together almost all of the high-quality items with at most an $\epsilon$ fraction of low-quality items. Perhaps surprisingly, we show that this is possible with an amount of work required of the manager, and each worker, that does not scale with $n$: the dataset can be curated with $\tilde{O}\Big(\frac{1}{\beta\alpha^3\epsilon^4}\Big)$ ratings per worker, and $\tilde{O}\Big(\frac{1}{\beta\epsilon^2}\Big)$ ratings by the manager, where $\beta$ is the fraction of high-quality items. Our results extend to the more general setting of peer prediction, including peer grading in online classrooms. version:1
arxiv-1606-05363 | Predicting Ambulance Demand: Challenges and Methods | http://arxiv.org/abs/1606.05363 | id:1606.05363 author:Zhengyi Zhou category:stat.ML stat.AP  published:2016-06-16 summary:Predicting ambulance demand accurately at a fine resolution in time and space (e.g., every hour and 1 km$^2$) is critical for staff / fleet management and dynamic deployment. There are several challenges: though the dataset is typically large-scale, demand per time period and locality is almost always zero. The demand arises from complex urban geography and exhibits complex spatio-temporal patterns, both of which need to captured and exploited. To address these challenges, we propose three methods based on Gaussian mixture models, kernel density estimation, and kernel warping. These methods provide spatio-temporal predictions for Toronto and Melbourne that are significantly more accurate than the current industry practice. version:1
arxiv-1606-05355 | Covariance of Motion and Appearance Featuresfor Spatio Temporal Recognition Tasks | http://arxiv.org/abs/1606.05355 | id:1606.05355 author:Subhabrata Bhattacharya, Nasim Souly, Mubarak Shah category:cs.CV  published:2016-06-16 summary:In this paper, we introduce an end-to-end framework for video analysis focused towards practical scenarios built on theoretical foundations from sparse representation, including a novel descriptor for general purpose video analysis. In our approach, we compute kinematic features from optical flow and first and second-order derivatives of intensities to represent motion and appearance respectively. These features are then used to construct covariance matrices which capture joint statistics of both low-level motion and appearance features extracted from a video. Using an over-complete dictionary of the covariance based descriptors built from labeled training samples, we formulate low-level event recognition as a sparse linear approximation problem. Within this, we pose the sparse decomposition of a covariance matrix, which also conforms to the space of semi-positive definite matrices, as a determinant maximization problem. Also since covariance matrices lie on non-linear Riemannian manifolds, we compare our former approach with a sparse linear approximation alternative that is suitable for equivalent vector spaces of covariance matrices. This is done by searching for the best projection of the query data on a dictionary using an Orthogonal Matching pursuit algorithm. We show the applicability of our video descriptor in two different application domains - namely low-level event recognition in unconstrained scenarios and gesture recognition using one shot learning. Our experiments provide promising insights in large scale video analysis. version:1
arxiv-1606-05560 | Estimation of matrix trace using machine learning | http://arxiv.org/abs/1606.05560 | id:1606.05560 author:Boram Yoon category:stat.ML math.NA  published:2016-06-16 summary:We present a new trace estimator of the matrix whose explicit form is not given but its matrix multiplication to a vector is available. The form of the estimator is similar to the Hutchison stochastic trace estimator, but instead of the random noise vectors in Hutchison estimator, we use small number of probing vectors determined by machine learning. Evaluation of the quality of estimates and bias correction are discussed. An unbiased estimator is proposed for the calculation of the expectation value of a function of traces. In the numerical experiments with random matrices, it is shown that the precision of trace estimates with $\mathcal{O}(10)$ probing vectors determined by the machine learning is similar to that with $\mathcal{O}(10000)$ random noise vectors. version:1
arxiv-1606-06177 | Understanding Innovation to Drive Sustainable Development | http://arxiv.org/abs/1606.06177 | id:1606.06177 author:Prasanna Sattigeri, Aurélie Lozano, Aleksandra Mojsilović, Kush R. Varshney, Mahmoud Naghshineh category:cs.CY stat.ML  published:2016-06-15 summary:Innovation is among the key factors driving a country's economic and social growth. But what are the factors that make a country innovative? How do they differ across different parts of the world and different stages of development? In this work done in collaboration with the World Economic Forum (WEF), we analyze the scores obtained through executive opinion surveys that constitute the WEF's Global Competitiveness Index in conjunction with other country-level metrics and indicators to identify actionable levers of innovation. The findings can help country leaders and organizations shape the policies to drive developmental activities and increase the capacity of innovation. version:1
